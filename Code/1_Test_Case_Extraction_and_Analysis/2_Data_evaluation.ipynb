{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33387a59",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "\n",
    "The purpose of this notebook is to streamline the process of manually evaluating the extracted test case data from notebook 1.\n",
    "\n",
    "For this we will sample test cases from the data (using a fixed seed for reproducibility) and have information about the test cases be displayed for manual evaluation, including the relevant lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f61f7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aee37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa1661",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set library root folder:\n",
    "\n",
    "# For TensorFlow\n",
    "library_root_tensorflow = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/Tensorflow/tensorflow-master/tensorflow/python/\" \n",
    "tests_root_tensorflow = \"kernel_tests\"\n",
    "save_data_to_tensorflow = \"extracted_data/tensorflow_evaluation_data.csv\"\n",
    "\n",
    "# For Pytorch\n",
    "library_root_pytorch = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/PyTorch/pytorch-master/\" \n",
    "tests_root_pytorch = \"test\"\n",
    "save_data_to_pytorch = \"extracted_data/pytorch_evaluation_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd6fc6",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4eca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>69</td>\n",
       "      <td>testAddN</td>\n",
       "      <td>59</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>sess.run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>np.random.rand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>astype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>226</td>\n",
       "      <td>testEmptyInput1D</td>\n",
       "      <td>219</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>astype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>226</td>\n",
       "      <td>testEmptyInput1D</td>\n",
       "      <td>219</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>1666</td>\n",
       "      <td>testAxis</td>\n",
       "      <td>1637</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>1647</td>\n",
       "      <td>self._scale_per_slice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            File_Path  Line_Number  Found_in_Function  \\\n",
       "0  kernel_tests\\aggregate_ops_test.py           69           testAddN   \n",
       "1  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "2  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "3      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "4      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "5      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "6      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "7      kernel_tests\\array_ops_test.py          226   testEmptyInput1D   \n",
       "8      kernel_tests\\array_ops_test.py          226   testEmptyInput1D   \n",
       "9      kernel_tests\\array_ops_test.py         1666           testAxis   \n",
       "\n",
       "   Function_Definition_Line_Number Assert_Statement_Type  \\\n",
       "0                               59        assertAllClose   \n",
       "1                               72        assertAllClose   \n",
       "2                               72        assertAllClose   \n",
       "3                              150        assertAllClose   \n",
       "4                              150        assertAllClose   \n",
       "5                              210        assertAllClose   \n",
       "6                              210        assertAllClose   \n",
       "7                              219        assertAllClose   \n",
       "8                              219        assertAllClose   \n",
       "9                             1637        assertAllClose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 66   \n",
       "1                          1                                 80   \n",
       "2                          2                                 79   \n",
       "3                          1                                154   \n",
       "4                          2                                164   \n",
       "5                          1                                212   \n",
       "6                          2                                214   \n",
       "7                          1                                221   \n",
       "8                          2                                223   \n",
       "9                          2                               1647   \n",
       "\n",
       "  Differential_Test_Function  \n",
       "0                     np.sum  \n",
       "1                     np.sum  \n",
       "2                   sess.run  \n",
       "3             np.random.rand  \n",
       "4     array_ops.boolean_mask  \n",
       "5                     astype  \n",
       "6     array_ops.boolean_mask  \n",
       "7                     astype  \n",
       "8     array_ops.boolean_mask  \n",
       "9      self._scale_per_slice  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow data and preview\n",
    "df_tensorflow = pd.read_csv('extracted_data/tensorflow_data.csv')\n",
    "df_tensorflow.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fa9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>dense_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>sparse_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>dense_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>sparse_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>2</td>\n",
       "      <td>2784</td>\n",
       "      <td>input2.var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>2</td>\n",
       "      <td>2785</td>\n",
       "      <td>input2.mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File_Path  Line_Number  \\\n",
       "0  test\\test_ao_sparse.py           98   \n",
       "1  test\\test_ao_sparse.py           98   \n",
       "2  test\\test_ao_sparse.py          103   \n",
       "3  test\\test_ao_sparse.py          103   \n",
       "4   test\\test_autograd.py         1329   \n",
       "5   test\\test_autograd.py         1329   \n",
       "6   test\\test_autograd.py         1340   \n",
       "7   test\\test_autograd.py         1340   \n",
       "8   test\\test_autograd.py         2790   \n",
       "9   test\\test_autograd.py         2790   \n",
       "\n",
       "                            Found_in_Function  \\\n",
       "0                         test_sparse_qlinear   \n",
       "1                         test_sparse_qlinear   \n",
       "2                         test_sparse_qlinear   \n",
       "3                         test_sparse_qlinear   \n",
       "4  test_set_grad_coroutines_benign_exceptions   \n",
       "5  test_set_grad_coroutines_benign_exceptions   \n",
       "6  test_set_grad_coroutines_benign_exceptions   \n",
       "7  test_set_grad_coroutines_benign_exceptions   \n",
       "8                test_var_mean_differentiable   \n",
       "9                test_var_mean_differentiable   \n",
       "\n",
       "   Function_Definition_Line_Number      Assert_Statement_Type  \\\n",
       "0                               32  assert_array_almost_equal   \n",
       "1                               32  assert_array_almost_equal   \n",
       "2                               32  assert_array_almost_equal   \n",
       "3                               32  assert_array_almost_equal   \n",
       "4                             1295                 assertLess   \n",
       "5                             1295                 assertLess   \n",
       "6                             1295                 assertLess   \n",
       "7                             1295                 assertLess   \n",
       "8                             2778                   allclose   \n",
       "9                             2778                   allclose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 96   \n",
       "1                          2                                 95   \n",
       "2                          1                                101   \n",
       "3                          2                                100   \n",
       "4                          1                               1328   \n",
       "5                          1                               1339   \n",
       "6                          1                               1328   \n",
       "7                          1                               1339   \n",
       "8                          2                               2784   \n",
       "9                          2                               2785   \n",
       "\n",
       "  Differential_Test_Function  \n",
       "0      dense_qlinear_dynamic  \n",
       "1     sparse_qlinear_dynamic  \n",
       "2              dense_qlinear  \n",
       "3             sparse_qlinear  \n",
       "4                 coro.throw  \n",
       "5                 coro.throw  \n",
       "6                 coro.throw  \n",
       "7                 coro.throw  \n",
       "8                 input2.var  \n",
       "9                input2.mean  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pytorch data and preview\n",
    "df_pytorch = pd.read_csv('extracted_data/pytorch_data.csv')\n",
    "df_pytorch.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed7e37",
   "metadata": {},
   "source": [
    "## Analyze coverage\n",
    "\n",
    "To track the progress of our test case extraction we display statistics about how many cases still are still unsupported. This is either denoted by an \"UNSUPPORTED ...\" statement in the \"Differential Test Function\" column of the data or by an empty string in this column, i.e. `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f66b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\t6 cases not covered.\n",
      "UNSUPPORTED Unary Operation    4\n",
      "NaN                            2\n",
      "Name: Differential_Test_Function, dtype: int64\n",
      "\n",
      "PyTorch:\t3 cases not covered.\n",
      "UNSUPPORTED Unary Operation    2\n",
      "NaN                            1\n",
      "Name: Differential_Test_Function, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "not_covered_tensorflow = df_tensorflow[df_tensorflow['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_tensorflow['Differential_Test_Function'].isna()]\n",
    "print(\"TensorFlow:\\t\"+ str(len(not_covered_tensorflow)) + \" cases not covered.\")\n",
    "print(not_covered_tensorflow.Differential_Test_Function.value_counts(dropna=False))\n",
    "\n",
    "not_covered_pytorch = df_pytorch[df_pytorch['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_pytorch['Differential_Test_Function'].isna()]\n",
    "print(\"\\nPyTorch:\\t\"+ str(len(not_covered_pytorch)) + \" cases not covered.\")\n",
    "print(not_covered_pytorch.Differential_Test_Function.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc70dade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>kernel_tests\\lookup_ops_test.py</td>\n",
       "      <td>3533</td>\n",
       "      <td>testMutableHashTableStringFloat</td>\n",
       "      <td>3518</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "      <td>UNSUPPORTED Unary Operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>kernel_tests\\lookup_ops_test.py</td>\n",
       "      <td>3550</td>\n",
       "      <td>testMutableHashTableIntFloat</td>\n",
       "      <td>3535</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>3536</td>\n",
       "      <td>UNSUPPORTED Unary Operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>kernel_tests\\tensor_array_ops_test.py</td>\n",
       "      <td>1056</td>\n",
       "      <td>_testWhileLoopWritePackGradients</td>\n",
       "      <td>972</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>UNSUPPORTED Unary Operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>kernel_tests\\tensor_array_ops_test.py</td>\n",
       "      <td>1057</td>\n",
       "      <td>_testWhileLoopWritePackGradients</td>\n",
       "      <td>972</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>UNSUPPORTED Unary Operation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File_Path  Line_Number  \\\n",
       "522        kernel_tests\\lookup_ops_test.py         3533   \n",
       "523        kernel_tests\\lookup_ops_test.py         3550   \n",
       "914  kernel_tests\\tensor_array_ops_test.py         1056   \n",
       "915  kernel_tests\\tensor_array_ops_test.py         1057   \n",
       "\n",
       "                    Found_in_Function  Function_Definition_Line_Number  \\\n",
       "522   testMutableHashTableStringFloat                             3518   \n",
       "523      testMutableHashTableIntFloat                             3535   \n",
       "914  _testWhileLoopWritePackGradients                              972   \n",
       "915  _testWhileLoopWritePackGradients                              972   \n",
       "\n",
       "    Assert_Statement_Type  Oracle_Argument_ Position  \\\n",
       "522        assertAllClose                          1   \n",
       "523        assertAllClose                          1   \n",
       "914        assertAllClose                          1   \n",
       "915        assertAllClose                          1   \n",
       "\n",
       "     Differential_Function_Line_Number   Differential_Test_Function  \n",
       "522                               3519  UNSUPPORTED Unary Operation  \n",
       "523                               3536  UNSUPPORTED Unary Operation  \n",
       "914                               1013  UNSUPPORTED Unary Operation  \n",
       "915                               1013  UNSUPPORTED Unary Operation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_covered_tensorflow[not_covered_tensorflow['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False)]\n",
    "\n",
    "#not_covered_pytorch[not_covered_pytorch['Differential_Test_Function'].isna()]\n",
    "#not_covered_tensorflow[not_covered_tensorflow['Differential_Test_Function'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a190e82",
   "metadata": {},
   "source": [
    "# Tool for manual evaluation\n",
    "\n",
    "This tool is meant to help with quickly evaluating test cases from the dataset. For each test case, it prints all information collected about the case, including the oracle argument position and the extracted function name, as well as the code inside the function where the test case was defined. Then the evaluator is asked for an evaluation of the test case via input. This evaluation is then stored alongside the test case in the data.\n",
    "\n",
    "Evaluation keys:  \n",
    "y: Test case correctly identified  \n",
    "n: Test case is not differential testing  \n",
    "?: Allows for the entry of a comment. This is meant for situations where the current case is differential testing, but the differential testing function was not extracted correctly (or some other data is incorrect).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc39e0de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data opened.\n",
      "Evaluation data opened.\n",
      "File_Path                            kernel_tests\\cwise_ops_unary_test.py\n",
      "Line_Number                                                            92\n",
      "Found_in_Function                                             _compareCpu\n",
      "Function_Definition_Line_Number                                        78\n",
      "Assert_Statement_Type                                      assertAllClose\n",
      "Oracle_Argument_ Position                                               1\n",
      "Differential_Function_Line_Number                                      83\n",
      "Differential_Test_Function                                        np_func\n",
      "Name: 218, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: The variables is assigned a parameter that gets passed through the function. This is because it is a private function that is called multiple times from a public one. So we would actually like to know the values that get passed through np_func. \n",
      "Re-evaluate? (y / n) n\n"
     ]
    }
   ],
   "source": [
    "class EvaluationAutomator:\n",
    "    def __init__(self, df, library_root, save_data_to):\n",
    "        \"\"\"Initialize the evaluation automator.\n",
    "        \n",
    "        df: Dataframe to evaluate.\n",
    "        library_root: The root folder of the DL library\n",
    "        save_data_to: Relative location to load/save the evaluation data\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.save_data_to = save_data_to\n",
    "        self.library_root = library_root\n",
    "        \n",
    "        # try importing evaluation data if it already exists\n",
    "        if os.path.isfile(self.save_data_to): \n",
    "            self.eval_df = pd.read_csv(self.save_data_to)\n",
    "            print(\"Evaluation data opened.\")\n",
    "        \n",
    "        # otherwise initialize evaluation df and add new column for the evaluation result\n",
    "        else:\n",
    "            self.eval_df = df.copy()\n",
    "            todo_list = [\"TODO\"] * len(self.eval_df.index)\n",
    "            self.eval_df.insert(len(df.columns), 'Evaluation', todo_list)\n",
    "            self.eval_df.to_csv(self.save_data_to)\n",
    "            print(\"New evaluation data created.\")\n",
    "            \n",
    "    def getEvalData(self):\n",
    "        \"\"\"Returns the data frame containing the evaluation data.\"\"\"\n",
    "        return self.eval_df\n",
    "    \n",
    "    def evaluate(self, index):\n",
    "        \"\"\"Present the data entry at the given index for evaluation.\"\"\"\n",
    "        \n",
    "        # present the data entry\n",
    "        print(self.df.iloc[index])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # check if it has already been evaluated\n",
    "        if self.eval_df.at[index, 'Evaluation'] != \"TODO\":\n",
    "            print(\"Already evaluated! Previous evaluation: \" + self.eval_df.at[index, 'Evaluation'])\n",
    "            if input(\"Re-evaluate? (y / n) \") != \"y\":\n",
    "                return\n",
    "            \n",
    "        \n",
    "        # print the relevant source code lines:\n",
    "        \n",
    "        # get source file of current test case and open it as an array of lines\n",
    "        source = open(self.library_root + self.df.iloc[index]['File_Path']).readlines()\n",
    "\n",
    "        # set beginning and end line number for the code section to display\n",
    "        beginning_line_no = self.df.iloc[index]['Function_Definition_Line_Number']\n",
    "        end_line_no = self.df.iloc[index]['Line_Number']\n",
    "\n",
    "        # print these lines \n",
    "        for line in range(beginning_line_no, end_line_no+1):\n",
    "            print(str(line) + \": \" + source[line-1])\n",
    "            \n",
    "        # check if the last line with the assert statement is complete or if the\n",
    "        # assert arguments were moved to new lines, in which case: print more lines\n",
    "        line = end_line_no\n",
    "        last_line = source[line-1]       \n",
    "        \n",
    "        # we can check if the assert statement is complete if it ends with a closed bracket\n",
    "        while not last_line.rstrip().endswith(\")\"):\n",
    "            line += 1\n",
    "            last_line = source[line-1]\n",
    "            print(str(line) + \": \" + last_line)\n",
    "            \n",
    "        # ask for a decision from the evaluator:\n",
    "        decision_bool = True\n",
    "        while decision_bool:\n",
    "            decision = input(\"Correctly identified? (y / n / ?): \")\n",
    "            \n",
    "            if decision in [\"y\", \"n\"]:\n",
    "                decision_bool = False\n",
    "\n",
    "            elif decision == \"?\":\n",
    "                decision = input(\"Please comment on this case: \")\n",
    "                decision_bool = False\n",
    "                \n",
    "            else:\n",
    "                print(\"Error. Please specify y/n/?\")\n",
    "                decision_bool = True\n",
    "                \n",
    "        # write the decision to the evaluation data\n",
    "        self.eval_df.at[index, 'Evaluation'] = decision\n",
    "        self.eval_df.to_csv(self.save_data_to, index=False)\n",
    "\n",
    "# initialize automators:\n",
    "# TensorFlow\n",
    "evalAutomator_tensorflow = EvaluationAutomator(df_tensorflow, library_root_tensorflow, save_data_to_tensorflow)\n",
    "\n",
    "# PyTorch\n",
    "evalAutomator_pytorch = EvaluationAutomator(df_pytorch, library_root_pytorch, save_data_to_pytorch)\n",
    "\n",
    "# test evaluation on a particular case\n",
    "evalAutomator_tensorflow.evaluate(218)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7996664",
   "metadata": {},
   "source": [
    "# Guide for evaluation\n",
    "\n",
    "For each test case, please try to check the following facts:\n",
    "\n",
    "- Is the test case a differential test case? \n",
    "- Was the correct argument identified? (Check if `Oracle_Arugment_Position` is indeed the oracle)\n",
    "- Is the extracted function one of the relevant internal or differential functions?\n",
    "\n",
    "If the answer to all three is questions is yes, then this case was most likely correctly identified (`y`)\n",
    "\n",
    "## Sampling cases for evaluation\n",
    "\n",
    "Set a seed and the number of cases you would like to evaluate, as well as the data to evaluate by setting the `evalAutomator` used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01547de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 + 3\n",
    "NUM_CASES = 10\n",
    "\n",
    "evalAutomator = evalAutomator_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe27d841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 374 (0 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\init_ops_test.py\n",
      "Line_Number                                                    880\n",
      "Found_in_Function                                         testGain\n",
      "Function_Definition_Line_Number                                871\n",
      "Assert_Statement_Type                               assertAllClose\n",
      "Oracle_Argument_ Position                                        1\n",
      "Differential_Function_Line_Number                              878\n",
      "Differential_Test_Function                                    eval\n",
      "Name: 374, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: n\n",
      "Re-evaluate? (y / n) n\n",
      "\n",
      "Case 681 (1 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\reduction_ops_test_big.py\n",
      "Line_Number                                                              77\n",
      "Found_in_Function                                            testFloat32Sum\n",
      "Function_Definition_Line_Number                                          52\n",
      "Assert_Statement_Type                                        assertAllClose\n",
      "Oracle_Argument_ Position                                                 1\n",
      "Differential_Function_Line_Number                                        65\n",
      "Differential_Test_Function                                          np.ones\n",
      "Name: 681, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: y\n",
      "Re-evaluate? (y / n) n\n",
      "\n",
      "Case 595 (2 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\map_ops_test.py\n",
      "Line_Number                                                   398\n",
      "Found_in_Function                               testStringKeyGrad\n",
      "Function_Definition_Line_Number                               383\n",
      "Assert_Statement_Type                              assertAllClose\n",
      "Oracle_Argument_ Position                                       1\n",
      "Differential_Function_Line_Number                             397\n",
      "Differential_Test_Function              map_ops.tensor_map_lookup\n",
      "Name: 595, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: y\n",
      "Re-evaluate? (y / n) n\n",
      "\n",
      "Case 734 (3 / 10)\n",
      "\n",
      "File_Path                             kernel_tests\\relu_op_test.py\n",
      "Line_Number                                                    547\n",
      "Found_in_Function                              testGradientFloat64\n",
      "Function_Definition_Line_Number                                541\n",
      "Assert_Statement_Type                                   assertLess\n",
      "Oracle_Argument_ Position                                        1\n",
      "Differential_Function_Line_Number                              545\n",
      "Differential_Test_Function           gradient_checker_v2.max_error\n",
      "Name: 734, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: n\n",
      "Re-evaluate? (y / n) n\n",
      "\n",
      "Case 1426 (4 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\v1_compat_tests\\session_ops_test.py\n",
      "Line_Number                                                                       273\n",
      "Found_in_Function                          testDirectHandleFeedOverlappingWithFetches\n",
      "Function_Definition_Line_Number                                                   261\n",
      "Assert_Statement_Type                                                  assertAllClose\n",
      "Oracle_Argument_ Position                                                           2\n",
      "Differential_Function_Line_Number                                                 272\n",
      "Differential_Test_Function                                                   sess.run\n",
      "Name: 1426, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: What is sess.run?\n",
      "Re-evaluate? (y / n) n\n",
      "\n",
      "Case 508 (5 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\inplace_ops_test.py\n",
      "Line_Number                                                       213\n",
      "Found_in_Function                         testInplaceOpOnEmptyTensors\n",
      "Function_Definition_Line_Number                                   198\n",
      "Assert_Statement_Type                                  assertAllClose\n",
      "Oracle_Argument_ Position                                           2\n",
      "Differential_Function_Line_Number                                 208\n",
      "Differential_Test_Function                                   np.zeros\n",
      "Name: 508, dtype: object\n",
      "\n",
      "\n",
      "198:   def testInplaceOpOnEmptyTensors(self):\n",
      "\n",
      "199:     op_fns = [\n",
      "\n",
      "200:         inplace_ops.inplace_add,\n",
      "\n",
      "201:         inplace_ops.inplace_sub,\n",
      "\n",
      "202:         inplace_ops.inplace_update,\n",
      "\n",
      "203:     ]\n",
      "\n",
      "204:     for dtype in [dtypes.float32, dtypes.int32, dtypes.int64]:\n",
      "\n",
      "205:       for op_fn in op_fns:\n",
      "\n",
      "206:         with test_util.use_gpu():\n",
      "\n",
      "207:           x = array_ops.zeros([7, 0], dtype)\n",
      "\n",
      "208:           y = np.zeros([7, 0], dtype.as_numpy_dtype)\n",
      "\n",
      "209:           self.assertAllClose(x, y)\n",
      "\n",
      "210:           x = op_fn(x, [3], array_ops.ones([1, 0], dtype))\n",
      "\n",
      "211:           self.assertAllClose(x, y)\n",
      "\n",
      "212:           x = op_fn(x, None, array_ops.ones([1, 0], dtype))\n",
      "\n",
      "213:           self.assertAllClose(x, y)\n",
      "\n",
      "Correctly identified? (y / n / ?): y\n",
      "\n",
      "Case 124 (6 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\constant_op_test.py\n",
      "Line_Number                                                       820\n",
      "Found_in_Function                                           testShape\n",
      "Function_Definition_Line_Number                                   815\n",
      "Assert_Statement_Type                                  assertAllClose\n",
      "Oracle_Argument_ Position                                           1\n",
      "Differential_Function_Line_Number                                 818\n",
      "Differential_Test_Function                         array_ops.identity\n",
      "Name: 124, dtype: object\n",
      "\n",
      "\n",
      "815:   def testShape(self):\n",
      "\n",
      "816:     with self.cached_session():\n",
      "\n",
      "817:       p = array_ops.placeholder(dtypes_lib.float32, shape=(10, 10), name=\"p\")\n",
      "\n",
      "818:       p_identity = array_ops.identity(p)\n",
      "\n",
      "819:       feed_array = np.random.rand(10, 10)\n",
      "\n",
      "820:       self.assertAllClose(\n",
      "\n",
      "821:           p_identity.eval(feed_dict={p: feed_array}), feed_array)\n",
      "\n",
      "Correctly identified? (y / n / ?): n\n",
      "\n",
      "Case 1144 (7 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\distributions\\multinomial_test.py\n",
      "Line_Number                                                                      93\n",
      "Found_in_Function                                                  testPmfUnderflow\n",
      "Function_Definition_Line_Number                                                  88\n",
      "Assert_Statement_Type                                                assertAllClose\n",
      "Oracle_Argument_ Position                                                         2\n",
      "Differential_Function_Line_Number                                                91\n",
      "Differential_Test_Function                                  multinomial.Multinomial\n",
      "Name: 1144, dtype: object\n",
      "\n",
      "\n",
      "88:   def testPmfUnderflow(self):\n",
      "\n",
      "89:     logits = np.array([[-200, 0]], dtype=np.float32)\n",
      "\n",
      "90:     with self.cached_session():\n",
      "\n",
      "91:       dist = multinomial.Multinomial(total_count=1., logits=logits)\n",
      "\n",
      "92:       lp = dist.log_prob([1., 0.]).eval()[0]\n",
      "\n",
      "93:       self.assertAllClose(-200, lp, atol=0, rtol=1e-6)\n",
      "\n",
      "Correctly identified? (y / n / ?): ?\n",
      "Please comment on this case: n\n",
      "\n",
      "Case 1183 (8 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\distributions\\normal_test.py\n",
      "Line_Number                                                                548\n",
      "Found_in_Function                                           testNormalNormalKL\n",
      "Function_Definition_Line_Number                                            531\n",
      "Assert_Statement_Type                                           assertAllClose\n",
      "Oracle_Argument_ Position                                                    2\n",
      "Differential_Function_Line_Number                                          545\n",
      "Differential_Test_Function                                              np.log\n",
      "Name: 1183, dtype: object\n",
      "\n",
      "\n",
      "531:   def testNormalNormalKL(self):\n",
      "\n",
      "532:     batch_size = 6\n",
      "\n",
      "533:     mu_a = np.array([3.0] * batch_size)\n",
      "\n",
      "534:     sigma_a = np.array([1.0, 2.0, 3.0, 1.5, 2.5, 3.5])\n",
      "\n",
      "535:     mu_b = np.array([-3.0] * batch_size)\n",
      "\n",
      "536:     sigma_b = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0])\n",
      "\n",
      "537: \n",
      "\n",
      "538:     n_a = normal_lib.Normal(loc=mu_a, scale=sigma_a)\n",
      "\n",
      "539:     n_b = normal_lib.Normal(loc=mu_b, scale=sigma_b)\n",
      "\n",
      "540: \n",
      "\n",
      "541:     kl = kullback_leibler.kl_divergence(n_a, n_b)\n",
      "\n",
      "542:     kl_val = self.evaluate(kl)\n",
      "\n",
      "543: \n",
      "\n",
      "544:     kl_expected = ((mu_a - mu_b)**2 / (2 * sigma_b**2) + 0.5 * (\n",
      "\n",
      "545:         (sigma_a**2 / sigma_b**2) - 1 - 2 * np.log(sigma_a / sigma_b)))\n",
      "\n",
      "546: \n",
      "\n",
      "547:     self.assertEqual(kl.get_shape(), (batch_size,))\n",
      "\n",
      "548:     self.assertAllClose(kl_val, kl_expected)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified? (y / n / ?): y\n",
      "\n",
      "Case 389 (9 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\inplace_ops_test.py\n",
      "Line_Number                                                        39\n",
      "Found_in_Function                                     testBasicUpdate\n",
      "Function_Definition_Line_Number                                    34\n",
      "Assert_Statement_Type                                  assertAllClose\n",
      "Oracle_Argument_ Position                                           1\n",
      "Differential_Function_Line_Number                                  43\n",
      "Differential_Test_Function                 inplace_ops.inplace_update\n",
      "Name: 389, dtype: object\n",
      "\n",
      "\n",
      "34:   def testBasicUpdate(self):\n",
      "\n",
      "35:     for dtype in [dtypes.float32, dtypes.int32, dtypes.int64]:\n",
      "\n",
      "36:       with test_util.use_gpu():\n",
      "\n",
      "37:         x = array_ops.ones([7, 3], dtype)\n",
      "\n",
      "38:         y = np.ones([7, 3], dtype.as_numpy_dtype)\n",
      "\n",
      "39:         self.assertAllClose(x, y)\n",
      "\n",
      "Correctly identified? (y / n / ?): ?\n",
      "Please comment on this case: Finds a function assignment that appears after the assert statement (also arg1 isn't the oracle). \n"
     ]
    }
   ],
   "source": [
    "# sample cases\n",
    "sampled_cases = df_tensorflow.sample(n=NUM_CASES, random_state=RANDOM_SEED)\n",
    "\n",
    "sample_counter = 0\n",
    "\n",
    "# iterate over each case and evaluate\n",
    "for i, row in sampled_cases.iterrows():\n",
    "    print(\"\\nCase \" + str(i) + \" (\" + str(sample_counter) + \" / \" + str(len(sampled_cases)) + \")\\n\")\n",
    "    evalAutomator.evaluate(i)\n",
    "    sample_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5330d",
   "metadata": {},
   "source": [
    "## Analyse evaluations\n",
    "\n",
    "Now we can gain summary statistics about the performance of our function extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551caaa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO    1695\n",
      "n          3\n",
      "y          2\n",
      "Name: Evaluation, dtype: int64\n",
      "\n",
      "n: 60 %\n",
      "y: 40 %\n",
      "?: 0 %\n"
     ]
    }
   ],
   "source": [
    "eval_data = evalAutomator.getEvalData()\n",
    "\n",
    "evaluation_counts = eval_data.Evaluation.value_counts()\n",
    "\n",
    "print(evaluation_counts)\n",
    "\n",
    "total_cases_evaluated = len(eval_data) - evaluation_counts['TODO'] \n",
    "\n",
    "print(\"\\nn: \" + str(round((evaluation_counts['n'] / total_cases_evaluated)*100)) + \" %\")\n",
    "\n",
    "print(\"y: \" + str(round((evaluation_counts['y'] / total_cases_evaluated)*100)) + \" %\")\n",
    "\n",
    "print(\"?: \" + str(round(((total_cases_evaluated - evaluation_counts['y'] - evaluation_counts['n']) / total_cases_evaluated)*100)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39d8c7",
   "metadata": {},
   "source": [
    "## Show the extracted functions\n",
    "\n",
    "Here we can gain a glimpse into the functions that were extracted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c319172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_qlinear_dynamic' 'sparse_qlinear_dynamic' 'dense_qlinear'\n",
      " 'sparse_qlinear' 'coro.throw' 'torch.cuda.memory_allocated'\n",
      " 'torch.cuda.max_memory_allocated' 'torch.cuda.memory_reserved'\n",
      " 'torch.cuda.max_memory_reserved' 'numpy' 'fn' 'script' nan\n",
      " 'torch.nn.functional.avg_pool2d' 'actual.view' 'self._avg_pool2d'\n",
      " 'F.avg_pool2d' 'torch.nn.functional.avg_pool3d' 'self._avg_pool3d'\n",
      " 'compute_norm' 'torch.eye' 'fc_op' 'torch.fbgemm_linear_fp16_weight'\n",
      " '_softmax' '_batchmatmul' '_fc' 'model' 'torch.tensor' 'perm_fn' 'to'\n",
      " 'F.cosine_similarity' 'torch._VF._add_relu' 'torch.relu' 'pool'\n",
      " 'ref_pool' 'double' 'params.data.dist' 'item' 'to_sparse'\n",
      " 'torch.fft.fftshift' 'bot_l' 'top_l' 'tg' 'lg' 'warmup_and_run_forward'\n",
      " 'run_addcmul' 'traced' 'torch_fn' 'run_remainder' 'foo' 'test'\n",
      " 'run_where' 'torch.empty' 'kernel.run' 'f' 'kernel.fallback' 'torch.mul'\n",
      " 'engine.draw' 'self._sobol_reference_samples' 'torch.randn'\n",
      " 'torch.nn.functional.layer_norm' 'F.linear'\n",
      " 'torch.ops.prepacked.linear_clamp_run' 'F.conv2d'\n",
      " 'torch.ops.prepacked.conv2d_clamp_run' 'F.conv_transpose2d'\n",
      " 'torch.ops.prepacked.conv2d_transpose_clamp_run' 'scripted_model'\n",
      " 'deserialized_scripted_model' 'deserialized_optimized_scripted_model'\n",
      " 'ops.custom.op2' 'self._get_grads' 'max' 'vec_to_tril_matrix'\n",
      " 'mobile_module' 'q_model' 'resnet' 'package_importer.import_module'\n",
      " 'conv_fn' 'torch.quantize_per_tensor' 'qconv_fn' 'conv_module'\n",
      " 'qconv_module' 'loaded_qconv_module' 'copied_conv'\n",
      " 'torch.ops.quantized.cat_relu' 'torch.ops.quantized.cat' 'torch.cat'\n",
      " 'qlinear_ref' 'qlinear' 'pack_fn' 'get_reference_result' 'pt_op' 'op'\n",
      " 'torch.embedding' 'quant_op' 'embedding_bag'\n",
      " 'torch.ops.quantized.embedding_bag_byte' 'q_avg_pool' 'torch.mean'\n",
      " 'r.contiguous' 'qr.dequantize' 'torch.quantize_per_channel'\n",
      " '_quantize_per_channel_ref_nd' 'quantize_ref'\n",
      " '_quantize_per_channel_sub_byte_ref' 'qr.transpose'\n",
      " '_fake_quantize_per_channel_affine_reference' 'fq_module'\n",
      " '_fake_quantize_per_channel_affine_grad_reference'\n",
      " '_fake_quantize_per_tensor_affine_reference'\n",
      " 'torch.fake_quantize_per_tensor_affine'\n",
      " '_fake_quantize_per_tensor_affine_grad_reference' 'detach'\n",
      " 'torch.dequantize' 'torch.fake_quantize_per_channel_affine' 'grad.detach'\n",
      " 'self.checkGraphModeFxOp' 'm2q' 'qgraph' 'torch.jit.script'\n",
      " 'qgraph_script' 'copy.deepcopy']\n",
      "['np.reshape' 'np.squeeze' 'np_easy' 'foo_np' 'np.mean' 'np.expand_dims'\n",
      " 'np.full' 'unpack_fn']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out all unsupported rows\n",
    "extracted_functions_df = eval_data[~eval_data['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False)]\n",
    "\n",
    "\n",
    "numpy_functions_df = extracted_functions_df[extracted_functions_df['Differential_Test_Function'].str.contains('np', na=False)]\n",
    "extracted_functions_df = extracted_functions_df[~extracted_functions_df['Differential_Test_Function'].str.contains('np', na=False)]\n",
    "\n",
    "stats_functions_df = extracted_functions_df[extracted_functions_df['Differential_Test_Function'].str.contains('stats', na=False)]\n",
    "extracted_functions_df = extracted_functions_df[~extracted_functions_df['Differential_Test_Function'].str.contains('stats', na=False)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extracted_functions = extracted_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions)\n",
    "\n",
    "\n",
    "\n",
    "extracted_functions_numpy = numpy_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions_numpy)\n",
    "\n",
    "extracted_functions_stats = stats_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
