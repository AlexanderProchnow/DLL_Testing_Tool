{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33387a59",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "\n",
    "The purpose of this notebook is to streamline the process of manually evaluating the extracted test case data from notebook 1.\n",
    "\n",
    "For this we will sample test cases from the data (using a fixed seed for reproducibility) and have information about the test cases be displayed for manual evaluation, including the relevant lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f61f7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aee37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa1661",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set library root folder:\n",
    "\n",
    "# For TensorFlow\n",
    "library_root_tensorflow = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/Tensorflow/tensorflow-master/tensorflow/python/\" \n",
    "tests_root_tensorflow = \"kernel_tests\"\n",
    "save_data_to_tensorflow = \"extracted_data/tensorflow_evaluation_data.csv\"\n",
    "\n",
    "# For Pytorch\n",
    "library_root_pytorch = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/PyTorch/pytorch-master/\" \n",
    "tests_root_pytorch = \"test\"\n",
    "save_data_to_pytorch = \"extracted_data/pytorch_evaluation_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd6fc6",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4eca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>69</td>\n",
       "      <td>testAddN</td>\n",
       "      <td>59</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>sess.run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>np.random.rand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>astype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>226</td>\n",
       "      <td>testEmptyInput1D</td>\n",
       "      <td>219</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>astype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>226</td>\n",
       "      <td>testEmptyInput1D</td>\n",
       "      <td>219</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>1666</td>\n",
       "      <td>testAxis</td>\n",
       "      <td>1637</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>1647</td>\n",
       "      <td>self._scale_per_slice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            File_Path  Line_Number  Found_in_Function  \\\n",
       "0  kernel_tests\\aggregate_ops_test.py           69           testAddN   \n",
       "1  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "2  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "3      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "4      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "5      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "6      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "7      kernel_tests\\array_ops_test.py          226   testEmptyInput1D   \n",
       "8      kernel_tests\\array_ops_test.py          226   testEmptyInput1D   \n",
       "9      kernel_tests\\array_ops_test.py         1666           testAxis   \n",
       "\n",
       "   Function_Definition_Line_Number Assert_Statement_Type  \\\n",
       "0                               59        assertAllClose   \n",
       "1                               72        assertAllClose   \n",
       "2                               72        assertAllClose   \n",
       "3                              150        assertAllClose   \n",
       "4                              150        assertAllClose   \n",
       "5                              210        assertAllClose   \n",
       "6                              210        assertAllClose   \n",
       "7                              219        assertAllClose   \n",
       "8                              219        assertAllClose   \n",
       "9                             1637        assertAllClose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 66   \n",
       "1                          1                                 80   \n",
       "2                          2                                 79   \n",
       "3                          1                                154   \n",
       "4                          2                                164   \n",
       "5                          1                                212   \n",
       "6                          2                                214   \n",
       "7                          1                                221   \n",
       "8                          2                                223   \n",
       "9                          2                               1647   \n",
       "\n",
       "  Differential_Test_Function  \n",
       "0                     np.sum  \n",
       "1                     np.sum  \n",
       "2                   sess.run  \n",
       "3             np.random.rand  \n",
       "4     array_ops.boolean_mask  \n",
       "5                     astype  \n",
       "6     array_ops.boolean_mask  \n",
       "7                     astype  \n",
       "8     array_ops.boolean_mask  \n",
       "9      self._scale_per_slice  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow data and preview\n",
    "df_tensorflow = pd.read_csv('extracted_data/tensorflow_data.csv')\n",
    "df_tensorflow.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fa9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>dense_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>sparse_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>dense_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>sparse_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>2</td>\n",
       "      <td>2784</td>\n",
       "      <td>input2.var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>2</td>\n",
       "      <td>2785</td>\n",
       "      <td>input2.mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File_Path  Line_Number  \\\n",
       "0  test\\test_ao_sparse.py           98   \n",
       "1  test\\test_ao_sparse.py           98   \n",
       "2  test\\test_ao_sparse.py          103   \n",
       "3  test\\test_ao_sparse.py          103   \n",
       "4   test\\test_autograd.py         1329   \n",
       "5   test\\test_autograd.py         1329   \n",
       "6   test\\test_autograd.py         1340   \n",
       "7   test\\test_autograd.py         1340   \n",
       "8   test\\test_autograd.py         2790   \n",
       "9   test\\test_autograd.py         2790   \n",
       "\n",
       "                            Found_in_Function  \\\n",
       "0                         test_sparse_qlinear   \n",
       "1                         test_sparse_qlinear   \n",
       "2                         test_sparse_qlinear   \n",
       "3                         test_sparse_qlinear   \n",
       "4  test_set_grad_coroutines_benign_exceptions   \n",
       "5  test_set_grad_coroutines_benign_exceptions   \n",
       "6  test_set_grad_coroutines_benign_exceptions   \n",
       "7  test_set_grad_coroutines_benign_exceptions   \n",
       "8                test_var_mean_differentiable   \n",
       "9                test_var_mean_differentiable   \n",
       "\n",
       "   Function_Definition_Line_Number      Assert_Statement_Type  \\\n",
       "0                               32  assert_array_almost_equal   \n",
       "1                               32  assert_array_almost_equal   \n",
       "2                               32  assert_array_almost_equal   \n",
       "3                               32  assert_array_almost_equal   \n",
       "4                             1295                 assertLess   \n",
       "5                             1295                 assertLess   \n",
       "6                             1295                 assertLess   \n",
       "7                             1295                 assertLess   \n",
       "8                             2778                   allclose   \n",
       "9                             2778                   allclose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 96   \n",
       "1                          2                                 95   \n",
       "2                          1                                101   \n",
       "3                          2                                100   \n",
       "4                          1                               1328   \n",
       "5                          1                               1339   \n",
       "6                          1                               1328   \n",
       "7                          1                               1339   \n",
       "8                          2                               2784   \n",
       "9                          2                               2785   \n",
       "\n",
       "  Differential_Test_Function  \n",
       "0      dense_qlinear_dynamic  \n",
       "1     sparse_qlinear_dynamic  \n",
       "2              dense_qlinear  \n",
       "3             sparse_qlinear  \n",
       "4                 coro.throw  \n",
       "5                 coro.throw  \n",
       "6                 coro.throw  \n",
       "7                 coro.throw  \n",
       "8                 input2.var  \n",
       "9                input2.mean  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pytorch data and preview\n",
    "df_pytorch = pd.read_csv('extracted_data/pytorch_data.csv')\n",
    "df_pytorch.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed7e37",
   "metadata": {},
   "source": [
    "## Analyze coverage\n",
    "\n",
    "To track the progress of our test case extraction we display statistics about how many cases still are still unsupported. This is either denoted by an \"UNSUPPORTED ...\" statement in the \"Differential Test Function\" column of the data or by an empty string in this column, i.e. `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f66b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\t6 cases not covered.\n",
      "UNSUPPORTED Unary Operation    4\n",
      "NaN                            2\n",
      "Name: Differential_Test_Function, dtype: int64\n",
      "\n",
      "PyTorch:\t3 cases not covered.\n",
      "UNSUPPORTED Unary Operation    2\n",
      "NaN                            1\n",
      "Name: Differential_Test_Function, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "not_covered_tensorflow = df_tensorflow[df_tensorflow['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_tensorflow['Differential_Test_Function'].isna()]\n",
    "print(\"TensorFlow:\\t\"+ str(len(not_covered_tensorflow)) + \" cases not covered.\")\n",
    "print(not_covered_tensorflow.Differential_Test_Function.value_counts(dropna=False))\n",
    "\n",
    "not_covered_pytorch = df_pytorch[df_pytorch['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_pytorch['Differential_Test_Function'].isna()]\n",
    "print(\"\\nPyTorch:\\t\"+ str(len(not_covered_pytorch)) + \" cases not covered.\")\n",
    "print(not_covered_pytorch.Differential_Test_Function.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc70dade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [File_Path, Line_Number, Found_in_Function, Function_Definition_Line_Number, Assert_Statement_Type, Oracle_Argument_ Position, Differential_Function_Line_Number, Differential_Test_Function]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_covered_tensorflow[not_covered_tensorflow['Differential_Test_Function'].str.contains('UNSUPPORTED Name', na=False)]\n",
    "\n",
    "#not_covered_pytorch[not_covered_pytorch['Differential_Test_Function'].isna()]\n",
    "#not_covered_tensorflow[not_covered_tensorflow['Differential_Test_Function'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a190e82",
   "metadata": {},
   "source": [
    "# Tool for manual evaluation\n",
    "\n",
    "This tool is meant to help with quickly evaluating test cases from the dataset. For each test case, it prints all information collected about the case, including the oracle argument position and the extracted function name, as well as the code inside the function where the test case was defined. Then the evaluator is asked for an evaluation of the test case via input. This evaluation is then stored alongside the test case in the data.\n",
    "\n",
    "Evaluation keys:  \n",
    "y: Test case correctly identified  \n",
    "n: Test case is not differential testing  \n",
    "?: Allows for the entry of a comment. This is meant for situations where the current case is differential testing, but the differential testing function was not extracted correctly (or some other data is incorrect).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc39e0de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data opened.\n",
      "Evaluation data opened.\n",
      "File_Path                                       kernel_tests\\diag_op_test.py\n",
      "Line_Number                                                              925\n",
      "Found_in_Function                                                   testGrad\n",
      "Function_Definition_Line_Number                                          900\n",
      "Assert_Statement_Type                                             assertLess\n",
      "Oracle_Argument_ Position                                                  1\n",
      "Differential_Function_Line_Number                                        906\n",
      "Differential_Test_Function           gradient_checker.compute_gradient_error\n",
      "Name: 218, dtype: object\n",
      "\n",
      "\n",
      "Already evaluated! Previous evaluation: Same code under test, with different parameters\n",
      "Re-evaluate? (y / n) n\n"
     ]
    }
   ],
   "source": [
    "class EvaluationAutomator:\n",
    "    def __init__(self, df, library_root, save_data_to):\n",
    "        \"\"\"Initialize the evaluation automator.\n",
    "        \n",
    "        df: Dataframe to evaluate.\n",
    "        library_root: The root folder of the DL library\n",
    "        save_data_to: Relative location to load/save the evaluation data\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.save_data_to = save_data_to\n",
    "        self.library_root = library_root\n",
    "        \n",
    "        # try importing evaluation data if it already exists\n",
    "        if os.path.isfile(self.save_data_to): \n",
    "            self.eval_df = pd.read_csv(self.save_data_to)\n",
    "            print(\"Evaluation data opened.\")\n",
    "        \n",
    "        # otherwise initialize evaluation df and add new column for the evaluation result\n",
    "        else:\n",
    "            self.eval_df = df.copy()\n",
    "            todo_list = [\"TODO\"] * len(self.eval_df.index)\n",
    "            self.eval_df.insert(len(df.columns), 'Evaluation', todo_list)\n",
    "            self.eval_df.to_csv(self.save_data_to)\n",
    "            print(\"New evaluation data created.\")\n",
    "            \n",
    "    def getEvalData(self):\n",
    "        \"\"\"Returns the data frame containing the evaluation data.\"\"\"\n",
    "        return self.eval_df\n",
    "    \n",
    "    def evaluate(self, index):\n",
    "        \"\"\"Present the data entry at the given index for evaluation.\"\"\"\n",
    "        \n",
    "        # present the data entry\n",
    "        print(self.df.iloc[index])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # check if it has already been evaluated\n",
    "        if self.eval_df.at[index, 'Evaluation'] != \"TODO\":\n",
    "            print(\"Already evaluated! Previous evaluation: \" + self.eval_df.at[index, 'Evaluation'])\n",
    "            if input(\"Re-evaluate? (y / n) \") != \"y\":\n",
    "                return\n",
    "            \n",
    "        \n",
    "        # print the relevant source code lines:\n",
    "        \n",
    "        # get source file of current test case and open it as an array of lines\n",
    "        source = open(self.library_root + self.df.iloc[index]['File_Path']).readlines()\n",
    "\n",
    "        # set beginning and end line number for the code section to display\n",
    "        beginning_line_no = self.df.iloc[index]['Function_Definition_Line_Number']\n",
    "        end_line_no = self.df.iloc[index]['Line_Number']\n",
    "\n",
    "        # print these lines\n",
    "        for line in range(beginning_line_no, end_line_no+1):\n",
    "            print(str(line) + \": \" + source[line-1])\n",
    "        \n",
    "        # ask for a decision from the evaluator:\n",
    "        decision_bool = True\n",
    "        while decision_bool:\n",
    "            decision = input(\"Correctly identified? (y / n / ?): \")\n",
    "            \n",
    "            if decision in [\"y\", \"n\"]:\n",
    "                decision_bool = False\n",
    "\n",
    "            elif decision == \"?\":\n",
    "                decision = input(\"Please comment on this case: \")\n",
    "                decision_bool = False\n",
    "                \n",
    "            else:\n",
    "                print(\"Error. Please specify y/n/?\")\n",
    "                decision_bool = True\n",
    "                \n",
    "        # write the decision to the evaluation data\n",
    "        self.eval_df.at[index, 'Evaluation'] = decision\n",
    "        self.eval_df.to_csv(self.save_data_to, index=False)\n",
    "\n",
    "# initialize automators:\n",
    "# TensorFlow\n",
    "evalAutomator_tensorflow = EvaluationAutomator(df_tensorflow, library_root_tensorflow, save_data_to_tensorflow)\n",
    "\n",
    "# PyTorch\n",
    "evalAutomator_pytorch = EvaluationAutomator(df_pytorch, library_root_pytorch, save_data_to_pytorch)\n",
    "\n",
    "# test evaluation on a particular case\n",
    "evalAutomator_tensorflow.evaluate(218)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7996664",
   "metadata": {},
   "source": [
    "# Guide for evaluation\n",
    "\n",
    "For each test case, please try to check the following facts:\n",
    "\n",
    "- Is the test case a differential test case? \n",
    "- Was the correct argument identified? (Check if `Oracle_Arugment_Position` is indeed the oracle)\n",
    "- Is the extracted function one of the relevant internal or differential functions?\n",
    "\n",
    "If the answer to all three is questions is yes, then this case was most likely correctly identified (`y`)\n",
    "\n",
    "## Sampling cases for evaluation\n",
    "\n",
    "Set a seed and the number of cases you would like to evaluate, as well as the data to evaluate by setting the `evalAutomator` used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01547de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 + 1\n",
    "NUM_CASES = 10\n",
    "\n",
    "evalAutomator = evalAutomator_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe27d841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 36 (0 / 10)\n",
      "\n",
      "File_Path                            kernel_tests\\basic_gpu_test.py\n",
      "Line_Number                                                     198\n",
      "Found_in_Function                                      testGradient\n",
      "Function_Definition_Line_Number                                 179\n",
      "Assert_Statement_Type                                    assertLess\n",
      "Oracle_Argument_ Position                                         1\n",
      "Differential_Function_Line_Number                               196\n",
      "Differential_Test_Function            gradient_checker_v2.max_error\n",
      "Name: 36, dtype: object\n",
      "\n",
      "\n",
      "179:   def testGradient(self):\n",
      "\n",
      "180:     x1 = (1 + np.linspace(0, 5, np.prod([1, 3, 2]))).astype(np.float32).reshape(\n",
      "\n",
      "181:         [1, 3, 2])\n",
      "\n",
      "182:     x2 = (1 + np.linspace(0, 5, np.prod([1, 3, 2]))).astype(np.float32).reshape(\n",
      "\n",
      "183:         [1, 3, 2])\n",
      "\n",
      "184: \n",
      "\n",
      "185:     def div_x1(x1):\n",
      "\n",
      "186:       return math_ops.truediv(x1, x2) * math_ops.cast(1.1, dtype=x1.dtype)\n",
      "\n",
      "187: \n",
      "\n",
      "188:     def div_x2(x2):\n",
      "\n",
      "189:       return math_ops.truediv(x1, x2) * math_ops.cast(1.1, dtype=x2.dtype)\n",
      "\n",
      "190: \n",
      "\n",
      "191:     with self.cached_session():\n",
      "\n",
      "192:       err = gradient_checker_v2.max_error(*gradient_checker_v2.compute_gradient(\n",
      "\n",
      "193:           div_x1, [x1]))\n",
      "\n",
      "194:       self.assertLess(err, self._GRAD_TOL[dtypes.as_dtype(x1.dtype)])\n",
      "\n",
      "195: \n",
      "\n",
      "196:       err = gradient_checker_v2.max_error(*gradient_checker_v2.compute_gradient(\n",
      "\n",
      "197:           div_x2, [x2]))\n",
      "\n",
      "198:       self.assertLess(err, self._GRAD_TOL[dtypes.as_dtype(x2.dtype)])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d37a10698f64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msampled_cases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nCase \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" (\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_counter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" / \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_cases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\")\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mevalAutomator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msample_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-39193907bb12>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mdecision_bool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mdecision_bool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Correctly identified? (y / n / ?): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdecision\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\programs\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             )\n\u001b[1;32m--> 848\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\programs\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# sample cases\n",
    "sampled_cases = df_tensorflow.sample(n=NUM_CASES, random_state=RANDOM_SEED)\n",
    "\n",
    "sample_counter = 0\n",
    "\n",
    "# iterate over each case and evaluate\n",
    "for i, row in sampled_cases.iterrows():\n",
    "    print(\"\\nCase \" + str(i) + \" (\" + str(sample_counter) + \" / \" + str(len(sampled_cases)) + \")\\n\")\n",
    "    evalAutomator.evaluate(i)\n",
    "    sample_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5330d",
   "metadata": {},
   "source": [
    "## Analyse evaluations\n",
    "\n",
    "Now we can gain summary statistics about the performance of our function extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551caaa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO                                                                          1328\n",
      "n                                                                               11\n",
      "y                                                                                9\n",
      "Same code under test, with different parameters                                  1\n",
      "What is sess.run?                                                                1\n",
      "When finding a self. function, goto that function and see what it contains       1\n",
      "should be rng.randn                                                              1\n",
      "Name: Evaluation, dtype: int64\n",
      "\n",
      "n: 46 %\n",
      "y: 38 %\n",
      "?: 17 %\n"
     ]
    }
   ],
   "source": [
    "eval_data = evalAutomator.getEvalData()\n",
    "\n",
    "evaluation_counts = eval_data.Evaluation.value_counts()\n",
    "\n",
    "print(evaluation_counts)\n",
    "\n",
    "total_cases_evaluated = len(eval_data) - evaluation_counts['TODO'] \n",
    "\n",
    "print(\"\\nn: \" + str(round((evaluation_counts['n'] / total_cases_evaluated)*100)) + \" %\")\n",
    "\n",
    "print(\"y: \" + str(round((evaluation_counts['y'] / total_cases_evaluated)*100)) + \" %\")\n",
    "\n",
    "print(\"?: \" + str(round(((total_cases_evaluated - evaluation_counts['y'] - evaluation_counts['n']) / total_cases_evaluated)*100)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39d8c7",
   "metadata": {},
   "source": [
    "## Show the extracted functions\n",
    "\n",
    "Here we can gain a glimpse into the functions that were extracted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c319172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sess.run' nan 'array_ops.boolean_mask' 'self._scale_per_slice'\n",
      " 'nn_ops.atrous_conv2d' 'nn_ops.conv2d' 'array_ops.space_to_batch'\n",
      " 'array_ops.batch_to_space' 'gradient_checker.compute_gradient_error'\n",
      " 'nn_ops.atrous_conv2d_transpose' 'nn_ops.conv2d_transpose'\n",
      " 'nn_impl.depthwise_conv2d' 'max' 'gradient_checker_v2.max_error'\n",
      " 'variables.Variable' 'old.copy' 'special.betainc' 'eval' 'astype' 'numpy'\n",
      " 'constant_op.constant' 'tf_ans.numpy' 'array_ops.identity'\n",
      " 'control_flow_ops.while_loop' 'control_flow_ops.cond' 'nn_ops.conv3d_v2'\n",
      " 'convolver1' 'nn_ops.convolution' 'jacob_n.astype'\n",
      " '_DepthwiseConv2dNumpy' '_GetVal' 'ops.convert_to_tensor'\n",
      " 'EquilibrateEigenVectorPhases' 'embedding_ops.embedding_lookup'\n",
      " 'embedding_ops._embedding_lookup_and_transform' 'embedding_sum.eval'\n",
      " 'embedding_ops.safe_embedding_lookup_sparse_v2'\n",
      " 'self._GetExpectedFractionalAvgPoolResult'\n",
      " 'self._GetExpectedFractionalMaxPoolResult' 'self._tfMLP' 'array_ops.ones'\n",
      " 'array_ops.zeros' 'op_fn' 'array_ops.tile' 'self.expected_pinv'\n",
      " 'scipy.linalg.eigh_tridiagonal' 'linalg.eigh_tridiagonal'\n",
      " 'losses.sigmoid_cross_entropy' 'losses.log_loss' 'losses.hinge_loss'\n",
      " 'losses.huber_loss' 'losses.mean_pairwise_squared_error' 'grad.eval'\n",
      " 'map_ops.tensor_map_lookup' 'array_ops.zeros_like' 'tape.gradient'\n",
      " 'x.astype' '_SolveWithNumpy' 'matrix.astype'\n",
      " 'test_util.matmul_without_tf32' '_Normalize' 'array_ops.concat'\n",
      " 'var_x._concat' 'variable_scope.get_variable' 'vals.flatten' 'flatten'\n",
      " 'pool_direct' 'session.run' 'array_ops.matrix_band_part' 'reshape'\n",
      " 'nn_ops.relu' 'nn_ops.relu6' 'nn_ops.leaky_relu' 'nn_ops.elu'\n",
      " 'nn_ops.selu' 'nn_ops.crelu' 'resource_variable_ops.ResourceVariable'\n",
      " 'root.call' 'load.load' 'handle_options' 'self._segmentReduce'\n",
      " 'self._sparseSegmentReduce' 'sparse_ops.sparse_tensor_to_dense'\n",
      " 'sparse_ops.sparse_to_dense' 'nn_ops.softmax' 'values.reshape'\n",
      " 'x_mat.dot' 'nn_ops.sparse_softmax_cross_entropy_with_logits'\n",
      " 'array_ops.reshape' 'math_ops.matmul' 'test_loss' 'math_ops.tensordot'\n",
      " '_tfconst' '_TapeFromGraphMode' 'ref.copy' 'self.randn'\n",
      " 'bernoulli.Bernoulli' 'categorical.Categorical' 'dist.cdf' 'prob'\n",
      " 'multinomial.Multinomial' 'logpdf' 'cdf' 'sf' 'logcdf' 'logsf' 'entropy'\n",
      " 'ppf' '_expected_pdf' '_logit' 'self._fill_triangular' 'self._adder.add'\n",
      " 'math_ops.imag' 'linalg.adjoint' 'rng.randn' 'rng.rand'\n",
      " 'a_sparse_mat.dot' 'todense' 'a_sm.to_dense' 'sparsify' 'c_sm.to_dense'\n",
      " 'sparse_csr_matrix_ops.matmul' 'util.test_moment_matching' 'sum'\n",
      " 'misc.derivative' 'stateless_op' 'dct_ops.dct' 'dct_ops.idct'\n",
      " 'fftpack.dct' 'fftpack.idct' 'self._tf_fft' 'self._tf_ifft'\n",
      " 'spectrogram_to_mel_matrix' 'mel_ops.linear_to_mel_weight_matrix'\n",
      " 'reconstruction_ops.overlap_and_add' 'shape_ops.frame'\n",
      " 'test.compute_gradient_error' 'spectral_ops.stft'\n",
      " 'spectral_ops.inverse_stft' 'window_ops.hann_window' 'tf_window_fn']\n",
      "['np.sum' 'np.linalg.solve' 'np_func' 'np.floor_divide'\n",
      " 'self._npBatchMatmul' 'self._npBias' 'np.reshape' 'np.zeros' 'np.array'\n",
      " 'np.random.rand' 'np.sqrt' 'np.angle' 'np.polyval' 'RandomInput'\n",
      " 'np.tile' 'np.einsum' 'np.diag' 'self._npMLP'\n",
      " 'inplace_ops.inplace_update' 'np.ones' 'array_ops.inplace_add'\n",
      " 'inplace_ops.inplace_add' 'inplace_ops.inplace_sub' 'np.empty' 'np_expm'\n",
      " 'np.identity' 'np.mean' 'self.np_auc' 'np.linalg.norm' 'self._np_reduce'\n",
      " 'np.amin' 'np.amax' 'np.max' 'self._npRelu' 'self._npRelu6'\n",
      " 'self._npLeakyRelu' 'self._npElu' 'np.abs' 'self._npSelu'\n",
      " 'np.concatenate' 'self._npSoftmax' 'self._npSoftplus' 'self._npSoftsign'\n",
      " 'np.arange' 'np.tensordot' 'np.random.random' 'np.trace' 'np.stack'\n",
      " 'np.matmul' 'np.where' 'np.asarray' 'np.swapaxes' 'np.log'\n",
      " 'np.linalg.inv' 'np.transpose' 'np.conj' 'np.repeat' 'self._np_fft'\n",
      " 'self._np_ifft' 'SpectralOpsTest._np_stft'\n",
      " 'SpectralOpsTest._np_inverse_stft']\n",
      "['boosted_trees_ops.boosted_trees_aggregate_stats' 'stats.beta.mean'\n",
      " 'stats.beta.var' 'stats.beta.entropy' 'stats.dirichlet.mean'\n",
      " 'stats.dirichlet.entropy' 'stats.expon.logpdf' 'stats.expon.cdf'\n",
      " 'stats.expon.logsf' 'stats.expon.mean' 'stats.expon.var'\n",
      " 'stats.expon.entropy' 'stats.gamma.logpdf' 'stats.gamma.cdf'\n",
      " 'stats.gamma.mean' 'stats.gamma.var' 'stats.gamma.std'\n",
      " 'stats.gamma.entropy' 'stats.laplace.logpdf' 'stats.laplace.cdf'\n",
      " 'stats.laplace.logcdf' 'stats.laplace.logsf' 'stats.laplace.mean'\n",
      " 'stats.laplace.var' 'stats.laplace.std' 'stats.laplace.entropy'\n",
      " 'stats.t.logpdf' 'stats.t.pdf' 'stats.t.logcdf' 'stats.t.cdf'\n",
      " 'stats.t.entropy' 'stats.t.var' 'stats.t.std' 'stats.uniform']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out all unsupported rows\n",
    "extracted_functions_df = eval_data[~eval_data['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False)]\n",
    "\n",
    "\n",
    "numpy_functions_df = extracted_functions_df[extracted_functions_df['Differential_Test_Function'].str.contains('np', na=False)]\n",
    "extracted_functions_df = extracted_functions_df[~extracted_functions_df['Differential_Test_Function'].str.contains('np', na=False)]\n",
    "\n",
    "stats_functions_df = extracted_functions_df[extracted_functions_df['Differential_Test_Function'].str.contains('stats', na=False)]\n",
    "extracted_functions_df = extracted_functions_df[~extracted_functions_df['Differential_Test_Function'].str.contains('stats', na=False)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extracted_functions = extracted_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions)\n",
    "\n",
    "\n",
    "\n",
    "extracted_functions_numpy = numpy_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions_numpy)\n",
    "\n",
    "extracted_functions_stats = stats_functions_df.Differential_Test_Function.unique()\n",
    "print(extracted_functions_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
