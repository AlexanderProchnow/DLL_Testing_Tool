{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33387a59",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "\n",
    "The purpose of this notebook is to streamline the process of manually evaluating the extracted test case data from notebook 1.\n",
    "\n",
    "For this we will sample test cases from the data (using a fixed seed for reproducibility) and have information about the test cases be displayed for manual evaluation, including the relevant lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f61f7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aee37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa1661",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set library root folder:\n",
    "\n",
    "# For TensorFlow\n",
    "library_root_tensorflow = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/Tensorflow/tensorflow-master/tensorflow/python/\" \n",
    "tests_root_tensorflow = \"kernel_tests\"\n",
    "save_data_to_tensorflow = \"extracted_data/tensorflow_evaluation_data.csv\"\n",
    "\n",
    "# For Pytorch\n",
    "library_root_pytorch = \"A:/BachelorThesis/DLL_Testing_Tool/DL_Libraries/PyTorch/pytorch-master/\" \n",
    "tests_root_pytorch = \"test\"\n",
    "save_data_to_pytorch = \"extracted_data/pytorch_evaluation_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd6fc6",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4eca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>69</td>\n",
       "      <td>testAddN</td>\n",
       "      <td>59</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>np.sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kernel_tests\\aggregate_ops_test.py</td>\n",
       "      <td>83</td>\n",
       "      <td>testUnknownShapes</td>\n",
       "      <td>72</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>sess.run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>172</td>\n",
       "      <td>CheckVersusNumpy</td>\n",
       "      <td>150</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>217</td>\n",
       "      <td>testEmptyInput2D</td>\n",
       "      <td>210</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>array_ops.boolean_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kernel_tests\\array_ops_test.py</td>\n",
       "      <td>226</td>\n",
       "      <td>testEmptyInput1D</td>\n",
       "      <td>219</td>\n",
       "      <td>assertAllClose</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            File_Path  Line_Number  Found_in_Function  \\\n",
       "0  kernel_tests\\aggregate_ops_test.py           69           testAddN   \n",
       "1  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "2  kernel_tests\\aggregate_ops_test.py           83  testUnknownShapes   \n",
       "3      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "4      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "5      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "6      kernel_tests\\array_ops_test.py          172   CheckVersusNumpy   \n",
       "7      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "8      kernel_tests\\array_ops_test.py          217   testEmptyInput2D   \n",
       "9      kernel_tests\\array_ops_test.py          226   testEmptyInput1D   \n",
       "\n",
       "   Function_Definition_Line_Number Assert_Statement_Type  \\\n",
       "0                               59        assertAllClose   \n",
       "1                               72        assertAllClose   \n",
       "2                               72        assertAllClose   \n",
       "3                              150        assertAllClose   \n",
       "4                              150        assertAllClose   \n",
       "5                              150        assertAllClose   \n",
       "6                              150        assertAllClose   \n",
       "7                              210        assertAllClose   \n",
       "8                              210        assertAllClose   \n",
       "9                              219        assertAllClose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 66   \n",
       "1                          1                                 80   \n",
       "2                          2                                 79   \n",
       "3                          1                                159   \n",
       "4                          1                                161   \n",
       "5                          1                                163   \n",
       "6                          2                                164   \n",
       "7                          1                                213   \n",
       "8                          2                                214   \n",
       "9                          1                                222   \n",
       "\n",
       "  Differential_Test_Function  \n",
       "0                     np.sum  \n",
       "1                     np.sum  \n",
       "2                   sess.run  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "5                        NaN  \n",
       "6     array_ops.boolean_mask  \n",
       "7                        NaN  \n",
       "8     array_ops.boolean_mask  \n",
       "9                        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow data and preview\n",
    "df_tensorflow = pd.read_csv('extracted_data/tensorflow_data.csv')\n",
    "df_tensorflow.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fa9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Found_in_Function</th>\n",
       "      <th>Function_Definition_Line_Number</th>\n",
       "      <th>Assert_Statement_Type</th>\n",
       "      <th>Oracle_Argument_ Position</th>\n",
       "      <th>Differential_Function_Line_Number</th>\n",
       "      <th>Differential_Test_Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>dense_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>98</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>sparse_qlinear_dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>dense_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test\\test_ao_sparse.py</td>\n",
       "      <td>103</td>\n",
       "      <td>test_sparse_qlinear</td>\n",
       "      <td>32</td>\n",
       "      <td>assert_array_almost_equal</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>sparse_qlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1329</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>1340</td>\n",
       "      <td>test_set_grad_coroutines_benign_exceptions</td>\n",
       "      <td>1295</td>\n",
       "      <td>assertLess</td>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>coro.throw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>1</td>\n",
       "      <td>2788</td>\n",
       "      <td>UNSUPPORTED Binary Operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test\\test_autograd.py</td>\n",
       "      <td>2790</td>\n",
       "      <td>test_var_mean_differentiable</td>\n",
       "      <td>2778</td>\n",
       "      <td>allclose</td>\n",
       "      <td>2</td>\n",
       "      <td>2789</td>\n",
       "      <td>UNSUPPORTED Binary Operation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File_Path  Line_Number  \\\n",
       "0  test\\test_ao_sparse.py           98   \n",
       "1  test\\test_ao_sparse.py           98   \n",
       "2  test\\test_ao_sparse.py          103   \n",
       "3  test\\test_ao_sparse.py          103   \n",
       "4   test\\test_autograd.py         1329   \n",
       "5   test\\test_autograd.py         1329   \n",
       "6   test\\test_autograd.py         1340   \n",
       "7   test\\test_autograd.py         1340   \n",
       "8   test\\test_autograd.py         2790   \n",
       "9   test\\test_autograd.py         2790   \n",
       "\n",
       "                            Found_in_Function  \\\n",
       "0                         test_sparse_qlinear   \n",
       "1                         test_sparse_qlinear   \n",
       "2                         test_sparse_qlinear   \n",
       "3                         test_sparse_qlinear   \n",
       "4  test_set_grad_coroutines_benign_exceptions   \n",
       "5  test_set_grad_coroutines_benign_exceptions   \n",
       "6  test_set_grad_coroutines_benign_exceptions   \n",
       "7  test_set_grad_coroutines_benign_exceptions   \n",
       "8                test_var_mean_differentiable   \n",
       "9                test_var_mean_differentiable   \n",
       "\n",
       "   Function_Definition_Line_Number      Assert_Statement_Type  \\\n",
       "0                               32  assert_array_almost_equal   \n",
       "1                               32  assert_array_almost_equal   \n",
       "2                               32  assert_array_almost_equal   \n",
       "3                               32  assert_array_almost_equal   \n",
       "4                             1295                 assertLess   \n",
       "5                             1295                 assertLess   \n",
       "6                             1295                 assertLess   \n",
       "7                             1295                 assertLess   \n",
       "8                             2778                   allclose   \n",
       "9                             2778                   allclose   \n",
       "\n",
       "   Oracle_Argument_ Position  Differential_Function_Line_Number  \\\n",
       "0                          1                                 96   \n",
       "1                          2                                 95   \n",
       "2                          1                                101   \n",
       "3                          2                                100   \n",
       "4                          1                               1328   \n",
       "5                          1                               1339   \n",
       "6                          1                               1328   \n",
       "7                          1                               1339   \n",
       "8                          1                               2788   \n",
       "9                          2                               2789   \n",
       "\n",
       "     Differential_Test_Function  \n",
       "0         dense_qlinear_dynamic  \n",
       "1        sparse_qlinear_dynamic  \n",
       "2                 dense_qlinear  \n",
       "3                sparse_qlinear  \n",
       "4                    coro.throw  \n",
       "5                    coro.throw  \n",
       "6                    coro.throw  \n",
       "7                    coro.throw  \n",
       "8  UNSUPPORTED Binary Operation  \n",
       "9  UNSUPPORTED Binary Operation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pytorch data and preview\n",
    "df_pytorch = pd.read_csv('extracted_data/pytorch_data.csv')\n",
    "df_pytorch.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed7e37",
   "metadata": {},
   "source": [
    "## Analyze coverage\n",
    "\n",
    "To track the progress of our test case extraction we display statistics about how many cases still are still unsupported. This is either denoted by an \"UNSUPPORTED ...\" statement in the \"Differential Test Function\" column of the data or by an empty string in this column, i.e. `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f66b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\t320 cases not covered.\n",
      "PyTorch:\t157 cases not covered.\n"
     ]
    }
   ],
   "source": [
    "not_covered_tensorflow = df_tensorflow[df_tensorflow['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_tensorflow['Differential_Test_Function'].isna()]\n",
    "print(\"TensorFlow:\\t\"+ str(len(not_covered_tensorflow)) + \" cases not covered.\")\n",
    "\n",
    "not_covered_pytorch = df_pytorch[df_pytorch['Differential_Test_Function'].str.contains('UNSUPPORTED', na=False) | df_pytorch['Differential_Test_Function'].isna()]\n",
    "print(\"PyTorch:\\t\"+ str(len(not_covered_pytorch)) + \" cases not covered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a190e82",
   "metadata": {},
   "source": [
    "# Tool for manual evaluation\n",
    "\n",
    "This tool is meant to help with quickly evaluating test cases from the dataset. For each test case, it prints all information collected about the case, including the oracle argument position and the extracted function name, as well as the code inside the function where the test case was defined. Then the evaluator is asked for an evaluation of the test case via input. This evaluation is then stored alongside the test case in the data.\n",
    "\n",
    "Evaluation keys:  \n",
    "y: Test case correctly identified  \n",
    "n: Test case is not differential testing  \n",
    "?: Allows for the entry of a comment. This is meant for situations where the current case is differential testing, but the differential testing function was not extracted correctly (or some other data is incorrect).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc39e0de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data opened.\n",
      "Evaluation data opened.\n",
      "File_Path                            kernel_tests\\aggregate_ops_test.py\n",
      "Line_Number                                                          83\n",
      "Found_in_Function                                     testUnknownShapes\n",
      "Function_Definition_Line_Number                                      72\n",
      "Assert_Statement_Type                                    assertAllClose\n",
      "Oracle_Argument_ Position                                             2\n",
      "Differential_Function_Line_Number                                    79\n",
      "Differential_Test_Function                                     sess.run\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "72:   def testUnknownShapes(self):\n",
      "\n",
      "73:     np.random.seed(12345)\n",
      "\n",
      "74:     with self.session() as sess:\n",
      "\n",
      "75:       for dtype in self._supported_types():\n",
      "\n",
      "76:         data = self._buildData((2, 2), dtype)\n",
      "\n",
      "77:         for count in range(1, self._MAX_N + 1):\n",
      "\n",
      "78:           data_ph = array_ops.placeholder(dtype=dtype)\n",
      "\n",
      "79:           actual = sess.run(math_ops.add_n([data_ph] * count), {data_ph: data})\n",
      "\n",
      "80:           expected = np.sum(np.vstack([np.expand_dims(data, 0)] * count),\n",
      "\n",
      "81:                             axis=0)\n",
      "\n",
      "82:           tol = 5e-3 if dtype == dtypes.float16 else 5e-7\n",
      "\n",
      "83:           self.assertAllClose(expected, actual, rtol=tol, atol=tol)\n",
      "\n",
      "Correctly identified? (y / n / ?): n\n"
     ]
    }
   ],
   "source": [
    "class EvaluationAutomator:\n",
    "    def __init__(self, df, library_root, save_data_to):\n",
    "        \"\"\"Initialize the evaluation automator.\n",
    "        \n",
    "        df: Dataframe to evaluate.\n",
    "        library_root: The root folder of the DL library\n",
    "        save_data_to: Relative location to load/save the evaluation data\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.save_data_to = save_data_to\n",
    "        self.library_root = library_root\n",
    "        \n",
    "        # try importing evaluation data if it already exists\n",
    "        if os.path.isfile(self.save_data_to): \n",
    "            self.eval_df = pd.read_csv(self.save_data_to)\n",
    "            print(\"Evaluation data opened.\")\n",
    "        \n",
    "        # otherwise initialize evaluation df and add new column for the evaluation result\n",
    "        else:\n",
    "            self.eval_df = df.copy()\n",
    "            todo_list = [\"TODO\"] * len(self.eval_df.index)\n",
    "            self.eval_df.insert(len(df.columns), 'Evaluation', todo_list)\n",
    "            self.eval_df.to_csv(self.save_data_to)\n",
    "            print(\"New evaluation data created.\")\n",
    "            \n",
    "            \n",
    "    def evaluate(self, index):\n",
    "        \"\"\"Present the data entry at the given index for evaluation.\"\"\"\n",
    "        \n",
    "        # present the data entry\n",
    "        print(self.df.iloc[index])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # check if it has already been evaluated\n",
    "        if self.eval_df.at[index, 'Evaluation'] != \"TODO\":\n",
    "            print(\"Already evaluated! Previous evaluation: \" + self.eval_df.at[index, 'Evaluation'])\n",
    "            if input(\"Re-evaluate? (y / n) \") != \"y\":\n",
    "                return\n",
    "            \n",
    "        \n",
    "        # print the relevant source code lines:\n",
    "        \n",
    "        # get source file of current test case and open it as an array of lines\n",
    "        source = open(self.library_root + self.df.iloc[index]['File_Path']).readlines()\n",
    "\n",
    "        # set beginning and end line number for the code section to display\n",
    "        beginning_line_no = self.df.iloc[index]['Function_Definition_Line_Number']\n",
    "        end_line_no = self.df.iloc[index]['Line_Number']\n",
    "\n",
    "        # print these lines\n",
    "        for line in range(beginning_line_no, end_line_no+1):\n",
    "            print(str(line) + \": \" + source[line-1])\n",
    "        \n",
    "        # ask for a decision from the evaluator:\n",
    "        decision_bool = True\n",
    "        while decision_bool:\n",
    "            decision = input(\"Correctly identified? (y / n / ?): \")\n",
    "            \n",
    "            if decision in [\"y\", \"n\"]:\n",
    "                decision_bool = False\n",
    "\n",
    "            elif decision == \"?\":\n",
    "                decision = input(\"Please comment on this case: \")\n",
    "                decision_bool = False\n",
    "                \n",
    "            else:\n",
    "                print(\"Error. Please specify y/n/?\")\n",
    "                decision_bool = True\n",
    "                \n",
    "        # write the decision to the evaluation data\n",
    "        self.eval_df.at[index, 'Evaluation'] = decision\n",
    "        self.eval_df.to_csv(self.save_data_to, index=False)\n",
    "\n",
    "# initialize automator:\n",
    "# TensorFlow\n",
    "evalAutomator_tensorflow = EvaluationAutomator(df_tensorflow, library_root_tensorflow, save_data_to_tensorflow)\n",
    "\n",
    "# PyTorch\n",
    "evalAutomator_pytorch = EvaluationAutomator(df_pytorch, library_root_pytorch, save_data_to_pytorch)\n",
    "\n",
    "# test evaluation on a particular case\n",
    "evalAutomator_tensorflow.evaluate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbce792",
   "metadata": {},
   "source": [
    "## Sampling cases for evaluation\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
