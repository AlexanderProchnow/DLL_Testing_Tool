
    <!DOCTYPE html>
    <html>
    <head>
    <style>
    .collapsible {
      background-color: #777;
      color: white;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: none;
      text-align: left;
      outline: none;
      font-size: 15px;
    }

    .active, .collapsible:hover {
      background-color: #555;
    }

    .content {
      padding: 0 18px;
      display: none;
      overflow: hidden;
      background-color: #f1f1f1;
    }
    </style>
    </head>
    <body>


 <br>Commit id closest to current version: b305160fd7e5866771575acf8b932ac9880ebb4c
<br>Date: 10-Jul-2019

 <br>Commit message: Merge pull request #30379 from ROCmSoftwarePlatform:google_upstream_xla_computation_placer<br><br>PiperOrigin-RevId: 257348879<br><br>
<br>Commit id closest to desired version: f1527c02b722050822c62386428fd9d0f8623e74
<br>Date: 12-Oct-2019

 <br>Commit message: Go: Update generated wrapper functions for TensorFlow ops.<br><br>PiperOrigin-RevId: 284705676<br>Change-Id: Ib0206485ca591f28b0beb8c007ad4e6a842e5fe3<br><br>
<br>_____________________________________tensorflow/python/keras/layers/recurrent.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26161</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>344</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26164</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>345</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26168</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>353</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26176</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>354</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26184</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>377</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26187</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>378</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26191</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>386</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26199</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>387</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26207</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>410</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26210</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>411</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26214</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>421</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26223</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>422</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26231</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>449</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26234</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>450</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26238</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>462</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26247</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>463</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26255</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>489</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26257</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>491</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26260</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>501</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26268</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>503</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26277</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>535</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26286</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>536</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26295</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>574</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26303</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>574</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26309</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>575</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
    <tr>
      <th>26317</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>575</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow/python/keras/layers/recurrent.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/recurrent.py b/tensorflow/python/keras/layers/recurrent.py
<br>index 5b88db6a346..eb8f43fd993 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/recurrent.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/recurrent.py</span>
<br>@@ -23,7 +23,9 @@ import collections
<br>&nbsp
<br>&nbspimport numpy as np
<br>&nbsp
<br><span style="color:green">+from tensorflow.python.distribute import distribution_strategy_context as ds_context</span>
<br>&nbspfrom tensorflow.python.eager import context
<br><span style="color:green">+from tensorflow.python.framework import ops</span>
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br>&nbspfrom tensorflow.python.keras import activations
<br>&nbspfrom tensorflow.python.keras import backend as K
<br>@@ -35,12 +37,21 @@ from tensorflow.python.keras.engine.input_spec import InputSpec
<br>&nbspfrom tensorflow.python.keras.utils import generic_utils
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.ops import array_ops
<br><span style="color:green">+from tensorflow.python.ops import control_flow_ops</span>
<br><span style="color:green">+from tensorflow.python.ops import control_flow_util</span>
<br><span style="color:green">+from tensorflow.python.ops import math_ops</span>
<br>&nbspfrom tensorflow.python.ops import state_ops
<br>&nbspfrom tensorflow.python.platform import tf_logging as logging
<br>&nbspfrom tensorflow.python.training.tracking import base as trackable
<br>&nbspfrom tensorflow.python.training.tracking import data_structures
<br>&nbspfrom tensorflow.python.util import nest
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br><span style="color:green">+from tensorflow.tools.docs import doc_controls</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+RECURRENT_DROPOUT_WARNING_MSG = (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'RNN `implementation=2` is not supported when `recurrent_dropout` is set. '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'Using `implementation=1`.')</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.layers.StackedRNNCells')
<br>@@ -55,14 +66,17 @@ class StackedRNNCells(Layer):
<br>&nbsp &nbsp &nbspExamples:
<br>&nbsp
<br>&nbsp &nbsp &nbsp```python
<br><span style="color:red">- &nbsp &nbspcells = [</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.layers.LSTMCell(output_dim),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.layers.LSTMCell(output_dim),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.layers.LSTMCell(output_dim),</span>
<br><span style="color:red">- &nbsp &nbsp]</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspinputs = keras.Input((timesteps, input_dim))</span>
<br><span style="color:red">- &nbsp &nbspx = keras.layers.RNN(cells)(inputs)</span>
<br><span style="color:green">+&nbsp &nbspbatch_size = 3</span>
<br><span style="color:green">+&nbsp &nbspsentence_max_length = 5</span>
<br><span style="color:green">+&nbsp &nbspn_features = 2</span>
<br><span style="color:green">+&nbsp &nbspnew_shape = (batch_size, sentence_max_length, n_features)</span>
<br><span style="color:green">+&nbsp &nbspx = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsprnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(2)]</span>
<br><span style="color:green">+&nbsp &nbspstacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)</span>
<br><span style="color:green">+&nbsp &nbsplstm_layer = tf.keras.layers.RNN(stacked_lstm)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspresult = lstm_layer(x)</span>
<br>&nbsp &nbsp &nbsp```
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>@@ -115,7 +129,7 @@ class StackedRNNCells(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn tuple(initial_states)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef call(self, inputs, states, constants=None, **kwargs):</span>
<br><span style="color:green">+&nbsp &nbspdef call(self, inputs, states, constants=None, training=None, **kwargs):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Recover per-cell states.
<br>&nbsp &nbsp &nbsp &nbsp &nbspstate_size = (self.state_size[::-1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reverse_state_order else self.state_size)
<br>@@ -128,6 +142,10 @@ class StackedRNNCells(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TF cell does not wrap the state into list when there is only one state.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_tf_rnn_cell = getattr(cell, '_is_tf_rnn_cell', None) is not None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstates = states[0] if len(states) == 1 and is_tf_rnn_cell else states
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif generic_utils.has_arg(cell.call, 'training'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['training'] = training</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs.pop('training', None)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif generic_utils.has_arg(cell.call, 'constants'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, states = cell.call(inputs, states, constants=constants,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs)
<br>@@ -181,6 +199,9 @@ class StackedRNNCells(Layer):
<br>&nbspclass RNN(Layer):
<br>&nbsp &nbsp &nbsp"""Base class for recurrent layers.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)</span>
<br><span style="color:green">+&nbsp &nbspfor details about the usage of RNN API.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArguments:
<br>&nbsp &nbsp &nbsp &nbsp &nbspcell: A RNN cell instance or a list of RNN cell instances.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA RNN cell is a class that has:
<br>@@ -190,8 +211,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsection "Note on passing external constants" below.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `state_size` attribute. This can be a single integer
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(single state) in which case it is the size of the recurrent
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate. This can also be a list/tuple of integers (one size per</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate. This can also be a list/tuple of integers (one size per state).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe `state_size` can also be TensorShape or tuple/list of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensorShape, to represent high dimension state.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `output_size` attribute. This can be a single integer or a
<br>@@ -219,21 +239,20 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn the case that `cell` is a list of RNN cell instances, the cells
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be stacked on top of each other in the RNN, resulting in an
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspefficient stacked RNN.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn_sequences: Boolean. Whether to return the last output</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the output sequence, or the full sequence.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn_state: Boolean. Whether to return the last state</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn_sequences: Boolean (default `False`). Whether to return the last</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput in the output sequence, or the full sequence.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn_state: Boolean (default `False`). Whether to return the last state</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin addition to the output.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgo_backwards: Boolean (default False).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgo_backwards: Boolean (default `False`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf True, process the input sequence backwards and return the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreversed sequence.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstateful: Boolean (default False). If True, the last state</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstateful: Boolean (default `False`). If True, the last state</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor each sample at index i in a batch will be used as initial
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate for the sample of index i in the following batch.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspunroll: Boolean (default False).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunroll: Boolean (default `False`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf True, the network will be unrolled, else a symbolic loop will be used.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnrolling can speed-up a RNN,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalthough it tends to be more memory-intensive.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnrolling is only suitable for short sequences.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnrolling can speed-up a RNN, although it tends to be more</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmemory-intensive. Unrolling is only suitable for short sequences.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptime_major: The shape format of the `inputs` and `outputs` tensors.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf True, the inputs and outputs will be in shape
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(timesteps, batch, ...)`, whereas in the False case, it will be
<br>@@ -245,7 +264,7 @@ class RNN(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspCall arguments:
<br>&nbsp &nbsp &nbsp &nbsp &nbspinputs: Input tensor.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmask: Binary tensor of shape `(samples, timesteps)` indicating whether</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmask: Binary tensor of shape `[batch_size, timesteps]` indicating whether</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa given timestep should be masked.
<br>&nbsp &nbsp &nbsp &nbsp &nbsptraining: Python boolean indicating whether the layer should behave in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining mode or in inference mode. This argument is passed to the cell
<br>@@ -256,25 +275,25 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptimestep.
<br>&nbsp
<br>&nbsp &nbsp &nbspInput shape:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspN-D tensor with shape `(batch_size, timesteps, ...)` or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`(timesteps, batch_size, ...)` when time_major is True.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspN-D tensor with shape `[batch_size, timesteps, ...]` or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`[timesteps, batch_size, ...]` when time_major is True.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspOutput shape:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp- If `return_state`: a list of tensors. The first tensor is
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe output. The remaining tensors are the last states,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach with shape `(batch_size, state_size)`, where `state_size` could</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach with shape `[batch_size, state_size]`, where `state_size` could</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe a high dimension tensor shape.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp- If `return_sequences`: N-D tensor with shape
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(batch_size, timesteps, output_size)`, where `output_size` could</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`[batch_size, timesteps, output_size]`, where `output_size` could</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe a high dimension tensor shape, or
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(timesteps, batch_size, output_size)` when `time_major` is True.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp- Else, N-D tensor with shape `(batch_size, output_size)`, where</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`[timesteps, batch_size, output_size]` when `time_major` is True.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- Else, N-D tensor with shape `[batch_size, output_size]`, where</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`output_size` could be a high dimension tensor shape.
<br>&nbsp
<br>&nbsp &nbsp &nbspMasking:
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis layer supports masking for input data with a variable number
<br>&nbsp &nbsp &nbsp &nbsp &nbspof timesteps. To introduce masks to your data,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspuse an [Embedding](embeddings.md) layer with the `mask_zero` parameter</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspuse an [tf.keras.layers.Embedding] layer with the `mask_zero` parameter</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspset to `True`.
<br>&nbsp
<br>&nbsp &nbsp &nbspNote on using statefulness in RNNs:
<br>@@ -408,6 +427,12 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._states = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.constants_spec = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._num_constants = 0
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._supports_ragged_inputs = True</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif stateful:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_context.has_strategy():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('RNNs with stateful=True not yet supported with '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tf.distribute.Strategy.')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbspdef states(self):
<br>@@ -588,6 +613,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor_shape.TensorShape(flat_cell_state_size[i])):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise validation_error
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@doc_controls.do_not_doc_inheritable</span>
<br>&nbsp &nbsp &nbspdef get_initial_state(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspget_initial_state_fn = getattr(self.cell, 'get_initial_state', None)
<br>&nbsp
<br>@@ -638,9 +664,12 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._num_constants = len(constants)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_specs += self.constants_spec
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# at this point additional_inputs cannot be empty</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis_keras_tensor = K.is_keras_tensor(nest.flatten(additional_inputs)[0])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor tensor in nest.flatten(additional_inputs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# additional_inputs can be empty if initial_state or constants are provided</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# but empty (e.g. the cell is stateless).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspflat_additional_inputs = nest.flatten(additional_inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_keras_tensor = K.is_keras_tensor(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_additional_inputs[0]) if flat_additional_inputs else True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor tensor in flat_additional_inputs:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif K.is_keras_tensor(tensor) != is_keras_tensor:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The initial state or constants of an RNN'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' layer cannot be specified with a mix of'
<br>@@ -676,9 +705,20 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants=None):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The input should be dense, padded with zeros. If a ragged input is fed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# into the layer, it is padded and the row lengths are used for masking.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs, row_lengths = K.convert_inputs_if_ragged(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_ragged_input = (row_lengths is not None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._validate_args_if_ragged(is_ragged_input, mask)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinputs, initial_state, constants = self._process_inputs(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, initial_state, constants)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._maybe_reset_cell_dropout_mask(self.cell)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(self.cell, StackedRNNCells):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor cell in self.cell.cells:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._maybe_reset_cell_dropout_mask(cell)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif mask is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Time step masks must be the same for each input.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(scottzhu): Should we accept multiple different masks?
<br>@@ -740,9 +780,10 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgo_backwards=self.go_backwards,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=mask,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspunroll=self.unroll,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length=timesteps,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length=row_lengths if row_lengths is not None else timesteps,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptime_major=self.time_major,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero_output_for_mask=self.zero_output_for_mask)
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.stateful:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdates = []
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor state_, state in zip(nest.flatten(self.states), nest.flatten(states)):
<br>@@ -750,7 +791,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(updates)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.return_sequences:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = outputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.maybe_convert_to_ragged(is_ragged_input, outputs, row_lengths)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = last_output
<br>&nbsp
<br>@@ -779,11 +820,22 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(initial_state) == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = inputs[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif initial_state is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppass</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif self.stateful:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state = self.states</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.stateful:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif initial_state is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When layer is stateful and initial_state is provided, check if the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# recorded state is same as the default value (zeros). Use the recorded</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# state if it is not same as the default.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnon_zero_count = math_ops.add_n([math_ops.count_nonzero_v2(s)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor s in nest.flatten(self.states)])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Set strict = True to keep the original structure of the state.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state = control_flow_ops.cond(non_zero_count > 0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrue_fn=lambda: self.states,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfalse_fn=lambda: initial_state,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrict=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state = self.states</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif initial_state is None:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state = self.get_initial_state(inputs)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(initial_state) != len(self.states):
<br>@@ -792,10 +844,45 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' initial states.')
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn inputs, initial_state, constants
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _validate_args_if_ragged(self, is_ragged_input, mask):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not is_ragged_input:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mask is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The mask that was passed in was ' + str(mask) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' and cannot be applied to RaggedTensor inputs. Please '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'make sure that there is no mask passed in by upstream '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'layers.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.unroll:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The input received constains RaggedTensors and does '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'not support unrolling. Disable unrolling by passing '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`unroll=False` in the RNN Layer constructor.')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _maybe_reset_cell_dropout_mask(self, cell):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(cell, DropoutRNNCellMixin):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell.reset_dropout_mask()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell.reset_recurrent_dropout_mask()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspdef reset_states(self, states=None):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Reset the recorded states for the stateful RNN layer.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCan only be used when RNN layer is constructed with `stateful` = `True`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspstates: Numpy arrays that contains the value for the initial state, which</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be feed to cell at the first time step. When the value is None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero filled numpy array will be created based on the cell state size.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspAttributeError: When the RNN layer is not stateful.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: When the batch size of the RNN layer is unknown.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: When the input numpy array is not compatible with the RNN</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplayer state, either size wise or dtype wise.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.stateful:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise AttributeError('Layer must be stateful.')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspspec_shape = None if self.input_spec is None else self.input_spec[0].shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspec_shape = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.input_spec is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspspec_shape = nest.flatten(self.input_spec[0])[0].shape</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif spec_shape is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# It is possible to have spec shape to be None, eg when construct a RNN
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# with a custom cell, or standard RNN layers (LSTM/GRU) which we only know
<br>@@ -882,6 +969,9 @@ class RNN(Layer):
<br>&nbspclass AbstractRNNCell(Layer):
<br>&nbsp &nbsp &nbsp"""Abstract object representing an RNN cell.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)</span>
<br><span style="color:green">+&nbsp &nbspfor details about the usage of RNN API.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspThis is the base class for implementing RNN cells with custom behavior.
<br>&nbsp
<br>&nbsp &nbsp &nbspEvery `RNNCell` must have the properties below and implement `call` with
<br>@@ -966,6 +1056,7 @@ class AbstractRNNCell(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@doc_controls.do_not_generate_docs</span>
<br>&nbspclass DropoutRNNCellMixin(object):
<br>&nbsp &nbsp &nbsp"""Object that hold dropout related fields for RNN Cell.
<br>&nbsp
<br>@@ -1026,11 +1117,11 @@ class DropoutRNNCellMixin(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspmask. If a new mask is generated, it will update the cache in the cell.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: the input tensor whose shape will be used to generate dropout</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: The input tensor whose shape will be used to generate dropout</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining: boolean tensor, whether its in training mode, dropout will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining: Boolean tensor, whether its in training mode, dropout will be</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspignored in non-training mode.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcount: int, how many dropout mask will be generated. It is useful for cell</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcount: Int, how many dropout mask will be generated. It is useful for cell</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat has internal weights fused together.
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of mask tensor, generated or cached mask based on context.
<br>@@ -1062,11 +1153,11 @@ class DropoutRNNCellMixin(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspmask. If a new mask is generated, it will update the cache in the cell.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: the input tensor whose shape will be used to generate dropout</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: The input tensor whose shape will be used to generate dropout</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining: boolean tensor, whether its in training mode, dropout will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining: Boolean tensor, whether its in training mode, dropout will be</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspignored in non-training mode.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcount: int, how many dropout mask will be generated. It is useful for cell</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcount: Int, how many dropout mask will be generated. It is useful for cell</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat has internal weights fused together.
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of mask tensor, generated or cached mask based on context.
<br>@@ -1098,41 +1189,69 @@ class DropoutRNNCellMixin(object):
<br>&nbspclass SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp"""Cell class for SimpleRNN.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)</span>
<br><span style="color:green">+&nbsp &nbspfor details about the usage of RNN API.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspThis class processes one step within the whole time sequence input, whereas</span>
<br><span style="color:green">+&nbsp &nbsp`tf.keras.layer.SimpleRNN` processes the whole sequence.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArguments:
<br>&nbsp &nbsp &nbsp &nbsp &nbspunits: Positive integer, dimensionality of the output space.
<br>&nbsp &nbsp &nbsp &nbsp &nbspactivation: Activation function to use.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault: hyperbolic tangent (`tanh`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you pass `None`, no activation is applied
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(ie. "linear" activation: `a(x) = x`).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspuse_bias: Boolean, (default `True`), whether the layer uses a bias vector.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for the linear transformation of the inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for the linear transformation of the inputs. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`glorot_uniform`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsprecurrent_initializer: Initializer for the `recurrent_kernel`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights matrix, used for the linear transformation of the recurrent state.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprecurrent_regularizer: Regularizer function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `recurrent_kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_constraint: Constraint function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprecurrent_constraint: Constraint function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `recurrent_kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_constraint: Constraint function applied to the bias vector.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdropout: Float between 0 and 1.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the inputs.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprecurrent_dropout: Float between 0 and 1.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the recurrent state.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault: `orthogonal`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector. Default: `zeros`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to the `kernel` weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprecurrent_regularizer: Regularizer function applied to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`recurrent_kernel` weights matrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_constraint: Constraint function applied to the `kernel` weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprecurrent_constraint: Constraint function applied to the `recurrent_kernel`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights matrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_constraint: Constraint function applied to the bias vector. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdropout: Float between 0 and 1. Fraction of the units to drop for the linear</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptransformation of the inputs. Default: 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprecurrent_dropout: Float between 0 and 1. Fraction of the units to drop for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the recurrent state. Default: 0.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspCall arguments:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs: A 2D tensor.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstates: List of state tensors corresponding to the previous timestep.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs: A 2D tensor, with shape of `[batch, feature]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstates: A 2D tensor with shape of `[batch, units]`, which is the state from</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe previous time step. For timestep 0, the initial state provided by user</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be feed to cell.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptraining: Python boolean indicating whether the layer should behave in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining mode or in inference mode. Only relevant when `dropout` or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`recurrent_dropout` is used.
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExamples:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspinputs = np.random.random([32, 10, 8]).astype(np.float32)</span>
<br><span style="color:green">+&nbsp &nbsprnn = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(4))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspoutput = rnn(inputs)  # The output has shape `[32, 4]`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsprnn = tf.keras.layers.RNN(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf.keras.layers.SimpleRNNCell(4),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_sequences=True,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_state=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp# whole_sequence_output has shape `[32, 10, 4]`.</span>
<br><span style="color:green">+&nbsp &nbsp# final_state has shape `[32, 4]`.</span>
<br><span style="color:green">+&nbsp &nbspwhole_sequence_output, final_state = rnn(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>@@ -1151,6 +1270,7 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(SimpleRNNCell, self).__init__(**kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.units = units
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.activation = activations.get(activation)
<br>@@ -1175,25 +1295,29 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdefault_caching_device = _caching_device(self)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(input_shape[-1], self.units),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.kernel_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.kernel_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.units, self.units),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='recurrent_kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.recurrent_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.recurrent_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.units,),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='bias',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.bias_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.bias_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>@@ -1261,41 +1385,47 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbspclass SimpleRNN(RNN):
<br>&nbsp &nbsp &nbsp"""Fully-connected RNN where the output is to be fed back to input.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)</span>
<br><span style="color:green">+&nbsp &nbspfor details about the usage of RNN API.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArguments:
<br>&nbsp &nbsp &nbsp &nbsp &nbspunits: Positive integer, dimensionality of the output space.
<br>&nbsp &nbsp &nbsp &nbsp &nbspactivation: Activation function to use.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault: hyperbolic tangent (`tanh`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you pass None, no activation is applied
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(ie. "linear" activation: `a(x) = x`).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspuse_bias: Boolean, (default `True`), whether the layer uses a bias vector.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for the linear transformation of the inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for the linear transformation of the inputs. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`glorot_uniform`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsprecurrent_initializer: Initializer for the `recurrent_kernel`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights matrix,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for the linear transformation of the recurrent state.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprecurrent_regularizer: Regularizer function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `recurrent_kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspactivity_regularizer: Regularizer function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe output of the layer (its "activation")..</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_constraint: Constraint function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprecurrent_constraint: Constraint function applied to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `recurrent_kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_constraint: Constraint function applied to the bias vector.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights matrix, used for the linear transformation of the recurrent state.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault: `orthogonal`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector. Default: `zeros`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to the `kernel` weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprecurrent_regularizer: Regularizer function applied to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`recurrent_kernel` weights matrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspactivity_regularizer: Regularizer function applied to the output of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplayer (its "activation"). Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_constraint: Constraint function applied to the `kernel` weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix. Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprecurrent_constraint: Constraint function applied to the `recurrent_kernel`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights matrix.  Default: `None`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_constraint: Constraint function applied to the bias vector. Default:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdropout: Float between 0 and 1.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for the linear transformation of the inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault: 0.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout: Float between 0 and 1.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the recurrent state.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the units to drop for the linear transformation of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent state. Default: 0.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn_sequences: Boolean. Whether to return the last output
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the output sequence, or the full sequence.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the output sequence, or the full sequence. Default: `False`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn_state: Boolean. Whether to return the last state
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin addition to the output.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspin addition to the output. Default: `False`</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspgo_backwards: Boolean (default False).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf True, process the input sequence backwards and return the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreversed sequence.
<br>@@ -1310,8 +1440,8 @@ class SimpleRNN(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnrolling is only suitable for short sequences.
<br>&nbsp
<br>&nbsp &nbsp &nbspCall arguments:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs: A 3D tensor.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmask: Binary tensor of shape `(samples, timesteps)` indicating whether</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs: A 3D tensor, with shape `[batch, timesteps, feature]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmask: Binary tensor of shape `[batch, timesteps]` indicating whether</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa given timestep should be masked.
<br>&nbsp &nbsp &nbsp &nbsp &nbsptraining: Python boolean indicating whether the layer should behave in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining mode or in inference mode. This argument is passed to the cell
<br>@@ -1319,6 +1449,22 @@ class SimpleRNN(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`recurrent_dropout` is used.
<br>&nbsp &nbsp &nbsp &nbsp &nbspinitial_state: List of initial state tensors to be passed to the first
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcall of the cell.
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExamples:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspinputs = np.random.random([32, 10, 8]).astype(np.float32)</span>
<br><span style="color:green">+&nbsp &nbspsimple_rnn = tf.keras.layers.SimpleRNN(4)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspoutput = simple_rnn(inputs)  # The output has shape `[32, 4]`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspsimple_rnn = tf.keras.layers.SimpleRNN(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp4, return_sequences=True, return_state=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp# whole_sequence_output has shape `[32, 10, 4]`.</span>
<br><span style="color:green">+&nbsp &nbsp# final_state has shape `[32, 4]`.</span>
<br><span style="color:green">+&nbsp &nbspwhole_sequence_output, final_state = simple_rnn(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>@@ -1362,7 +1508,9 @@ class SimpleRNN(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_constraint=recurrent_constraint,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbias_constraint=bias_constraint,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=dropout,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=recurrent_dropout)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=recurrent_dropout,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=kwargs.get('dtype'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=kwargs.get('trainable', True))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(SimpleRNN, self).__init__(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_sequences=return_sequences,
<br>@@ -1375,8 +1523,7 @@ class SimpleRNN(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = [InputSpec(ndim=3)]
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs, mask=None, training=None, initial_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_dropout_mask()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_recurrent_dropout_mask()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._maybe_reset_cell_dropout_mask(self.cell)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn super(SimpleRNN, self).call(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, mask=mask, training=training, initial_state=initial_state)
<br>&nbsp
<br>@@ -1554,6 +1701,7 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation=1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_after=False,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(GRUCell, self).__init__(**kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.units = units
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.activation = activations.get(activation)
<br>@@ -1574,7 +1722,11 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.dropout = min(1., max(0., dropout))
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_dropout = min(1., max(0., recurrent_dropout))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.implementation = implementation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.recurrent_dropout != 0 and implementation != 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.debug(RECURRENT_DROPOUT_WARNING_MSG)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = implementation</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.reset_after = reset_after
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.state_size = self.units
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.output_size = self.units
<br>@@ -1582,18 +1734,21 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_dim = input_shape[-1]
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdefault_caching_device = _caching_device(self)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(input_dim, self.units * 3),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.kernel_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.kernel_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.units, self.units * 3),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='recurrent_kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.recurrent_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.recurrent_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self.reset_after:
<br>@@ -1608,7 +1763,8 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='bias',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.bias_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.bias_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>@@ -1686,12 +1842,7 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# biases: bias_z_i, bias_r_i, bias_h_i
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_x = K.bias_add(matrix_x, input_bias)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z = matrix_x[:, :self.units]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_r = matrix_x[:, self.units: 2 * self.units]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_h = matrix_x[:, 2 * self.units:]</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0. < self.recurrent_dropout < 1.:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1 = h_tm1 * rec_dp_mask[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z, x_r, x_h = array_ops.split(matrix_x, 3, axis=-1)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# hidden state projected by all gate matrices at once
<br>@@ -1702,14 +1853,14 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# hidden state projected separately for update/reset and new
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = K.dot(h_tm1, self.recurrent_kernel[:, :2 * self.units])
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z = matrix_inner[:, :self.units]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r = matrix_inner[:, self.units:2 * self.units]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z, recurrent_r, recurrent_h = array_ops.split(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner, [self.units, self.units, -1], axis=-1)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = self.recurrent_activation(x_z + recurrent_z)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = self.recurrent_activation(x_r + recurrent_r)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = r * matrix_inner[:, 2 * self.units:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = r * recurrent_h</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = K.dot(r * h_tm1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel[:, 2 * self.units:])
<br>@@ -1827,7 +1978,7 @@ class GRU(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspefficient because it avoids transposes at the beginning and end of the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRNN calculation. However, most TensorFlow data is batch-major, so by
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault this function accepts input and emits output in batch-major
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform. </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspform.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreset_after: GRU convention (whether to apply reset gate after or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbefore matrix multiplication). False = "before" (default),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrue = "after" (CuDNN compatible).
<br>@@ -1890,7 +2041,9 @@ class GRU(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=dropout,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=recurrent_dropout,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation=implementation,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_after=reset_after)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_after=reset_after,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=kwargs.get('dtype'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=kwargs.get('trainable', True))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(GRU, self).__init__(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_sequences=return_sequences,
<br>@@ -1903,8 +2056,7 @@ class GRU(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = [InputSpec(ndim=3)]
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs, mask=None, training=None, initial_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_dropout_mask()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_recurrent_dropout_mask()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._maybe_reset_cell_dropout_mask(self.cell)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn super(GRU, self).call(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, mask=mask, training=training, initial_state=initial_state)
<br>&nbsp
<br>@@ -2103,6 +2255,7 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation=1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(LSTMCell, self).__init__(**kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.units = units
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.activation = activations.get(activation)
<br>@@ -2124,7 +2277,11 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.dropout = min(1., max(0., dropout))
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_dropout = min(1., max(0., recurrent_dropout))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.implementation = implementation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.recurrent_dropout != 0 and implementation != 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.debug(RECURRENT_DROPOUT_WARNING_MSG)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = implementation</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# tuple(_ListWrapper) was silently dropping list content in at least 2.7.10,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# and fixed after 2.7.16. Converting the state_size to wrapper around
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# NoDependency(), so that the base_layer.__setattr__ will not convert it to
<br>@@ -2136,19 +2293,22 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdefault_caching_device = _caching_device(self)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_dim = input_shape[-1]
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(input_dim, self.units * 4),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.kernel_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.kernel_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.kernel_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel = self.add_weight(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.units, self.units * 4),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='recurrent_kernel',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.recurrent_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.recurrent_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.recurrent_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.unit_forget_bias:
<br>@@ -2166,7 +2326,8 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='bias',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=bias_initializer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.bias_regularizer,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.bias_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcaching_device=default_caching_device)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>@@ -2244,8 +2405,6 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0. < self.dropout < 1.:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = inputs * dp_mask[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = K.dot(inputs, self.kernel)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0. < self.recurrent_dropout < 1.:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1 = h_tm1 * rec_dp_mask[0]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz += K.dot(h_tm1, self.recurrent_kernel)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = K.bias_add(z, self.bias)
<br>@@ -2516,7 +2675,9 @@ class LSTM(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbias_constraint=bias_constraint,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=dropout,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=recurrent_dropout,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation=implementation)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation=implementation,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=kwargs.get('dtype'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=kwargs.get('trainable', True))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(LSTM, self).__init__(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_sequences=return_sequences,
<br>@@ -2529,8 +2690,7 @@ class LSTM(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = [InputSpec(ndim=3)]
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs, mask=None, training=None, initial_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_dropout_mask()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.cell.reset_recurrent_dropout_mask()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._maybe_reset_cell_dropout_mask(self.cell)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn super(LSTM, self).call(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, mask=mask, training=training, initial_state=initial_state)
<br>&nbsp
<br>@@ -2754,3 +2914,50 @@ def _generate_zero_filled_state(batch_size_tensor, state_size, dtype):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn nest.map_structure(create_zeros, state_size)
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn create_zeros(state_size)
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _caching_device(rnn_cell):</span>
<br><span style="color:green">+&nbsp &nbsp"""Returns the caching device for the RNN variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspThis is useful for distributed training, when variable is not located as same</span>
<br><span style="color:green">+&nbsp &nbspdevice as the training worker. By enabling the device cache, this allows</span>
<br><span style="color:green">+&nbsp &nbspworker to read the variable once and cache locally, rather than read it every</span>
<br><span style="color:green">+&nbsp &nbsptime step from remote when it is needed.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspNote that this is assuming the variable that cell needs for each time step is</span>
<br><span style="color:green">+&nbsp &nbsphaving the same value in the forward path, and only gets updated in the</span>
<br><span style="color:green">+&nbsp &nbspbackprop. It is true for all the default cells (SimpleRNN, GRU, LSTM). If the</span>
<br><span style="color:green">+&nbsp &nbspcell body relies on any variable that gets updated every time step, then</span>
<br><span style="color:green">+&nbsp &nbspcaching device will cause it to read the stall value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprnn_cell: the rnn cell instance.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspif context.executing_eagerly():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# caching_device is not supported in eager mode.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn None</span>
<br><span style="color:green">+&nbsp &nbspif not getattr(rnn_cell, '_enable_caching_device', False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn None</span>
<br><span style="color:green">+&nbsp &nbsp# Don't set a caching device when running in a loop, since it is possible that</span>
<br><span style="color:green">+&nbsp &nbsp# train steps could be wrapped in a tf.while_loop. In that scenario caching</span>
<br><span style="color:green">+&nbsp &nbsp# prevents forward computations in loop iterations from re-reading the</span>
<br><span style="color:green">+&nbsp &nbsp# updated weights.</span>
<br><span style="color:green">+&nbsp &nbspif control_flow_util.IsInWhileLoop(ops.get_default_graph()):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging.warn('Variable read device caching has been disabled because the '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'RNN is in tf.while_loop loop context, which will cause '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'reading stalled value in forward path. This could slow down '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the training due to duplicated variable reads. Please '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'consider updating your code to remove tf.while_loop if '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'possible.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn None</span>
<br><span style="color:green">+&nbsp &nbspif rnn_cell._dtype_policy.should_cast_variables:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging.warn('Variable read device caching has been disabled since it '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'doesn\'t work with the mixed precision API. This is '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'likely to cause a slowdown for RNN training due to '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'duplicated read of variable for each timestep, which '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'will be significant in a multi remote worker setting. '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Please consider disabling mixed precision API if '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the performance has been affected.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn None</span>
<br><span style="color:green">+&nbsp &nbsp# Cache the value on the device that access the variable.</span>
<br><span style="color:green">+&nbsp &nbspreturn lambda op: op.device</span>
<br></p>
</div>
<br><br><br>_____________________________________tensorflow/python/keras/engine/input_layer.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26283</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>535</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>528</td>
      <td>keras.Input</td>
      <td>tensorflow/python/keras/engine/input_layer.py</td>
    </tr>
    <tr>
      <th>26292</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>536</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>528</td>
      <td>keras.Input</td>
      <td>tensorflow/python/keras/engine/input_layer.py</td>
    </tr>
    <tr>
      <th>26323</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>610</td>
      <td>keras.Input</td>
      <td>tensorflow/python/keras/engine/input_layer.py</td>
    </tr>
    <tr>
      <th>26329</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>610</td>
      <td>keras.Input</td>
      <td>tensorflow/python/keras/engine/input_layer.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/engine/input_layer.py b/tensorflow/python/keras/engine/input_layer.py
<br>index 2440448c62a..bae50419939 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/engine/input_layer.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/engine/input_layer.py</span>
<br>@@ -25,6 +25,7 @@ from tensorflow.python.keras import backend
<br>&nbspfrom tensorflow.python.keras.distribute import distributed_training_utils
<br>&nbspfrom tensorflow.python.keras.engine import base_layer
<br>&nbspfrom tensorflow.python.keras.engine import node as node_module
<br><span style="color:green">+from tensorflow.python.keras.saving.saved_model import layer_serialization</span>
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbsp
<br>@@ -71,8 +72,8 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif strategy and batch_size is not None and \
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistributed_training_utils.global_batch_size_supported(strategy):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_size % strategy.num_replicas_in_sync != 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument value {} cannot be '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'divisible by number of replicas {}'.format(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument ({}) must be divisible by '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the number of replicas ({})'.format(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size, strategy.num_replicas_in_sync))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = batch_size // strategy.num_replicas_in_sync
<br>&nbsp
<br>@@ -102,6 +103,7 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(InputLayer, self).__init__(dtype=dtype, name=name)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.sparse = sparse
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.ragged = ragged</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.batch_size = batch_size
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.supports_masking = True
<br>&nbsp
<br>@@ -152,10 +154,15 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_input_shape': self._batch_input_shape,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dtype': self.dtype,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sparse': self.sparse,
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': self.ragged,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'name': self.name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp}
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn config
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@property</span>
<br><span style="color:green">+&nbsp &nbspdef _trackable_saved_model_saver(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn layer_serialization.InputLayerSavedModelSaver(self)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbsp@keras_export('keras.layers.Input', 'keras.Input')
<br>&nbspdef Input(  # pylint: disable=invalid-name
<br>@@ -204,7 +211,8 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues of 'None' in the 'shape' argument represent ragged dimensions.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor more information about RaggedTensors, see
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/guide/ragged_tensors.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: deprecated arguments support.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: deprecated arguments support. Supports `batch_shape` and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`batch_input_shape`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspA `tensor`.
<br>@@ -235,15 +243,21 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Cannot set both sparse and ragged to True in a Keras input.')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspbatch_shape = None</span>
<br><span style="color:red">- &nbsp &nbspif 'batch_shape' in kwargs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbatch_shape = kwargs.pop('batch_shape')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif shape and batch_shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Only provide the shape OR '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_shape argument to '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Input, not both at the same time.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbatch_size = batch_shape[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshape = batch_shape[1:]</span>
<br><span style="color:green">+&nbsp &nbspinput_layer_config = {'name': name, 'dtype': dtype, 'sparse': sparse,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': ragged, 'input_tensor': tensor}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspbatch_input_shape = kwargs.pop('batch_input_shape',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs.pop('batch_shape', None))</span>
<br><span style="color:green">+&nbsp &nbspif shape and batch_input_shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspraise ValueError('Only provide the `shape` OR `batch_input_shape` argument '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to Input, not both at the same time.')</span>
<br><span style="color:green">+&nbsp &nbspif batch_input_shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape = batch_input_shape[1:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinput_layer_config.update({'batch_input_shape': batch_input_shape})</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinput_layer_config.update(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp{'batch_size': batch_size, 'input_shape': shape})</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspif kwargs:
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Unrecognized keyword arguments:', kwargs.keys())
<br>&nbsp
<br>@@ -253,23 +267,7 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`shape` does not include the batch '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dimension.')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspif batch_shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinput_layer = InputLayer(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_input_shape=batch_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse=sparse,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged=ragged,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor=tensor)</span>
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinput_layer = InputLayer(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape=shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=batch_size,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse=sparse,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged=ragged,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor=tensor)</span>
<br><span style="color:green">+&nbsp &nbspinput_layer = InputLayer(**input_layer_config)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp# Return tensor including `_keras_history`.
<br>&nbsp &nbsp &nbsp# Note that in this case train_output and test_output are the same pointer.
<br></p>
</div>
<br><br><br>_____________________________________tensorflow/python/keras/engine/training.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26322</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>613</td>
      <td>keras.models.Model</td>
      <td>tensorflow/python/keras/engine/training.py</td>
    </tr>
    <tr>
      <th>26327</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>613</td>
      <td>keras.models.Model</td>
      <td>tensorflow/python/keras/engine/training.py</td>
    </tr>
    <tr>
      <th>26328</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>633</td>
      <td>keras.models.Model</td>
      <td>tensorflow/python/keras/engine/training.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/engine/training.py b/tensorflow/python/keras/engine/training.py
<br>index 44b938d1235..78c4feb7be9 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/engine/training.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/engine/training.py</span>
<br>@@ -19,17 +19,15 @@ from __future__ import division
<br>&nbspfrom __future__ import print_function
<br>&nbsp
<br>&nbspimport collections
<br><span style="color:red">- import json</span>
<br>&nbspimport numpy as np
<br>&nbsp
<br><span style="color:red">- from tensorflow.python import tf2</span>
<br>&nbspfrom tensorflow.python.data.ops import dataset_ops
<br>&nbspfrom tensorflow.python.data.ops import iterator_ops
<br><span style="color:red">- from tensorflow.python.distribute import distribution_strategy_context</span>
<br><span style="color:red">- from tensorflow.python.distribute import multi_worker_util</span>
<br><span style="color:green">+from tensorflow.python.distribute import distribution_strategy_context as ds_context</span>
<br>&nbspfrom tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.eager import def_function
<br>&nbspfrom tensorflow.python.eager import monitoring
<br><span style="color:green">+from tensorflow.python.framework import composite_tensor</span>
<br>&nbspfrom tensorflow.python.framework import composite_tensor_utils
<br>&nbspfrom tensorflow.python.framework import constant_op
<br>&nbspfrom tensorflow.python.framework import ops
<br>@@ -44,14 +42,16 @@ from tensorflow.python.keras import metrics as metrics_module
<br>&nbspfrom tensorflow.python.keras import optimizers
<br>&nbspfrom tensorflow.python.keras.distribute import distributed_training_utils
<br>&nbspfrom tensorflow.python.keras.engine import network
<br><span style="color:red">- from tensorflow.python.keras.engine import training_arrays</span>
<br>&nbspfrom tensorflow.python.keras.engine import training_distributed
<br><span style="color:red">- from tensorflow.python.keras.engine import training_eager</span>
<br><span style="color:red">- from tensorflow.python.keras.engine import training_generator</span>
<br>&nbspfrom tensorflow.python.keras.engine import training_utils
<br><span style="color:red">- from tensorflow.python.keras.saving import saving_utils</span>
<br><span style="color:green">+from tensorflow.python.keras.engine import training_v2</span>
<br><span style="color:green">+from tensorflow.python.keras.engine import training_v2_utils</span>
<br><span style="color:green">+from tensorflow.python.keras.mixed_precision.experimental import loss_scale_optimizer</span>
<br><span style="color:green">+from tensorflow.python.keras.optimizer_v2 import optimizer_v2</span>
<br><span style="color:green">+from tensorflow.python.keras.saving.saved_model import model_serialization</span>
<br>&nbspfrom tensorflow.python.keras.utils import data_utils
<br>&nbspfrom tensorflow.python.keras.utils import losses_utils
<br><span style="color:green">+from tensorflow.python.keras.utils import version_utils</span>
<br>&nbspfrom tensorflow.python.keras.utils.mode_keys import ModeKeys
<br>&nbspfrom tensorflow.python.ops import array_ops
<br>&nbspfrom tensorflow.python.ops import math_ops
<br>@@ -59,8 +59,8 @@ from tensorflow.python.ops.losses import util as tf_losses_utils
<br>&nbspfrom tensorflow.python.platform import tf_logging as logging
<br>&nbspfrom tensorflow.python.training.tracking import base as trackable
<br>&nbspfrom tensorflow.python.training.tracking import layer_utils as trackable_layer_utils
<br><span style="color:green">+from tensorflow.python.util import deprecation</span>
<br>&nbspfrom tensorflow.python.util import nest
<br><span style="color:red">- from tensorflow.python.util import serialization</span>
<br>&nbspfrom tensorflow.python.util import tf_inspect
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbsp
<br>@@ -74,7 +74,7 @@ _keras_api_gauge = monitoring.BoolGauge('/tensorflow/api/keras',
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.models.Model', 'keras.Model')
<br><span style="color:red">- class Model(network.Network):</span>
<br><span style="color:green">+class Model(network.Network, version_utils.VersionSelector):</span>
<br>&nbsp &nbsp &nbsp"""`Model` groups layers into an object with training and inference features.
<br>&nbsp
<br>&nbsp &nbsp &nbspThere are two ways to instantiate a `Model`:
<br>@@ -140,14 +140,14 @@ class Model(network.Network):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self, *args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(Model, self).__init__(*args, **kwargs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# initializing _distribution_strategy here since it is possible to call</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# predict on a model without compiling it.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._distribution_strategy = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# This flag is used to track if the user is using the deprecated path of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# passing distribution strategy to compile rather than creating the model</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# under distribution strategy scope.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._compile_distribution = False</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('model').set(True)</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Model must be created under scope of DistStrat it will be trained with.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif ds_context.has_strategy():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = ds_context.get_strategy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Defaults to value of `tf.config.experimental_functions_run_eagerly`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._run_eagerly = None
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_weights(self):
<br>@@ -156,30 +156,70 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA flat list of Numpy arrays.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith self._distribution_strategy.scope():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn super(Model, self).get_weights()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn super(Model, self).get_weights()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith self.distribute_strategy.scope():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn super(Model, self).get_weights()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef load_weights(self, filepath, by_name=False, skip_mismatch=False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf `by_name` is False weights are loaded based on the network's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptopology. This means the architecture should be the same as when the weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwere saved.  Note that layers that don't have weights are not taken into</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaccount in the topological ordering, so adding or removing layers is fine as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplong as they don't have weights.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf `by_name` is True, weights are loaded into layers only if they share the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsame name. This is useful for fine-tuning or transfer-learning models where</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsome of the layers have changed.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspOnly topological loading (`by_name=False`) is supported when loading weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom the TensorFlow format. Note that topological loading differs slightly</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbetween TensorFlow and HDF5 formats for user-defined classes inheriting from</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTensorFlow format loads based on the object-local names of attributes to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhich layers are assigned in the `Model`'s constructor.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArguments:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfilepath: String, path to the weights file to load. For weight files in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensorFlow format, this is the file prefix (the same as was passed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto `save_weights`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspby_name: Boolean, whether to load weights by name or by topological</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporder. Only topological loading is supported for weight files in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensorFlow format.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspskip_mismatch: Boolean, whether to skip loading of layers where there is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa mismatch in the number of weights, or a mismatch in the shape of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe weight (only valid when `by_name=True`).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen loading a weight file in TensorFlow format, returns the same status</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobject as `tf.train.Checkpoint.restore`. When graph building, restore</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspops are run automatically as soon as the network is built (on first call</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor user-defined classes inheriting from `Model`, immediately if it is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalready built).</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef load_weights(self, filepath, by_name=False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Loads all layer weights, either from a TensorFlow or an HDF5 file."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen loading weights in HDF5 format, returns `None`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspImportError: If h5py is not available and the weight file is in HDF5</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspformat.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`False`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif distributed_training_utils.is_tpu_strategy(self._distribution_strategy):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy.extended.steps_per_run > 1 and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(not network._is_hdf5_filepath(filepath))):  # pylint: disable=protected-access
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Load weights is not yet supported with TPUStrategy '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'with steps_per_run greater than 1.')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn super(Model, self).load_weights(filepath, by_name)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn super(Model, self).load_weights(filepath, by_name, skip_mismatch)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@trackable.no_automatic_dependency_tracking
<br>&nbsp &nbsp &nbspdef compile(self,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer='rmsprop',</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_weights=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribute=None,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Configures the model for training.
<br>&nbsp
<br>@@ -187,10 +227,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer: String (name of optimizer) or optimizer instance.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `tf.keras.optimizers`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss: String (name of objective function), objective function or
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.losses.Loss` instance. See `tf.losses`. If the model has</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple outputs, you can use a different loss on each output by</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppassing a dictionary or a list of losses. The loss value that will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe minimized by the model will then be the sum of all individual</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction is any callable with the signature</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`scalar_loss = fn(y_true, y_pred)`. If the model has multiple</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs, you can use a different loss on each output by passing a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdictionary or a list of losses. The loss value that will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspminimized by the model will then be the sum of all individual</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplosses.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics: List of metrics to be evaluated by the model during training
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand testing. Typically you will use `metrics=['accuracy']`.
<br>@@ -217,56 +259,15 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdictionary or a list of modes.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics: List of metrics to be evaluated and weighted
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspby sample_weight or class_weight during training and testing.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors: By default, Keras will create placeholders for the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel's target, which will be fed with the target data during</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining. If instead you would like to use your own</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget tensors (in turn, Keras will not expect external</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumpy data for these targets at training time), you</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan specify them via the `target_tensors` argument. It can be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa single tensor (for a single-output model), a list of tensors,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor a dict mapping output names to target tensors.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribute: NOT SUPPORTED IN TF 2.0, please create and compile the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel under distribution strategy scope instead of passing it to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompile.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: Any additional arguments.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspRaises:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of invalid arguments for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`optimizer`, `loss`, `metrics` or `sample_weight_mode`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('compile').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._validate_compile(optimizer, **kwargs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._run_eagerly = kwargs.pop('run_eagerly', None)
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif distribute is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif tf2.enabled():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Distribute argument in compile is not available in TF 2.0 please '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'create the model under the distribution strategy scope.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('Distribute argument in compile is deprecated please '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'create the model under the distribution strategy scope.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = distribute</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._compile_distribution = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif distribution_strategy_context.has_strategy():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When the user builds the model in the DS scope and cross replica</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# context we want distribution strategy to be set but when building the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# replica copies of the models internally we should not be compiling</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# with distribution strategy and use the default compilation path.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif distribution_strategy_context.in_cross_replica_context():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy_context.get_strategy())</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Check whether the experimental feature of distributing the Model without</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# cloning is requested.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(b/124517980, b/124377929): Remove this temporary undocumented way</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# of enabling the feature and graduate it to the main distributed code path.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._cloning = kwargs.pop('cloning', False)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._validate_compile_param_for_distribution_strategy(self.run_eagerly,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.optimizer = optimizers.get(optimizer)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._set_optimizer(optimizer)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# We've disabled automatic dependency tracking for this method, but do want
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# to add a checkpoint dependency on the optimizer if it's trackable.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self.optimizer, trackable.Trackable):
<br>@@ -277,10 +278,6 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.sample_weight_mode = sample_weight_mode
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._compile_metrics = metrics or []
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._compile_weighted_metrics = weighted_metrics
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly and target_tensors is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'target_tensors argument is not supported when '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'running a model eagerly.')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# _training_endpoints contains a list of _TrainingEndpoint object, which has
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# all the model output/target/loss and related metadata.
<br>@@ -293,11 +290,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._distributed_model_cache = {}
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._distributed_function_cache = {}
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (not context.executing_eagerly() and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy is not None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Ensures a Session is created and configured correctly for Distribution</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Strategy.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.configure_and_create_distributed_session(self._distribution_strategy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Clear any `_eager_losses` cached from a previous `Model.__call__`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._clear_losses()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Initialize model metric attributes.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._init_metric_attributes()
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.built or not self.inputs or not self.outputs:
<br>@@ -306,13 +301,13 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# time the model gets called on training data.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._is_compiled = True
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('compile').set(True)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Prepare list of loss functions, same size of model outputs.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.loss_functions = training_utils.prepare_loss_functions(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.loss, self.output_names)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptarget_tensors = self._process_target_tensor_for_compile(target_tensors)</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptarget_tensors = self._process_target_tensor_for_compile(None)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor o, n, l, t in zip(self.outputs, self.output_names,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.loss_functions, target_tensors):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint = _TrainingEndpoint(o, n, l)
<br>@@ -351,8 +346,6 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Functions for train, test and predict will
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# be compiled lazily when required.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This saves time when the user is not using all functions.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._function_kwargs = kwargs</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.train_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.test_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.predict_function = None
<br>@@ -360,20 +353,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Collected trainable weights, sorted in topological order.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._collected_trainable_weights = self.trainable_weights
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Validate all variables were correctly created in distribution scope.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._distribution_strategy and not self._compile_distribution:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor v in self.variables:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrategy = self._distribution_strategy</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not strategy.extended.variable_created_in_scope(v):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Variable (%s) was not created in the distribution strategy '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scope of (%s). It is most likely due to not all layers or '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the model or optimizer being created outside the distribution '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'strategy scope. Try to make sure your code looks similar '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to the following.\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'with strategy.scope():\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'  model=_create_model()\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'  model.compile(...)'% (v, strategy))</span>
<br><span style="color:green">+&nbsp &nbsp@trackable.no_automatic_dependency_tracking</span>
<br><span style="color:green">+&nbsp &nbspdef _init_distributed_function_cache_if_not_compiled(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not hasattr(self, '_distributed_function_cache'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distributed_function_cache = {}</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbspdef metrics(self):
<br>@@ -388,6 +371,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbspdef metrics_names(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Returns the model's display labels for all outputs."""
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# This property includes all output names including `loss` and per-output</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# losses for backward compatibility.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmetrics_names = ['loss']
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._is_compiled:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Add output loss metric names to the metric names list.
<br>@@ -398,15 +384,17 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not e.should_skip_target()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp])
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Add compile metrics/weighted metrics' names to the metric names list.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics_names.extend([m.name for m in self._compile_metric_functions])</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Add metric names from layers.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor layer in self.layers:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics_names += [m.name for m in layer._metrics]  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmetrics_names += [m.name for m in self._metrics]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Add all metric names.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmetrics_names += [m.name for m in self.metrics]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn metrics_names
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@property</span>
<br><span style="color:green">+&nbsp &nbspdef distribute_strategy(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""The `tf.distribute.Strategy` this model was created under."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._distribution_strategy is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ds_context._get_default_strategy()  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self._distribution_strategy</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbspdef run_eagerly(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Settable attribute indicating whether the model should run eagerly.
<br>@@ -452,27 +440,23 @@ class Model(network.Network):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _select_training_loop(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Select training loop for fit/eval/predict based on the inputs."""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Case 1: distribution strategy.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif multi_worker_util.in_multi_worker_mode():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_distributed.DistributionMultiWorkerTrainingLoop()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_distributed.DistributionSingleWorkerTrainingLoop()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Case 2: generator-like. Input is Python generator, or Sequence object,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# or a non-distributed Dataset or iterator in eager execution.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif data_utils.is_generator_or_sequence(inputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_generator.GeneratorOrSequenceTrainingLoop()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif training_utils.is_eager_dataset_or_iterator(inputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_generator.EagerDatasetOrIteratorTrainingLoop()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Case 3: Symbolic tensors or Numpy array-like.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# This includes Datasets and iterators in graph mode (since they</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# generate symbolic tensors).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_generator.GeneratorLikeTrainingLoop()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TODO(kaftan) or TODO(scottzhu): This check should eventually be nicely</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#  integrated into the data adapters in the v2 loop. We can't do this yet</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#  because we currently have to fall back for unhandled data types.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(inputs, (iterator_ops.Iterator,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.OwnedIterator)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('For performance reasons Keras `fit`, `evaluate` and'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`predict` accept tf.data `Datasets` as input but not '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'iterators that have been manually generated from '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Datasets by users. Please directly pass in the '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'original `Dataset` object instead of passing in '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`iter(dataset)`.')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._in_multi_worker_mode():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_distributed.DistributionMultiWorkerTrainingLoop(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_v2.Loop())</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_arrays.ArrayLikeTrainingLoop()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn training_v2.Loop()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef fit(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx=None,
<br>@@ -504,22 +488,24 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the model has named inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator. Should return a tuple</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset. Should return a tuple</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof either `(inputs, targets)` or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(inputs, targets, sample_weights)`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A generator or `keras.utils.Sequence` returning `(inputs, targets)`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `(inputs, targets, sample weights)`.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA more detailed description of unpacking behavior for iterator types</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Dataset, generator, Sequence) is given below.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit could be either Numpy array(s) or TensorFlow tensor(s).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt should be consistent with `x` (you cannot have Numpy inputs and
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset, dataset</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator, generator, or `keras.utils.Sequence` instance, `y` should</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset, generator,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `keras.utils.Sequence` instance, `y` should</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot be specified (since targets will be obtained from `x`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Integer or `None`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of samples per gradient update.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `batch_size` will default to 32.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDo not specify the `batch_size` if your data is in the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, dataset, dataset iterators,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, datasets,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerators, or `keras.utils.Sequence` instances (since they generate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepochs: Integer. Number of epochs to train the model.
<br>@@ -546,7 +532,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspon this data at the end of each epoch.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe validation data is selected from the last samples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the `x` and `y` data provided, before shuffling. This argument is
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot supported when `x` is a dataset, dataset iterator, generator or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot supported when `x` is a dataset, generator or</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` instance.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_data: Data on which to evaluate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe loss and any model metrics at the end of each epoch.
<br>@@ -555,9 +541,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_data` could be:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- tuple `(x_val, y_val)` of Numpy arrays or tensors
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- dataset or a dataset iterator</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- dataset</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor the first two cases, `batch_size` must be provided.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor the last case, `validation_steps` must be provided.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor the last case, `validation_steps` could be provided.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Boolean (whether to shuffle the training data
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbefore each epoch) or str (for 'batch').
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch' is a special option for dealing with the
<br>@@ -580,7 +567,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto apply a different weight to every timestep of every sample.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn this case you should make sure to specify
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`sample_weight_mode="temporal"` in `compile()`. This argument is not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset, dataset iterator, generator, or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset, generator, or</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` instance, instead provide the sample_weights
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas the third element of `x`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_epoch: Integer.
<br>@@ -593,19 +580,23 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensorFlow data tensors, the default `None` is equal to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe number of samples in your dataset divided by
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe batch size, or 1 if that cannot be determined. If x is a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.data` dataset or a dataset iterator, and 'steps_per_epoch'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.data` dataset, and 'steps_per_epoch'</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis None, the epoch will run until the input dataset is exhausted.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis argument is not supported with array inputs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_steps: Only relevant if `validation_data` is provided and
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis a dataset or dataset iterator. Total number of steps (batches of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis a `tf.data` dataset. Total number of steps (batches of</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsamples) to draw before stopping when performing validation
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspat the end of every epoch. If validation_data is a `tf.data` dataset</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor a dataset iterator, and 'validation_steps' is None, validation</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill run until the `validation_data` dataset is exhausted.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspat the end of every epoch. If 'validation_steps' is None, validation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill run until the `validation_data` dataset is exhausted. In the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcase of a infinite dataset, it will run into a infinite loop.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf 'validation_steps' is specified and only part of the dataset</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be consumed, the evaluation will start from the beginning of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe dataset at each epoch. This ensures that the same validation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsamples are used every time.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_freq: Only relevant if validation data is provided. Integer
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `collections.Container` instance (e.g. list, tuple, etc.). If an</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinteger, specifies how many training epochs to run before a new</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation run is performed, e.g. `validation_freq=2` runs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf an integer, specifies how many training epochs to run before a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew validation run is performed, e.g. `validation_freq=2` runs</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation every 2 epochs. If a Container, specifies the epochs on
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich to run validation, e.g. `validation_freq=[1, 2, 10]` runs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation at the end of the 1st, 2nd, and 10th epochs.
<br>@@ -625,6 +616,30 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe generator as they can't be passed easily to children processes.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: Used for backwards compatibility.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUnpacking behavior for iterator-like inputs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA common pattern is to pass a tf.data.Dataset, generator, or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspyield not only features (x) but optionally targets (y) and sample weights.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspKeras requires that the output of such iterator-likes be unambiguous. The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator should return a tuple of length 1, 2, or 3, where the optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsecond and third elements will be used for y and sample_weight</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprespectively. Any other type provided will be wrapped in a length one</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptuple, effectively treating everything as 'x'. When yielding dicts, they</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspshould still adhere to the top-level tuple structure.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspe.g. `({"x0": x0, "x1": x1}, y)`. Keras will not attempt to separate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeatures, targets, and weights from the keys of a single dict.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA notable unsupported data type is the namedtuple. The reason is that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspit behaves like both an ordered datatype (tuple) and a mapping</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdatatype (dict). So given a namedtuple of the form:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`namedtuple("example_tuple", ["y", "x"])`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspit is ambiguous whether to reverse the order of the elements when</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpreting the value. Even worse is a tuple of the form:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`namedtuple("other_tuple", ["x", "y", "z"])`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhere it is unclear if the tuple was intended to be unpacked into x, y,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspand sample_weight or passed through as a single element to `x`. As a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult the data processing code will simply raise a ValueError if it</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspencounters a namedtuple. (Along with instructions to remedy the issue.)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA `History` object. Its `History.history` attribute is
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa record of training loss values and metrics values
<br>@@ -636,7 +651,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of mismatch between the provided input data
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand what the model expects.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('train').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('fit').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Legacy graph support is contained in `training_v1.Model`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'fit')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Legacy support
<br>&nbsp &nbsp &nbsp &nbsp &nbspif 'nb_epoch' in kwargs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning(
<br>@@ -645,6 +662,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif kwargs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('Unrecognized keyword arguments: ' + str(kwargs))
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('fit')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunc = self._select_training_loop(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn func.fit(
<br>@@ -691,20 +709,23 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the model has named inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A generator or `keras.utils.Sequence` instance.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA more detailed description of unpacking behavior for iterator types</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Dataset, generator, Sequence) is given in the `Unpacking behavior</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor iterator-like inputs` section of `Model.fit`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit could be either Numpy array(s) or TensorFlow tensor(s).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt should be consistent with `x` (you cannot have Numpy inputs and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `x` is a dataset, dataset iterator, generator or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `x` is a dataset, generator or</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` instance, `y` should not be specified (since
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptargets will be obtained from the iterator/dataset).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Integer or `None`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of samples per gradient update.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `batch_size` will default to 32.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDo not specify the `batch_size` is your data is in the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, dataset, dataset iterators,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDo not specify the `batch_size` if your data is in the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, dataset,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerators, or `keras.utils.Sequence` instances (since they generate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: 0 or 1. Verbosity mode.
<br>@@ -720,13 +741,13 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto apply a different weight to every timestep of every sample.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn this case you should make sure to specify
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`sample_weight_mode="temporal"` in `compile()`. This argument is not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset or a dataset iterator, instead pass</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset, instead pass</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample weights as the third element of `x`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps: Integer or `None`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTotal number of steps (batches of samples)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbefore declaring the evaluation round finished.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIgnored with the default value of `None`.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf x is a `tf.data` dataset or a dataset iterator, and `steps` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf x is a `tf.data` dataset and `steps` is</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNone, 'evaluate' will run until the dataset is exhausted.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis argument is not supported with array inputs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of `keras.callbacks.Callback` instances.
<br>@@ -746,6 +767,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiprocessing, you should not pass non-picklable arguments to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe generator as they can't be passed easily to children processes.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee the discussion of `Unpacking behavior for iterator-like inputs` for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`Model.fit`.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScalar test loss (if the model has a single output and no metrics)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor list of scalars (if the model has multiple outputs
<br>@@ -756,7 +780,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: in case of invalid arguments.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('evaluate').set(True)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'evaluate')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('evaluate')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunc = self._select_training_loop(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn func.evaluate(
<br>@@ -791,20 +817,23 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A TensorFlow tensor, or a list of tensors
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A generator or `keras.utils.Sequence` instance.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA more detailed description of unpacking behavior for iterator types</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Dataset, generator, Sequence) is given in the `Unpacking behavior</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor iterator-like inputs` section of `Model.fit`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Integer or `None`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of samples per gradient update.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `batch_size` will default to 32.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDo not specify the `batch_size` is your data is in the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, dataset, dataset iterators,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDo not specify the `batch_size` if your data is in the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspform of symbolic tensors, dataset,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerators, or `keras.utils.Sequence` instances (since they generate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: Verbosity mode, 0 or 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps: Total number of steps (batches of samples)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbefore declaring the prediction round finished.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIgnored with the default value of `None`. If x is a `tf.data`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset or a dataset iterator, and `steps` is None, `predict` will</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset and `steps` is None, `predict` will</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun until the input dataset is exhausted.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of `keras.callbacks.Callback` instances.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of callbacks to apply during prediction.
<br>@@ -823,6 +852,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiprocessing, you should not pass non-picklable arguments to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe generator as they can't be passed easily to children processes.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee the discussion of `Unpacking behavior for iterator-like inputs` for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`Model.fit`. Note that Model.predict uses the same interpretation rules as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthree methods.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumpy array(s) of predictions.
<br>@@ -834,6 +867,8 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat is not a multiple of the batch size.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('predict').set(True)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'predict')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('predict')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunc = self._select_training_loop(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn func.predict(
<br>@@ -853,10 +888,6 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor m in metrics:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm.reset_states()
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Reset metrics on all the distributed (cloned) models.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistributed_training_utils._reset_metrics(self)  # pylint: disable=protected-access</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef train_on_batch(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=None,
<br>@@ -873,11 +904,11 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the model has named inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`, it could be either Numpy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray(s) or TensorFlow tensor(s). It should be consistent with `x`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(you cannot have Numpy inputs and tensor targets, or inversely). If
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`x` is a dataset or a dataset iterator, `y` should not be specified</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`x` is a dataset, `y` should not be specified</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(since targets will be obtained from the iterator).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight: Optional array of the same length as x, containing
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights to apply to the model's loss for each sample. In the case of
<br>@@ -885,7 +916,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsequence_length), to apply a different weight to every timestep of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspevery sample. In this case you should make sure to specify
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode="temporal" in compile(). This argument is not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight: Optional dictionary mapping class indices (integers) to a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweight (float) to apply to the model's loss for the samples from this
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass during training. This can be useful to tell the model to "pay
<br>@@ -905,45 +936,20 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of invalid user-provided arguments.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If at this point we are in the replica context, then it is okay to execute</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# the Eager code path.  The expected way to get here is to call `fit` that</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# calls `train_on_batch` on each replica.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy_context.in_cross_replica_context()):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`train_on_batch` is not supported for models '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'distributed with tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate and standardize user data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx, y, sample_weights = self._standardize_user_data(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, y, sample_weight=sample_weight, class_weight=class_weight,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspextract_tensors_from_dataset=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If `self._distribution_strategy` is True, then we are in a replica context</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# at this point because of the check above.  `train_on_batch` is being run</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# for each replica by `self._distribution_strategy` and the same code path</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# as Eager is expected to be taken.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly or self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = training_eager.train_on_batch(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights=sample_weights,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_loss_metrics=self._output_loss_metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = training_utils.ModelInputs(x).as_list()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspins = x + (y or []) + (sample_weights or [])</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(K.symbolic_learning_phase(), int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspins += [True]  # Add learning phase value.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._update_sample_weight_modes(sample_weights=sample_weights)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._make_train_function()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = self.train_function(ins)  # pylint: disable=not-callable</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif reset_metrics:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.reset_metrics()</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('train_on_batch')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = training_v2_utils.train_on_batch(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=y,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight=sample_weight,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight=class_weight,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_metrics=reset_metrics,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstandalone=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = [training_v2_utils._non_none_constant_value(v) for v in outputs]  # pylint: disable=protected-access</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(outputs) == 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn outputs[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = outputs[0]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn outputs
<br>&nbsp
<br>&nbsp &nbsp &nbspdef test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True):
<br>@@ -957,13 +963,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the model has named inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit could be either Numpy array(s) or TensorFlow tensor(s).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt should be consistent with `x` (you cannot have Numpy inputs and
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset or a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset iterator, `y` should not be specified</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(since targets will be obtained from the iterator).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset `y` should</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot be specified (since targets will be obtained from the iterator).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight: Optional array of the same length as x, containing
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights to apply to the model's loss for each sample.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn the case of temporal data, you can pass a 2D array
<br>@@ -971,7 +976,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto apply a different weight to every timestep of every sample.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn this case you should make sure to specify
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode="temporal" in compile(). This argument is not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupported when `x` is a dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_metrics: If `True`, the metrics returned will be only for this
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch. If `False`, the metrics will be statefully accumulated across
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches.
<br>@@ -986,36 +991,19 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of invalid user-provided arguments.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy_context.in_cross_replica_context()):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`test_on_batch` is not supported for models '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'distributed with tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate and standardize user data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx, y, sample_weights = self._standardize_user_data(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If `self._distribution_strategy` is True, then we are in a replica context</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# at this point.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly or self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = training_eager.test_on_batch(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights=sample_weights,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_loss_metrics=self._output_loss_metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = training_utils.ModelInputs(x).as_list()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = x + (y or []) + (sample_weights or [])</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._update_sample_weight_modes(sample_weights=sample_weights)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._make_test_function()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = self.test_function(inputs)  # pylint: disable=not-callable</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif reset_metrics:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.reset_metrics()</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('test_on_batch')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = training_v2_utils.test_on_batch(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=y,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight=sample_weight,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_metrics=reset_metrics,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstandalone=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = [training_v2_utils._non_none_constant_value(v) for v in outputs]  # pylint: disable=protected-access</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(outputs) == 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn outputs[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = outputs[0]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn outputs
<br>&nbsp
<br>&nbsp &nbsp &nbspdef predict_on_batch(self, x):
<br>@@ -1027,7 +1015,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A TensorFlow tensor, or a list of tensors
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumpy array(s) of predictions.
<br>@@ -1036,32 +1024,11 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of mismatch between given number of inputs and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpectations of the model.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy_context.in_cross_replica_context()):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`predict_on_batch` is not supported for models distributed with'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate and standardize user data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs, _, _ = self._standardize_user_data(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, extract_tensors_from_dataset=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If `self._distribution_strategy` is True, then we are in a replica context</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# at this point.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly or self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = training_utils.cast_if_floating_dtype(inputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(inputs, collections.Sequence):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Unwrap lists with only one input, as we do when training on batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(inputs) == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = inputs[0]</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self(inputs)  # pylint: disable=not-callable</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._make_predict_function()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs = self.predict_function(inputs)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif len(outputs) == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn outputs[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('predict_on_batch')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn training_v2_utils.predict_on_batch(self, x, standalone=True)</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@deprecation.deprecated(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspNone, 'Please use Model.fit, which supports generators.')</span>
<br>&nbsp &nbsp &nbspdef fit_generator(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=None,
<br>@@ -1079,108 +1046,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_epoch=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Fits the model on data yielded batch-by-batch by a Python generator.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe generator is run in parallel to the model, for efficiency.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspFor instance, this allows you to do real-time data augmentation</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspon images on CPU in parallel to training your model on GPU.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe use of `keras.utils.Sequence` guarantees the ordering</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspand guarantees the single use of every input per epoch when</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspusing `use_multiprocessing=True`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspArguments:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator: A generator or an instance of `Sequence`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(`keras.utils.Sequence`)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobject in order to avoid duplicate data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using multiprocessing.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe output of the generator must be either</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- a tuple `(inputs, targets)`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- a tuple `(inputs, targets, sample_weights)`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis tuple (a single output of the generator) makes a single batch.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTherefore, all arrays in this tuple must have the same length (equal</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto the size of this batch). Different batches may have different</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsizes.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor example, the last batch of the epoch is commonly smaller than</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspothers, if the size of the dataset is not divisible by the batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe generator is expected to loop over its data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindefinitely. An epoch finishes when `steps_per_epoch`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches have been seen by the model.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch: Total number of steps (batches of samples)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto yield from `generator` before declaring one epoch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfinished and starting the next epoch. It should typically</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe equal to the number of samples of your dataset</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdivided by the batch size.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOptional for `Sequence`: if unspecified, will use</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `len(generator)` as a number of steps.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepochs: Integer, total number of iterations on the data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: Verbosity mode, 0, 1, or 2.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of callbacks to be called during training.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_data: This can be either</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- a generator for the validation data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- a tuple (inputs, targets)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- a tuple (inputs, targets, sample_weights).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_steps: Only relevant if `validation_data`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis a generator. Total number of steps (batches of samples)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto yield from `generator` before stopping.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOptional for `Sequence`: if unspecified, will use</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `len(validation_data)` as a number of steps.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_freq: Only relevant if validation data is provided. Integer</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `collections.Container` instance (e.g. list, tuple, etc.). If an</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinteger, specifies how many training epochs to run before a new</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation run is performed, e.g. `validation_freq=2` runs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation every 2 epochs. If a Container, specifies the epochs on</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation at the end of the 1st, 2nd, and 10th epochs.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight: Dictionary mapping class indices to a weight</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor the class.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size: Integer. Maximum size for the generator queue.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `max_queue_size` will default to 10.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Maximum number of processes to spin up</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `workers` will default to 1. If 0, will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexecute the generator on the main thread.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `True`, use process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `use_multiprocessing` will default to `False`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that because this implementation relies on multiprocessing,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspyou should not pass non-picklable arguments to the generator</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas they can't be passed easily to children processes.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Boolean. Whether to shuffle the order of the batches at</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe beginning of each epoch. Only used with instances</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof `Sequence` (`keras.utils.Sequence`).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspHas no effect when `steps_per_epoch` is not `None`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_epoch: Epoch at which to start training</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(useful for resuming a previous training run)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA `History` object.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExample:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp```python</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef generate_arrays_from_file(path):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = open(path)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor line in f:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# create numpy arrays of input data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# and labels, from each line in the file</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx1, x2, y = process_line(line)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspyield ({'input_1': x1, 'input_2': x2}, {'output': y})</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf.close()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=10000, epochs=10)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp```</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case the generator yields data in an invalid format.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDEPRECATED:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Model.fit` now supports generators, so there is no longer any need to use</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis endpoint.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`fit_generator` is not supported for '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'models compiled with tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('train').set(True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn training_generator.fit_generator(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('fit_generator').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self.fit(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=steps_per_epoch,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepochs=epochs,
<br>@@ -1194,9 +1065,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers=workers,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing=use_multiprocessing,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle=shuffle,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_epoch=initial_epoch,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_name='steps_per_epoch')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_epoch=initial_epoch)</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@deprecation.deprecated(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspNone, 'Please use Model.evaluate, which supports generators.')</span>
<br>&nbsp &nbsp &nbspdef evaluate_generator(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps=None,
<br>@@ -1207,53 +1079,14 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Evaluates the model on a data generator.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe generator should return the same kind of data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspas accepted by `test_on_batch`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspArguments:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator: Generator yielding tuples (inputs, targets)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor (inputs, targets, sample_weights)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor an instance of `keras.utils.Sequence`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobject in order to avoid duplicate data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using multiprocessing.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps: Total number of steps (batches of samples)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto yield from `generator` before stopping.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOptional for `Sequence`: if unspecified, will use</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `len(generator)` as a number of steps.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of `keras.callbacks.Callback` instances.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of callbacks to apply during evaluation.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size: maximum size for the generator queue</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Maximum number of processes to spin up</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `workers` will default to 1. If 0, will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexecute the generator on the main thread.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `True`, use process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `use_multiprocessing` will default to `False`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that because this implementation relies on multiprocessing,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspyou should not pass non-picklable arguments to the generator</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas they can't be passed easily to children processes.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: Verbosity mode, 0 or 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScalar test loss (if the model has a single output and no metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor list of scalars (if the model has multiple outputs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand/or metrics). The attribute `model.metrics_names` will give you</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe display labels for the scalar outputs.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: in case of invalid arguments.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case the generator yields data in an invalid format.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDEPRECATED:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Model.evaluate` now supports generators, so there is no longer any need</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspto use this endpoint.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`evaluate_generator` is not supported for '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'models compiled with tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('evaluate').set(True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn training_generator.evaluate_generator(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('evaluate_generator').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_call_args('evaluate_generator')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self.evaluate(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps=steps,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size=max_queue_size,
<br>@@ -1262,6 +1095,8 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose=verbose,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks=callbacks)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@deprecation.deprecated(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspNone, 'Please use Model.predict, which supports generators.')</span>
<br>&nbsp &nbsp &nbspdef predict_generator(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps=None,
<br>@@ -1272,45 +1107,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Generates predictions for the input samples from a data generator.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe generator should return the same kind of data as accepted by</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`predict_on_batch`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspArguments:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator: Generator yielding batches of input samples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor an instance of `keras.utils.Sequence` object in order to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspavoid duplicate data when using multiprocessing.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps: Total number of steps (batches of samples)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto yield from `generator` before stopping.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOptional for `Sequence`: if unspecified, will use</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `len(generator)` as a number of steps.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of `keras.callbacks.Callback` instances.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of callbacks to apply during prediction.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size: Maximum size for the generator queue.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Maximum number of processes to spin up</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `workers` will default to 1. If 0, will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexecute the generator on the main thread.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `True`, use process-based threading.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf unspecified, `use_multiprocessing` will default to `False`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that because this implementation relies on multiprocessing,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspyou should not pass non-picklable arguments to the generator</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas they can't be passed easily to children processes.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: verbosity mode, 0 or 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumpy array(s) of predictions.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case the generator yields data in an invalid format.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDEPRECATED:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Model.predict` now supports generators, so there is no longer any need</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspto use this endpoint.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`predict_generator` is not supported for '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'models compiled with tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('predict').set(True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn training_generator.predict_generator(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_keras_api_gauge.get_cell('predict_generator').set(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self.predict(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps=steps,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size=max_queue_size,
<br>@@ -1319,6 +1121,108 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose=verbose,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks=callbacks)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _check_call_args(self, method_name):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Check that `call` has only one positional arg."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Always allow first arg, regardless of arg name.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfullargspec = self._call_full_argspec</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif fullargspec.defaults:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsppositional_args = fullargspec.args[:-len(fullargspec.defaults)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsppositional_args = fullargspec.args</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif 'training' in positional_args:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsppositional_args.remove('training')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# self and first arg can be positional.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif len(positional_args) > 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspextra_args = positional_args[2:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Models passed to `' + method_name + '` can only have `training` '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'and the first argument in `call` as positional arguments, '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'found: ' + str(extra_args) + '.')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _set_optimizer(self, optimizer):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Sets self.optimizer.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSets self.optimizer to `optimizer`, potentially wrapping it with a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspLossScaleOptimizer.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer: The optimizer(s) to assign to self.optimizer.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(optimizer, (list, tuple)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.optimizer = [optimizers.get(opt) for opt in optimizer]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.optimizer = optimizers.get(optimizer)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (self._dtype_policy.loss_scale is not None and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot isinstance(self.optimizer,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_scale_optimizer.LossScaleOptimizer)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self.optimizer, list):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('When a dtype policy with a loss scale is used, you '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'can only pass a single optimizer. Using policy %s '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'and got optimizers: %s' %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dtype_policy, self.optimizer)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(self.optimizer, optimizer_v2.OptimizerV2):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('"optimizer" must be an instance of '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tf.keras.optimizers.Optimizer when a dype policy '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'with a loss scale  used, but got: %s. Using policy: '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'%s' %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.optimizer, self._dtype_policy))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.optimizer = loss_scale_optimizer.LossScaleOptimizer(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.optimizer, self._dtype_policy.loss_scale)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (isinstance(self.optimizer, loss_scale_optimizer.LossScaleOptimizer) and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dtype_policy.loss_scale and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.optimizer.loss_scale != self._dtype_policy.loss_scale):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('LossScale of LossScaleOptimizer passed to compile (%s) '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'is not the same as the dtype policy\'s loss scale (%s). '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Because the dtype policy has a loss scale, you should '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'pass an optimizer that is not wrapped with a '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'LossScaleOptimizer,'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp% (self.optimizer.loss_scale,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dtype_policy.loss_scale))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _validate_compile(self, optimizer, **kwargs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Performs validation checks for the default `compile`."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_any_keras_optimizer_v1 = any(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(isinstance(opt, optimizers.Optimizer) and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot isinstance(opt, optimizers.TFOptimizer))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor opt in nest.flatten(optimizer))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif is_any_keras_optimizer_v1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`tf.compat.v1.keras` Optimizer (', optimizer, ') is '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'not supported when eager execution is enabled. Use a '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`tf.keras` Optimizer instead, or disable eager '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'execution.')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkwargs.pop('cloning', None)  # Legacy DistStrat argument, never used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkwargs.pop('experimental_run_tf_function', None)  # Always `True`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif kwargs.pop('distribute', None) is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Distribute argument in compile is not available in TF 2.0 please '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'create the model under the distribution strategy scope.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif kwargs.pop('target_tensors', None) is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'target_tensors argument is not supported when executing eagerly.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinvalid_kwargs = set(kwargs) - {'run_eagerly'}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif invalid_kwargs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('Invalid keyword argument(s) in `compile`: %s' %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(invalid_kwargs,))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Model must be created and compiled with the same DistStrat.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.built and ds_context.has_strategy():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrategy = ds_context.get_strategy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor v in self.variables:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not strategy.extended.variable_created_in_scope(v):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Variable (%s) was not created in the distribution strategy '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scope of (%s). It is most likely due to not all layers or '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the model or optimizer being created outside the distribution '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'strategy scope. Try to make sure your code looks similar '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to the following.\n'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'with strategy.scope():\n'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'  model=_create_model()\n'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'  model.compile(...)' % (v, strategy))</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspdef _prepare_validation_data(self, validation_data, batch_size,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_steps):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Unpack and check the validation data."""
<br>@@ -1332,40 +1236,14 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps=validation_steps,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_name='validation_steps')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef _validate_compile_param_for_distribution_strategy(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself, run_eagerly, sample_weight_mode, target_tensors, weighted_metrics):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate that arguments passed by the user to `compile` are supported by</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# tf.distribute.Strategy.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._distribution_strategy:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif sample_weight_mode:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('sample_weight_mode is not supported with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif weighted_metrics:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('weighted_metrics is not supported with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tf.distribute.Strategy.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif target_tensors:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('target_tensors is not supported with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tf.distribute.Strategy.')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif run_eagerly:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'We currently do not support enabling `run_eagerly` with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'distribution strategy.')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (distributed_training_utils.is_distributing_by_cloning(self) and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(not self.built or not self.inputs or not self.outputs)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'We currently do not support distribution strategy with a '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`Sequential` model that is created without `input_shape`/'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`input_dim` set in its first layer or a subclassed model.')</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef _process_target_tensor_for_compile(self, target_tensors):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.run_eagerly:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# target tensor is not supported with run_eagerly. Create a list with None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# as placeholder for each output.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn [None for _ in self.output_names]
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif target_tensors not in (None, []):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif target_tensors is not None and not (isinstance(target_tensors, list) and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors == []):  # pylint: disable=g-explicit-bool-comparison</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(target_tensors, list):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(target_tensors) != len(self.outputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>@@ -1415,14 +1293,19 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbspdef _update_sample_weight_modes(self, sample_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Updates sample weight modes based on training/eval inputs.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSample weight placeholders will be created for all or no outputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbased on whether sample_weight is provided for any output.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf model contains `_sample_weight_modes` we check if the input
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`sample_weights` corresponds to the sample weight modes.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1. If sample weight mode for output i is 'temporal', we do not</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspchange it as the `temporal` mode has been set by the user.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2. Set sample weight mode to be 'samplewise' for output i if sample</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweight mode was not set before and sample weight inputs are given.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1. Set sample weight mode to be 'temporal' for output i, if `compile`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode was set to `temporal` and sample weight inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare given for one or more outputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2. Set sample weight mode to be 'samplewise' for output i, if `compile`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode was not set and sample weight inputs are given for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspone or more outputs.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp3. Reset sample weight mode to None for output i if sample weight mode
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwas set to 'samplewise' but there is no sample weight input.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwas set but there is no sample weight input.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights: List of sample weights of the same length as model outputs
<br>@@ -1430,21 +1313,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self._is_compiled:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif not sample_weights:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights = [None] * len(self._training_endpoints)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor endpoint, sample_weight in zip(self._training_endpoints,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif endpoint.sample_weight_mode == 'temporal':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If sample weight mode for endpoint is 'temporal', do nothing.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontinue</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif endpoint.sample_weight_mode is None and sample_weight is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Set sample weight mode to be 'samplewise' for output i if sample</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# weight mode was not set before and sample weight inputs are given.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.sample_weight_mode = 'samplewise'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif (endpoint.sample_weight_mode == 'samplewise' and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight is None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Reset sample weight mode to None for output i if sample weight mode</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# was set to 'samplewise' but there is no sample weight input.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif sample_weights and any([s is not None for s in sample_weights]):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor endpoint in self._training_endpoints:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.sample_weight_mode = (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.sample_weight_mode or 'samplewise')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor endpoint in self._training_endpoints:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.sample_weight_mode = None
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _recompile_weights_loss_and_weighted_metrics(self):
<br>@@ -1574,6 +1448,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# differentiate between use case where a custom optimizer
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# expects a vector loss value vs unreduced per-sample loss value.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_loss = loss_fn(y_true, y_pred, sample_weight=sample_weight)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_reduction = losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(self.outputs) > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Keep track of stateful result tensor for the loss.
<br>@@ -1581,9 +1456,7 @@ class Model(network.Network):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Scale output loss for distribution. For custom losses we assume
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# reduction was mean.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (getattr(loss_fn, 'reduction',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplosses_utils.ReductionV2.SUM_OVER_BATCH_SIZE) ==</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplosses_utils.ReductionV2.SUM_OVER_BATCH_SIZE):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif loss_reduction == losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_loss = losses_utils.scale_loss_for_distribution(output_loss)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif total_loss is None:
<br>@@ -1620,13 +1493,6 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.callback_model
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn self
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef _make_callback_model(self, grouped_model):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfirst_replicated_model = self._distribution_strategy.unwrap(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgrouped_model)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# We initialize the callback model with the first replicated model.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._replicated_model = DistributedCallbackModel(first_replicated_model)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._replicated_model.set_original_model(self)</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef _validate_or_infer_batch_size(self, batch_size, steps, x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Validates that the `batch_size` provided is consistent with InputLayer.
<br>&nbsp
<br>@@ -1648,31 +1514,41 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe validated batch_size, auto-inferred from the first layer if not
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprovided.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif batch_size is not None and isinstance(x, dataset_ops.DatasetV2):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument must not be specified when'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' using dataset as an input.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (isinstance(x, (dataset_ops.DatasetV1,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset_ops.DatasetV2,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_utils.Sequence)) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_inspect.isgenerator(x)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_size is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'The `batch_size` argument must not be specified for the given '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'input type. Received input: {}, batch_size: {}'.format(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, batch_size))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplayers = super(Model, self).layers  # Avoids the override in Sequential.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif layers:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfirst_layer = layers[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Avoids the override in Sequential.layers which filters Input layers.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (Which are often the very layers that we're after.)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplayers = trackable_layer_utils.filter_empty_layer_containers(self._layers)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfirst_layer = next(layers, None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif first_layer:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# The per-replica static batch size.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatic_batch_size = training_utils.get_static_batch_size(first_layer)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif static_batch_size is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsplit_batch_size = self._distribution_strategy and \</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Determine number of times the user-supplied batch size will be split.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy and</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistributed_training_utils.global_batch_size_supported(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif split_batch_size:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_replicas = self._distribution_strategy.num_replicas_in_sync</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_splits_for_ds = self._distribution_strategy.num_replicas_in_sync</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_splits_for_ds = 1</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check `batch_size` argument is consistent with InputLayer.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_size is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif split_batch_size:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_size % num_replicas != 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument value {} cannot be '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'divisible by number of replicas {}'.format(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size, num_replicas))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspper_replica_batch_size = batch_size // num_replicas</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspper_replica_batch_size = batch_size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_size % num_splits_for_ds != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument ({}) must be divisible '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the by number of replicas ({})'.format(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size, num_splits_for_ds))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspper_replica_batch_size = batch_size // num_splits_for_ds</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif per_replica_batch_size != static_batch_size:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `batch_size` argument value {} is '
<br>@@ -1682,35 +1558,29 @@ class Model(network.Network):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check Dataset/Iterator batch size is consistent with InputLayer.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(x, (dataset_ops.DatasetV2, iterator_ops.Iterator,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.IteratorV2)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.OwnedIterator)):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_batch_size = tensor_shape.as_dimension(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnest.flatten(dataset_ops.get_legacy_output_shapes(x))[0][0]).value
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_batch_size is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif split_batch_size:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_batch_size % num_replicas != 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'The batch output shape of your `Dataset` {} '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'cannot be divisible by number of replicas {}'.format(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_batch_size, num_replicas))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_batch_size = ds_batch_size // num_replicas</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_batch_size != static_batch_size:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_batch_size % num_splits_for_ds != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'The batch output shape of your `Dataset` {} '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'cannot be divisible by number of replicas {}'.format(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_batch_size, num_splits_for_ds))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_per_replica_batch_size = ds_batch_size // num_splits_for_ds</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ds_per_replica_batch_size != static_batch_size:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The batch output shape of your `Dataset` is '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'{}, which is incompatible with the specified '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch size of your Input Layer: {}'.format(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_batch_size, static_batch_size))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspds_per_replica_batch_size,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatic_batch_size))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Set inferred batch size from the InputLayer.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif steps is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = static_batch_size</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (batch_size is None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand steps is None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand not isinstance(x, (dataset_ops.DatasetV2,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.Iterator,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.IteratorV2,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_utils.Sequence))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand not tf_inspect.isgenerator(x)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = static_batch_size * num_splits_for_ds</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif batch_size is None and steps is None:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Backwards compatibility
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = 32
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn batch_size
<br>@@ -1727,7 +1597,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights = [None] * len(self._training_endpoints)
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor endpoint, weight in zip(self._training_endpoints, sample_weights):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.populate_sample_weight(weight)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspendpoint.populate_sample_weight(weight, endpoint.sample_weight_mode)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _cache_output_metric_attributes(self, metrics, weighted_metrics):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Caches metric name and function attributes for every model output."""
<br>@@ -1932,6 +1802,9 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbspdef _make_train_function(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsphas_recompiled = self._recompile_weights_loss_and_weighted_metrics()
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._check_trainable_weights_consistency()
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(self.optimizer, list):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The `optimizer` in `compile` should be a single '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'optimizer.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# If we have re-compiled the loss/weighted metric sub-graphs then create
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# train function even if one exists already. This is because
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# `_feed_sample_weights` list has been updated on re-copmpile.
<br>@@ -1966,8 +1839,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfn = K.function(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, [self.total_loss] + metrics_tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdates=updates,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='train_function',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**self._function_kwargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='train_function')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsetattr(self, 'train_function', fn)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Restore the current trainable state
<br>@@ -1996,8 +1868,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfn = K.function(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, [self.total_loss] + metrics_tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdates=updates,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='test_function',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**self._function_kwargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='test_function')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsetattr(self, 'test_function', fn)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _make_predict_function(self):
<br>@@ -2077,20 +1948,6 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError('`sample_weight` is currently not supported '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'when using TPUStrategy.')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (self.stateful and distributed_training_utils.is_tpu_strategy(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy) and self._distribution_strategy.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_replicas_in_sync != 1):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Single core must be used for computation on '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'stateful models. Consider adding `device_assignment` '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'parameter to TPUStrategy using\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'topology = tf.contrib.distribute.'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'initialize_tpu_system()\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'device_assignment = tf.contrib.tpu.DeviceAssignment('</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'topology, core_assignment=tf.contrib.tpu.'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'SINGLE_CORE_ASSIGNMENT)\n'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tpu_strategy = tf.contrib.distribute.TPUStrategy('</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'device_assignment=device_assignment)')</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Validates `steps` and `shuffle` arguments right at the beginning
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# since we use it to construct the dataset object.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# TODO(anjalisridhar): Remove this check once we refactor the
<br>@@ -2111,12 +1968,11 @@ class Model(network.Network):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfirst_x_value = nest.flatten(x)[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(first_x_value, np.ndarray):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = distributed_training_utils.list_to_tuple(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = training_utils.list_to_tuple(x)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif y is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = distributed_training_utils.list_to_tuple(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = training_utils.list_to_tuple(y)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif sample_weight is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight = distributed_training_utils.list_to_tuple(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight = training_utils.list_to_tuple(sample_weight)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin_tuple = (x, y, sample_weight)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin_tuple = (x, y)
<br>@@ -2184,13 +2040,12 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(in case the model has multiple inputs).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the model has named inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset or a dataset iterator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data` dataset.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit could be either Numpy array(s) or TensorFlow tensor(s).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt should be consistent with `x` (you cannot have Numpy inputs and
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset or a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset iterator, `y` should not be specified</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(since targets will be obtained from the iterator).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor targets, or inversely). If `x` is a dataset, `y` should not be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspecified (since targets will be obtained from the iterator).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight: An optional sample-weight array passed by the user to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweight the importance of each sample in `x`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight: An optional class-weight array by the user to
<br>@@ -2253,134 +2108,24 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif check_steps:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.check_steps_argument(x, steps, steps_name)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# First, we build/compile the model on the fly if necessary.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspall_inputs = []</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis_build_called = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis_compile_called = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Whether this is a subclassed model that expects dictionary inputs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# rather than list inputs (e.g. FeatureColumn-based models).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdict_inputs = False</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# First, we build the model on the fly if necessary.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.inputs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We need to use `x_input` to set the model inputs.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If input data is a dataset iterator in graph mode or if it is an eager</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# iterator and only one batch of samples is required, we fetch the data</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# tensors from the iterator and then standardize them.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(x, (dataset_ops.DatasetV1, dataset_ops.DatasetV2)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_input, y_input, _ = training_utils.extract_tensors_from_dataset(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_input = x</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_input = y</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We type-check that `x_input` and `y_input` are either single arrays</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# or lists of arrays, and extract a flat list of inputs from the passed</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# structure.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(x_input, (list, tuple)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not all(isinstance(v, np.ndarray) or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor_util.is_tensor(v) for v in x_input):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Please provide as model inputs either a single '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'array or a list of arrays. You passed: x=' + str(x))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs += list(x_input)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif isinstance(x_input, dict):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdict_inputs = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeys = sorted(x_input.keys())</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs = [x_input[k] for k in keys]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (not isinstance(x_input, np.ndarray) and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot tensor_util.is_tensor(x_input)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Please provide as model inputs either a single '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'array or a list of arrays. You passed: x=' + str(x))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs.append(x_input)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Now that we have a flat set of inputs, we make sure that none of them</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# are CompositeTensors or CompositeTensorValues of any type (or scipy</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sparse arrays, which we treat as SparseTensor values). We cannot safely</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# infer input data from an arbitrary composite tensor, so we don't try -</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# users should explictly add composite tensor inputs to their subclassed</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# models.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor input_tensor in all_inputs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (composite_tensor_utils.is_composite_or_composite_value(input_tensor)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(b/132691975): Document subclass-model CT input handling.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'All SparseTensor and RaggedTensor inputs must be explicitly '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'declared using a keras.Input() with sparse=True or ragged=True. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'We found an undeclared input %s. For Sequential models, please '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'add a keras.Input() as your first Layer. For subclassed models, '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'please call self._add_inputs() on your input set, which you can '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'create using keras.Input() for each input to your model.' %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(input_tensor,))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Build the model using the retrieved inputs (value or symbolic).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If values or generated from a dataset, then in symbolic-mode</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# placeholders will be created to match the value shapes.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs, y_input, dict_inputs = self._build_model_with_inputs(x, y)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_build_called = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif is_dataset:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef create_tensor_spec(t):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tensor_spec.TensorSpec(t.shape, t.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = nest.map_structure(create_tensor_spec, x_input)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif training_utils.has_tensors(x_input):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = training_utils.cast_if_floating_dtype(x_input)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = x_input</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._set_inputs(cast_inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_input = y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Whether this is a subclassed model that expects dictionary inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# rather than list inputs (e.g. FeatureColumn-based models).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdict_inputs = isinstance(self.inputs, dict)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_build_called = False</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_input = y</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Second, we compile the model on the fly if necessary, mostly for subclass</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# models.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_compile_called = False</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self._is_compiled and self.optimizer:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# On-the-fly compilation of the model.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif y_input is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We need to use `y` to set the model targets.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif training_utils.has_tensors(y_input):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_input = training_utils.cast_if_floating_dtype(y_input)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(y_input, (list, tuple)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not all(isinstance(v, np.ndarray) or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor_util.is_tensor(v) for v in y_input):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Please provide as model targets either a single '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'array or a list of arrays. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'You passed: y=' + str(y))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs += list(y_input)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif isinstance(y_input, dict):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('You cannot pass a dictionary as model targets.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (not isinstance(y_input, np.ndarray) and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot tensor_util.is_tensor(y_input)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Please provide as model targets either a single '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'array or a list of arrays. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'You passed: y=' + str(y))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs.append(y_input)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Typecheck that all inputs are *either* value *or* symbolic.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(fchollet): this check could be removed in Eager mode?</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif any(tensor_util.is_tensor(v) for v in all_inputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not all(tensor_util.is_tensor(v) for v in all_inputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Do not pass inputs that mix Numpy arrays and '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'TensorFlow tensors. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'You passed: x=' + str(x) + '; y=' + str(y))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif is_dataset or context.executing_eagerly():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Handle target tensors if any passed.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif y_input is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(y_input, (list, tuple)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_input = [y_input]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = [v for v in y_input if _is_symbolic_tensor(v)]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._compile_from_inputs(all_inputs, y_input, x, y)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_compile_called = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.compile(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer=self.optimizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss=self.loss,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics=self._compile_metrics,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics=self._compile_weighted_metrics,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_weights=self.loss_weights,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors=target_tensors,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun_eagerly=self.run_eagerly,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcloning=self._cloning)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# In graph mode, if we had just set inputs and targets as symbolic tensors
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# by invoking build and compile on the model respectively, we do not have to
<br>@@ -2388,14 +2133,25 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# part of the graph.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Note: in this case, `any` and `all` are equivalent since we disallow
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# mixed symbolic/value inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (not self.run_eagerly and is_build_called and is_compile_called and</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# self.run_eagerly is not free to compute, so we want to reuse the value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprun_eagerly = self.run_eagerly</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (not run_eagerly and is_build_called and is_compile_called and</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot is_dataset  and any(_is_symbolic_tensor(v) for v in all_inputs)):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn [], [], None
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# What follows is input validation and standardization to list format,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# in the case where all inputs are value arrays.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self._standardize_tensors(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, y, sample_weight,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun_eagerly=run_eagerly,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdict_inputs=dict_inputs,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_dataset=is_dataset,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight=class_weight,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=batch_size)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.run_eagerly:</span>
<br><span style="color:green">+&nbsp &nbspdef _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_dataset, class_weight=None, batch_size=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif run_eagerly:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In eager mode, do not do shape validation
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# since the network has no input nodes (placeholders) to be fed.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_input_names = self.input_names
<br>@@ -2438,7 +2194,19 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor (a, b) in zip(flat_inputs, flat_expected_inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconverted_x.append(_convert_scipy_sparse_tensor(a, b))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = nest.pack_sequence_as(x, converted_x, expand_composites=False)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_shapes = nest.map_structure(type_spec.type_spec_from_value, x)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _type_spec_from_value(value):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Grab type_spec without converting array-likes to tensors."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(value, composite_tensor.CompositeTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn value._type_spec  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Get a TensorSpec for array-like data without</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# converting the data to a Tensor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(value, 'shape') and hasattr(value, 'dtype'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tensor_spec.TensorSpec(value.shape, value.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn type_spec.type_spec_from_value(value)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_shapes = nest.map_structure(_type_spec_from_value, x)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspflat_inputs = nest.flatten(x_shapes, expand_composites=False)
<br>&nbsp &nbsp &nbsp &nbsp &nbspflat_expected_inputs = nest.flatten(self.inputs, expand_composites=False)
<br>@@ -2446,16 +2214,16 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnest.assert_same_structure(a, b, expand_composites=True)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif y is not None:
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Prepare self._sample_weight_modes. List with the same length as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# model outputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.prepare_sample_weight_modes(self._training_endpoints,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.sample_weight_mode)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_output_names = self._feed_output_names</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_sample_weight_modes = self._sample_weight_modes</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._is_graph_network:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_output_names = self._feed_output_names</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_output_shapes = None
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Sample weighting not supported in this case.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(fchollet): consider supporting it.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_sample_weight_modes = [None for _ in self.outputs]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_output_names = self._feed_output_names</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_output_shapes = self._feed_output_shapes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_sample_weight_modes = self._sample_weight_modes</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Standardize the outputs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = training_utils.standardize_input_data(
<br>@@ -2473,6 +2241,7 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight, feed_output_names)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weights = training_utils.standardize_class_weights(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight, feed_output_names)
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights = [
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.standardize_weights(ref, sw, cw, mode)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,
<br>@@ -2481,24 +2250,18 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check that all arrays have the same length.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._distribution_strategy:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.check_array_lengths(x, y, sample_weights)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._is_graph_network and not self.run_eagerly:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._is_graph_network and not run_eagerly:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Additional checks to avoid users mistakenly using improper loss fns.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.check_loss_and_target_compatibility(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy, self._feed_loss_fns, feed_output_shapes)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If sample weight mode has not been set and weights are None for all the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# model outputs, return None (we do not create placeholders for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sample weights) so we do not want to feed any value.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_sample_weight_mode_set = any(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsps is not None for s in feed_sample_weight_modes)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (not is_sample_weight_mode_set and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall(s is None for s in sample_weights)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights = None  # If the list contains only None, return None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights, _, _ = training_utils.handle_partial_sample_weights(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy, sample_weights, feed_sample_weight_modes, check_all_flat=True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = []
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weights = None
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.stateful and batch_size:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.stateful and batch_size and not is_dataset:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check that for stateful networks, number of samples is a multiple
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# of the static batch size.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x[0].shape[0] % batch_size != 0:
<br>@@ -2514,6 +2277,112 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = dict(zip(feed_input_names, x))
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x, y, sample_weights
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _build_model_with_inputs(self, inputs, targets):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Build the model (set model inputs/outputs), mainly for subclass model."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprocessed_inputs = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_dict_inputs = False</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsporig_inputs = inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We need to use `inputs` to set the model inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If input data is a dataset iterator in graph mode or if it is an eager</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# iterator and only one batch of samples is required, we fetch the data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# tensors from the iterator and then standardize them.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(inputs, (dataset_ops.DatasetV1, dataset_ops.DatasetV2)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, targets, _ = training_utils.extract_tensors_from_dataset(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We type-check that `inputs` and `targets` are either single arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# or lists of arrays, and extract a flat list of inputs from the passed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# structure.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptraining_utils.validate_input_types(inputs, orig_inputs)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(inputs, (list, tuple)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprocessed_inputs += list(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif isinstance(inputs, dict):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_dict_inputs = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeys = sorted(inputs.keys())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprocessed_inputs = [inputs[k] for k in keys]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprocessed_inputs.append(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Now that we have a flat set of inputs, we make sure that none of them</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# are CompositeTensors or CompositeTensorValues of any type (or scipy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# sparse arrays, which we treat as SparseTensor values). We cannot safely</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# infer input data from an arbitrary composite tensor, so we don't try -</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# users should explicitly add composite tensor inputs to their subclassed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# models.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor input_tensor in processed_inputs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif composite_tensor_utils.is_composite_or_composite_value(input_tensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(b/132691975): Document subclass-model CT input handling.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'All SparseTensor and RaggedTensor inputs must be explicitly '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'declared using a keras.Input() with sparse=True or ragged=True. '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'We found an undeclared input %s. For Sequential models, please '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'add a keras.Input() as your first Layer. For subclassed models, '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'please call self._set_inputs() on your input set, which you can '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'create using keras.Input() for each input to your model.' %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(input_tensor,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Build the model using the retrieved inputs (value or symbolic).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If values are generated from a dataset, then in symbolic-mode</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# placeholders will be created to match the value shapes.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(orig_inputs, (dataset_ops.DatasetV1, dataset_ops.DatasetV2,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.Iterator)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self.inputs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# For subclassed models, a robust input spec is not available so we</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# must cast to the model dtype.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = training_utils.cast_if_floating_dtype(inputs, self.dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef create_tensor_spec(t):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tensor_spec.TensorSpec(t.shape, t.dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = nest.map_structure(create_tensor_spec, inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif training_utils.has_tensors(inputs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = training_utils.cast_if_floating_dtype(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcast_inputs = inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._set_inputs(cast_inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn processed_inputs, targets, is_dict_inputs</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _compile_from_inputs(self, all_inputs, target, orig_inputs, orig_target):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif target is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We need to use `y` to set the model targets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif training_utils.has_tensors(target):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget = training_utils.cast_if_floating_dtype_and_mismatch(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget, self.outputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.validate_input_types(target, orig_target,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspallow_dict=False, field_name='target')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(target, (list, tuple)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs += list(target)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_inputs.append(target)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Type check that all inputs are *either* value *or* symbolic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TODO(fchollet): this check could be removed in Eager mode?</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif any(tensor_util.is_tensor(v) for v in all_inputs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not all(tensor_util.is_tensor(v) for v in all_inputs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Do not pass inputs that mix Numpy arrays and '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'TensorFlow tensors. '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'You passed: x=' + str(orig_inputs) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'; y=' + str(orig_target))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_dataset = isinstance(orig_inputs, (dataset_ops.DatasetV1,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataset_ops.DatasetV2,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator_ops.Iterator))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif is_dataset or context.executing_eagerly():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Handle target tensors if any passed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif target is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(target, (list, tuple)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget = [target]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = [v for v in target if _is_symbolic_tensor(v)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors = None</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.compile(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer=self.optimizer,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss=self.loss,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics=self._compile_metrics,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics=self._compile_weighted_metrics,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_weights=self.loss_weights,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptarget_tensors=target_tensors,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight_mode=self.sample_weight_mode,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun_eagerly=self.run_eagerly)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp# TODO(omalleyt): Consider changing to a more descriptive function name.
<br>&nbsp &nbsp &nbspdef _set_inputs(self, inputs, outputs=None, training=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Set model's input and output specs based on the input data received.
<br>@@ -2583,6 +2452,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = (None,) + tuple(inputs.shape[1:])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._build_input_shape = input_shape
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Cast inputs to the compute dtype. This is primarily used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# when saving to determine the correct dtype in the input signature.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs = self._maybe_cast_inputs(inputs)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# On-the-fly setting of symbolic model inputs (either by using the tensor
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# provided, or by creating a placeholder if Numpy data was provided).
<br>&nbsp &nbsp &nbsp &nbsp &nbspmodel_inputs = training_utils.ModelInputs(inputs)
<br>@@ -2605,6 +2478,8 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp@trackable.no_automatic_dependency_tracking
<br>&nbsp &nbsp &nbspdef _set_output_attrs(self, outputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Sets attributes related to the outputs of the Model."""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# NOTE(taylorrobie): This convention cannot be changed without updating the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#                    data adapter since it assumes nest.flatten ordering.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutputs = nest.flatten(outputs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.outputs = outputs
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.output_names = training_utils.generic_output_names(outputs)
<br>@@ -2706,23 +2581,10 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbspadd_metric metrics.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspmetrics = []
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif getattr(self, '_output_loss_metrics', None) is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics.extend(self._output_loss_metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif hasattr(self, 'metrics'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics.extend(self.metrics)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmetrics.extend(getattr(self, '_output_loss_metrics', None) or [])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmetrics.extend(getattr(self, 'metrics', None) or [])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn metrics
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp@property</span>
<br><span style="color:red">- &nbsp &nbspdef _object_identifier(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn '_tf_keras_model'</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp@property</span>
<br><span style="color:red">- &nbsp &nbspdef _tracking_metadata(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmetadata = json.loads(super(Model, self)._tracking_metadata)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmetadata.update(saving_utils.model_metadata(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself, include_optimizer=True, require_config=False))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn json.dumps(metadata, default=serialization.get_json_type)</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef _assert_compile_was_called(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Checks whether `compile` has been called. If it has been called,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# then the optimizer is set. This is different from whether the
<br>@@ -2733,45 +2595,40 @@ class Model(network.Network):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'training/testing. '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Use `model.compile(optimizer, loss)`.')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _in_multi_worker_mode(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Method to infer if this `Model` is working in multi-worker settings.</span>
<br>&nbsp
<br><span style="color:red">- class DistributedCallbackModel(Model):</span>
<br><span style="color:red">- &nbsp &nbsp"""Model that is used for callbacks with tf.distribute.Strategy."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMulti-worker training refers to the setup where the training is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistributed across multiple workers, as opposed to the case where</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsponly a local process performs the training. This function is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspused to infer for example whether or not a distribute coordinator</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshould be run, and thus TensorFlow servers should be started for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcommunication with other servers in the cluster, or whether or not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsaving/restoring checkpoints is relevant for preemption fault tolerance.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef __init__(self, model):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(DistributedCallbackModel, self).__init__()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.optimizer = model.optimizer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExperimental. Signature and implementation are subject to change.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef set_original_model(self, orig_model):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._original_model = orig_model</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhether this model indicates it's working in multi-worker settings.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstrategy = self._get_distribution_strategy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn strategy and strategy.extended._in_multi_worker_mode()  # pylint: disable=protected-access</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef save_weights(self, filepath, overwrite=True, save_format=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._replicated_model.save_weights(filepath, overwrite=overwrite,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format=save_format)</span>
<br><span style="color:green">+&nbsp &nbspdef _get_distribution_strategy(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If the model was compiled under the scope of a `tf.distribute.Strategy',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `self._distribution_strategy` would have been set and model should infer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# that as the used strategy (even if it's out of strategy scope already).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstrategy = self._distribution_strategy</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef save(self, filepath, overwrite=True, include_optimizer=True):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# save weights from the distributed model to the original model</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdistributed_model_weights = self.get_weights()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._original_model.set_weights(distributed_model_weights)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(anjalisridhar): Do we need to save the original model here?</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Saving the first replicated model works as well.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._original_model.save(filepath, overwrite=True, include_optimizer=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Otherwise, use the strategy whose scope this is in.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not strategy and ds_context.has_strategy():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrategy = ds_context.get_strategy()</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef load_weights(self, filepath, by_name=False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._original_model.load_weights(filepath, by_name=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Copy the weights from the original model to each of the replicated models.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsporig_model_weights = self._original_model.get_weights()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdistributed_training_utils.set_weights(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._original_model._distribution_strategy, self,  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporig_model_weights)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn strategy</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef __getattr__(self, item):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Whitelisted atttributes of the model that can be accessed by the user</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# during a callback.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif item not in ('_setattr_tracking', '_layers'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('You are accessing attribute ' + item + ' of the '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'DistributedCallbackModel that may not have been set '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'correctly.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn super(DistributedCallbackModel, self).__getattr__(item)</span>
<br><span style="color:green">+&nbsp &nbsp@property</span>
<br><span style="color:green">+&nbsp &nbspdef _trackable_saved_model_saver(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn model_serialization.ModelSavedModelSaver(self)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspclass _TrainingEndpoint(object):
<br>@@ -2977,20 +2834,20 @@ class _TrainingEndpoint(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.sample_weight_mode is not None and self.sample_weight is None) or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.sample_weight_mode is None and self.sample_weight is not None))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef populate_sample_weight(self, sample_weight=None):</span>
<br><span style="color:green">+&nbsp &nbspdef populate_sample_weight(self, sample_weight, sample_weight_mode):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Populate the sample weight and based on the sample weight mode."""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (sample_weight is None and (self.should_skip_target_weights() or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.sample_weight_mode is None or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontext.executing_eagerly())):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (sample_weight is None and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.should_skip_target_weights() or sample_weight_mode is None or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontext.executing_eagerly())):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._sample_weight = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspassert self.sample_weight_mode in ['temporal', 'samplewise']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.sample_weight_mode == 'temporal':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassert sample_weight_mode in ['temporal', 'samplewise']</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif sample_weight_mode == 'temporal':</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault_value = [[1.]]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = [None, None]
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# self.sample_weight_mode == 'samplewise'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sample_weight_mode == 'samplewise'</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault_value = [1.]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = [None]
<br>&nbsp
<br>@@ -3062,6 +2919,11 @@ def _convert_scipy_sparse_tensor(value, expected_input):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif issparse is not None and issparse(value):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif ops.is_dense_tensor_like(expected_input):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In TF2 we do not silently densify sparse matrices.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('A SciPy sparse matrix was passed to a model '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'that expects dense inputs. Please densify your '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'inputs first, such as by calling `x.toarray().')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn value.toarray()
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse_coo = value.tocoo()
<br></p>
</div>
<br><br><br>
<br>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
</body>
</html>