
    <!DOCTYPE html>
    <html>
    <head>
    <style>
    .collapsible {
      background-color: #777;
      color: white;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: none;
      text-align: left;
      outline: none;
      font-size: 15px;
    }

    .active, .collapsible:hover {
      background-color: #555;
    }

    .content {
      padding: 0 18px;
      display: none;
      overflow: hidden;
      background-color: #f1f1f1;
    }
    </style>
    </head>
    <body>


 <br>Commit id closest to current version: eaa2fdef699ba0b81a75434f6483891f11cc116f
<br>Date: 29-Dec-2017

 <br>Commit message: BUG: optimize: fix bug related with function call calculation for Brent algorithm<br><br>
<br>Commit id closest to desired version: bf0806b0c5a09e1e0b6bea89f01aa5659e256cec
<br>Date: 10-Sep-2021

 <br>Commit message: ENH: optimize std in scipy.stats.binned_statistic (#14629)<br><br><br>
<br>_____________________________________scipy/sparse/coo.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19419</th>
      <td>test\test_sparse.py</td>
      <td>3317</td>
      <td>test_sparse_matmul</td>
      <td>3214</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>3243</td>
      <td>scipy.sparse.coo_matrix</td>
      <td>scipy/sparse/coo.py</td>
    </tr>
    <tr>
      <th>19421</th>
      <td>test\test_sparse.py</td>
      <td>3317</td>
      <td>test_sparse_matmul</td>
      <td>3214</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>3244</td>
      <td>scipy.sparse.coo_matrix</td>
      <td>scipy/sparse/coo.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/scipy/sparse/coo.py b/scipy/sparse/coo.py
<br>index 07bd7bca9..9f6568ce9 100644
<br><span style="color:red">- -- a/scipy/sparse/coo.py</span>
<br><span style="color:green">+++ b/scipy/sparse/coo.py</span>
<br>@@ -1,5 +1,4 @@
<br>&nbsp""" A sparse matrix in COOrdinate or 'triplet' format"""
<br><span style="color:red">- from __future__ import division, print_function, absolute_import</span>
<br>&nbsp
<br>&nbsp__docformat__ = "restructuredtext en"
<br>&nbsp
<br>@@ -9,14 +8,15 @@ from warnings import warn
<br>&nbsp
<br>&nbspimport numpy as np
<br>&nbsp
<br><span style="color:red">- from scipy._lib.six import zip as izip</span>
<br>&nbsp
<br>&nbspfrom ._sparsetools import coo_tocsr, coo_todense, coo_matvec
<br>&nbspfrom .base import isspmatrix, SparseEfficiencyWarning, spmatrix
<br>&nbspfrom .data import _data_matrix, _minmax_mixin
<br>&nbspfrom .sputils import (upcast, upcast_char, to_native, isshape, getdtype,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspget_index_dtype, downcast_intp_index, check_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcheck_reshape_kwargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgetdata, get_index_dtype, downcast_intp_index,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcheck_shape, check_reshape_kwargs, matrix)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+import operator</span>
<br>&nbsp
<br>&nbsp
<br>&nbspclass coo_matrix(_data_matrix, _minmax_mixin):
<br>@@ -54,7 +54,7 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp &nbsp &nbsp &nbsp &nbspndim : int
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of dimensions (this is always 2)
<br>&nbsp &nbsp &nbsp &nbsp &nbspnnz
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of nonzero elements</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of stored values, including explicit zeros</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCOO format data array of the matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsprow
<br>@@ -88,7 +88,7 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> # Constructing an empty matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.sparse import coo_matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> coo_matrix((3, 4), dtype=np.int8).toarray()
<br>@@ -131,22 +131,23 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, N = arg1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._shape = check_shape((M, N))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspidx_dtype = get_index_dtype(maxval=max(M, N))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_dtype = getdtype(dtype, default=float)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.row = np.array([], dtype=idx_dtype)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.col = np.array([], dtype=idx_dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data = np.array([], getdtype(dtype, default=float))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data = np.array([], dtype=data_dtype)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.has_canonical_format = True
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobj, (row, col) = arg1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept (TypeError, ValueError):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('invalid input format')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept (TypeError, ValueError) as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('invalid input format') from e</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(row) == 0 or len(col) == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('cannot infer dimensions from zero '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sized index arrays')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = np.max(row) + 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspN = np.max(col) + 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = operator.index(np.max(row)) + 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspN = operator.index(np.max(col)) + 1</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._shape = check_shape((M, N))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use 2 steps to ensure shape has length 2.
<br>@@ -156,9 +157,8 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspidx_dtype = get_index_dtype(maxval=max(self.shape))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.row = np.array(row, copy=copy, dtype=idx_dtype)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.col = np.array(col, copy=copy, dtype=idx_dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data = np.array(obj, copy=copy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data = getdata(obj, copy=copy, dtype=dtype)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.has_canonical_format = False
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isspmatrix(arg1):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isspmatrix_coo(arg1) and copy:
<br>@@ -179,8 +179,12 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif M.ndim != 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('expected dimension <= 2 array or matrix')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._shape = check_shape(M.shape)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._shape = check_shape(M.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif check_shape(shape) != self._shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('inconsistent shapes: %s != %s' %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(shape, self._shape))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.row, self.col = M.nonzero()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data = M[self.row, self.col]
<br>@@ -205,10 +209,17 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnrows, ncols = self.shape
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif order == 'C':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_indices = ncols * self.row + self.col</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Upcast to avoid overflows: the coo_matrix constructor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# below will downcast the results to a smaller dtype, if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# possible.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype = get_index_dtype(maxval=(ncols * max(0, nrows - 1) + max(0, ncols - 1)))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_indices = np.multiply(ncols, self.row, dtype=dtype) + self.col</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_row, new_col = divmod(flat_indices, shape[1])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif order == 'F':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_indices = self.row + nrows * self.col</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype = get_index_dtype(maxval=(nrows * max(0, ncols - 1) + max(0, nrows - 1)))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_indices = np.multiply(nrows, self.col, dtype=dtype) + self.row</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_col, new_row = divmod(flat_indices, shape[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("'order' must be 'C' or 'F'")
<br>@@ -436,7 +447,7 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.sum_duplicates()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdok = dok_matrix((self.shape), dtype=self.dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdok._update(izip(izip(self.row,self.col),self.data))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdok._update(zip(zip(self.row,self.col),self.data))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dok
<br>&nbsp
<br>@@ -445,7 +456,7 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef diagonal(self, k=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprows, cols = self.shape
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif k <= -rows or k >= cols:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("k exceeds matrix dimensions")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.empty(0, dtype=self.data.dtype)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdiag = np.zeros(min(rows + min(k, 0), cols - max(k, 0)),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self.dtype)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdiag_mask = (self.row + k) == self.col
<br>@@ -556,14 +567,15 @@ class coo_matrix(_data_matrix, _minmax_mixin):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _add_dense(self, other):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif other.shape != self.shape:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Incompatible shapes.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Incompatible shapes ({} and {})'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.format(self.shape, other.shape))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype = upcast_char(self.dtype.char, other.dtype.char)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.array(other, dtype=dtype, copy=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfortran = int(result.flags.f_contiguous)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, N = self.shape
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcoo_todense(M, N, self.nnz, self.row, self.col, self.data,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult.ravel('A'), fortran)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.matrix(result, copy=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn matrix(result, copy=False)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mul_vector(self, other):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#output array
<br></p>
</div>
<br><br><br>_____________________________________scipy/stats/stats.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>23749</th>
      <td>test\test_torch.py</td>
      <td>4393</td>
      <td>test_geometric_kstest</td>
      <td>4385</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>4392</td>
      <td>stats.chisquare</td>
      <td>scipy/stats/stats.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/scipy/stats/stats.py b/scipy/stats/stats.py
<br>index 4275920da..8eadb5e45 100644
<br><span style="color:red">- -- a/scipy/stats/stats.py</span>
<br><span style="color:green">+++ b/scipy/stats/stats.py</span>
<br>@@ -17,135 +17,7 @@
<br>&nbsp# such damage.
<br>&nbsp
<br>&nbsp"""
<br><span style="color:red">- A collection of basic statistical functions for Python.  The function</span>
<br><span style="color:red">- names appear below.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbspSome scalar functions defined here are also available in the scipy.special</span>
<br><span style="color:red">- &nbsppackage where they work on arbitrary sized arrays.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Disclaimers:  The function list is obviously incomplete and, worse, the</span>
<br><span style="color:red">- functions are not optimized.  All functions have been tested (some more</span>
<br><span style="color:red">- so than others), but they are far from bulletproof.  Thus, as with any</span>
<br><span style="color:red">- free software, no warranty or guarantee is expressed or implied. :-)  A</span>
<br><span style="color:red">- few extra functions that don't appear in the list below can be found by</span>
<br><span style="color:red">- interested treasure-hunters.  These functions don't necessarily have</span>
<br><span style="color:red">- both list and array versions but were deemed useful.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Central Tendency</span>
<br><span style="color:red">- ----------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgmean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsphmean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmode</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Moments</span>
<br><span style="color:red">- -------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmoment</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvariation</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspskew</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkurtosis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnormaltest</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Altered Versions</span>
<br><span style="color:red">- ----------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptmean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptvar</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptstd</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptsem</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdescribe</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Frequency Stats</span>
<br><span style="color:red">- ---------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspitemfreq</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscoreatpercentile</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppercentileofscore</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcumfreq</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprelfreq</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Variability</span>
<br><span style="color:red">- -----------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspobrientransform</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsem</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspzmap</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspzscore</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspiqr</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Trimming Functions</span>
<br><span style="color:red">- ------------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsptrimboth</span>
<br><span style="color:red">- &nbsp &nbsp &nbsptrim1</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Correlation Functions</span>
<br><span style="color:red">- ---------------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsppearsonr</span>
<br><span style="color:red">- &nbsp &nbsp &nbspfisher_exact</span>
<br><span style="color:red">- &nbsp &nbsp &nbspspearmanr</span>
<br><span style="color:red">- &nbsp &nbsp &nbsppointbiserialr</span>
<br><span style="color:red">- &nbsp &nbsp &nbspkendalltau</span>
<br><span style="color:red">- &nbsp &nbsp &nbspweightedtau</span>
<br><span style="color:red">- &nbsp &nbsp &nbsplinregress</span>
<br><span style="color:red">- &nbsp &nbsp &nbsptheilslopes</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Inferential Stats</span>
<br><span style="color:red">- -----------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbspttest_1samp</span>
<br><span style="color:red">- &nbsp &nbsp &nbspttest_ind</span>
<br><span style="color:red">- &nbsp &nbsp &nbspttest_ind_from_stats</span>
<br><span style="color:red">- &nbsp &nbsp &nbspttest_rel</span>
<br><span style="color:red">- &nbsp &nbsp &nbspchisquare</span>
<br><span style="color:red">- &nbsp &nbsp &nbsppower_divergence</span>
<br><span style="color:red">- &nbsp &nbsp &nbspks_2samp</span>
<br><span style="color:red">- &nbsp &nbsp &nbspmannwhitneyu</span>
<br><span style="color:red">- &nbsp &nbsp &nbspranksums</span>
<br><span style="color:red">- &nbsp &nbsp &nbspwilcoxon</span>
<br><span style="color:red">- &nbsp &nbsp &nbspkruskal</span>
<br><span style="color:red">- &nbsp &nbsp &nbspfriedmanchisquare</span>
<br><span style="color:red">- &nbsp &nbsp &nbspcombine_pvalues</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Statistical Distances</span>
<br><span style="color:red">- ---------------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbspwasserstein_distance</span>
<br><span style="color:red">- &nbsp &nbsp &nbspenergy_distance</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- ANOVA Functions</span>
<br><span style="color:red">- ---------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbspf_oneway</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- Support Functions</span>
<br><span style="color:red">- -----------------</span>
<br><span style="color:red">- .. autosummary::</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp:toctree: generated/</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsprankdata</span>
<br><span style="color:green">+A collection of basic statistical functions for Python.</span>
<br>&nbsp
<br>&nbspReferences
<br>&nbsp----------
<br>@@ -154,43 +26,86 @@ References
<br>&nbsp &nbsp &nbsp &nbspYork. 2000.
<br>&nbsp
<br>&nbsp"""
<br><span style="color:red">- </span>
<br><span style="color:red">- from __future__ import division, print_function, absolute_import</span>
<br><span style="color:red">- </span>
<br>&nbspimport warnings
<br>&nbspimport math
<br><span style="color:green">+from math import gcd</span>
<br>&nbspfrom collections import namedtuple
<br>&nbsp
<br>&nbspimport numpy as np
<br><span style="color:red">- from numpy import array, asarray, ma, zeros</span>
<br><span style="color:green">+from numpy import array, asarray, ma</span>
<br>&nbsp
<br><span style="color:red">- from scipy._lib.six import callable, string_types</span>
<br><span style="color:red">- from scipy._lib._version import NumpyVersion</span>
<br><span style="color:green">+from scipy.spatial.distance import cdist</span>
<br><span style="color:green">+from scipy.ndimage import _measurements</span>
<br><span style="color:green">+from scipy._lib._util import (check_random_state, MapWrapper,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprng_integers, float_factorial)</span>
<br>&nbspimport scipy.special as special
<br><span style="color:red">- import scipy.linalg as linalg</span>
<br><span style="color:green">+from scipy import linalg</span>
<br>&nbspfrom . import distributions
<br>&nbspfrom . import mstats_basic
<br><span style="color:red">- from ._distn_infrastructure import _lazywhere</span>
<br><span style="color:red">- from ._stats_mstats_common import _find_repeats, linregress, theilslopes</span>
<br><span style="color:red">- from ._stats import _kendall_dis, _toint64, _weightedrankedtau</span>
<br><span style="color:green">+from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsiegelslopes)</span>
<br><span style="color:green">+from ._stats import (_kendall_dis, _toint64, _weightedrankedtau,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_local_correlations)</span>
<br><span style="color:green">+from dataclasses import make_dataclass</span>
<br><span style="color:green">+from ._hypotests import _all_partitions</span>
<br><span style="color:green">+from ._axis_nan_policy import (_axis_nan_policy_factory,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_broadcast_concatenate)</span>
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+# Functions/classes in other files should be added in `__init__.py`, not here</span>
<br>&nbsp__all__ = ['find_repeats', 'gmean', 'hmean', 'mode', 'tmean', 'tvar',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tmin', 'tmax', 'tstd', 'tsem', 'moment', 'variation',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'skew', 'kurtosis', 'describe', 'skewtest', 'kurtosistest',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'normaltest', 'jarque_bera', 'itemfreq',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scoreatpercentile', 'percentileofscore',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'cumfreq', 'relfreq', 'obrientransform',
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sem', 'zmap', 'zscore', 'iqr',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sigmaclip', 'trimboth', 'trim1', 'trim_mean', 'f_oneway',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'pearsonr', 'fisher_exact', 'spearmanr', 'pointbiserialr',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kendalltau', 'weightedtau',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'linregress', 'theilslopes', 'ttest_1samp',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ttest_ind', 'ttest_ind_from_stats', 'ttest_rel', 'kstest',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'chisquare', 'power_divergence', 'ks_2samp', 'mannwhitneyu',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sem', 'zmap', 'zscore', 'iqr', 'gstd', 'median_absolute_deviation',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'median_abs_deviation',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sigmaclip', 'trimboth', 'trim1', 'trim_mean',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'f_oneway', 'F_onewayConstantInputWarning',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'F_onewayBadInputSizesWarning',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'PearsonRConstantInputWarning', 'PearsonRNearConstantInputWarning',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'pearsonr', 'fisher_exact',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'SpearmanRConstantInputWarning', 'spearmanr', 'pointbiserialr',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kendalltau', 'weightedtau', 'multiscale_graphcorr',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'linregress', 'siegelslopes', 'theilslopes', 'ttest_1samp',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ttest_ind', 'ttest_ind_from_stats', 'ttest_rel',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kstest', 'ks_1samp', 'ks_2samp',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'chisquare', 'power_divergence',</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'tiecorrect', 'ranksums', 'kruskal', 'friedmanchisquare',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'rankdata',
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'combine_pvalues', 'wasserstein_distance', 'energy_distance']</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'combine_pvalues', 'wasserstein_distance', 'energy_distance',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'brunnermunzel', 'alexandergovern']</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _contains_nan(a, nan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppolicies = ['propagate', 'raise', 'omit']</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nan_policy not in policies:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("nan_policy must be one of {%s}" %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp', '.join("'%s'" % s for s in policies))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Calling np.sum to avoid creating a huge array into memory</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# e.g. np.isnan(a).any()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = np.isnan(np.sum(a))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept TypeError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This can happen when attempting to sum things which are not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# numbers (e.g. as in the function `mode`). Try an alternative method:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = np.nan in set(a.ravel())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept TypeError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Don't know what to do. Fall back to omitting nan values and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# issue a warning.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = False</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = 'omit'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn("The input array could not be properly "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"checked for nan values. nan values "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"will be ignored.", RuntimeWarning)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'raise':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The input contains nan values")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn contains_nan, nan_policy</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _chk_asarray(a, axis):
<br>@@ -225,34 +140,82 @@ def _chk2_asarray(a, b, axis):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn a, b, outaxis
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def _contains_nan(a, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppolicies = ['propagate', 'raise', 'omit']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif nan_policy not in policies:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("nan_policy must be one of {%s}" %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp', '.join("'%s'" % s for s in policies))</span>
<br><span style="color:green">+def _shape_with_dropped_axis(a, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGiven an array `a` and an integer `axis`, return the shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof `a` with the `axis` dimension removed.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.zeros((3, 5, 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> _shape_with_dropped_axis(a, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(3, 2)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshp = list(a.shape)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptry:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Calling np.sum to avoid creating a huge array into memory</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# e.g. np.isnan(a).any()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = np.isnan(np.sum(a))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexcept TypeError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If the check cannot be properly performed we fallback to omitting</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# nan values and raising a warning. This can happen when attempting to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sum things that are not numbers (e.g. as in the function `mode`).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = 'omit'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn("The input array could not be properly checked for nan "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"values. nan values will be ignored.", RuntimeWarning)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel shp[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept IndexError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise np.AxisError(axis, a.ndim) from None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tuple(shp)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'raise':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The input contains nan values")</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn (contains_nan, nan_policy)</span>
<br><span style="color:green">+def _broadcast_shapes(shape1, shape2):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGiven two shapes (i.e. tuples of integers), return the shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthat would result from broadcasting two arrays with the given</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshapes.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> _broadcast_shapes((2, 1), (4, 1, 3))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(4, 2, 3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd = len(shape1) - len(shape2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif d <= 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshp1 = (1,)*(-d) + shape1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshp2 = shape2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshp1 = shape1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshp2 = (1,)*d + shape2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor n1, n2 in zip(shp1, shp2):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n1 == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif n2 == 1 or n1 == n2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'shapes {shape1} and {shape2} could not be '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'broadcast together')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape.append(n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tuple(shape)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br><span style="color:green">+def _broadcast_shapes_with_dropped_axis(a, b, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGiven two arrays `a` and `b` and an integer `axis`, find the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape of the broadcast result after dropping `axis` from the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshapes of `a` and `b`.</span>
<br>&nbsp
<br><span style="color:red">- def gmean(a, axis=0, dtype=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.zeros((5, 2, 1))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = np.zeros((1, 9, 3))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> _broadcast_shapes_with_dropped_axis(a, b, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(5, 3)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the geometric mean along the specified axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshp1 = _shape_with_dropped_axis(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshp2 = _shape_with_dropped_axis(b, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshp = _broadcast_shapes(shp1, shp2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept ValueError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'non-axis shapes {shp1} and {shp2} could not be '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'broadcast together') from None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn shp</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def gmean(a, axis=0, dtype=None, weights=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the geometric mean along the specified axis.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturn the geometric average of the array elements.
<br>&nbsp &nbsp &nbsp &nbsp &nbspThat is:  n-th root of (x1 * x2 * ... * xn)
<br>@@ -270,11 +233,15 @@ def gmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype of a, unless a has an integer dtype with a precision less than
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat of the default platform integer. In that case, the default
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplatform integer is used.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspweights : array_like, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe weights array can either be 1-D (in which case its length must be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe size of `a` along the given `axis`) or of the same shape as `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None, which gives each value a weight of 1.0.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspgmean : ndarray
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee dtype parameter above</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `dtype` parameter above.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -292,6 +259,10 @@ def gmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsparise in the calculations such as Not a Number and infinity because masked
<br>&nbsp &nbsp &nbsp &nbsp &nbsparrays automatically mask any non-finite values.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] "Weighted Geometric Mean", *Wikipedia*, https://en.wikipedia.org/wiki/Weighted_geometric_mean.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import gmean
<br>@@ -299,6 +270,7 @@ def gmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp2.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> gmean([1, 2, 3, 4, 5, 6, 7])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp3.3800151591412964
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(a, np.ndarray):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if not an ndarray object attempt to convert it
<br>@@ -311,12 +283,15 @@ def gmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_a = np.log(np.asarray(a, dtype=dtype))
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_a = np.log(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn np.exp(log_a.mean(axis=axis))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif weights is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights = np.asanyarray(weights, dtype=dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.exp(np.average(log_a, axis=axis, weights=weights))</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef hmean(a, axis=0, dtype=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the harmonic mean along the specified axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate the harmonic mean along the specified axis.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThat is:  n / (1/x1 + 1/x2 + ... + 1/xn)
<br>&nbsp
<br>@@ -337,7 +312,7 @@ def hmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsphmean : ndarray
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `dtype` parameter above</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `dtype` parameter above.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -361,11 +336,12 @@ def hmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp1.6000000000000001
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> hmean([1, 2, 3, 4, 5, 6, 7])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp2.6997245179063363
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(a, np.ndarray):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.array(a, dtype=dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif np.all(a > 0):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Harmonic mean only defined if greater than zero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.all(a >= 0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Harmonic mean only defined if greater than or equal to to zero.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(a, np.ma.MaskedArray):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = a.count(axis)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -374,17 +350,18 @@ def hmean(a, axis=0, dtype=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = a.shape[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = a.shape[axis]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn size / np.sum(1.0 / a, axis=axis, dtype=dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn size / np.sum(1.0 / a, axis=axis, dtype=dtype)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Harmonic mean only defined if all elements greater "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"than zero")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"than or equal to zero")</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspModeResult = namedtuple('ModeResult', ('mode', 'count'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef mode(a, axis=0, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturn an array of the modal (most common) value in the passed array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Return an array of the modal (most common) value in the passed array.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf there is more than one such value, only the smallest is returned.
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe bin-count for the modal bins is also returned.
<br>@@ -397,9 +374,12 @@ def mode(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to operate. Default is 0. If None, compute over
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -417,12 +397,12 @@ def mode(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...               [4, 7, 5, 9]])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.mode(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([[3, 1, 0, 0]]), array([[1, 1, 1, 1]]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspModeResult(mode=array([[3, 1, 0, 0]]), count=array([[1, 1, 1, 1]]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspTo get mode of whole array, specify ``axis=None``:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.mode(a, axis=None)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([3]), array([3]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspModeResult(mode=array([3]), count=array([3]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>@@ -435,19 +415,42 @@ def mode(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.mode(a, axis)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscores = np.unique(np.ravel(a))       # get ALL unique values</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptestshape = list(a.shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptestshape[axis] = 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoldmostfreq = np.zeros(testshape, dtype=a.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoldcounts = np.zeros(testshape, dtype=int)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor score in scores:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptemplate = (a == score)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcounts = np.expand_dims(np.sum(template, axis), axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmostfrequent = np.where(counts > oldcounts, score, oldmostfreq)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldcounts = np.maximum(counts, oldcounts)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldmostfreq = mostfrequent</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn ModeResult(mostfrequent, oldcounts)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif a.dtype == object and np.nan in set(a.ravel()):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Fall back to a slower method since np.unique does not work with NaN</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscores = set(np.ravel(a))  # get ALL unique values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptestshape = list(a.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptestshape[axis] = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldmostfreq = np.zeros(testshape, dtype=a.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldcounts = np.zeros(testshape, dtype=int)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor score in scores:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptemplate = (a == score)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcounts = np.sum(template, axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmostfrequent = np.where(counts > oldcounts, score, oldmostfreq)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldcounts = np.maximum(counts, oldcounts)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoldmostfreq = mostfrequent</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ModeResult(mostfrequent, oldcounts)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _mode1D(a):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals, cnts = np.unique(a, return_counts=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals[cnts.argmax()], cnts.max()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# np.apply_along_axis will convert the _mode1D tuples to a numpy array,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# casting types in the process.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# This recreates the results without that issue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# View of a, rotated so the requested axis is last</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin_dims = list(range(a.ndim))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_view = np.transpose(a, in_dims[:axis] + in_dims[axis+1:] + [axis])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinds = np.ndindex(a_view.shape[:-1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmodes = np.empty(a_view.shape[:-1], dtype=a.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcounts = np.empty(a_view.shape[:-1], dtype=np.int_)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor ind in inds:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodes[ind], counts[ind] = _mode1D(a_view[ind])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnewshape = list(a.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnewshape[axis] = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn ModeResult(modes.reshape(newshape), counts.reshape(newshape))</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _mask_to_limits(a, limits, inclusive):
<br>@@ -473,6 +476,7 @@ def _mask_to_limits(a, limits, inclusive):
<br>&nbsp &nbsp &nbsp &nbsp &nbspRaises
<br>&nbsp &nbsp &nbsp &nbsp &nbsp------
<br>&nbsp &nbsp &nbsp &nbsp &nbspA ValueError if there are no values within the given limits.
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsplower_limit, upper_limit = limits
<br>&nbsp &nbsp &nbsp &nbsp &nbsplower_include, upper_include = inclusive
<br>@@ -496,8 +500,7 @@ def _mask_to_limits(a, limits, inclusive):
<br>&nbsp
<br>&nbsp
<br>&nbspdef tmean(a, limits=None, inclusive=(True, True), axis=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed mean.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed mean.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function finds the arithmetic mean of given values, ignoring values
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutside the given `limits`.
<br>@@ -521,10 +524,11 @@ def tmean(a, limits=None, inclusive=(True, True), axis=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptmean : float
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed mean.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptrim_mean : returns mean after trimming a proportion from both tails.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptrim_mean : Returns mean after trimming a proportion from both tails.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -545,8 +549,7 @@ def tmean(a, limits=None, inclusive=(True, True), axis=None):
<br>&nbsp
<br>&nbsp
<br>&nbspdef tvar(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed variance.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed variance.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function computes the sample variance of an array of values,
<br>&nbsp &nbsp &nbsp &nbsp &nbspwhile ignoring values which are outside of given `limits`.
<br>@@ -591,17 +594,16 @@ def tvar(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa = asarray(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa = a.astype(float).ravel()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = a.astype(float)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif limits is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = len(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn a.var() * n / (n - 1.)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn a.var(ddof=ddof, axis=axis)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspam = _mask_to_limits(a, limits, inclusive)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn np.ma.var(am, ddof=ddof, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspamnan = am.filled(fill_value=np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.nanvar(amnan, ddof=ddof, axis=axis)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef tmin(a, lowerlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed minimum.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed minimum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function finds the miminum value of an array `a` along the
<br>&nbsp &nbsp &nbsp &nbsp &nbspspecified axis, but only considering values greater than a specified
<br>@@ -610,7 +612,7 @@ def tmin(a, lowerlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray of values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of values.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsplowerlimit : None or float, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValues in the input array less than the given limit will be ignored.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen lowerlimit is None, then all values are used. The default value
<br>@@ -622,13 +624,17 @@ def tmin(a, lowerlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis flag determines whether values exactly equal to the lower limit
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare included.  The default value is True.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptmin : float, int or ndarray
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed minimum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -659,8 +665,7 @@ def tmin(a, lowerlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp
<br>&nbspdef tmax(a, upperlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed maximum.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed maximum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function computes the maximum value of an array along a given axis,
<br>&nbsp &nbsp &nbsp &nbsp &nbspwhile ignoring values larger than a specified upper limit.
<br>@@ -668,7 +673,7 @@ def tmax(a, upperlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray of values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of values.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspupperlimit : None or float, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValues in the input array greater than the given limit will be ignored.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen upperlimit is None, then all values are used. The default value
<br>@@ -680,13 +685,17 @@ def tmax(a, upperlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis flag determines whether values exactly equal to the upper limit
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare included.  The default value is True.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptmax : float, int or ndarray
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed maximum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -717,8 +726,7 @@ def tmax(a, upperlimit=None, axis=0, inclusive=True, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp
<br>&nbspdef tstd(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed sample standard deviation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed sample standard deviation.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function finds the sample standard deviation of given values,
<br>&nbsp &nbsp &nbsp &nbsp &nbspignoring values outside the given `limits`.
<br>@@ -726,7 +734,7 @@ def tstd(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray of values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of values.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsplimits : None or (lower limit, upper limit), optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValues in the input array less than the lower limit or greater than the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper limit will be ignored. When limits is None, then all values are
<br>@@ -745,6 +753,7 @@ def tstd(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptstd : float
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed sample standard deviation.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -765,8 +774,7 @@ def tstd(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp
<br>&nbsp
<br>&nbspdef tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the trimmed standard error of the mean.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the trimmed standard error of the mean.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function finds the standard error of the mean for given
<br>&nbsp &nbsp &nbsp &nbsp &nbspvalues, ignoring values outside the given `limits`.
<br>@@ -774,7 +782,7 @@ def tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray of values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of values.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsplimits : None or (lower limit, upper limit), optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValues in the input array less than the lower limit or greater than the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper limit will be ignored. When limits is None, then all values are
<br>@@ -793,6 +801,7 @@ def tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptsem : float
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed standard error of the mean.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -822,28 +831,30 @@ def tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1):
<br>&nbsp#              MOMENTS              #
<br>&nbsp#####################################
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef moment(a, moment=1, axis=0, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the nth moment about the mean for a sample.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Calculate the nth moment about the mean for a sample.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspA moment is a specific quantitative measure of the shape of a set of
<br>&nbsp &nbsp &nbsp &nbsp &nbsppoints. It is often used to calculate coefficients of skewness and kurtosis
<br>&nbsp &nbsp &nbsp &nbsp &nbspdue to its close relationship with them.
<br>&nbsp
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmoment : int or array_like of ints, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporder of central moment that is returned. Default is 1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOrder of central moment that is returned. Default is 1.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which the central moment is computed. Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -852,7 +863,7 @@ def moment(a, moment=1, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis None. The denominator for the moment calculation is the number of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobservations, no degrees of freedom correction is done.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspkurtosis, skew, describe
<br>&nbsp
<br>@@ -869,7 +880,7 @@ def moment(a, moment=1, axis=0, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] http://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] https://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -878,6 +889,7 @@ def moment(a, moment=1, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> moment([1, 2, 3, 4, 5], moment=2)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp2.0
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -888,45 +900,43 @@ def moment(a, moment=1, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.moment(a, moment, axis)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif a.size == 0:
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoment_shape = list(a.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel moment_shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype = a.dtype.type if a.dtype.kind in 'fc' else np.float64</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# empty array, return nan(s) with shape matching `moment`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isscalar(moment):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout_shape = (moment_shape if np.isscalar(moment)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse [len(moment)] + moment_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(out_shape) == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dtype(np.nan)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.ones(np.asarray(moment).shape, dtype=np.float64) * np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.full(out_shape, np.nan, dtype=dtype)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# for array_like moment input, return a value for each.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not np.isscalar(moment):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmmnt = [_moment(a, i, axis) for i in moment]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = a.mean(axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmmnt = [_moment(a, i, axis, mean=mean) for i in moment]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array(mmnt)
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _moment(a, moment, axis)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def _moment(a, moment, axis):</span>
<br><span style="color:green">+# Moment with optional pre-computed mean, equal to a.mean(axis, keepdims=True)</span>
<br><span style="color:green">+def _moment(a, moment, axis, *, mean=None):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif np.abs(moment - np.round(moment)) > 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All moment parameters must be integers")
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif moment == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When moment equals 0, the result is 1, by definition.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif moment == 0 or moment == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# By definition the zeroth moment about the mean is 1, and the first</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# moment is 0.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = list(a.shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel shape[axis]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# return an actual array of the appropriate shape</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.ones(shape, dtype=float)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the input was 1D, so return a scalar instead of a rank-0 array</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype = a.dtype.type if a.dtype.kind in 'fc' else np.float64</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif moment == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# By definition the first moment about the mean is 0.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = list(a.shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel shape[axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# return an actual array of the appropriate shape</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.zeros(shape, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(shape) == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dtype(1.0 if moment == 0 else 0.0)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the input was 1D, so return a scalar instead of a rank-0 array</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.float64(0.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (np.ones(shape, dtype=dtype) if moment == 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse np.zeros(shape, dtype=dtype))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Exponentiation by squares: form exponent sequence
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_list = [moment]
<br>@@ -939,7 +949,8 @@ def _moment(a, moment, axis):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_list.append(current_n)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Starting point for exponentiation by squares
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_zero_mean = a - np.expand_dims(np.mean(a, axis), axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = a.mean(axis, keepdims=True) if mean is None else mean</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_zero_mean = a - mean</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n_list[-1] == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsps = a_zero_mean.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -953,10 +964,17 @@ def _moment(a, moment, axis):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.mean(s, axis)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def variation(a, axis=0, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the coefficient of variation, the ratio of the biased standard</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdeviation to the mean.</span>
<br><span style="color:green">+def variation(a, axis=0, nan_policy='propagate', ddof=0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the coefficient of variation.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe coefficient of variation is the standard deviation divided by the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmean.  This function is equivalent to::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.std(x, axis=axis, ddof=ddof) / np.mean(x)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe default for ``ddof`` is 0, but many definitions of the coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof variation use the square root of the unbiased sample variance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor the sample standard deviation, which corresponds to ``ddof=1``.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -966,9 +984,15 @@ def variation(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to calculate the coefficient of variation. Default
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis 0. If None, compute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspddof : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDelta degrees of freedom.  Default is 0.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -986,6 +1010,7 @@ def variation(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import variation
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> variation([1, 2, 3, 4, 5])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.47140452079103173
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -993,34 +1018,36 @@ def variation(a, axis=0, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.variation(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.variation(a, axis, ddof)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn a.std(axis) / a.mean(axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn a.std(axis, ddof=ddof) / a.mean(axis)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef skew(a, axis=0, bias=True, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the skewness of a data set.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Compute the sample skewness of a data set.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspFor normally distributed data, the skewness should be about 0. For</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspunimodal continuous distributions, a skewness value > 0 means that</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthere is more weight in the right tail of the distribution. The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor normally distributed data, the skewness should be about zero. For</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunimodal continuous distributions, a skewness value greater than zero means</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthat there is more weight in the right tail of the distribution. The</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunction `skewtest` can be used to determine if the skewness value
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis close enough to 0, statistically speaking.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis close enough to zero, statistically speaking.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : ndarray
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which skewness is calculated. Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias : bool, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, then the calculations are corrected for statistical bias.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -1028,9 +1055,34 @@ def skew(a, axis=0, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe skewness of values along an axis, returning 0 where all values are
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequal.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe sample skewness is computed as the Fisher-Pearson coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof skewness, i.e.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspg_1=\frac{m_3}{m_2^{3/2}}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm_i=\frac{1}{N}\sum_{n=1}^N(x[n]-\bar{x})^i</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis the biased sample :math:`i\texttt{th}` central moment, and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`\bar{x}` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe sample mean.  If ``bias`` is False, the calculations are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorrected for bias and the value computed is the adjusted</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFisher-Pearson standardized moment coefficient, i.e.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspG_1=\frac{k_3}{k_2^{3/2}}=</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\frac{\sqrt{N(N-1)}}{N-2}\frac{m_3}{m_2^{3/2}}.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability and Statistics Tables and Formulae. Chapman & Hall: New
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspYork. 2000.
<br>@@ -1043,6 +1095,7 @@ def skew(a, axis=0, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> skew([2, 8, 0, 4, 1, 9, 9, 0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.2650554122698573
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = a.shape[axis]
<br>@@ -1053,14 +1106,14 @@ def skew(a, axis=0, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.skew(a, axis, bias)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspm2 = moment(a, 2, axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspm3 = moment(a, 3, axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspzero = (m2 == 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvals = _lazywhere(~zero, (m2, m3),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda m2, m3: m3 / m2**1.5,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmean = a.mean(axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm2 = _moment(a, 2, axis, mean=mean)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm3 = _moment(a, 3, axis, mean=mean)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(all='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero = (m2 <= (np.finfo(m2.dtype).resolution * mean.squeeze(axis))**2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = np.where(zero, 0, m3 / m2**1.5)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_correct = (n > 2) & (m2 > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_correct = ~zero & (n > 2)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif can_correct.any():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm2 = np.extract(can_correct, m2)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm3 = np.extract(can_correct, m3)
<br>@@ -1074,8 +1127,7 @@ def skew(a, axis=0, bias=True, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp
<br>&nbspdef kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the kurtosis (Fisher or Pearson) of a dataset.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the kurtosis (Fisher or Pearson) of a dataset.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspKurtosis is the fourth central moment divided by the square of the
<br>&nbsp &nbsp &nbsp &nbsp &nbspvariance. If Fisher's definition is used, then 3.0 is subtracted from
<br>@@ -1089,7 +1141,7 @@ def kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata for which the kurtosis is calculated</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspData for which the kurtosis is calculated.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which the kurtosis is calculated. Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.
<br>@@ -1117,9 +1169,42 @@ def kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIn Fisher's definiton, the kurtosis of the normal distribution is zero.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIn the following example, the kurtosis is close to zero, because it was</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcalculated from the dataset, not from the continuous distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import norm, kurtosis</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> data = norm.rvs(size=1000, random_state=3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> kurtosis(data)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-0.06928694200380558</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe distribution with a higher kurtosis has a heavier tail.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe zero valued kurtosis of the normal distribution in Fisher's definition</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcan serve as a reference point.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> import matplotlib.pyplot as plt</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> import scipy.stats as stats</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import kurtosis
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> kurtosis([1, 2, 3, 4, 5])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-1.3</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.linspace(-5, 5, 100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ax = plt.subplot()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> distnames = ['laplace', 'norm', 'uniform']</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> for distname in distnames:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     if distname == 'uniform':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...         dist = getattr(stats, distname)(loc=-2, scale=4)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     else:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...         dist = getattr(stats, distname)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     data = dist.rvs(size=1000)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     kur = kurtosis(data, fisher=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     y = dist.pdf(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     ax.plot(x, y, label="{}, {}".format(distname, round(kur, 3)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...     ax.legend()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Laplace distribution has a heavier tail than the normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe uniform distribution (which has negative kurtosis) has the thinnest</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptail.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -1130,17 +1215,15 @@ def kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.kurtosis(a, axis, fisher, bias)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = a.shape[axis]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspm2 = moment(a, 2, axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspm4 = moment(a, 4, axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspzero = (m2 == 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspolderr = np.seterr(all='ignore')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmean = a.mean(axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm2 = _moment(a, 2, axis, mean=mean)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm4 = _moment(a, 4, axis, mean=mean)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(all='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero = (m2 <= (np.finfo(m2.dtype).resolution * mean.squeeze(axis))**2)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = np.where(zero, 0, m4 / m2**2.0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfinally:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.seterr(**olderr)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_correct = (n > 3) & (m2 > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_correct = ~zero & (n > 3)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif can_correct.any():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm2 = np.extract(can_correct, m2)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm4 = np.extract(can_correct, m4)
<br>@@ -1150,10 +1233,8 @@ def kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif vals.ndim == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = vals.item()  # array scalar
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif fisher:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals - 3</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn vals - 3 if fisher else vals</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspDescribeResult = namedtuple('DescribeResult',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('nobs', 'minmax', 'mean', 'variance', 'skewness',
<br>@@ -1161,44 +1242,49 @@ DescribeResult = namedtuple('DescribeResult',
<br>&nbsp
<br>&nbsp
<br>&nbspdef describe(a, axis=0, ddof=1, bias=True, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute several descriptive statistics of the passed array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute several descriptive statistics of the passed array.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput data.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput data.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which statistics are calculated. Default is 0.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which statistics are calculated. Default is 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspddof : int, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDelta degrees of freedom (only for variance).  Default is 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias : bool, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, then the skewness and kurtosis calculations are corrected for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistical bias.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, then the skewness and kurtosis calculations are corrected</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor statistical bias.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspnobs : int or ndarray of ints
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of observations (length of data along `axis`).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen 'omit' is chosen as nan_policy, each column is counted separately.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of observations (length of data along `axis`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen 'omit' is chosen as nan_policy, the length along each axis</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspslice is counted separately.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspminmax: tuple of ndarrays or floats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMinimum and maximum value of data array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMinimum and maximum value of `a` along the given axis.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmean : ndarray or float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArithmetic mean of data along axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArithmetic mean of `a` along the given axis.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspvariance : ndarray or float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnbiased variance of the data along axis, denominator is number of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobservations minus one.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnbiased variance of `a` along the given axis; denominator is number</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof observations minus one.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspskewness : ndarray or float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSkewness, based on moment calculations with denominator equal to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe number of observations, i.e. no degrees of freedom correction.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSkewness of `a` along the given axis, based on moment calculations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith denominator equal to the number of observations, i.e. no degrees</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof freedom correction.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkurtosis : ndarray or float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKurtosis (Fisher).  The kurtosis is normalized so that it is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero for the normal distribution.  No degrees of freedom are used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKurtosis (Fisher) of `a` along the given axis.  The kurtosis is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnormalized so that it is zero for the normal distribution.  No</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdegrees of freedom are used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -1209,13 +1295,14 @@ def describe(a, axis=0, ddof=1, bias=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> a = np.arange(10)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.describe(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspDescribeResult(nobs=10, minmax=(0, 9), mean=4.5, variance=9.1666666666666661,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspskewness=0.0, kurtosis=-1.2242424242424244)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDescribeResult(nobs=10, minmax=(0, 9), mean=4.5,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance=9.166666666666666, skewness=0.0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkurtosis=-1.2242424242424244)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> b = [[1, 2], [3, 4]]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.describe(b)
<br>&nbsp &nbsp &nbsp &nbsp &nbspDescribeResult(nobs=2, minmax=(array([1, 2]), array([3, 4])),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean=array([ 2., 3.]), variance=array([ 2., 2.]),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspskewness=array([ 0., 0.]), kurtosis=array([-2., -2.]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean=array([2., 3.]), variance=array([2., 2.]),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspskewness=array([0., 0.]), kurtosis=array([-2., -2.]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>@@ -1241,12 +1328,30 @@ def describe(a, axis=0, ddof=1, bias=True, nan_policy='propagate'):
<br>&nbsp#         NORMALITY TESTS           #
<br>&nbsp#####################################
<br>&nbsp
<br><span style="color:green">+</span>
<br><span style="color:green">+def _normtest_finish(z, alternative):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Common code between all the normality-test functions."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == 'less':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.norm.cdf(z)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == 'greater':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.norm.sf(z)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == 'two-sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 2 * distributions.norm.sf(np.abs(z))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("alternative must be "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"'less', 'greater' or 'two-sided'")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif z.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = z[()]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn z, prob</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspSkewtestResult = namedtuple('SkewtestResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def skewtest(a, axis=0, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTest whether the skew is different from the normal distribution.</span>
<br><span style="color:green">+def skewtest(a, axis=0, nan_policy='propagate', alternative='two-sided'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Test whether the skew is different from the normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function tests the null hypothesis that the skewness of
<br>&nbsp &nbsp &nbsp &nbsp &nbspthe population that the sample was drawn from is the same
<br>@@ -1255,21 +1360,37 @@ def skewtest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe data to be tested</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe data to be tested.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which statistics are calculated. Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the skewness of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis different from that of the normal distribution (i.e. 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the skewness of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis less than that of the normal distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the skewness of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis greater than that of the normal distribution</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe computed z-score for this test.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa 2-sided p-value for the hypothesis test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value for the hypothesis test.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -1285,13 +1406,18 @@ def skewtest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import skewtest
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> skewtest([1, 2, 3, 4, 5, 6, 7, 8])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=1.0108048609177787, pvalue=0.31210983614218968)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=1.0108048609177787, pvalue=0.3121098361421897)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> skewtest([2, 8, 0, 4, 1, 9, 9, 0])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=0.44626385374196975, pvalue=0.65540666312754592)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=0.44626385374196975, pvalue=0.6554066631275459)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> skewtest([1, 2, 3, 4, 5, 6, 7, 8000])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=3.5717735103604071, pvalue=0.00035457199058231331)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=3.571773510360407, pvalue=0.0003545719905823133)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> skewtest([100, 100, 100, 100, 100, 100, 100, 101])
<br>&nbsp &nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=3.5717766638478072, pvalue=0.000354567720281634)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> skewtest([1, 2, 3, 4, 5, 6, 7, 8], alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=1.0108048609177787, pvalue=0.8439450819289052)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> skewtest([1, 2, 3, 4, 5, 6, 7, 8], alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSkewtestResult(statistic=1.0108048609177787, pvalue=0.15605491807109484)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -1299,13 +1425,13 @@ def skewtest(a, axis=0, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.skewtest(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.skewtest(a, axis, alternative)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif axis is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.ravel(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspb2 = skew(a, axis)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = float(a.shape[axis])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif n < 8:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"skewtest is not valid with less than 8 samples; %i samples"
<br>@@ -1319,42 +1445,57 @@ def skewtest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspy = np.where(y == 0, 1, y)
<br>&nbsp &nbsp &nbsp &nbsp &nbspZ = delta * np.log(y / alpha + np.sqrt((y / alpha)**2 + 1))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn SkewtestResult(Z, 2 * distributions.norm.sf(np.abs(Z)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn SkewtestResult(*_normtest_finish(Z, alternative))</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspKurtosistestResult = namedtuple('KurtosistestResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def kurtosistest(a, axis=0, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTest whether a dataset has normal kurtosis.</span>
<br><span style="color:green">+def kurtosistest(a, axis=0, nan_policy='propagate', alternative='two-sided'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Test whether a dataset has normal kurtosis.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function tests the null hypothesis that the kurtosis
<br>&nbsp &nbsp &nbsp &nbsp &nbspof the population from which the sample was drawn is that
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspof the normal distribution: ``kurtosis = 3(n-1)/(n+1)``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray of the sample data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of the sample data.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to compute test. Default is 0. If None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the kurtosis of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis different from that of the normal distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the kurtosis of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis less than that of the normal distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the kurtosis of the distribution underlying the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis greater than that of the normal distribution</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe computed z-score for this test.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe 2-sided p-value for the hypothesis test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value for the hypothesis test.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspValid only for n>20.  The Z-score is set to 0 for bad entries.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis function uses the method described in [1]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValid only for n>20. This function uses the method described in [1]_.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1365,12 +1506,17 @@ def kurtosistest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import kurtosistest
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> kurtosistest(list(range(20)))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=-1.7058104152122062, pvalue=0.088043383325283484)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(28041990)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> s = np.random.normal(0, 1, 1000)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=-1.7058104152122062, pvalue=0.08804338332528348)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> kurtosistest(list(range(20)), alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=-1.7058104152122062, pvalue=0.04402169166264174)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> kurtosistest(list(range(20)), alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=-1.7058104152122062, pvalue=0.9559783083373583)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> s = rng.normal(0, 1, 1000)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> kurtosistest(s)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=1.2317590987707365, pvalue=0.21803908613450895)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKurtosistestResult(statistic=-1.475047944490622, pvalue=0.14019965402996987)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -1378,9 +1524,9 @@ def kurtosistest(a, axis=0, nan_policy='propagate'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.kurtosistest(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.kurtosistest(a, axis, alternative)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = float(a.shape[axis])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif n < 5:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"kurtosistest requires at least 5 observations; %i observations"
<br>@@ -1400,28 +1546,30 @@ def kurtosistest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspA = 6.0 + 8.0/sqrtbeta1 * (2.0/sqrtbeta1 + np.sqrt(1+4.0/(sqrtbeta1**2)))
<br>&nbsp &nbsp &nbsp &nbsp &nbspterm1 = 1 - 2/(9.0*A)
<br>&nbsp &nbsp &nbsp &nbsp &nbspdenom = 1 + x*np.sqrt(2/(A-4.0))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdenom = np.where(denom < 0, 99, denom)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspterm2 = np.where(denom < 0, term1, np.power((1-2.0/A)/denom, 1/3.0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspterm2 = np.sign(denom) * np.where(denom == 0.0, np.nan,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.power((1-2.0/A)/np.abs(denom), 1/3.0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.any(denom == 0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = "Test statistic not defined in some cases due to division by " \</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"zero. Return nan in that case..."</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(msg, RuntimeWarning)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspZ = (term1 - term2) / np.sqrt(2/(9.0*A))  # [1]_ Eq. 5
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspZ = np.where(denom == 99, 0, Z)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif Z.ndim == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspZ = Z[()]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# zprob uses upper tail, so Z needs to be positive
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn KurtosistestResult(Z, 2 * distributions.norm.sf(np.abs(Z)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn KurtosistestResult(*_normtest_finish(Z, alternative))</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspNormaltestResult = namedtuple('NormaltestResult', ('statistic', 'pvalue'))
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef normaltest(a, axis=0, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTest whether a sample differs from a normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Test whether a sample differs from a normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function tests the null hypothesis that a sample comes
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom a normal distribution.  It is based on D'Agostino and
<br>&nbsp &nbsp &nbsp &nbsp &nbspPearson's [1]_, [2]_ test that combines skew and kurtosis to
<br>&nbsp &nbsp &nbsp &nbsp &nbspproduce an omnibus test of normality.
<br>&nbsp
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br>@@ -1430,9 +1578,12 @@ def normaltest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to compute test. Default is 0. If None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompute over the whole array `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -1453,20 +1604,21 @@ def normaltest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> pts = 1000
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(28041990)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> a = np.random.normal(0, 1, size=pts)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> b = np.random.normal(2, 1, size=pts)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = rng.normal(0, 1, size=pts)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = rng.normal(2, 1, size=pts)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> x = np.concatenate((a, b))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> k2, p = stats.normaltest(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> alpha = 1e-3
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> print("p = {:g}".format(p))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspp = 3.27207e-11</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspp = 8.4713e-19</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> if p < alpha:  # null hypothesis: x comes from a normal distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...     print("The null hypothesis can be rejected")
<br>&nbsp &nbsp &nbsp &nbsp &nbsp... else:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...     print("The null hypothesis cannot be rejected")
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe null hypothesis can be rejected
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp
<br>@@ -1483,9 +1635,11 @@ def normaltest(a, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn NormaltestResult(k2, distributions.chi2.sf(k2, 2))
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+Jarque_beraResult = namedtuple('Jarque_beraResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspdef jarque_bera(x):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspPerform the Jarque-Bera goodness of fit test on sample data.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Perform the Jarque-Bera goodness of fit test on sample data.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe Jarque-Bera test tests whether the sample data has the skewness and
<br>&nbsp &nbsp &nbsp &nbsp &nbspkurtosis matching a normal distribution.
<br>@@ -1515,17 +1669,19 @@ def jarque_bera(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x = np.random.normal(0, 1, 100000)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> y = np.random.rayleigh(1, 100000)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.jarque_bera(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(4.7165707989581342, 0.09458225503041906)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.jarque_bera(y)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(6713.7098548143422, 0.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = rng.normal(0, 1, 100000)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> jarque_bera_test = stats.jarque_bera(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> jarque_bera_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspJarque_beraResult(statistic=3.3415184718131554, pvalue=0.18810419594996775)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> jarque_bera_test.statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp3.3415184718131554</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> jarque_bera_test.pvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.18810419594996775</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = float(x.size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = x.size</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif n == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('At least one observation is required.')
<br>&nbsp
<br>@@ -1536,49 +1692,53 @@ def jarque_bera(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbspjb_value = n / 6 * (skewness**2 + (kurtosis - 3)**2 / 4)
<br>&nbsp &nbsp &nbsp &nbsp &nbspp = 1 - distributions.chi2.cdf(jb_value, 2)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn jb_value, p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn Jarque_beraResult(jb_value, p)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp#####################################
<br>&nbsp#        FREQUENCY FUNCTIONS        #
<br>&nbsp#####################################
<br>&nbsp
<br><span style="color:green">+# deindent to work around numpy/gh-16202</span>
<br><span style="color:green">+@np.deprecate(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmessage="`itemfreq` is deprecated and will be removed in a "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"future version. Use instead `np.unique(..., return_counts=True)`")</span>
<br>&nbspdef itemfreq(a):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturn a 2-D array of item frequencies.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa : (N,) array_like</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br><span style="color:green">+Return a 2-D array of item frequencies.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspitemfreq : (K, 2) ndarray</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA 2-D frequency table.  Column 1 contains sorted, unique values from</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`a`, column 2 contains their respective counts.</span>
<br><span style="color:green">+Parameters</span>
<br><span style="color:green">+----------</span>
<br><span style="color:green">+a : (N,) array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> a = np.array([1, 1, 5, 0, 1, 2, 2, 0, 1, 4])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.itemfreq(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 0.,  2.],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 1.,  4.],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 2.,  2.],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 4.,  1.],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 5.,  1.]])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.bincount(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([2, 4, 2, 0, 1, 1])</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.itemfreq(a/10.)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 0. ,  2. ],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.1,  4. ],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.2,  2. ],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.4,  1. ],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.5,  1. ]])</span>
<br><span style="color:green">+Returns</span>
<br><span style="color:green">+-------</span>
<br><span style="color:green">+itemfreq : (K, 2) ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA 2-D frequency table.  Column 1 contains sorted, unique values from</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`a`, column 2 contains their respective counts.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Examples</span>
<br><span style="color:green">+--------</span>
<br><span style="color:green">+>>> from scipy import stats</span>
<br><span style="color:green">+>>> a = np.array([1, 1, 5, 0, 1, 2, 2, 0, 1, 4])</span>
<br><span style="color:green">+>>> stats.itemfreq(a)</span>
<br><span style="color:green">+array([[ 0.,  2.],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 1.,  4.],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 2.,  2.],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 4.,  1.],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 5.,  1.]])</span>
<br><span style="color:green">+>>> np.bincount(a)</span>
<br><span style="color:green">+array([2, 4, 2, 0, 1, 1])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+>>> stats.itemfreq(a/10.)</span>
<br><span style="color:green">+array([[ 0. ,  2. ],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.1,  4. ],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.2,  2. ],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.4,  1. ],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.5,  1. ]])</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspitems, inv = np.unique(a, return_inverse=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbspfreq = np.bincount(inv)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([items, freq]).T
<br>@@ -1586,8 +1746,7 @@ def itemfreq(a):
<br>&nbsp
<br>&nbspdef scoreatpercentile(a, per, limit=(), interpolation_method='fraction',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the score at a given percentile of the input sequence.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate the score at a given percentile of the input sequence.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor example, the score at `per=50` is the median. If the desired quantile
<br>&nbsp &nbsp &nbsp &nbsp &nbsplies between two data points, we interpolate between them, according to
<br>@@ -1606,13 +1765,14 @@ def scoreatpercentile(a, per, limit=(), interpolation_method='fraction',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompute the percentile. Values of `a` outside
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis (closed) interval will be ignored.
<br>&nbsp &nbsp &nbsp &nbsp &nbspinterpolation_method : {'fraction', 'lower', 'higher'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis optional parameter specifies the interpolation method to use,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecifies the interpolation method to use,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen the desired quantile lies between two data points `i` and `j`
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'fraction'):</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- fraction: ``i + (j - i) * fraction`` where ``fraction`` is the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfractional part of the index surrounded by ``i`` and ``j``.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- lower: ``i``.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- higher: ``j``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'fraction': ``i + (j - i) * fraction`` where ``fraction`` is the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfractional part of the index surrounded by ``i`` and ``j``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'lower': ``i``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'higher': ``j``</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which the percentiles are computed. Default is None. If
<br>@@ -1630,7 +1790,7 @@ def scoreatpercentile(a, per, limit=(), interpolation_method='fraction',
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function will become obsolete in the future.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspFor Numpy 1.9 and higher, `numpy.percentile` provides all the functionality</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor NumPy 1.9 and higher, `numpy.percentile` provides all the functionality</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspthat `scoreatpercentile` provides.  And it's significantly faster.
<br>&nbsp &nbsp &nbsp &nbsp &nbspTherefore it's recommended to use `numpy.percentile` for users that have
<br>&nbsp &nbsp &nbsp &nbsp &nbspnumpy >= 1.9.
<br>@@ -1651,30 +1811,31 @@ def scoreatpercentile(a, per, limit=(), interpolation_method='fraction',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isscalar(per):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.ones(np.asarray(per).shape, dtype=np.float64) * np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.full(np.asarray(per).shape, np.nan, dtype=np.float64)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif limit:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = a[(limit[0] <= a) & (a <= limit[1])]
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsorted = np.sort(a, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsorted_ = np.sort(a, axis=axis)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif axis is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = 0
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn _compute_qth_percentile(sorted, per, interpolation_method, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn _compute_qth_percentile(sorted_, per, interpolation_method, axis)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp# handle sequence of per's without calling sort multiple times
<br><span style="color:red">- def _compute_qth_percentile(sorted, per, interpolation_method, axis):</span>
<br><span style="color:green">+def _compute_qth_percentile(sorted_, per, interpolation_method, axis):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not np.isscalar(per):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscore = [_compute_qth_percentile(sorted, i, interpolation_method, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscore = [_compute_qth_percentile(sorted_, i,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpolation_method, axis)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in per]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array(score)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (per < 0) or (per > 100):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not (0 <= per <= 100):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("percentile must be in the range [0, 100]")
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspindexer = [slice(None)] * sorted.ndim</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspidx = per / 100. * (sorted.shape[axis] - 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindexer = [slice(None)] * sorted_.ndim</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspidx = per / 100. * (sorted_.shape[axis] - 1)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif int(idx) != idx:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# round fractional indices according to interpolation method
<br>@@ -1697,18 +1858,17 @@ def _compute_qth_percentile(sorted, per, interpolation_method, axis):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindexer[axis] = slice(i, i + 2)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspj = i + 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights = array([(j - idx), (idx - i)], float)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwshape = [1] * sorted.ndim</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwshape = [1] * sorted_.ndim</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwshape[axis] = 2
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights.shape = wshape
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsumval = weights.sum()
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Use np.add.reduce (== np.sum but a little faster) to coerce data type
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.add.reduce(sorted_[tuple(indexer)] * weights, axis=axis) / sumval</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef percentileofscore(a, score, kind='rank'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe percentile rank of a score relative to a list of scores.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the percentile rank of a score relative to a list of scores.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspA `percentileofscore` of, for example, 80% means that 80% of the
<br>&nbsp &nbsp &nbsp &nbsp &nbspscores in `a` are below the given score. In the case of gaps or
<br>@@ -1721,22 +1881,18 @@ def percentileofscore(a, score, kind='rank'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspscore : int or float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScore that is compared to the elements in `a`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkind : {'rank', 'weak', 'strict', 'mean'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis optional parameter specifies the interpretation of the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresulting score:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "rank": Average percentage ranking of score.  In case of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple matches, average the percentage rankings of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall matching scores.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "weak": This kind corresponds to the definition of a cumulative</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution function.  A percentileofscore of 80%</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmeans that 80% of values are less than or equal</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto the provided score.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "strict": Similar to "weak", except that only values that are</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrictly less than the given score are counted.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "mean": The average of the "weak" and "strict" scores, often used in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptesting.  See</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttp://en.wikipedia.org/wiki/Percentile_rank</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecifies the interpretation of the resulting score.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'rank'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'rank': Average percentage ranking of score.  In case of multiple</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatches, average the percentage rankings of all matching scores.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'weak': This kind corresponds to the definition of a cumulative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution function.  A percentileofscore of 80% means that 80%</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof values are less than or equal to the provided score.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'strict': Similar to "weak", except that only values that are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrictly less than the given score are counted.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'mean': The average of the "weak" and "strict" scores, often used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin testing.  See https://en.wikipedia.org/wiki/Percentile_rank</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -1771,33 +1927,32 @@ def percentileofscore(a, score, kind='rank'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.percentileofscore([1, 2, 3, 3, 4], 3, kind='weak')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp80.0
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe average between the weak and the strict scores is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe average between the weak and the strict scores is:</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.percentileofscore([1, 2, 3, 3, 4], 3, kind='mean')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp60.0
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa = np.array(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.isnan(score):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = np.asarray(a)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = len(a)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif n == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn 100.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif kind == 'rank':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.any(a == score):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.append(a, score)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_len = np.array(list(range(len(a))))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_len = np.array(list(range(len(a)))) + 1.0</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.sort(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspidx = [a == score]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppct = (np.mean(a_len[idx]) / n) * 100.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = np.count_nonzero(a < score)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright = np.count_nonzero(a <= score)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppct = (right + left + (1 if right > left else 0)) * 50.0/n</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn pct
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif kind == 'strict':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(a < score) / float(n) * 100</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.count_nonzero(a < score) / n * 100</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif kind == 'weak':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(a <= score) / float(n) * 100</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.count_nonzero(a <= score) / n * 100</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif kind == 'mean':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (np.sum(a < score) + np.sum(a <= score)) * 50 / float(n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppct = (np.count_nonzero(a < score)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp+ np.count_nonzero(a <= score)) / n * 50</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn pct</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("kind can only be 'rank', 'strict', 'weak' or 'mean'")
<br>&nbsp
<br>@@ -1806,8 +1961,10 @@ HistogramResult = namedtuple('HistogramResult',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('count', 'lowerlimit', 'binsize', 'extrapoints'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def _histogram(a, numbins=10, defaultlimits=None, weights=None, printextras=False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+def _histogram(a, numbins=10, defaultlimits=None, weights=None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprintextras=False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Create a histogram.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspSeparate the range into several bins and return the number of instances
<br>&nbsp &nbsp &nbsp &nbsp &nbspin each bin.
<br>&nbsp
<br>@@ -1888,8 +2045,7 @@ CumfreqResult = namedtuple('CumfreqResult',
<br>&nbsp
<br>&nbsp
<br>&nbspdef cumfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturn a cumulative frequency histogram, using the histogram function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Return a cumulative frequency histogram, using the histogram function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspA cumulative histogram is a mapping that counts the cumulative number of
<br>&nbsp &nbsp &nbsp &nbsp &nbspobservations in all of the bins up to the specified bin.
<br>@@ -1923,7 +2079,9 @@ def cumfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> import matplotlib.pyplot as plt
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from numpy.random import default_rng</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = default_rng()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [1, 4, 2, 1, 3, 1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> res = stats.cumfreq(x, numbins=4, defaultreallimits=(1.5, 5))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> res.cumcount
<br>@@ -1933,7 +2091,6 @@ def cumfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspCreate a normal distribution with 1000 random values
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rng = np.random.RandomState(seed=12345)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> samples = stats.norm.rvs(size=1000, random_state=rng)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspCalculate cumulative frequencies
<br>@@ -1970,8 +2127,7 @@ RelfreqResult = namedtuple('RelfreqResult',
<br>&nbsp
<br>&nbsp
<br>&nbspdef relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturn a relative frequency histogram, using the histogram function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Return a relative frequency histogram, using the histogram function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspA relative frequency  histogram is a mapping of the number of
<br>&nbsp &nbsp &nbsp &nbsp &nbspobservations in each of the bins relative to the total of observations.
<br>@@ -1996,7 +2152,7 @@ def relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrequency : ndarray
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBinned values of relative frequency.
<br>&nbsp &nbsp &nbsp &nbsp &nbsplowerlimit : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLower real limit</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLower real limit.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbinsize : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWidth of each bin.
<br>&nbsp &nbsp &nbsp &nbsp &nbspextrapoints : int
<br>@@ -2005,7 +2161,9 @@ def relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> import matplotlib.pyplot as plt
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from numpy.random import default_rng</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = default_rng()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> a = np.array([2, 4, 1, 2, 3, 2])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> res = stats.relfreq(a, numbins=4)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> res.frequency
<br>@@ -2015,7 +2173,6 @@ def relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspCreate a normal distribution with 1000 random values
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rng = np.random.RandomState(seed=12345)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> samples = stats.norm.rvs(size=1000, random_state=rng)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspCalculate relative frequencies
<br>@@ -2040,7 +2197,7 @@ def relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa = np.asanyarray(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbsph, l, b, e = _histogram(a, numbins, defaultreallimits, weights=weights)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsph = h / float(a.shape[0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsph = h / a.shape[0]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn RelfreqResult(h, l, b, e)
<br>&nbsp
<br>@@ -2050,8 +2207,7 @@ def relfreq(a, numbins=10, defaultreallimits=None, weights=None):
<br>&nbsp#####################################
<br>&nbsp
<br>&nbspdef obrientransform(*args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the O'Brien transform on input data (any number of arrays).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the O'Brien transform on input data (any number of arrays).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspUsed to test for homogeneity of variance prior to running one-way stats.
<br>&nbsp &nbsp &nbsp &nbsp &nbspEach array in ``*args`` is one level of a factor.
<br>@@ -2099,11 +2255,13 @@ def obrientransform(*args):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf we require that ``p < 0.05`` for significance, we cannot conclude
<br>&nbsp &nbsp &nbsp &nbsp &nbspthat the variances are different.
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspTINY = np.sqrt(np.finfo(float).eps)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# `arrays` will hold the transformed arguments.
<br>&nbsp &nbsp &nbsp &nbsp &nbsparrays = []
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsLast = None</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor arg in args:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.asarray(arg)
<br>@@ -2122,12 +2280,18 @@ def obrientransform(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Lack of convergence in obrientransform.')
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrays.append(t)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsLast = a.shape</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif sLast:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor arr in arrays[:-1]:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif sLast != arr.shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array(arrays, dtype=object)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn np.array(arrays)
<br>&nbsp
<br>&nbsp
<br>&nbspdef sem(a, axis=0, ddof=1, nan_policy='propagate'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute standard error of the mean.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspCalculate the standard error of the mean (or standard error of
<br>&nbsp &nbsp &nbsp &nbsp &nbspmeasurement) of the values in the input array.
<br>&nbsp
<br>@@ -2144,9 +2308,12 @@ def sem(a, axis=0, ddof=1, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor bias in limited samples relative to the population estimate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof variance. Defaults to 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -2186,25 +2353,77 @@ def sem(a, axis=0, ddof=1, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn s
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def zscore(a, axis=0, ddof=0):</span>
<br><span style="color:green">+def _isconst(x):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the z score of each value in the sample, relative to the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsample mean and standard deviation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCheck if all values in x are the same.  nans are ignored.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa : array_like</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array like object containing the sample data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis : int or None, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to operate. Default is 0. If None, compute over</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe whole array `a`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspddof : int, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom correction in the calculation of the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstandard deviation. Default is 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx must be a 1d array.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspzscore : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe return value is a 1d array with length 1, so it can be used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin np.apply_along_axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = x[~np.isnan(x)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif y.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([True])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (y[0] == y).all(keepdims=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _quiet_nanmean(x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute nanmean for the 1d array x, but quietly return nan if x is all nan.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe return value is a 1d array with length 1, so it can be used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin np.apply_along_axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = x[~np.isnan(x)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif y.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([np.nan])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.mean(y, keepdims=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _quiet_nanstd(x, ddof=0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute nanstd for the 1d array x, but quietly return nan if x is all nan.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe return value is a 1d array with length 1, so it can be used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin np.apply_along_axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = x[~np.isnan(x)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif y.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([np.nan])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.std(y, keepdims=True, ddof=ddof)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def zscore(a, axis=0, ddof=0, nan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the z score.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the z score of each value in the sample, relative to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample mean and standard deviation.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array like object containing the sample data.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int or None, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to operate. Default is 0. If None, compute over</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe whole array `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspddof : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom correction in the calculation of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstandard deviation. Default is 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.  Note that when the value is 'omit',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnans in the input also propagate to the output, but they do not affect</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe z-scores computed for the non-nan values.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspzscore : array_like</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe z-scores, standardized by mean and standard deviation of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput array `a`.
<br>&nbsp
<br>@@ -2237,18 +2456,19 @@ def zscore(a, axis=0, ddof=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.26796377, -1.12598418,  1.23283094, -0.37481053],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.22095197,  0.24468594,  1.19042819, -1.21416216],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.82780366,  1.4457416 , -0.43867764, -0.1792603 ]])
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAn example with `nan_policy='omit'`:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.array([[25.11, 30.10, np.nan, 32.02, 43.15],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [14.95, 16.06, 121.25, 94.35, 29.81]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.zscore(x, axis=1, nan_policy='omit')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[-1.13490897, -0.37830299,         nan, -0.08718406,  1.60039602],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa = np.asanyarray(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmns = a.mean(axis=axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsstd = a.std(axis=axis, ddof=ddof)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif axis and mns.ndim < a.ndim:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ((a - np.expand_dims(mns, axis=axis)) /</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.expand_dims(sstd, axis=axis))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (a - mns) / sstd</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn zmap(a, a, axis=axis, ddof=ddof, nan_policy=nan_policy)</span>
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def zmap(scores, compare, axis=0, ddof=0):</span>
<br><span style="color:green">+def zmap(scores, compare, axis=0, ddof=0, nan_policy='propagate'):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspCalculate the relative z-scores.
<br>&nbsp
<br>@@ -2270,6 +2490,13 @@ def zmap(scores, compare, axis=0, ddof=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspddof : int, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom correction in the calculation of the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstandard deviation. Default is 0.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle the occurrence of nans in `compare`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'propagate' returns nan, 'raise' raises an exception, 'omit'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspperforms the calculations ignoring nan values. Default is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'propagate'. Note that when the value is 'omit', nans in `scores`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalso propagate to the output, but they do not affect the z-scores</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomputed for the non-nan values.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -2289,15 +2516,168 @@ def zmap(scores, compare, axis=0, ddof=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> b = [0, 1, 2, 3, 4]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> zmap(a, b)
<br>&nbsp &nbsp &nbsp &nbsp &nbsparray([-1.06066017,  0.        ,  0.35355339,  0.70710678])
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscores, compare = map(np.asanyarray, [scores, compare])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmns = compare.mean(axis=axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsstd = compare.std(axis=axis, ddof=ddof)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif axis and mns.ndim < compare.ndim:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ((scores - np.expand_dims(mns, axis=axis)) /</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.expand_dims(sstd, axis=axis))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = np.asanyarray(compare)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif a.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.empty(a.shape)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(a, nan_policy)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmn = _quiet_nanmean(a.ravel())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd = _quiet_nanstd(a.ravel(), ddof=ddof)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisconst = _isconst(a.ravel())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmn = np.apply_along_axis(_quiet_nanmean, axis, a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd = np.apply_along_axis(_quiet_nanstd, axis, a, ddof=ddof)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisconst = np.apply_along_axis(_isconst, axis, a)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (scores - mns) / sstd</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmn = a.mean(axis=axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd = a.std(axis=axis, ddof=ddof, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisconst = (a.item(0) == a).all()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisconst = (_first(a, axis) == a).all(axis=axis, keepdims=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Set std deviations that are 0 to 1 to avoid division by 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstd[isconst] = 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspz = (scores - mn) / std</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Set the outputs associated with a constant input to nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspz[np.broadcast_to(isconst, z.shape)] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn z</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def gstd(a, axis=0, ddof=1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCalculate the geometric standard deviation of an array.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe geometric standard deviation describes the spread of a set of numbers</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere the geometric mean is preferred. It is a multiplicative factor, and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspso a dimensionless quantity.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIt is defined as the exponent of the standard deviation of ``log(a)``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMathematically the population geometric standard deviation can be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspevaluated as::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgstd = exp(std(log(a)))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.3.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array like object containing the sample data.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int, tuple or None, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to operate. Default is 0. If None, compute over</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe whole array `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspddof : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegree of freedom correction in the calculation of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgeometric standard deviation. Default is 1.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspndarray or float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array of the geometric standard deviation. If `axis` is None or `a`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis a 1d array a float is returned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAs the calculation requires the use of logarithms the geometric standard</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdeviation only supports strictly positive values. Any non-positive or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinfinite values will raise a `ValueError`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe geometric standard deviation is sometimes confused with the exponent of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe standard deviation, ``exp(std(a))``. Instead the geometric standard</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdeviation is ``exp(std(log(a)))``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe default value for `ddof` is different to the default value (0) used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspby other ddof containing functions, such as ``np.std`` and ``np.nanstd``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFind the geometric standard deviation of a log-normally distributed sample.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNote that the standard deviation of the distribution is one, on a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplog scale this evaluates to approximately ``exp(1)``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import gstd</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> sample = rng.lognormal(mean=0, sigma=1, size=1000)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> gstd(sample)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2.810010162475324</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the geometric standard deviation of a multidimensional array and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof a given axis.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.arange(1, 25).reshape(2, 3, 4)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> gstd(a, axis=None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2.2944076136018947</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> gstd(a, axis=2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[1.82424757, 1.22436866, 1.13183117],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[1.09348306, 1.07244798, 1.05914985]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> gstd(a, axis=(1,2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([2.12939215, 1.22120169])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe geometric standard deviation further handles masked arrays.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.arange(1, 25).reshape(2, 3, 4)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ma = np.ma.masked_where(a > 16, a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ma</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmasked_array(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata=[[[1, 2, 3, 4],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[5, 6, 7, 8],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[9, 10, 11, 12]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[[13, 14, 15, 16],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[--, --, --, --],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[--, --, --, --]]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=[[[False, False, False, False],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[False, False, False, False],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[False, False, False, False]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[[False, False, False, False],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ True,  True,  True,  True],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ True,  True,  True,  True]]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfill_value=999999)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> gstd(ma, axis=2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmasked_array(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata=[[1.8242475707663655, 1.2243686572447428, 1.1318311657788478],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[1.0934830582350938, --, --]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=[[False, False, False],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[False,  True,  True]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfill_value=999999)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = np.asanyarray(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplog = ma.log if isinstance(a, ma.MaskedArray) else np.log</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith warnings.catch_warnings():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.simplefilter("error", RuntimeWarning)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(np.std(log(a), axis=axis, ddof=ddof))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept RuntimeWarning as w:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(a).any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Infinite value encountered. The geometric standard deviation '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'is defined for strictly positive values only.'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp) from w</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_nan = np.isnan(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_nan_any = a_nan.any()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# exclude NaN's from negativity check, but</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# avoid expensive masking for arrays with no NaN</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ((a_nan_any and np.less_equal(np.nanmin(a), 0)) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(not a_nan_any and np.less_equal(a, 0).any())):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Non positive value encountered. The geometric standard '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'deviation is defined for strictly positive values only.'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp) from w</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif 'Degrees of freedom <= 0 for slice' == str(w):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(w) from w</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#  Remaining warnings don't need to be exceptions.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(np.std(log(a, where=~a_nan), axis=axis, ddof=ddof))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept TypeError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Invalid array input. The inputs could not be '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'safely coerced to any supported types') from e</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp# Private dictionary initialized only once at module level
<br>@@ -2306,9 +2686,9 @@ _scale_conversions = {'raw': 1.0,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'normal': special.erfinv(0.5) * 2.0 * math.sqrt(2.0)}
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',</span>
<br><span style="color:green">+def iqr(x, axis=None, rng=(25, 75), scale=1.0, nan_policy='propagate',</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpolation='linear', keepdims=False):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspCompute the interquartile range of the data along the specified axis.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe interquartile range (IQR) is the difference between the 75th and
<br>@@ -2339,30 +2719,38 @@ def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe numerical value of scale will be divided out of the final
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult. The following string values are recognized:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raw' : No scaling, just return the raw IQR.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'normal' : Scale by :math:`2 \\sqrt{2} erf^{-1}(\\frac{1}{2}) \\approx 1.349`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raw' : No scaling, just return the raw IQR.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**Deprecated!**  Use `scale=1` instead.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'normal' : Scale by</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp:math:`2 \sqrt{2} erf^{-1}(\frac{1}{2}) \approx 1.349`.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe default is 'raw'. Array-like scale is also allowed, as long</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe default is 1.0. The use of scale='raw' is deprecated.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray-like scale is also allowed, as long</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas it broadcasts correctly to the output such that
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``out / scale`` is a valid operation. The output dimensions
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepend on the input array, `x`, the `axis` argument, and the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keepdims` flag.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturns nan, 'raise' throws an error, 'omit' performs the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcalculations ignoring nan values. Default is 'propagate'.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinterpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinterpolation : {'linear', 'lower', 'higher', 'midpoint',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'nearest'}, optional</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecifies the interpolation method to use when the percentile
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspboundaries lie between two data points `i` and `j`:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspboundaries lie between two data points `i` and `j`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'linear'):</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'linear' : `i + (j - i) * fraction`, where `fraction` is the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfractional part of the index surrounded by `i` and `j`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'lower' : `i`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'higher' : `j`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'nearest' : `i` or `j` whichever is nearest.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'midpoint' : `(i + j) / 2`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'linear': `i + (j - i) * fraction`, where `fraction` is the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfractional part of the index surrounded by `i` and `j`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'lower': `i`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'higher': `j`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'nearest': `i` or `j` whichever is nearest.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'midpoint': `(i + j) / 2`.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 'linear'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkeepdims : bool, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf this is set to `True`, the reduced axes are left in the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult as dimensions with size one. With this option, the result
<br>@@ -2380,23 +2768,6 @@ def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspnumpy.std, numpy.var
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import iqr</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[10,  7,  4],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 3,  2,  1]])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> iqr(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp4.0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([ 3.5,  2.5,  1.5])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([ 3.,  1.])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=1, keepdims=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 3.],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 1.]])</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function is heavily dependent on the version of `numpy` that is
<br>@@ -2423,6 +2794,24 @@ def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] "Interquartile range" https://en.wikipedia.org/wiki/Interquartile_range
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [2] "Robust measures of scale" https://en.wikipedia.org/wiki/Robust_measures_of_scale
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [3] "Quantile" https://en.wikipedia.org/wiki/Quantile
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import iqr</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[10,  7,  4],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 3,  2,  1]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> iqr(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp4.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([ 3.5,  2.5,  1.5])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([ 3.,  1.])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> iqr(x, axis=1, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[ 3.],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 1.]])</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = asarray(x)
<br>&nbsp
<br>@@ -2433,26 +2822,34 @@ def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# An error may be raised here, so fail-fast, before doing lengthy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# computations, even though `scale` is not used until later
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(scale, string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(scale, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale_key = scale.lower()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale_key not in _scale_conversions:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("{0} not a valid scale for `iqr`".format(scale))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale_key == 'raw':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"use of scale='raw' is deprecated, use scale=1.0 instead",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.VisibleDeprecationWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = _scale_conversions[scale_key]
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Select the percentile function to use based on nans and policy
<br>&nbsp &nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(x, nan_policy)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppercentile_func = _iqr_nanpercentile</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppercentile_func = np.nanpercentile</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppercentile_func = _iqr_percentile</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppercentile_func = np.percentile</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(rng) != 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("quantile range must be two element sequence")
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.isnan(rng).any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("range must not contain NaNs")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsprng = sorted(rng)
<br>&nbsp &nbsp &nbsp &nbsp &nbsppct = percentile_func(x, rng, axis=axis, interpolation=interpolation,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeepdims=keepdims, contains_nan=contains_nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeepdims=keepdims)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspout = np.subtract(pct[1], pct[0])
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif scale != 1.0:
<br>@@ -2461,129 +2858,322 @@ def iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate',
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def _iqr_percentile(x, q, axis=None, interpolation='linear', keepdims=False, contains_nan=False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspPrivate wrapper that works around older versions of `numpy`.</span>
<br><span style="color:green">+def _mad_1d(x, center, nan_policy):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Median absolute deviation for 1-d array x.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# This is a helper function for `median_abs_deviation`; it assumes its</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# arguments have been validated already.  In particular,  x must be a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# 1-d numpy array, center must be callable, and if nan_policy is not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# 'propagate', it is assumed to be 'omit', because 'raise' is handled</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# in `median_abs_deviation`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# No warning is generated if x is empty or all nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspisnan = np.isnan(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isnan.any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif nan_policy == 'propagate':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x[~isnan]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif x.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# MAD of an empty array is nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Edge cases have been handled, so do the basic MAD calculation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmed = center(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmad = np.median(np.abs(x - med))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn mad</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def median_abs_deviation(x, axis=0, center=np.median, scale=1.0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the median absolute deviation of the data along the given axis.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe median absolute deviation (MAD, [1]_) computes the median over the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspabsolute deviations from the median. It is a measure of dispersion</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsimilar to the standard deviation but more robust to outliers [2]_.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe MAD of an empty array is ``np.nan``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.5.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array or object that can be converted to an array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int or None, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which the range is computed. Default is 0. If None, compute</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe MAD over the entire array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcenter : callable, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA function that will return the central value. The default is to use</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.median. Any user defined function used will need to have the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction signature ``func(arr, axis)``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscale : scalar or str, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe numerical value of scale will be divided out of the final</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult. The default is 1.0. The string "normal" is also accepted,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand results in `scale` being the inverse of the standard normal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspquantile function at 0.75, which is approximately 0.67449.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray-like scale is also allowed, as long as it broadcasts correctly</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto the output such that ``out / scale`` is a valid operation. The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput dimensions depend on the input array, `x`, and the `axis`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargument.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmad : scalar or ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf ``axis=None``, a scalar is returned. If the input contains</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspintegers or floats of smaller precision than ``np.float64``, then the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput data-type is ``np.float64``. Otherwise, the output data-type is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe same as that of the input.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnumpy.std, numpy.var, numpy.median, scipy.stats.iqr, scipy.stats.tmean,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.tstd, scipy.stats.tvar</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe `center` argument only affects the calculation of the central value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparound which the MAD is calculated. That is, passing in ``center=np.mean``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwill calculate the MAD around the mean - it will not calculate the *mean*</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspabsolute deviation.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe input array may contain `inf`, but if `center` returns `inf`, the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorresponding MAD for that data will be `nan`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] "Median absolute deviation",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Median_absolute_deviation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] "Robust measures of scale",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Robust_measures_of_scale</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen comparing the behavior of `median_abs_deviation` with ``np.std``,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe latter is affected when we change a single value of an array to have an</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutlier value while the MAD hardly changes:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(size=100, scale=1, random_state=123456)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x.std()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.9973906394005013</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.82832610097857</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x[0] = 345.6</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x.std()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp34.42304872314415</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.8323442311590675</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAxis handling example:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[10,  7,  4],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 3,  2,  1]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([3.5, 2.5, 1.5])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x, axis=None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspScale normal example:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(size=1000000, scale=2, random_state=123456)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp1.3487398527041636</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.median_abs_deviation(x, scale='normal')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp1.9996446978061115</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWhile this function is pretty much necessary for the moment, it</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshould be removed as soon as the minimum supported numpy version</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspallows.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif contains_nan and NumpyVersion(np.__version__) < '1.10.0a':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# I see no way to avoid the version check to ensure that the corrected</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# NaN behavior has been implemented except to call `percentile` on a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# small array.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = "Keyword nan_policy='propagate' not correctly supported for " \</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"numpy versions < 1.10.x. The default behavior of " \</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"`numpy.percentile` will be used."</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(msg, RuntimeWarning)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not callable(center):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("The argument 'center' must be callable. The given "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"value {repr(center)} is not callable.")</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# For older versions of numpy, there are two things that can cause a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# problem here: missing keywords and non-scalar axis. The former can be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# partially handled with a warning, the latter can be handled fully by</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# hacking in an implementation similar to numpy's function for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# providing multi-axis functionality</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# (`numpy.lib.function_base._ureduce` for the curious).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.percentile(x, q, axis=axis, keepdims=keepdims,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpolation=interpolation)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexcept TypeError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif interpolation != 'linear' or keepdims:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# At time or writing, this means np.__version__ < 1.9.0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn("Keywords interpolation and keepdims not supported "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"for your version of numpy", RuntimeWarning)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Special processing if axis is an iterable</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporiginal_size = len(axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept TypeError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Axis is a scalar at this point</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppass</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# An error may be raised here, so fail-fast, before doing lengthy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# computations, even though `scale` is not used until later</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(scale, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale.lower() == 'normal':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = 0.6744897501960817  # special.ndtri(0.75)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = np.unique(np.asarray(axis) % x.ndim)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif original_size > axis.size:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# mimic numpy if axes are duplicated</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("duplicate value in axis")</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis.size == x.ndim:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# axis includes all axes: revert to None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif axis.size == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# no rolling necessary</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = axis[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# roll multiple axes to the end and flatten that part out</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor ax in axis[::-1]:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.rollaxis(x, ax, x.ndim)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x.reshape(x.shape[:-axis.size] +</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(np.prod(x.shape[-axis.size:]),))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = -1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.percentile(x, q, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f"{scale} is not a valid scale value.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = asarray(x)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn result</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Consistent with `np.var` and `np.std`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not x.size:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_shape = tuple(item for i, item in enumerate(x.shape) if i != axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif nan_shape == ():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Return nan, not array(nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.full(nan_shape, np.nan)</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(x, nan_policy)</span>
<br>&nbsp
<br><span style="color:red">- def _iqr_nanpercentile(x, q, axis=None, interpolation='linear', keepdims=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan=False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspPrivate wrapper that works around the following:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1. A bug in `np.nanpercentile` that was around until numpy version</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1.11.0.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2. A bug in `np.percentile` NaN handling that was fixed in numpy</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspversion 1.10.0.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp3. The non-existence of `np.nanpercentile` before numpy version</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1.9.0.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWhile this function is pretty much necessary for the moment, it</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshould be removed as soon as the minimum supported numpy version</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspallows.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif hasattr(np, 'nanpercentile'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# At time or writing, this means np.__version__ < 1.9.0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.nanpercentile(x, q, axis=axis,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpolation=interpolation,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeepdims=keepdims)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If non-scalar result and nanpercentile does not do proper axis roll.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# I see no way of avoiding the version test since dimensions may just</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# happen to match in the data.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif result.ndim > 1 and NumpyVersion(np.__version__) < '1.11.0a':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = np.asarray(axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis.size == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If only one axis specified, reduction happens along that dimension</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis.ndim == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = axis[None]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.rollaxis(result, axis[0])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If multiple axes, reduced dimeision is last</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.rollaxis(result, -1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif contains_nan:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmad = _mad_1d(x.ravel(), center, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmad = np.apply_along_axis(_mad_1d, axis, x, center, nan_policy)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = "Keyword nan_policy='omit' not correctly supported for numpy " \</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"versions < 1.9.x. The default behavior of  numpy.percentile " \</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"will be used."</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(msg, RuntimeWarning)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = _iqr_percentile(x, q, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmed = center(x, axis=None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmad = np.median(np.abs(x - med))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Wrap the call to center() in expand_dims() so it acts like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# keepdims=True was used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmed = np.expand_dims(center(x, axis=axis), axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmad = np.median(np.abs(x - med), axis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn mad / scale</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+# Keep the top newline so that the message does not show up on the stats page</span>
<br><span style="color:green">+_median_absolute_deviation_deprec_msg = """</span>
<br><span style="color:green">+To preserve the existing default behavior, use</span>
<br><span style="color:green">+`scipy.stats.median_abs_deviation(..., scale=1/1.4826)`.</span>
<br><span style="color:green">+The value 1.4826 is not numerically precise for scaling</span>
<br><span style="color:green">+with a normal distribution. For a numerically precise value, use</span>
<br><span style="color:green">+`scipy.stats.median_abs_deviation(..., scale='normal')`.</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+# Due to numpy/gh-16349 we need to unindent the entire docstring</span>
<br><span style="color:green">+@np.deprecate(old_name='median_absolute_deviation',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_name='median_abs_deviation',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmessage=_median_absolute_deviation_deprec_msg)</span>
<br><span style="color:green">+def median_absolute_deviation(x, axis=0, center=np.median, scale=1.4826,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:green">+Compute the median absolute deviation of the data along the given axis.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+The median absolute deviation (MAD, [1]_) computes the median over the</span>
<br><span style="color:green">+absolute deviations from the median. It is a measure of dispersion</span>
<br><span style="color:green">+similar to the standard deviation but more robust to outliers [2]_.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+The MAD of an empty array is ``np.nan``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+.. versionadded:: 1.3.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Parameters</span>
<br><span style="color:green">+----------</span>
<br><span style="color:green">+x : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspInput array or object that can be converted to an array.</span>
<br><span style="color:green">+axis : int or None, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAxis along which the range is computed. Default is 0. If None, compute</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe MAD over the entire array.</span>
<br><span style="color:green">+center : callable, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA function that will return the central value. The default is to use</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnp.median. Any user defined function used will need to have the function</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsignature ``func(arr, axis)``.</span>
<br><span style="color:green">+scale : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe scaling factor applied to the MAD. The default scale (1.4826)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspensures consistency with the standard deviation for normally distributed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata.</span>
<br><span style="color:green">+nan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Returns</span>
<br><span style="color:green">+-------</span>
<br><span style="color:green">+mad : scalar or ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf ``axis=None``, a scalar is returned. If the input contains</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspintegers or floats of smaller precision than ``np.float64``, then the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutput data-type is ``np.float64``. Otherwise, the output data-type is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe same as that of the input.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+See Also</span>
<br><span style="color:green">+--------</span>
<br><span style="color:green">+numpy.std, numpy.var, numpy.median, scipy.stats.iqr, scipy.stats.tmean,</span>
<br><span style="color:green">+scipy.stats.tstd, scipy.stats.tvar</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Notes</span>
<br><span style="color:green">+-----</span>
<br><span style="color:green">+The `center` argument only affects the calculation of the central value</span>
<br><span style="color:green">+around which the MAD is calculated. That is, passing in ``center=np.mean``</span>
<br><span style="color:green">+will calculate the MAD around the mean - it will not calculate the *mean*</span>
<br><span style="color:green">+absolute deviation.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+References</span>
<br><span style="color:green">+----------</span>
<br><span style="color:green">+.. [1] "Median absolute deviation",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Median_absolute_deviation</span>
<br><span style="color:green">+.. [2] "Robust measures of scale",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Robust_measures_of_scale</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Examples</span>
<br><span style="color:green">+--------</span>
<br><span style="color:green">+When comparing the behavior of `median_absolute_deviation` with ``np.std``,</span>
<br><span style="color:green">+the latter is affected when we change a single value of an array to have an</span>
<br><span style="color:green">+outlier value while the MAD hardly changes:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+>>> from scipy import stats</span>
<br><span style="color:green">+>>> x = stats.norm.rvs(size=100, scale=1, random_state=123456)</span>
<br><span style="color:green">+>>> x.std()</span>
<br><span style="color:green">+0.9973906394005013</span>
<br><span style="color:green">+>>> stats.median_absolute_deviation(x)</span>
<br><span style="color:green">+1.2280762773108278</span>
<br><span style="color:green">+>>> x[0] = 345.6</span>
<br><span style="color:green">+>>> x.std()</span>
<br><span style="color:green">+34.42304872314415</span>
<br><span style="color:green">+>>> stats.median_absolute_deviation(x)</span>
<br><span style="color:green">+1.2340335571164334</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Axis handling example:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+>>> x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<br><span style="color:green">+>>> x</span>
<br><span style="color:green">+array([[10,  7,  4],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 3,  2,  1]])</span>
<br><span style="color:green">+>>> stats.median_absolute_deviation(x)</span>
<br><span style="color:green">+array([5.1891, 3.7065, 2.2239])</span>
<br><span style="color:green">+>>> stats.median_absolute_deviation(x, axis=None)</span>
<br><span style="color:green">+2.9652</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(scale, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale.lower() == 'raw':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"use of scale='raw' is deprecated, use scale=1.0 instead",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.VisibleDeprecationWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = 1.0</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn result</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not isinstance(scale, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = 1 / scale</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn median_abs_deviation(x, axis=axis, center=center, scale=scale,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy=nan_policy)</span>
<br>&nbsp
<br>&nbsp#####################################
<br>&nbsp#         TRIMMING FUNCTIONS        #
<br>&nbsp#####################################
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspSigmaclipResult = namedtuple('SigmaclipResult', ('clipped', 'lower', 'upper'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef sigmaclip(a, low=4., high=4.):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIterative sigma-clipping of array elements.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Perform iterative sigma-clipping of array elements.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe output array contains only those elements of the input array `c`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthat satisfy the conditions ::</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspStarting from the full sample, all elements outside the critical range are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspremoved, i.e. all elements of the input array `c` that satisfy either of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe following conditions::</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean(c) - std(c)*low < c < mean(c) + std(c)*high</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc < mean(c) - std(c)*low</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc > mean(c) + std(c)*high</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspStarting from the full sample, all elements outside the critical range are</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspremoved. The iteration continues with a new critical range until no</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelements are outside the range.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe iteration continues with the updated sample until no</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelements are outside the (updated) range.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2634,22 +3224,21 @@ def sigmaclip(a, low=4., high=4.):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = c.size
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcritlower = c_mean - c_std * low
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcritupper = c_mean + c_std * high
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc = c[(c > critlower) & (c < critupper)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc = c[(c >= critlower) & (c <= critupper)]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdelta = size - c.size
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn SigmaclipResult(c, critlower, critupper)
<br>&nbsp
<br>&nbsp
<br>&nbspdef trimboth(a, proportiontocut, axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSlices off a proportion of items from both ends of an array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Slice off a proportion of items from both ends of an array.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSlices off the passed proportion of items from both ends of the passed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSlice off the passed proportion of items from both ends of the passed</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsparray (i.e., with `proportiontocut` = 0.1, slices leftmost 10% **and**
<br>&nbsp &nbsp &nbsp &nbsp &nbsprightmost 10% of scores). The trimmed values are the lowest and
<br>&nbsp &nbsp &nbsp &nbsp &nbsphighest ones.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSlices off less if proportion results in a non-integer slice index (i.e.,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconservatively slices off`proportiontocut`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSlice off less if proportion results in a non-integer slice index (i.e.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspconservatively slices off `proportiontocut`).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2699,25 +3288,24 @@ def trimboth(a, proportiontocut, axis=0):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspsl = [slice(None)] * atmp.ndim
<br>&nbsp &nbsp &nbsp &nbsp &nbspsl[axis] = slice(lowercut, uppercut)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn atmp[sl]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn atmp[tuple(sl)]</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef trim1(a, proportiontocut, tail='right', axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSlices off a proportion from ONE end of the passed array distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Slice off a proportion from ONE end of the passed array distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf `proportiontocut` = 0.1, slices off 'leftmost' or 'rightmost'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp10% of scores. The lowest or highest values are trimmed (depending on
<br>&nbsp &nbsp &nbsp &nbsp &nbspthe tail).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSlices off less if proportion results in a non-integer slice index</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(i.e., conservatively slices off `proportiontocut` ).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSlice off less if proportion results in a non-integer slice index</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(i.e. conservatively slices off `proportiontocut` ).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspproportiontocut : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction to cut off of 'left' or 'right' of distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction to cut off of 'left' or 'right' of distribution.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptail : {'left', 'right'}, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to 'right'.
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>@@ -2730,6 +3318,14 @@ def trim1(a, proportiontocut, tail='right', axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrimmed version of array `a`. The order of the trimmed content is
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspundefined.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.arange(20)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = stats.trim1(a, 0.5, 'left')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([10, 11, 12, 13, 14, 16, 15, 17, 18, 19])</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa = np.asarray(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif axis is None:
<br>@@ -2756,8 +3352,7 @@ def trim1(a, proportiontocut, tail='right', axis=0):
<br>&nbsp
<br>&nbsp
<br>&nbspdef trim_mean(a, proportiontocut, axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturn mean of array after trimming distribution from both tails.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Return mean of array after trimming distribution from both tails.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf `proportiontocut` = 0.1, slices off 'leftmost' and 'rightmost' 10% of
<br>&nbsp &nbsp &nbsp &nbsp &nbspscores. The input is sorted before slicing. Slices off less if proportion
<br>@@ -2767,9 +3362,9 @@ def trim_mean(a, proportiontocut, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspproportiontocut : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction to cut off of both tails of the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction to cut off of both tails of the distribution.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspaxis : int or None, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which the trimmed means are computed. Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, compute over the whole array `a`.
<br>@@ -2782,7 +3377,7 @@ def trim_mean(a, proportiontocut, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptrimboth
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptmean : compute the trimmed mean ignoring values outside given `limits`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptmean : Compute the trimmed mean ignoring values outside given `limits`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -2822,14 +3417,57 @@ def trim_mean(a, proportiontocut, axis=0):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspsl = [slice(None)] * atmp.ndim
<br>&nbsp &nbsp &nbsp &nbsp &nbspsl[axis] = slice(lowercut, uppercut)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn np.mean(atmp[sl], axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.mean(atmp[tuple(sl)], axis=axis)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspF_onewayResult = namedtuple('F_onewayResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def f_oneway(*args):</span>
<br><span style="color:green">+class F_onewayConstantInputWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWarning generated by `f_oneway` when an input is constant, e.g.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspeach of the samples provided is a constant array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, msg=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif msg is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("Each of the input arrays is constant;"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"the F statistic is not defined or infinite")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = (msg,)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class F_onewayBadInputSizesWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWarning generated by `f_oneway` when an input has length 0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspor if all the inputs have length 1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppass</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _create_f_oneway_nan_result(shape, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a helper function for f_oneway for creating the return values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin certain degenerate conditions.  It creates return values that are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall nan with the appropriate shape for the given `shape` and `axis`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspPerforms a 1-way ANOVA.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis = np.core.multiarray.normalize_axis_index(axis, len(shape))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshp = shape[:axis] + shape[axis+1:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif shp == ():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = np.full(shp, fill_value=np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = f.copy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn F_onewayResult(f, prob)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _first(arr, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Return arr[..., 0:1, ...] where 0:1 is in the `axis` position."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.take_along_axis(arr, np.array(0, ndmin=arr.ndim), axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def f_oneway(*args, axis=0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Perform one-way ANOVA.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe one-way ANOVA tests the null hypothesis that two or more groups have
<br>&nbsp &nbsp &nbsp &nbsp &nbspthe same population mean.  The test is applied to samples from two or
<br>@@ -2838,14 +3476,31 @@ def f_oneway(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspsample1, sample2, ... : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample measurements for each group.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample measurements for each group.  There must be at least</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo arguments.  If the arrays are multidimensional, then all the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdimensions of the array must be the same except for `axis`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis of the input arrays along which the test is applied.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 0.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe computed F-value of the test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe computed F statistic of the test.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe associated p-value from the F-distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe associated p-value from the F distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWarns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspF_onewayConstantInputWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRaised if each of the input arrays is constant array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn this case the F statistic is either infinite or isn't defined,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspso ``np.inf`` or ``np.nan`` is returned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspF_onewayBadInputSizesWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRaised if the length of any input array is 0, or if all the input</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrays have length 1.  ``np.nan`` is returned for the F statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand the p-value in these cases.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -2857,29 +3512,42 @@ def f_oneway(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp3. The population standard deviations of the groups are all equal.  This
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspproperty is known as homoscedasticity.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf these assumptions are not true for a given set of data, it may still be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppossible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) although</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith some loss of power.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf these assumptions are not true for a given set of data, it may still</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbe possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe Alexander-Govern test (`scipy.stats.alexandergovern`) although with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsome loss of power.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe length of each group must be at least one, and there must be at</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspleast one group with length greater than one.  If these conditions</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspare not satisfied, a warning is generated and (``np.nan``, ``np.nan``)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis returned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf each group contains constant values, and there exist at least two</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgroups with different values, the function generates a warning and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturns (``np.inf``, 0).</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe algorithm is from Heiman[2], pp.394-7.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf all values in all groups are the same, function generates a warning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand returns (``np.nan``, ``np.nan``).</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe algorithm is from Heiman [2]_, pp.394-7.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] Lowry, Richard.  "Concepts and Applications of Inferential</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics". Chapter 14.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttp://faculty.vassar.edu/lowry/ch14pt1.html</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] R. Lowry, "Concepts and Applications of Inferential Statistics",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspChapter 14, 2014, http://vassarstats.net/textbook/</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] Heiman, G.W.  Research Methods in Statistics. 2002.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] G.W. Heiman, "Understanding research methods and statistics: An</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspintegrated introduction for psychology", Houghton, Mifflin and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompany, 2001.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [3] McDonald, G. H. "Handbook of Biological Statistics", One-way ANOVA.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] G.H. McDonald, "Handbook of Biological Statistics", One-way ANOVA.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttp://www.biostathandbook.com/onewayanova.html
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> import scipy.stats as stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import f_oneway</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp[3]_ Here are some data on a shell measurement (the length of the anterior</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspHere are some data [3]_ on a shell measurement (the length of the anterior</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspadductor muscle scar, standardized by dividing by length) in the mussel
<br>&nbsp &nbsp &nbsp &nbsp &nbspMytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;
<br>&nbsp &nbsp &nbsp &nbsp &nbspPetersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a
<br>@@ -2893,138 +3561,563 @@ def f_oneway(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...            0.0689]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.f_oneway(tillamook, newport, petersburg, magadan, tvarminne)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(7.1210194716424473, 0.00028122423145345439)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> f_oneway(tillamook, newport, petersburg, magadan, tvarminne)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspF_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`f_oneway` accepts multidimensional input arrays.  When the inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspare multidimensional and `axis` is not given, the test is performed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalong the first axis of the input arrays.  For the following data, the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptest is performed three times, once for each column.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.array([[9.87, 9.03, 6.81],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [7.18, 8.35, 7.00],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [8.39, 7.58, 7.68],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [7.45, 6.33, 9.35],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [6.41, 7.10, 9.33],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [8.00, 8.24, 8.44]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = np.array([[6.35, 7.30, 7.16],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [6.65, 6.68, 7.63],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [5.72, 7.73, 6.72],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [7.01, 9.19, 7.41],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [7.75, 7.87, 8.30],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [6.90, 7.97, 6.97]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> c = np.array([[3.31, 8.77, 1.01],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [8.25, 3.24, 3.62],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [6.32, 8.81, 5.19],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [7.48, 8.83, 8.91],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [8.59, 6.01, 6.07],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [3.07, 9.72, 7.48]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> F, p = f_oneway(a, b, c)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> F</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([1.75676344, 0.03701228, 3.76439349])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.20630784, 0.96375203, 0.04733157])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif len(args) < 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(f'at least two inputs are required; got {len(args)}.')</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspargs = [np.asarray(arg, dtype=float) for arg in args]
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# ANOVA on N groups, each in its own array
<br>&nbsp &nbsp &nbsp &nbsp &nbspnum_groups = len(args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspalldata = np.concatenate(args)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbign = len(alldata)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We haven't explicitly validated axis, but if it is bad, this call of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# np.concatenate will raise np.AxisError.  The call will raise ValueError</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# if the dimensions of all the arrays, except the axis dimension, are not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the same.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalldata = np.concatenate(args, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbign = alldata.shape[axis]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Check this after forming alldata, so shape errors are detected</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# and reported before checking for 0 length inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif any(arg.shape[axis] == 0 for arg in args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(F_onewayBadInputSizesWarning('at least one input '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'has length 0'))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _create_f_oneway_nan_result(alldata.shape, axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Must have at least one group with length greater than 1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif all(arg.shape[axis] == 1 for arg in args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ('all input arrays have length 1.  f_oneway requires that at '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'least one input has length greater than 1.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(F_onewayBadInputSizesWarning(msg))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _create_f_oneway_nan_result(alldata.shape, axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Check if the values within each group are constant, and if the common</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# value in at least one group is different from that in another group.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Based on https://github.com/scipy/scipy/issues/11669</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If axis=0, say, and the groups have shape (n0, ...), (n1, ...), ...,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# then is_const is a boolean array with shape (num_groups, ...).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# It is True if the groups along the axis slice are each consant.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# In the typical case where each input array is 1-d, is_const is a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# 1-d array with length num_groups.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_const = np.concatenate([(_first(a, axis) == a).all(axis=axis,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor a in args], axis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# all_const is a boolean array with shape (...) (see previous comment).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# It is True if the values within each group along the axis slice are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the same (e.g. [[3, 3, 3], [5, 5, 5, 5], [4, 4, 4]]).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall_const = is_const.all(axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif all_const.any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(F_onewayConstantInputWarning())</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# all_same_const is True if all the values in the groups along the axis=0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# slice are the same (e.g. [[3, 3, 3], [3, 3, 3, 3], [3, 3, 3]]).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall_same_const = (_first(alldata, axis) == alldata).all(axis=axis)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Determine the mean of the data, and subtract that from all inputs to a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# variance (via sum_of_sq / sq_of_sum) calculation.  Variance is invariance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# variance (via sum_of_sq / sq_of_sum) calculation.  Variance is invariant</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# to a shift in location, and centering all data around zero vastly
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# improves numerical stability.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoffset = alldata.mean()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoffset = alldata.mean(axis=axis, keepdims=True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspalldata -= offset
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsstot = _sum_of_squares(alldata) - (_square_of_sums(alldata) / float(bign))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnormalized_ss = _square_of_sums(alldata, axis=axis) / bign</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsstot = _sum_of_squares(alldata, axis=axis) - normalized_ss</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspssbn = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor a in args:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspssbn += _square_of_sums(a - offset) / float(len(a))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspssbn += _square_of_sums(a - offset, axis=axis) / a.shape[axis]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Naming: variables ending in bn/b are for "between treatments", wn/w are
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# for "within treatments"
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspssbn -= (_square_of_sums(alldata) / float(bign))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspssbn -= normalized_ss</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsswn = sstot - ssbn
<br>&nbsp &nbsp &nbsp &nbsp &nbspdfbn = num_groups - 1
<br>&nbsp &nbsp &nbsp &nbsp &nbspdfwn = bign - num_groups
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmsb = ssbn / float(dfbn)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmsw = sswn / float(dfwn)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspf = msb / msw</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmsb = ssbn / dfbn</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmsw = sswn / dfwn</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore', invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = msb / msw</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspprob = special.fdtrc(dfbn, dfwn, f)   # equivalent to stats.f.sf
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Fix any f values that should be inf or nan because the corresponding</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# inputs were constant.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.isscalar(f):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif all_same_const:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif all_const:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = np.inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 0.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf[all_const] = np.inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob[all_const] = 0.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf[all_same_const] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob[all_same_const] = np.nan</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn F_onewayResult(f, prob)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+def alexandergovern(*args, nan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Performs the Alexander Govern test.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Alexander-Govern approximation tests the equality of k independent</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmeans in the face of heterogeneity of variance. The test is applied to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsamples from two or more groups, possibly with differing sizes.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample1, sample2, ... : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample measurements for each group.  There must be at least</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo samples.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe computed A statistic of the test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe associated p-value from the chi-squared distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWarns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlexanderGovernConstantInputWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRaised if an input is a constant array.  The statistic is not defined</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin this case, so ``np.nan`` is returned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspf_oneway : one-way ANOVA</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe use of this test relies on several assumptions.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp1. The samples are independent.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2. Each sample is from a normally distributed population.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp3. Unlike `f_oneway`, this test does not assume on homoscedasticity,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstead relaxing the assumption of equal variances.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspInput samples must be finite, one dimensional, and with size greater than</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspone.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] Alexander, Ralph A., and Diane M. Govern. "A New and Simpler</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspApproximation for ANOVA under Variance Heterogeneity." Journal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof Educational Statistics, vol. 19, no. 2, 1994, pp. 91-101.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspJSTOR, www.jstor.org/stable/1165140. Accessed 12 Sept. 2020.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import alexandergovern</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspHere are some data on annual percentage rate of interest charged on</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnew car loans at nine of the largest banks in four American cities</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptaken from the National Institute of Standards and Technology's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspANOVA dataset.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe use `alexandergovern` to test the null hypothesis that all cities</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphave the same mean APR against the alternative that the cities do not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall have the same mean APR. We decide that a sigificance level of 5%</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis required to reject the null hypothesis in favor of the alternative.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> atlanta = [13.75, 13.75, 13.5, 13.5, 13.0, 13.0, 13.0, 12.75, 12.5]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> chicago = [14.25, 13.0, 12.75, 12.5, 12.5, 12.4, 12.3, 11.9, 11.9]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> houston = [14.0, 14.0, 13.51, 13.5, 13.5, 13.25, 13.0, 12.5, 12.5]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> memphis = [15.0, 14.0, 13.75, 13.59, 13.25, 12.97, 12.5, 12.25,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...           11.89]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> alexandergovern(atlanta, chicago, houston, memphis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlexanderGovernResult(statistic=4.65087071883494,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue=0.19922132490385214)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe p-value is 0.1992, indicating a nearly 20% chance of observing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuch an extreme value of the test statistic under the null hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis exceeds 5%, so we do not reject the null hypothesis in favor of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe alternative.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspargs = _alexandergovern_input_validation(args, nan_policy)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.any([(arg == arg[0]).all() for arg in args]):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(AlexanderGovernConstantInputWarning())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn AlexanderGovernResult(np.nan, np.nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The following formula numbers reference the equation described on</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# page 92 by Alexander, Govern. Formulas 5, 6, and 7 describe other</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# tests that serve as the basis for equation (8) but are not needed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# to perform the test.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# precalculate mean and length of each sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplengths = np.array([ma.count(arg) if nan_policy == 'omit' else len(arg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor arg in args])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmeans = np.array([np.mean(arg) for arg in args])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (1) determine standard error of the mean for each sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstandard_errors = [np.std(arg, ddof=1) / np.sqrt(length)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor arg, length in zip(args, lengths)]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (2) define a weight for each sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinv_sq_se = 1 / np.square(standard_errors)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspweights = inv_sq_se / np.sum(inv_sq_se)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (3) determine variance-weighted estimate of the common mean</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvar_w = np.sum(weights * means)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (4) determine one-sample t statistic for each group</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt_stats = (means - var_w)/standard_errors</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate parameters to be used in transformation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspv = lengths - 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = v - .5</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspb = 48 * a**2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspc = (a * np.log(1 + (t_stats ** 2)/v))**.5</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (8) perform a normalizing transformation on t statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspz = (c + ((c**3 + 3*c)/b) -</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp((4*c**7 + 33*c**5 + 240*c**3 + 855*c) /</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(b**2*10 + 8*b*c**4 + 1000*b)))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (9) calculate statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA = np.sum(np.square(z))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# "[the p value is determined from] central chi-square random deviates</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# with k - 1 degrees of freedom". Alexander, Govern (94)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspp = distributions.chi2.sf(A, len(args) - 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn AlexanderGovernResult(A, p)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _alexandergovern_input_validation(args, nan_policy):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif len(args) < 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(f"2 or more inputs required, got {len(args)}")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# input arrays are flattened</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspargs = [np.asarray(arg, dtype=float) for arg in args]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor i, arg in enumerate(args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.size(arg) <= 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Input sample size must be greater than one.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif arg.ndim != 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Input samples must be one-dimensional")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(arg).any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Input samples must be finite.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(arg, nan_policy=nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs[i] = ma.masked_invalid(arg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn args</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+AlexanderGovernResult = make_dataclass("AlexanderGovernResult", ("statistic",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"pvalue"))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class AlexanderGovernConstantInputWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Warning generated by `alexandergovern` when an input is constant."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, msg=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif msg is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("An input array is constant; the statistic is not defined.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = (msg,)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class PearsonRConstantInputWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Warning generated by `pearsonr` when an input is constant."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, msg=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif msg is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("An input array is constant; the correlation coefficient "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"is not defined.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = (msg,)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class PearsonRNearConstantInputWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Warning generated by `pearsonr` when an input is nearly constant."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, msg=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif msg is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("An input array is nearly constant; the computed "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"correlation coefficient may be inaccurate.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = (msg,)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspdef pearsonr(x, y):
<br>&nbsp &nbsp &nbsp &nbsp &nbspr"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate a Pearson correlation coefficient and the p-value for testing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnon-correlation.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe Pearson correlation coefficient measures the linear relationship</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbetween two datasets. Strictly speaking, Pearson's correlation requires</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthat each dataset be normally distributed, and not necessarily zero-mean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspLike other correlation coefficients, this one varies between -1 and +1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith 0 implying no correlation. Correlations of -1 or +1 imply an exact</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplinear relationship. Positive correlations imply that as x increases, so</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdoes y. Negative correlations imply that as x increases, y decreases.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPearson correlation coefficient and p-value for testing non-correlation.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe p-value roughly indicates the probability of an uncorrelated system</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspproducing datasets that have a Pearson correlation at least as extreme</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspas the one computed from these datasets. The p-values are not entirely</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreliable but are probably reasonable for datasets larger than 500 or so.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Pearson correlation coefficient [1]_ measures the linear relationship</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbetween two datasets.  The calculation of the p-value relies on the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassumption that each dataset is normally distributed.  (See Kowalski [3]_</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor a discussion of the effects of non-normality of the input on the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution of the correlation coefficient.)  Like other correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcoefficients, this one varies between -1 and +1 with 0 implying no</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorrelation. Correlations of -1 or +1 imply an exact linear relationship.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspx : (N,) array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspy : (N,) array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspr : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPearson's correlation coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPearson's correlation coefficient.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspp-value : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2-tailed p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo-tailed p-value.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWarns</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPearsonRConstantInputWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRaised if an input is a constant array.  The correlation coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis not defined in this case, so ``np.nan`` is returned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPearsonRNearConstantInputWarning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRaised if an input is "nearly" constant.  The array ``x`` is considered</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumerical errors in the calculation ``x - mean(x)`` in this case might</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult in an inaccurate calculation of r.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspearmanr : Spearman rank-order correlation coefficient.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkendalltau : Kendall's tau, a correlation measure for ordinal data.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe correlation coefficient is calculated as follows:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. math::
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr_{pb} = \frac{\sum (x - m_x) (y - m_y)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp}{\sqrt{\sum (x - m_x)^2 (y - m_y)^2}}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = \frac{\sum (x - m_x) (y - m_y)}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp{\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere :math:`m_x` is the mean of the vector x and :math:`m_y` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe mean of the vector y.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUnder the assumption that x and y are drawn from</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindependent normal distributions (so the population correlation coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis 0), the probability density function of the sample correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcoefficient r is ([1]_, [2]_):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf(r) = \frac{{(1-r^2)}^{n/2-2}}{\mathrm{B}(\frac{1}{2},\frac{n}{2}-1)}</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwhere :math:`m_x` is the mean of the vector :math:`x` and :math:`m_y` is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe mean of the vector :math:`y`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere n is the number of samples, and B is the beta function.  This</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis sometimes referred to as the exact distribution of r.  This is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe distribution that is used in `pearsonr` to compute the p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe distribution is a beta distribution on the interval [-1, 1],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith equal shape parameters a = b = n/2 - 1.  In terms of SciPy's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspimplementation of the beta distribution, the distribution of r is::</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe p-value returned by `pearsonr` is a two-sided p-value. The p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsproughly indicates the probability of an uncorrelated system</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspproducing datasets that have a Pearson correlation at least as extreme</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspas the one computed from these datasets. More precisely, for a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgiven sample with correlation coefficient r, the p-value is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe probability that abs(r') of a random sample x' and y' drawn from</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe population with zero correlation would be greater than or equal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspto abs(r). In terms of the object ``dist`` shown above, the p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor a given r and length n can be computed as::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = 2*dist.cdf(-abs(r))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen n is 2, the above continuous distribution is not well-defined.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspOne can interpret the limit of the beta distribution as the shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspparameters a and b approach a = b = 0 as a discrete distribution with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspequal probability masses at r = 1 and r = -1.  More directly, one</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcan observe that, given the data x = [x1, x2] and y = [y1, y2], and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassuming x1 != x2 and y1 != y2, the only possible values for r are 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand -1.  Because abs(r') for any sample x' and y' with length 2 will</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbe 1, the two-sided p-value for a sample of length 2 is always 1.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsphttp://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] "Pearson correlation coefficient", Wikipedia,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Pearson_correlation_coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] Student, "Probable error of a correlation coefficient",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBiometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] C. J. Kowalski, "On the Effects of Non-Normality on the Distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the Sample Product-Moment Correlation Coefficient"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspJournal of the Royal Statistical Society. Series C (Applied</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics), Vol. 21, No. 1 (1972), pp. 1-12.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> a = np.array([0, 0, 0, 1, 1, 1, 1])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> b = np.arange(7)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr(a, b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.8660254037844386, 0.011724811003954654)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr([1,2,3,4,5], [5,6,7,8,7])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.83205029433784372, 0.080509573298498519)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr([1, 2, 3, 4, 5], [10, 9, 2.5, 6, 4])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(-0.7426106572325057, 0.1505558088534455)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThere is a linear dependence between x and y if y = a + b*x + e, where</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa,b are constants and e is a random error term, assumed to be independent</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof x. For simplicity, assume that x is standard normal, a=0, b=1 and let</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspe follow a normal distribution with mean zero and standard deviation s>0.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> s = 0.5</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(size=500)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> e = stats.norm.rvs(scale=s, size=500)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = x + e</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(0.9029601878969703, 8.428978827629898e-185) # may vary</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis should be close to the exact value given by</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> 1/np.sqrt(1 + s**2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.8944271909999159</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor s=0.5, we observe a high level of correlation. In general, a large</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvariance of the noise reduces the correlation, while the correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspapproaches one as the variance of the error goes to zero.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIt is important to keep in mind that no correlation does not imply</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindependence unless (x, y) is jointly normal. Correlation can even be zero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhen there is a very simple dependence structure: if X follows a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstandard normal distribution, let y = abs(x). Note that the correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbetween x and y is zero. Indeed, since the expectation of x is zero,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspby symmetry. The following lines of code illustrate this observation:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = np.abs(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(-0.016172891856853524, 0.7182823678751942) # may vary</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA non-zero correlation coefficient can be misleading. For example, if X has</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa standard normal distribution, define y = x if x < 0 and y = 0 otherwise.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspimplying a high level of correlation:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = np.where(x < 0, x, 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.pearsonr(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(0.8537091583771509, 3.183461621422181e-143) # may vary</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is unintuitive since there is no dependence of x and y if x is larger</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthan zero which happens in about half of the cases if we sample x and y.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# x and y should have same length.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = len(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif n != len(y):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('x and y must have the same length.')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif n < 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('x and y must have length at least 2.')</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbspy = np.asarray(y)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = len(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmx = x.mean()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmy = y.mean()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspxm, ym = x - mx, y - my</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr_num = np.add.reduce(xm * ym)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr_den = np.sqrt(_sum_of_squares(xm) * _sum_of_squares(ym))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr = r_num / r_den</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If an input is constant, the correlation coefficient is not defined.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif (x == x[0]).all() or (y == y[0]).all():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(PearsonRConstantInputWarning())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan, np.nan</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# dtype is the data type for the calculations.  This expression ensures</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# that the data type is at least 64 bit floating point.  It might have</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# more precision if the input is, for example, np.longdouble.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdtype = type(1.0 + x[0] + y[0])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif n == 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dtype(np.sign(x[1] - x[0])*np.sign(y[1] - y[0])), 1.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxmean = x.mean(dtype=dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspymean = y.mean(dtype=dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# By using `astype(dtype)`, we ensure that the intermediate calculations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# use at least 64 bit floating point.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxm = x.astype(dtype) - xmean</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspym = y.astype(dtype) - ymean</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# scipy.linalg.norm(xm) does not overflow if xm is, for example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# [-5e210, 5e210, 3e200, -3e200]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnormxm = linalg.norm(xm)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnormym = linalg.norm(ym)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthreshold = 1e-13</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif normxm < threshold*abs(xmean) or normym < threshold*abs(ymean):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If all the values in x (likewise y) are very close to the mean,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the loss of precision that occurs in the subtraction xm = x - xmean</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# might result in large errors in r.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(PearsonRNearConstantInputWarning())</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr = np.dot(xm/normxm, ym/normym)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Presumably, if abs(r) > 1, then it is only some small artifact of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# floating point arithmetic.
<br>&nbsp &nbsp &nbsp &nbsp &nbspr = max(min(r, 1.0), -1.0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdf = n - 2</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif abs(r) == 1.0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 0.0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt_squared = r**2 * (df / ((1.0 - r) * (1.0 + r)))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = _betai(0.5*df, 0.5, df/(df+t_squared))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# As explained in the docstring, the p-value can be computed as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#     p = 2*dist.cdf(-abs(r))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# where dist is the beta distribution on [-1, 1] with shape parameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# a = b = n/2 - 1.  `special.btdtr` is the CDF for the beta distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# on [0, 1].  To use it, we make the transformation  x = (r + 1)/2; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# shape parameters do not change.  Then -abs(r) used in `cdf(-abs(r))`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# becomes x = (-abs(r) + 1)/2 = 0.5*(1 - abs(r)).  (r is cast to float64</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# to avoid a TypeError raised by btdtr when r is higher precision.)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspab = n/2 - 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprob = 2*special.btdtr(ab, ab, 0.5*(1 - abs(np.float64(r))))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn r, prob
<br>&nbsp
<br>&nbsp
<br>&nbspdef fisher_exact(table, alternative='two-sided'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Performs a Fisher exact test on a 2x2 contingency table.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Perform a Fisher exact test on a 2x2 contingency table.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsptable : array_like of ints
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA 2x2 contingency table.  Elements should be non-negative integers.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA 2x2 contingency table.  Elements must be non-negative integers.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhich alternative hypothesis to the null hypothesis the test uses.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': one-sided</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': one-sided</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee the Notes for more details.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -3038,18 +4131,107 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspchi2_contingency : Chi-square test of independence of variables in a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontingency table.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontingency table.  This can be used as an alternative to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`fisher_exact` when the numbers in the table are large.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbarnard_exact : Barnard's exact test, which is a more powerful alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthan Fisher's exact test for 2x2 contingency tables.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspboschloo_exact : Boschloo's exact test, which is a more powerful alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthan Fisher's exact test for 2x2 contingency tables.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe calculated odds ratio is different from the one R uses. This scipy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Null hypothesis and p-values*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe null hypothesis is that the input table is from the hypergeometric</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution with parameters (as used in `hypergeom`)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``M = a + b + c + d``, ``n = a + b`` and ``N = a + c``, where the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinput table is ``[[a, b], [c, d]]``.  This distribution has support</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``max(0, N + n - M) <= x <= min(N, n)``, or, in terms of the values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspin the input table, ``min(0, a - d) <= x <= a + min(b, c)``.  ``x``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcan be interpreted as the upper-left element of a 2x2 table, so the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptables in the distribution have form::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  x           n - x     ]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[N - x    M - (n + N) + x]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor example, if::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptable = [6  2]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[1  4]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthen the support is ``2 <= x <= 7``, and the tables in the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspare::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[2 6]   [3 5]   [4 4]   [5 3]   [6 2]  [7 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[5 0]   [4 1]   [3 2]   [2 3]   [1 4]  [0 5]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe probability of each table is given by the hypergeometric distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``hypergeom.pmf(x, M, n, N)``.  For this example, these are (rounded to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthree significant digits)::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx       2      3      4      5       6        7</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp  0.0163  0.163  0.408  0.326  0.0816  0.00466</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThese can be computed with::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import hypergeom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> table = np.array([[6, 2], [1, 4]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> M = table.sum()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> n = table[0].sum()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> N = table[:, 0].sum()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> start, end = hypergeom.support(M, n, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> hypergeom.pmf(np.arange(start, end+1), M, n, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([0.01631702, 0.16317016, 0.40792541, 0.32634033, 0.08158508,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.004662  ])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe two-sided p-value is the probability that, under the null hypothesis,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa random table would have a probability equal to or less than the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprobability of the input table.  For our example, the probability of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe input table (where ``x = 6``) is 0.0816.  The x values where the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprobability does not exceed this are 2, 6 and 7, so the two-sided p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis ``0.0163 + 0.0816 + 0.00466 ~= 0.10256``::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import fisher_exact</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> oddsr, p = fisher_exact(table, alternative='two-sided')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.10256410256410257</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe one-sided p-value for ``alternative='greater'`` is the probability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthat a random table has ``x >= a``, which in our example is ``x >= 6``,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspor ``0.0816 + 0.00466 ~= 0.08626``::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> oddsr, p = fisher_exact(table, alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.08624708624708627</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is equivalent to computing the survival function of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution at ``x = 5`` (one less than ``x`` from the input table,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbecause we want to include the probability of ``x = 6`` in the sum)::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> hypergeom.sf(5, M, n, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.08624708624708627</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor ``alternative='less'``, the one-sided p-value is the probability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthat a random table has ``x <= a``, (i.e. ``x <= 6`` in our example),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspor ``0.0163 + 0.163 + 0.408 + 0.326 + 0.0816 ~= 0.9949``::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> oddsr, p = fisher_exact(table, alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.9953379953379957</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is equivalent to computing the cumulative distribution function</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the distribution at ``x = 6``:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> hypergeom.cdf(6, M, n, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.9953379953379957</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Odds ratio*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe calculated odds ratio is different from the one R uses. This SciPy</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspimplementation returns the (more common) "unconditional Maximum
<br>&nbsp &nbsp &nbsp &nbsp &nbspLikelihood Estimate", while R uses the "conditional Maximum Likelihood
<br>&nbsp &nbsp &nbsp &nbsp &nbspEstimate".
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspFor tables with large numbers, the (inexact) chi-square test implemented</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspin the function `chi2_contingency` can also be used.</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspSay we spend a few days counting whales and sharks in the Atlantic and
<br>@@ -3062,8 +4244,8 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspWe use this table to find the p-value:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> import scipy.stats as stats</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> oddsratio, pvalue = stats.fisher_exact([[8, 2], [1, 5]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import fisher_exact</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> oddsratio, pvalue = fisher_exact([[8, 2], [1, 5]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> pvalue
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.0349...
<br>&nbsp
<br>@@ -3075,7 +4257,8 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsphypergeom = distributions.hypergeom
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspc = np.asarray(table, dtype=np.int64)  # int32 is not enough for the algorithm</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# int32 is not enough for the algorithm</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspc = np.asarray(table, dtype=np.int64)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not c.shape == (2, 2):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The input `table` must be of shape (2, 2).")
<br>&nbsp
<br>@@ -3088,7 +4271,7 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan, 1.0
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif c[1, 0] > 0 and c[0, 1] > 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoddsratio = c[0, 0] * c[1, 1] / float(c[1, 0] * c[0, 1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoddsratio = c[0, 0] * c[1, 1] / (c[1, 0] * c[0, 1])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoddsratio = np.inf
<br>&nbsp
<br>@@ -3097,9 +4280,7 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = c[0, 0] + c[1, 0]
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef binary_search(n, n1, n2, side):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Binary search for where to begin lower/upper halves in two-sided</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptest.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Binary search for where to begin halves in two-sided test."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif side == "upper":
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspminval = mode
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxval = n
<br>@@ -3126,14 +4307,16 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif guess == -1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspguess = minval
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif side == "upper":
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile guess > 0 and hypergeom.pmf(guess, n1 + n2, n1, n) < pexact * epsilon:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile guess > 0 and \</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphypergeom.pmf(guess, n1 + n2, n1, n) < pexact * epsilon:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspguess -= 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile hypergeom.pmf(guess, n1 + n2, n1, n) > pexact / epsilon:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspguess += 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile hypergeom.pmf(guess, n1 + n2, n1, n) < pexact * epsilon:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspguess += 1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile guess > 0 and hypergeom.pmf(guess, n1 + n2, n1, n) > pexact / epsilon:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile guess > 0 and \</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphypergeom.pmf(guess, n1 + n2, n1, n) > pexact / epsilon:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspguess -= 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn guess
<br>&nbsp
<br>@@ -3143,7 +4326,7 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Same formula as the 'less' case, but with the second column.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue = hypergeom.cdf(c[0, 1], n1 + n2, n1, c[0, 1] + c[1, 1])
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif alternative == 'two-sided':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = int(float((n + 1) * (n1 + 1)) / (n1 + n2 + 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = int((n + 1) * (n1 + 1) / (n1 + n2 + 2))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppexact = hypergeom.pmf(c[0, 0], n1 + n2, n1, n)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppmode = hypergeom.pmf(mode, n1 + n2, n1, n)
<br>&nbsp
<br>@@ -3169,27 +4352,36 @@ def fisher_exact(table, alternative='two-sided'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = "`alternative` should be one of {'two-sided', 'less', 'greater'}"
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(msg)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif pvalue > 1.0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue = 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue = min(pvalue, 1.0)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn oddsratio, pvalue
<br>&nbsp
<br><span style="color:green">+</span>
<br><span style="color:green">+class SpearmanRConstantInputWarning(RuntimeWarning):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Warning generated by `spearmanr` when an input is constant."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, msg=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif msg is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("An input array is constant; the correlation coefficient "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"is not defined.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = (msg,)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspSpearmanrResult = namedtuple('SpearmanrResult', ('correlation', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def spearmanr(a, b=None, axis=0, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate a Spearman rank-order correlation coefficient and the p-value</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspto test for non-correlation.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe Spearman correlation is a nonparametric measure of the monotonicity</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspof the relationship between two datasets. Unlike the Pearson correlation,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe Spearman correlation does not assume that both datasets are normally</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdistributed. Like other correlation coefficients, this one varies</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbetween -1 and +1 with 0 implying no correlation. Correlations of -1 or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp+1 imply an exact monotonic relationship. Positive correlations imply that</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspas x increases, so does y. Negative correlations imply that as x</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspincreases, y decreases.</span>
<br><span style="color:green">+def spearmanr(a, b=None, axis=0, nan_policy='propagate',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative='two-sided'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate a Spearman correlation coefficient with associated p-value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Spearman rank-order correlation coefficient is a nonparametric measure</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the monotonicity of the relationship between two datasets. Unlike the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPearson correlation, the Spearman correlation does not assume that both</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdatasets are normally distributed. Like other correlation coefficients,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthis one varies between -1 and +1 with 0 implying no correlation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCorrelations of -1 or +1 imply an exact monotonic relationship. Positive</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorrelations imply that as x increases, so does y. Negative correlations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspimply that as x increases, y decreases.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe p-value roughly indicates the probability of an uncorrelated system
<br>&nbsp &nbsp &nbsp &nbsp &nbspproducing datasets that have a Spearman correlation at least as extreme
<br>@@ -3210,28 +4402,38 @@ def spearmanr(a, b=None, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach row represents a variable, while the columns contain observations.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf axis=None, then both arrays will be raveled.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the correlation is nonzero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the correlation is negative (less than zero)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater':  the correlation is positive (greater than zero)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspcorrelation : float or ndarray (2-D square)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpearman correlation matrix or correlation coefficient (if only 2
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariables are given as parameters. Correlation matrix is square with
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplength equal to total number of variables (columns or rows) in a and b</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcombined.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplength equal to total number of variables (columns or rows) in ``a``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand ``b`` combined.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe two-sided p-value for a hypothesis test whose null hypothesis is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat two sets of data are uncorrelated, has same dimension as rho.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspChanges in scipy 0.8.0: rewrite to add tie-handling, and axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value for a hypothesis test whose null hypotheisis</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis that two sets of data are uncorrelated. See `alternative` above</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor alternative hypotheses. `pvalue` has the same</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape as `correlation`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability and Statistics Tables and Formulae. Chapman & Hall: New
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspYork. 2000.
<br>@@ -3241,95 +4443,124 @@ def spearmanr(a, b=None, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr([1,2,3,4,5], [5,6,7,8,7])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.82078268166812329, 0.088587005313543798)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(1234321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x2n = np.random.randn(100, 2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> y2n = np.random.randn(100, 2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=0.82078..., pvalue=0.08858...)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x2n = rng.standard_normal((100, 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y2n = rng.standard_normal((100, 2))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr(x2n)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.059969996999699973, 0.55338590803773591)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=-0.07960396039603959, pvalue=0.4311168705769747)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr(x2n[:,0], x2n[:,1])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.059969996999699973, 0.55338590803773591)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=-0.07960396039603959, pvalue=0.4311168705769747)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> rho, pval = stats.spearmanr(x2n, y2n)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> rho
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.18569457,  0.110003  ,  1.        ,  0.03488749],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.06258626,  0.02534653,  0.03488749,  1.        ]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[ 1.        , -0.07960396, -0.08314431,  0.09662166],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.07960396,  1.        , -0.14448245,  0.16738074],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.08314431, -0.14448245,  1.        ,  0.03234323],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.09662166,  0.16738074,  0.03234323,  1.        ]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> pval
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 0.        ,  0.55338591,  0.06435364,  0.53617935],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.55338591,  0.        ,  0.27592895,  0.80234077],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.06435364,  0.27592895,  0.        ,  0.73039992],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.53617935,  0.80234077,  0.73039992,  0.        ]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[0.        , 0.43111687, 0.41084066, 0.33891628],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[0.43111687, 0.        , 0.15151618, 0.09600687],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[0.41084066, 0.15151618, 0.        , 0.74938561],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[0.33891628, 0.09600687, 0.74938561, 0.        ]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> rho, pval = stats.spearmanr(x2n.T, y2n.T, axis=1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> rho
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.18569457,  0.110003  ,  1.        ,  0.03488749],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.06258626,  0.02534653,  0.03488749,  1.        ]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[ 1.        , -0.07960396, -0.08314431,  0.09662166],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.07960396,  1.        , -0.14448245,  0.16738074],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.08314431, -0.14448245,  1.        ,  0.03234323],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.09662166,  0.16738074,  0.03234323,  1.        ]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr(x2n, y2n, axis=None)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.10816770419260482, 0.1273562188027364)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=0.044981624540613524, pvalue=0.5270803651336189)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr(x2n.ravel(), y2n.ravel())
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.10816770419260482, 0.1273562188027364)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=0.044981624540613524, pvalue=0.5270803651336189)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> xint = np.random.randint(10, size=(100, 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> xint = rng.integers(10, size=(100, 2))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.spearmanr(xint)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.052760927029710199, 0.60213045837062351)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpearmanrResult(correlation=0.09800224850707953, pvalue=0.3320271757932076)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa, axisout = _chk_asarray(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif axis is not None and axis > 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("spearmanr only handles 1-D or 2-D arrays, "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"supplied axis argument {}, please use only "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"values 0, 1 or None for axis".format(axis))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa_contains_nan, nan_policy = _contains_nan(a, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa, axisout = _chk_asarray(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif a.ndim > 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("spearmanr only handles 1-D or 2-D arrays")</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif a_contains_nan:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif b is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a.ndim < 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("`spearmanr` needs at least 2 "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"variables to compare")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Concatenate a and b, so that we now only have to handle the case</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# of a 2-D `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb, _ = _chk_asarray(b, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axisout == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.column_stack((a, b))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.row_stack((a, b))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif a.size <= 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn_vars = a.shape[1 - axisout]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn_obs = a.shape[axisout]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif n_obs <= 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Handle empty arrays or single observations.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(np.nan, np.nan)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspar = np.apply_along_axis(rankdata, axisout, a)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbr = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif b is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb, axisout = _chk_asarray(b, axis)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb_contains_nan, nan_policy = _contains_nan(b, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif axisout == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (a[:, 0][0] == a[:, 0]).all() or (a[:, 1][0] == a[:, 1]).all():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If an input is constant, the correlation coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# is not defined.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(SpearmanRConstantInputWarning())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(np.nan, np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:  # case when axisout == 1 b/c a is 2 dim only</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (a[0, :][0] == a[0, :]).all() or (a[1, :][0] == a[1, :]).all():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If an input is constant, the correlation coefficient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# is not defined.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(SpearmanRConstantInputWarning())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(np.nan, np.nan)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a_contains_nan or b_contains_nan:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb = ma.masked_invalid(b)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif nan_policy == 'propagate':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprho, pval = mstats_basic.spearmanr(a, b, axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(rho * np.nan, pval * np.nan)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif nan_policy == 'omit':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.spearmanr(a, b, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_contains_nan, nan_policy = _contains_nan(a, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvariable_has_nan = np.zeros(n_vars, dtype=bool)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif a_contains_nan:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif nan_policy == 'omit':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.spearmanr(a, axis=axis, nan_policy=nan_policy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative=alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif nan_policy == 'propagate':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a.ndim == 1 or n_vars <= 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(np.nan, np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Keep track of variables with NaNs, set the outputs to NaN</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# only for those variables</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariable_has_nan = np.isnan(a).any(axis=axisout)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbr = np.apply_along_axis(rankdata, axisout, b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = a.shape[axisout]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprs = np.corrcoef(ar, br, rowvar=axisout)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_ranked = np.apply_along_axis(rankdata, axisout, a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprs = np.corrcoef(a_ranked, rowvar=axisout)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdof = n_obs - 2  # degrees of freedom</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspolderr = np.seterr(divide='ignore')  # rs can have elements equal to 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# rs can have elements equal to 1, so avoid zero division warnings</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore'):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# clip the small negative values possibly caused by rounding
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# errors before taking the square root
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = rs * np.sqrt(((n-2)/((rs+1.0)*(1.0-rs))).clip(0))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfinally:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.seterr(**olderr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = rs * np.sqrt((dof/((rs+1.0)*(1.0-rs))).clip(0))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprob = 2 * distributions.t.sf(np.abs(t), n-2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(dof, t, alternative)</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# For backwards compatibility, return scalars when comparing 2 columns</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif rs.shape == (2, 2):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(rs[1, 0], prob[1, 0])
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprs[variable_has_nan, :] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprs[:, variable_has_nan] = np.nan</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn SpearmanrResult(rs, prob)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspPointbiserialrResult = namedtuple('PointbiserialrResult',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('correlation', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef pointbiserialr(x, y):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate a point biserial correlation coefficient and its p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Calculate a point biserial correlation coefficient and its p-value.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe point biserial correlation is used to measure the relationship
<br>&nbsp &nbsp &nbsp &nbsp &nbspbetween a binary variable, x, and a continuous variable, y. Like other
<br>@@ -3350,14 +4581,14 @@ def pointbiserialr(x, y):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspcorrelation : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspR value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspR value.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2-tailed p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo-sided p-value.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`pointbiserialr` uses a t-test with ``n-1`` degrees of freedom.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIt is equivalent to `pearsonr.`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIt is equivalent to `pearsonr`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe value of the point-biserial correlation can be calculated from:
<br>&nbsp
<br>@@ -3392,7 +4623,9 @@ def pointbiserialr(x, y):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariable. Point-Biserial Correlation.", Ann. Math. Statist., Vol. 25,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp. 3, pp. 603-607, 1954.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [3] http://onlinelibrary.wiley.com/doi/10.1002/9781118445112.stat06227/full</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] D. Kornbrot "Point Biserial Correlation", In Wiley StatsRef:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics Reference Online (eds N. Balakrishnan, et al.), 2014.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp:doi:`10.1002/9781118445112.stat06227`</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3415,39 +4648,65 @@ def pointbiserialr(x, y):
<br>&nbspKendalltauResult = namedtuple('KendalltauResult', ('correlation', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate Kendall's tau, a correlation measure for ordinal data.</span>
<br><span style="color:green">+def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod='auto', variant='b', alternative='two-sided'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate Kendall's tau, a correlation measure for ordinal data.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspKendall's tau is a measure of the correspondence between two rankings.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspValues close to 1 indicate strong agreement, values close to -1 indicate</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstrong disagreement.  This is the 1945 "tau-b" version of Kendall's</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptau [2]_, which can account for ties and which reduces to the 1938 "tau-a"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspversion [1]_ in absence of ties.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValues close to 1 indicate strong agreement, and values close to -1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindicate strong disagreement. This implements two variants of Kendall's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptau: tau-b (the default) and tau-c (also known as Stuart's tau-c). These</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdiffer only in how they are normalized to lie within the range -1 to 1;</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe hypothesis tests (their p-values) are identical. Kendall's original</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptau-a is not implemented separately because both tau-b and tau-c reduce</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspto tau-a in the absence of ties.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspx, y : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArrays of rankings, of the same shape. If arrays are not 1-D, they will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe flattened to 1-D.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArrays of rankings, of the same shape. If arrays are not 1-D, they</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be flattened to 1-D.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinitial_lexsort : bool, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUnused (deprecated).
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'. Note that if the input contains nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'omit' delegates to mstats_basic.kendalltau(), which has a different</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod : {'auto', 'asymptotic', 'exact'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines which method is used to calculate the p-value [5]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'auto'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'auto': selects the appropriate method based on a trade-off</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbetween speed and accuracy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'asymptotic': uses a normal approximation valid for large samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'exact': computes the exact p-value, but can only be used if no ties</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare present. As the sample size increases, the 'exact' computation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptime may grow and the result may lose some precision.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvariant: {'b', 'c'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines which variant of Kendall's tau is returned. Default is 'b'.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the rank correlation is nonzero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the rank correlation is negative (less than zero)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater':  the rank correlation is positive (greater than zero)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspcorrelation : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe tau statistic.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe two-sided p-value for a hypothesis test whose null hypothesis is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value for a hypothesis test whose null hypothesis is</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspan absence of association, tau = 0.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspspearmanr : Calculates a Spearman rank-order correlation coefficient.
<br>&nbsp &nbsp &nbsp &nbsp &nbsptheilslopes : Computes the Theil-Sen estimator for a set of points (x, y).
<br>@@ -3457,12 +4716,15 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe definition of Kendall's tau that is used is [2]_::
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptau = (P - Q) / sqrt((P + Q + T) * (P + Q + U))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptau_b = (P - Q) / sqrt((P + Q + T) * (P + Q + U))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptau_c = 2 (P - Q) / (n**2 * (m - 1) / m)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspwhere P is the number of concordant pairs, Q the number of discordant
<br>&nbsp &nbsp &nbsp &nbsp &nbsppairs, T the number of ties only in `x`, and U the number of ties only in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`y`.  If a tie occurs for the same pair in both `x` and `y`, it is not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspadded to either T or U.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspadded to either T or U. n is the total number of samples, and m is the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnumber of unique values in either `x` or `y`, whichever is smaller.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3475,6 +4737,8 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [4] Peter M. Fenwick, "A new data structure for cumulative frequency
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptables", Software: Practice and Experience, Vol. 24, No. 3,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppp. 327-336, 1994.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [5] Maurice G. Kendall, "Rank Correlation Methods" (4th Edition),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCharles Griffin & Co., 1970.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3492,10 +4756,11 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspy = np.asarray(y).ravel()
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif x.size != y.size:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All inputs to `kendalltau` must be of the same size, "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"found x-size %s and y-size %s" % (x.size, y.size))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All inputs to `kendalltau` must be of the same "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"size, found x-size {x.size} and y-size {y.size}")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif not x.size or not y.size:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KendalltauResult(np.nan, np.nan)  # Return NaN if arrays are empty</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Return NaN if arrays are empty</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KendalltauResult(np.nan, np.nan)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# check both x and y
<br>&nbsp &nbsp &nbsp &nbsp &nbspcnx, npx = _contains_nan(x, nan_policy)
<br>@@ -3510,7 +4775,13 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif contains_nan and nan_policy == 'omit':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = ma.masked_invalid(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = ma.masked_invalid(y)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.kendalltau(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif variant == 'b':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.kendalltau(x, y, method=method, use_ties=True,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative=alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmessage = ("nan_policy='omit' is currently compatible only with "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"variant='b'.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(message)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif initial_lexsort is not None:  # deprecate to drop!
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn('"initial_lexsort" is gone!')
<br>@@ -3519,8 +4790,8 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcnt = np.bincount(ranks).astype('int64', copy=False)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcnt = cnt[cnt > 1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ((cnt * (cnt - 1) // 2).sum(),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(cnt * (cnt - 1.) * (cnt - 2)).sum(),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(cnt * (cnt - 1.) * (2*cnt + 5)).sum())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(cnt * (cnt - 1.) * (cnt - 2)).sum(),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(cnt * (cnt - 1.) * (2*cnt + 5)).sum())</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspsize = x.size
<br>&nbsp &nbsp &nbsp &nbsp &nbspperm = np.argsort(y)  # sort on y and convert y to dense ranks
<br>@@ -3535,7 +4806,7 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdis = _kendall_dis(x, y)  # discordant pairs
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspobs = np.r_[True, (x[1:] != x[:-1]) | (y[1:] != y[:-1]), True]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcnt = np.diff(np.where(obs)[0]).astype('int64', copy=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcnt = np.diff(np.nonzero(obs)[0]).astype('int64', copy=False)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspntie = (cnt * (cnt - 1) // 2).sum()  # joint ties
<br>&nbsp &nbsp &nbsp &nbsp &nbspxtie, x0, x1 = count_rank_tie(x)     # ties in x, stats
<br>@@ -3549,26 +4820,51 @@ def kendalltau(x, y, initial_lexsort=None, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Note that tot = con + dis + (xtie - ntie) + (ytie - ntie) + ntie
<br>&nbsp &nbsp &nbsp &nbsp &nbsp#               = con + dis + xtie + ytie - ntie
<br>&nbsp &nbsp &nbsp &nbsp &nbspcon_minus_dis = tot - xtie - ytie + ntie - 2 * dis
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptau = con_minus_dis / np.sqrt(tot - xtie) / np.sqrt(tot - ytie)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif variant == 'b':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptau = con_minus_dis / np.sqrt(tot - xtie) / np.sqrt(tot - ytie)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif variant == 'c':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspminclasses = min(len(set(x)), len(set(y)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptau = 2*con_minus_dis / (size**2 * (minclasses-1)/minclasses)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f"Unknown variant of the method chosen: {variant}. "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"variant must be 'b' or 'c'.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Limit range to fix computational errors
<br>&nbsp &nbsp &nbsp &nbsp &nbsptau = min(1., max(-1., tau))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# con_minus_dis is approx normally distributed with this variance [3]_</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvar = (size * (size - 1) * (2.*size + 5) - x1 - y1) / 18. + (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2. * xtie * ytie) / (size * (size - 1)) + x0 * y0 / (9. *</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize * (size - 1) * (size - 2))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppvalue = special.erfc(np.abs(con_minus_dis) / np.sqrt(var) / np.sqrt(2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The p-value calculation is the same for all variants since the p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# depends only on con_minus_dis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif method == 'exact' and (xtie != 0 or ytie != 0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Ties found, exact method cannot be used.")</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Limit range to fix computational errors</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn KendalltauResult(min(1., max(-1., tau)), pvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif method == 'auto':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (xtie == 0 and ytie == 0) and (size <= 33 or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmin(dis, tot-dis) <= 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod = 'exact'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod = 'asymptotic'</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif xtie == 0 and ytie == 0 and method == 'exact':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue = mstats_basic._kendall_p_exact(size, tot-dis, alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif method == 'asymptotic':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# con_minus_dis is approx normally distributed with this variance [3]_</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = size * (size - 1.)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvar = ((m * (2*size + 5) - x1 - y1) / 18 +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = con_minus_dis / np.sqrt(var)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, pvalue = _normtest_finish(z, alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f"Unknown method {method} specified.  Use 'auto', "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"'exact' or 'asymptotic'.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn KendalltauResult(tau, pvalue)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspWeightedTauResult = namedtuple('WeightedTauResult', ('correlation', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef weightedtau(x, y, rank=True, weigher=None, additive=True):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute a weighted version of Kendall's :math:`\tau`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Compute a weighted version of Kendall's :math:`\tau`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe weighted :math:`\tau` is a weighted version of Kendall's
<br>&nbsp &nbsp &nbsp &nbsp &nbsp:math:`\tau` in which exchanges of high weight are more influential than
<br>@@ -3578,32 +4874,30 @@ def weightedtau(x, y, rank=True, weigher=None, additive=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbspunimportant elements [1]_.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe weighting is defined by means of a rank array, which assigns a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnonnegative rank to each element, and a weigher function, which</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspassigns a weight based from the rank to each element. The weight of an</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexchange is then the sum or the product of the weights of the ranks of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe exchanged elements. The default parameters compute</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp:math:`\tau_\mathrm h`: an exchange between elements with rank</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp:math:`r` and :math:`s` (starting from zero) has weight</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp:math:`1/(r+1) + 1/(s+1)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnonnegative rank to each element (higher importance ranks being</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassociated with smaller values, e.g., 0 is the highest possible rank),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand a weigher function, which assigns a weight based on the rank to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspeach element. The weight of an exchange is then the sum or the product</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the weights of the ranks of the exchanged elements. The default</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspparameters compute :math:`\tau_\mathrm h`: an exchange between</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelements with rank :math:`r` and :math:`s` (starting from zero) has</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspweight :math:`1/(r+1) + 1/(s+1)`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSpecifying a rank array is meaningful only if you have in mind an
<br>&nbsp &nbsp &nbsp &nbsp &nbspexternal criterion of importance. If, as it usually happens, you do
<br>&nbsp &nbsp &nbsp &nbsp &nbspnot have in mind a specific rank, the weighted :math:`\tau` is
<br>&nbsp &nbsp &nbsp &nbsp &nbspdefined by averaging the values obtained using the decreasing
<br>&nbsp &nbsp &nbsp &nbsp &nbsplexicographical rank by (`x`, `y`) and by (`y`, `x`). This is the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbehavior with default parameters.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNote that if you are computing the weighted :math:`\tau` on arrays of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspranks, rather than of scores (i.e., a larger value implies a lower</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprank) you must negate the ranks, so that elements of higher rank are</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspassociated with a larger value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbehavior with default parameters. Note that the convention used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphere for ranking (lower values imply higher importance) is opposite</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspto that used by other SciPy statistical functions.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspx, y : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArrays of scores, of the same shape. If arrays are not 1-D, they will
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe flattened to 1-D.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprank: array_like of ints or bool, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprank : array_like of ints or bool, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA nonnegative rank assigned to each element. If it is None, the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdecreasing lexicographical rank by (`x`, `y`) will be used: elements of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphigher rank will be those with larger `x`-values, using `y`-values to
<br>@@ -3630,7 +4924,7 @@ def weightedtau(x, y, rank=True, weigher=None, additive=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPresently ``np.nan``, as the null statistics is unknown (even in the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditive hyperbolic case).
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspkendalltau : Calculates Kendall's tau.
<br>&nbsp &nbsp &nbsp &nbsp &nbspspearmanr : Calculates a Spearman rank-order correlation coefficient.
<br>@@ -3695,23 +4989,25 @@ def weightedtau(x, y, rank=True, weigher=None, additive=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.weightedtau(x, y, rank=None)
<br>&nbsp &nbsp &nbsp &nbsp &nbspWeightedTauResult(correlation=-0.4157652301037516, pvalue=nan)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.weightedtau(y, x, rank=None)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWeightedTauResult(correlation=-0.71813413296990281, pvalue=nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWeightedTauResult(correlation=-0.7181341329699028, pvalue=nan)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x).ravel()
<br>&nbsp &nbsp &nbsp &nbsp &nbspy = np.asarray(y).ravel()
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif x.size != y.size:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All inputs to `weightedtau` must be of the same size, "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All inputs to `weightedtau` must be "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"of the same size, "</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"found x-size %s and y-size %s" % (x.size, y.size))
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not x.size:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn WeightedTauResult(np.nan, np.nan)  # Return NaN if arrays are empty</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Return NaN if arrays are empty</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn WeightedTauResult(np.nan, np.nan)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# If there are NaNs we apply _toint64()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif np.isnan(np.min(x)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = _toint64(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif np.isnan(np.min(y)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = _toint64(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.isnan(np.sum(x)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = _toint64(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.isnan(np.sum(y)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = _toint64(y)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Reduce to ranks unsupported types
<br>&nbsp &nbsp &nbsp &nbsp &nbspif x.dtype != y.dtype:
<br>@@ -3735,114 +5031,705 @@ def weightedtau(x, y, rank=True, weigher=None, additive=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif rank is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprank = np.asarray(rank).ravel()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif rank.size != x.size:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All inputs to `weightedtau` must be of the same size, "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"found x-size %s and rank-size %s" % (x.size, rank.size))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"All inputs to `weightedtau` must be of the same size, "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"found x-size %s and rank-size %s" % (x.size, rank.size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn WeightedTauResult(_weightedrankedtau(x, y, rank, weigher, additive), np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn WeightedTauResult(_weightedrankedtau(x, y, rank, weigher, additive),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.nan)</span>
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- #####################################</span>
<br><span style="color:red">- #       INFERENTIAL STATISTICS      #</span>
<br><span style="color:red">- #####################################</span>
<br><span style="color:green">+# FROM MGCPY: https://github.com/neurodata/mgcpy</span>
<br>&nbsp
<br><span style="color:red">- Ttest_1sampResult = namedtuple('Ttest_1sampResult', ('statistic', 'pvalue'))</span>
<br>&nbsp
<br><span style="color:green">+class _ParallelP:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Helper function to calculate parallel p-value."""</span>
<br>&nbsp
<br><span style="color:red">- def ttest_1samp(a, popmean, axis=0, nan_policy='propagate'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the T-test for the mean of ONE group of scores.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, x, y, random_states):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.x = x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.y = y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.random_states = random_states</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is a two-sided test for the null hypothesis that the expected value</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(mean) of a sample of independent observations `a` is equal to the given</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppopulation mean, `popmean`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __call__(self, index):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporder = self.random_states[index].permutation(self.y.shape[0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermy = self.y[order][:, order]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# calculate permuted stats, store in null distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspperm_stat = _mgc_stat(self.x, permy)[0]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn perm_stat</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _perm_test(x, y, stat, reps=1000, workers=-1, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Helper function that calculates the p-value. See below for uses.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa : array_like</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample observation</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppopmean : float or array_like</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpected value in null hypothesis, if array_like than it must have the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsame shape as `a` excluding the axis dimension</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis : int or None, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to compute test. If None, compute over the whole</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray `a`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx, y : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`x` and `y` have shapes `(n, p)` and `(n, q)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample test statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreps : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe number of replications used to estimate the null when using the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermutation test. The default is 1000 replications.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspworkers : int or map-like callable, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `workers` is an int the population is subdivided into `workers`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsections and evaluated in parallel (uses</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`multiprocessing.Pool <multiprocessing>`). Supply `-1` to use all cores</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspavailable to the Process. Alternatively supply a map-like callable,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuch as `multiprocessing.Pool.map` for evaluating the population in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparallel. This evaluation is carried out as `workers(func, iterable)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRequires that `func` be pickleable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstatistic : float or array</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt-statistic</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppvalue : float or array</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-tailed p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample test p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnull_dist : list</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe approximated null distribution.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# generate seeds for each rep (change to new parallel random number</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# capabilities in numpy >= 1.17+)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state = check_random_state(random_state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_states = [np.random.RandomState(rng_integers(random_state, 1 << 32,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=4, dtype=np.uint32)) for _ in range(reps)]</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(7654567)  # fix seed to get the same result</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# parallelizes with specified workers over number of reps and set seeds</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspparallelp = _ParallelP(x=x, y=y, random_states=random_states)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith MapWrapper(workers) as mapwrapper:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnull_dist = np.array(list(mapwrapper(parallelp, range(reps))))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTest if mean of random sample is equal to true mean, and different mean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWe reject the null hypothesis in the second case and don't reject it in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe first case.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate p-value and significant permutation map through list</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue = (null_dist >= stat).sum() / reps</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs,5.0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([-0.68014479, -0.04323899]), array([ 0.49961383,  0.96568674]))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs,0.0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([ 2.77025808,  4.11038784]), array([ 0.00789095,  0.00014999]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# correct for a p-value of 0. This is because, with bootstrapping</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# permutations, a p-value of 0 is incorrect</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif pvalue == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue = 1 / reps</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples using axis and non-scalar dimension for population mean.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn pvalue, null_dist</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs,[5.0,0.0])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs.T,[5.0,0.0],axis=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs,[[5.0],[0.0]])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([[-0.68014479, -0.04323899],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 2.77025808,  4.11038784]]), array([[  4.99613833e-01,   9.65686743e-01],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  7.89094663e-03,   1.49986458e-04]]))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)</span>
<br><span style="color:green">+def _euclidean_dist(x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn cdist(x, x)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(a, nan_policy)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_1samp(a, popmean, axis)</span>
<br><span style="color:green">+MGCResult = namedtuple('MGCResult', ('stat', 'pvalue', 'mgc_dict'))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdf = n - 1</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspd = np.mean(a, axis) - popmean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspv = np.var(a, axis, ddof=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdenom = np.sqrt(v / float(n))</span>
<br><span style="color:green">+def multiscale_graphcorr(x, y, compute_distance=_euclidean_dist, reps=1000,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers=1, is_twosamp=False, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Computes the Multiscale Graph Correlation (MGC) test statistic.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore', invalid='ignore'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.divide(d, denom)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSpecifically, for each point, MGC finds the :math:`k`-nearest neighbors for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspone property (e.g. cloud density), and the :math:`l`-nearest neighbors for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe other property (e.g. grass wetness) [1]_. This pair :math:`(k, l)` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcalled the "scale". A priori, however, it is not know which scales will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmost informative. So, MGC computes all distance pairs, and then efficiently</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcomputes the distance correlations for all scales. The local correlations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspillustrate which scales are relatively informative about the relationship.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe key, therefore, to successfully discover and decipher relationships</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbetween disparate data modalities is to adaptively determine which scales</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspare the most informative, and the geometric implication for the most</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinformative scales. Doing so not only provides an estimate of whether the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmodalities are related, but also provides insight into how the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdetermination was made. This is especially important in high-dimensional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata, where simple visualizations do not reveal relationships to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunaided human eye. Characterizations of this implementation in particular</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphave been derived from and benchmarked within in [2]_.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn Ttest_1sampResult(t, prob)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx, y : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf ``x`` and ``y`` have shapes ``(n, p)`` and ``(n, q)`` where `n` is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe number of samples and `p` and `q` are the number of dimensions,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen the MGC independence test will be run.  Alternatively, ``x`` and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``y`` can have shapes ``(n, n)`` if they are distance or similarity</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrices, and ``compute_distance`` must be sent to ``None``. If ``x``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand ``y`` have shapes ``(n, p)`` and ``(m, p)``, an unpaired</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-sample MGC test will be run.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcompute_distance : callable, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA function that computes the distance or similarity among the samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwithin each data matrix. Set to ``None`` if ``x`` and ``y`` are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalready distance matrices. The default uses the euclidean norm metric.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you are calling a custom function, either create the distance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix before-hand or create a function of the form</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``compute_distance(x)`` where `x` is the data matrix for which</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppairwise distances are calculated.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreps : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe number of replications used to estimate the null when using the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermutation test. The default is ``1000``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspworkers : int or map-like callable, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf ``workers`` is an int the population is subdivided into ``workers``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsections and evaluated in parallel (uses ``multiprocessing.Pool</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp<multiprocessing>``). Supply ``-1`` to use all cores available to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProcess. Alternatively supply a map-like callable, such as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``multiprocessing.Pool.map`` for evaluating the p-value in parallel.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis evaluation is carried out as ``workers(func, iterable)``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRequires that `func` be pickleable. The default is ``1``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_twosamp : bool, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `True`, a two sample test will be run. If ``x`` and ``y`` have</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes ``(n, p)`` and ``(m, p)``, this optional will be overriden and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspset to ``True``. Set to ``True`` if ``x`` and ``y`` both have shapes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``(n, p)`` and a two sample test is desired. The default is ``False``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that this will not run if inputs are distance matrices.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample MGC test statistic within `[-1, 1]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value obtained via permutation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmgc_dict : dict</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspContains additional useful additional returns containing the following</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeys:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- mgc_map : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA 2D representation of the latent geometry of the relationship.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the relationship.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- opt_scale : (int, int)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe estimated optimal scale as a `(x, y)` pair.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- null_dist : list</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe null distribution derived from the permuted matrices</span>
<br>&nbsp
<br><span style="color:red">- def _ttest_finish(df, t):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Common code between all 3 t-test functions."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprob = distributions.t.sf(np.abs(t), df) * 2  # use np.abs to get upper tail</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif t.ndim == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = t[()]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppearsonr : Pearson correlation coefficient and p-value for testing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnon-correlation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkendalltau : Calculates Kendall's tau.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspearmanr : Calculates a Spearman rank-order correlation coefficient.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn t, prob</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA description of the process of MGC and applications on neuroscience data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcan be found in [1]_. It is performed using the following steps:</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#. Two distance matrices :math:`D^X` and :math:`D^Y` are computed and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodified to be mean zero columnwise. This results in two</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp:math:`n \times n` distance matrices :math:`A` and :math:`B` (the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcentering and unbiased modification) [3]_.</span>
<br>&nbsp
<br><span style="color:red">- def _ttest_ind_from_stats(mean1, mean2, denom, df):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#. For all values :math:`k` and :math:`l` from :math:`1, ..., n`,</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspd = mean1 - mean2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* The :math:`k`-nearest neighbor and :math:`l`-nearest neighbor graphs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare calculated for each property. Here, :math:`G_k (i, j)` indicates</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe :math:`k`-smallest values of the :math:`i`-th row of :math:`A`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand :math:`H_l (i, j)` indicates the :math:`l` smallested values of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe :math:`i`-th row of :math:`B`</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* Let :math:`\circ` denotes the entry-wise matrix product, then local</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcorrelations are summed and normalized using the following statistic:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc^{kl} = \frac{\sum_{ij} A G_k B H_l}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp{\sqrt{\sum_{ij} A^2 G_k \times \sum_{ij} B^2 H_l}}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#. The MGC test statistic is the smoothed optimal local correlation of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp:math:`\{ c^{kl} \}`. Denote the smoothing operation as :math:`R(\cdot)`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(which essentially set all isolated large correlations) as 0 and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconnected large correlations the same as before, see [3]_.) MGC is,</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMGC_n (x, y) = \max_{(k, l)} R \left(c^{kl} \left( x_n, y_n \right)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\right)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe test statistic returns a value between :math:`(-1, 1)` since it is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnormalized.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe p-value returned is calculated using a permutation test. This process</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis completed by first randomly permuting :math:`y` to estimate the null</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution and then calculating the probability of observing a test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic, under the null, at least as extreme as the observed test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMGC requires at least 5 samples to run with reliable results. It can also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphandle high-dimensional data sets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIn addition, by manipulating the input data matrices, the two-sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptesting problem can be reduced to the independence testing problem [4]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGiven sample data :math:`U` and :math:`V` of sizes :math:`p \times n`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`p \times m`, data matrix :math:`X` and :math:`Y` can be created as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfollows:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspX = [U | V] \in \mathcal{R}^{p \times (n + m)}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspY = [0_{1 \times n} | 1_{1 \times m}] \in \mathcal{R}^{(n + m)}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThen, the MGC statistic can be calculated as normal. This methodology can</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbe extended to similar tests such as distance correlation [4]_.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.4.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] Vogelstein, J. T., Bridgeford, E. W., Wang, Q., Priebe, C. E.,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMaggioni, M., & Shen, C. (2019). Discovering and deciphering</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprelationships across disparate data modalities. ELife.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] Panda, S., Palaniappan, S., Xiong, J., Swaminathan, A.,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRamachandran, S., Bridgeford, E. W., ... Vogelstein, J. T. (2019).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmgcpy: A Comprehensive High Dimensional Independence Testing Python</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPackage. :arXiv:`1907.02088`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] Shen, C., Priebe, C.E., & Vogelstein, J. T. (2019). From distance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcorrelation to multiscale graph correlation. Journal of the American</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistical Association.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [4] Shen, C. & Vogelstein, J. T. (2018). The Exact Equivalence of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDistance and Kernel Methods for Hypothesis Testing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp:arXiv:`1806.05514`</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multiscale_graphcorr</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.arange(100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stat, pvalue, _ = multiscale_graphcorr(x, y, workers=-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> '%.1f, %.3f' % (stat, pvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'1.0, 0.001'</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlternatively,</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.arange(100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> mgc = multiscale_graphcorr(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> '%.1f, %.3f' % (mgc.stat, mgc.pvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'1.0, 0.001'</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTo run an unpaired two-sample test,</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.arange(100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = np.arange(79)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> mgc = multiscale_graphcorr(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> '%.3f, %.2f' % (mgc.stat, mgc.pvalue)  # doctest: +SKIP</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'0.033, 0.02'</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspor, if shape of the inputs are the same,</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.arange(100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> mgc = multiscale_graphcorr(x, y, is_twosamp=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> '%.3f, %.1f' % (mgc.stat, mgc.pvalue)  # doctest: +SKIP</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'-0.008, 1.0'</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("x and y must be ndarrays")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# convert arrays of type (n,) to (n, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif x.ndim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x[:, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif x.ndim != 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Expected a 2-D array `x`, found shape "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"{}".format(x.shape))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif y.ndim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = y[:, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif y.ndim != 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Expected a 2-D array `y`, found shape "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"{}".format(y.shape))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnx, px = x.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspny, py = y.shape</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# check for NaNs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_contains_nan(x, nan_policy='raise')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_contains_nan(y, nan_policy='raise')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# check for positive or negative infinity and raise error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.sum(np.isinf(x)) > 0 or np.sum(np.isinf(y)) > 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Inputs contain infinities")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nx != ny:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif px == py:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# reshape x and y for two sample testing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_twosamp = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Shape mismatch, x and y must have shape [n, p] "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"and [n, q] or have shape [n, p] and [m, p].")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nx < 5 or ny < 5:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("MGC requires at least 5 samples to give reasonable "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"results.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# convert x and y to float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = x.astype(np.float64)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = y.astype(np.float64)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# check if compute_distance_matrix if a callable()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not callable(compute_distance) and compute_distance is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Compute_distance must be a function.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# check if number of reps exists, integer, or > 0 (if under 1000 raises</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# warning)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not isinstance(reps, int) or reps < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Number of reps must be an integer greater than 0.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif reps < 1000:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("The number of replications is low (under 1000), and p-value "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"calculations may be unreliable. Use the p-value result, with "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"caution!")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(msg, RuntimeWarning)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif is_twosamp:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif compute_distance is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Cannot run if inputs are distance matrices")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, y = _two_sample_transform(x, y)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif compute_distance is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# compute distance matrices for x and y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = compute_distance(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = compute_distance(y)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate MGC stat</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat, stat_dict = _mgc_stat(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_mgc_map = stat_dict["stat_mgc_map"]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspopt_scale = stat_dict["opt_scale"]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate permutation MGC p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue, null_dist = _perm_test(x, y, stat, reps=reps, workers=workers,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state=random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# save all stats (other than stat/p-value) in dictionary</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmgc_dict = {"mgc_map": stat_mgc_map,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"opt_scale": opt_scale,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"null_dist": null_dist}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn MGCResult(stat, pvalue, mgc_dict)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _mgc_stat(distx, disty):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Helper function that calculates the MGC stat. See above for use.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx, y : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`x` and `y` have shapes `(n, p)` and `(n, q)` or `(n, n)` and `(n, n)`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif distance matrices.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample MGC test statistic within `[-1, 1]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_dict : dict</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspContains additional useful additional returns containing the following</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeys:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- stat_mgc_map : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMGC-map of the statistics.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- opt_scale : (float, float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe estimated optimal scale as a `(x, y)` pair.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate MGC map and optimal scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_mgc_map = _local_correlations(distx, disty, global_corr='mgc')</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn, m = stat_mgc_map.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif m == 1 or n == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the global scale at is the statistic calculated at maximial nearest</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# neighbors. There is not enough local scale to search over, so</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# default to global scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstat = stat_mgc_map[m - 1][n - 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspopt_scale = m * n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsamp_size = len(distx) - 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# threshold to find connected region of significant local correlations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsig_connect = _threshold_mgc_map(stat_mgc_map, samp_size)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# maximum within the significant region</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstat, opt_scale = _smooth_mgc_map(sig_connect, stat_mgc_map)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_dict = {"stat_mgc_map": stat_mgc_map,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"opt_scale": opt_scale}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn stat, stat_dict</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _threshold_mgc_map(stat_mgc_map, samp_size):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFinds a connected region of significance in the MGC-map by thresholding.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_mgc_map : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAll local correlations within `[-1,1]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsamp_size : int</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample size of original data.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsig_connect : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA binary matrix with 1's indicating the significant region.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm, n = stat_mgc_map.shape</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# 0.02 is simply an empirical threshold, this can be set to 0.01 or 0.05</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# with varying levels of performance. Threshold is based on a beta</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# approximation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspper_sig = 1 - (0.02 / samp_size)  # Percentile to consider as significant</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthreshold = samp_size * (samp_size - 3)/4 - 1/2  # Beta approximation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthreshold = distributions.beta.ppf(per_sig, threshold, threshold) * 2 - 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the global scale at is the statistic calculated at maximial nearest</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# neighbors. Threshold is the maximium on the global and local scales</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthreshold = max(threshold, stat_mgc_map[m - 1][n - 1])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# find the largest connected component of significant correlations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsig_connect = stat_mgc_map > threshold</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.sum(sig_connect) > 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsig_connect, _ = _measurements.label(sig_connect)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, label_counts = np.unique(sig_connect, return_counts=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# skip the first element in label_counts, as it is count(zeros)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_label = np.argmax(label_counts[1:]) + 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsig_connect = sig_connect == max_label</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsig_connect = np.array([[False]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn sig_connect</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _smooth_mgc_map(sig_connect, stat_mgc_map):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Finds the smoothed maximal within the significant region R.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf area of R is too small it returns the last local correlation. Otherwise,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturns the maximum within significant_connected_region.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsig_connect: ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA binary matrix with 1's indicating the significant region.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat_mgc_map: ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAll local correlations within `[-1, 1]`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sample MGC statistic within `[-1, 1]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspopt_scale: (float, float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe estimated optimal scale as an `(x, y)` pair.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm, n = stat_mgc_map.shape</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the global scale at is the statistic calculated at maximial nearest</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# neighbors. By default, statistic and optimal scale are global.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstat = stat_mgc_map[m - 1][n - 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspopt_scale = [m, n]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.linalg.norm(sig_connect) != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# proceed only when the connected region's area is sufficiently large</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# 0.02 is simply an empirical threshold, this can be set to 0.01 or 0.05</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# with varying levels of performance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.sum(sig_connect) >= np.ceil(0.02 * max(m, n)) * min(m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_corr = max(stat_mgc_map[sig_connect])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# find all scales within significant_connected_region that maximize</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the local correlation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_corr_index = np.where((stat_mgc_map >= max_corr) & sig_connect)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif max_corr >= stat:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstat = max_corr</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, l = max_corr_index</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspone_d_indices = k * n + l  # 2D to 1D indexing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = np.max(one_d_indices) // n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspl = np.max(one_d_indices) % n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspopt_scale = [k+1, l+1]  # adding 1s to match R indexing</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn stat, opt_scale</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _two_sample_transform(u, v):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Helper function that concatenates x and y for two sample MGC stat.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee above for use.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspu, v : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`u` and `v` have shapes `(n, p)` and `(m, p)`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspConcatenate `u` and `v` along the `axis = 0`. `x` thus has shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(2n, p)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLabel matrix for `x` where 0 refers to samples that comes from `u` and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1 refers to samples that come from `v`. `y` thus has shape `(2n, 1)`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnx = u.shape[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspny = v.shape[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = np.concatenate([u, v], axis=0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = np.concatenate([np.zeros(nx), np.ones(ny)], axis=0).reshape(-1, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn x, y</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+#####################################</span>
<br><span style="color:green">+#       INFERENTIAL STATISTICS      #</span>
<br><span style="color:green">+#####################################</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Ttest_1sampResult = namedtuple('Ttest_1sampResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def ttest_1samp(a, popmean, axis=0, nan_policy='propagate',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative="two-sided"):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate the T-test for the mean of ONE group of scores.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a test for the null hypothesis that the expected value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(mean) of a sample of independent observations `a` is equal to the given</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppopulation mean, `popmean`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSample observation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppopmean : float or array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExpected value in null hypothesis. If array_like, then it must have the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsame shape as `a` excluding the axis dimension.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int or None, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to compute test; default is 0. If None, compute over</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe whole array `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the mean of the underlying distribution of the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis different than the given population mean (`popmean`)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the mean of the underlying distribution of the sample is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspless than the given population mean (`popmean`)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the mean of the underlying distribution of the sample is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgreater than the given population mean (`popmean`)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float or array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt-statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float or array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo-sided p-value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50, 2), random_state=rng)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTest if mean of random sample is equal to true mean, and different mean.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe reject the null hypothesis in the second case and don't reject it in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe first case.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs, 5.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_1sampResult(statistic=array([-2.09794637, -1.75977004]), pvalue=array([0.04108952, 0.08468867]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_1samp(rvs, 0.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_1sampResult(statistic=array([1.64495065, 1.62095307]), pvalue=array([0.10638103, 0.11144602]))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples using axis and non-scalar dimension for population mean.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result = stats.ttest_1samp(rvs, [5.0, 0.0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([-2.09794637,  1.62095307])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.pvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.04108952, 0.11144602])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result = stats.ttest_1samp(rvs.T, [5.0, 0.0], axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([-2.09794637,  1.62095307])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.pvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.04108952, 0.11144602])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result = stats.ttest_1samp(rvs, [[5.0], [0.0]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[-2.09794637, -1.75977004],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 1.64495065,  1.62095307]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> result.pvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[0.04108952, 0.08468867],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[0.10638103, 0.11144602]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcontains_nan, nan_policy = _contains_nan(a, nan_policy)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_1samp(a, popmean, axis, alternative)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdf = n - 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd = np.mean(a, axis) - popmean</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspv = np.var(a, axis, ddof=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdenom = np.sqrt(v / n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore', invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.divide(d, denom)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t, alternative)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn Ttest_1sampResult(t, prob)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _ttest_finish(df, t, alternative):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Common code between all 3 t-test functions."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We use ``stdtr`` directly here as it handles the case when ``nan``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# values are present in the data and masked arrays are passed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# while ``t.cdf`` emits runtime warnings. This way ``_ttest_finish``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# can be shared between the ``stats`` and ``mstats`` versions.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == 'less':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = special.stdtr(df, t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == 'greater':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = special.stdtr(df, -t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == 'two-sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = special.stdtr(df, -np.abs(t))*2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("alternative must be "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"'less', 'greater' or 'two-sided'")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif t.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = t[()]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif pval.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = pval[()]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn t, pval</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _ttest_ind_from_stats(mean1, mean2, denom, df, alternative):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd = mean1 - mean2</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore', invalid='ignore'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.divide(d, denom)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t, alternative)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn (t, prob)
<br>&nbsp
<br>@@ -3866,15 +5753,16 @@ def _equal_var_ttest_denom(v1, n1, v2, n2):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdenom = np.sqrt(svar * (1.0 / n1 + 1.0 / n2))
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn df, denom
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspTtest_indResult = namedtuple('Ttest_indResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequal_var=True):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequal_var=True, alternative="two-sided"):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspT-test for means of two independent samples from descriptive statistics.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is a two-sided test for the null hypothesis that two independent</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a test for the null hypothesis that two independent</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsamples have identical average (expected) values.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>@@ -3886,7 +5774,7 @@ def ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br>&nbsp &nbsp &nbsp &nbsp &nbspnobs1 : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe number(s) of observations of sample 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbspmean2 : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe mean(s) of sample 2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe mean(s) of sample 2.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspstd2 : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe standard deviations(s) of sample 2.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnobs2 : array_like
<br>@@ -3896,11 +5784,22 @@ def ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat assumes equal population variances [1]_.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, perform Welch's t-test, which does not assume equal
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppopulation variance [2]_.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the means of the distributions are unequal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the mean of the first distribution is less than the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean of the second distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the mean of the first distribution is greater than the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean of the second distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float or array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculated t-statistics</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculated t-statistics.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float or array
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe two-tailed p-value.
<br>&nbsp
<br>@@ -3910,14 +5809,13 @@ def ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 0.16.0
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] http://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] http://en.wikipedia.org/wiki/Welch%27s_t_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3934,7 +5832,7 @@ def ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import ttest_ind_from_stats
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> ttest_ind_from_stats(mean1=15.0, std1=np.sqrt(87.5), nobs1=13,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...                      mean2=12.0, std2=np.sqrt(39.0), nobs2=11)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=0.90513580933102689, pvalue=0.37519967975814872)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=0.9051358093310269, pvalue=0.3751996797581487)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor comparison, here is the data from which those summary statistics
<br>&nbsp &nbsp &nbsp &nbsp &nbspwere taken.  With this data, we can compute the same result using
<br>@@ -3944,24 +5842,97 @@ def ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> b = np.array([2, 4, 6, 9, 11, 13, 14, 15, 18, 19, 21])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import ttest_ind
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> ttest_ind(a, b)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=0.905135809331027, pvalue=0.37519967975814861)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=0.905135809331027, pvalue=0.3751996797581486)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSuppose we instead have binary data and would like to apply a t-test to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcompare the proportion of 1s in two independent groups::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of    Sample     Sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSize    ones        Mean     Variance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSample 1    150      30         0.2        0.16</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSample 2    200      45         0.225      0.174375</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe sample mean :math:`\hat{p}` is the proportion of ones in the sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand the variance for a binary observation is estimated by</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`\hat{p}(1-\hat{p})`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ttest_ind_from_stats(mean1=0.2, std1=np.sqrt(0.16), nobs1=150,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                      mean2=0.225, std2=np.sqrt(0.17437), nobs2=200)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-0.564327545549774, pvalue=0.5728947691244874)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor comparison, we could compute the t statistic and p-value using</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparrays of 0s and 1s and `scipy.stat.ttest_ind`, as above.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> group1 = np.array([1]*30 + [0]*(150-30))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> group2 = np.array([1]*45 + [0]*(200-45))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ttest_ind(group1, group2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-0.5627179589855622, pvalue=0.573989277115258)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmean1 = np.asarray(mean1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstd1 = np.asarray(std1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmean2 = np.asarray(mean2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstd2 = np.asarray(std2)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif equal_var:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _equal_var_ttest_denom(std1**2, nobs1, std2**2, nobs2)
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _unequal_var_ttest_denom(std1**2, nobs1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd2**2, nobs2)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspres = _ttest_ind_from_stats(mean1, mean2, denom, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspres = _ttest_ind_from_stats(mean1, mean2, denom, df, alternative)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn Ttest_indResult(*res)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate'):</span>
<br><span style="color:green">+def _ttest_nans(a, b, axis, namedtuple_type):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGenerate an array of `nan`, with shape determined by `a`, `b` and `axis`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis function is used by ttest_ind and ttest_rel to create the return</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvalue when one of the inputs has size 0.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe shapes of the arrays are determined by dropping `axis` from the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshapes of `a` and `b` and broadcasting what is left.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe return value is a named tuple of the type given in `namedtuple_type`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.zeros((9, 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = np.zeros((5, 1))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> _ttest_nans(a, b, 0, Ttest_indResult)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=array([nan, nan]), pvalue=array([nan, nan]))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.zeros((3, 0, 9))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = np.zeros((1, 10))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stat, p = _ttest_nans(a, b, -1, Ttest_indResult)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stat</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([], shape=(3, 0), dtype=float64)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([], shape=(3, 0), dtype=float64)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = np.zeros(10)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = np.zeros(7)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> _ttest_nans(a, b, 0, Ttest_indResult)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=nan, pvalue=nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshp = _broadcast_shapes_with_dropped_axis(a, b, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif len(shp) == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.full(shp, fill_value=np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = t.copy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn namedtuple_type(t, p)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermutations=None, random_state=None, alternative="two-sided",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrim=0):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspCalculate the T-test for the means of *two independent* samples of scores.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is a two-sided test for the null hypothesis that 2 independent samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a test for the null hypothesis that 2 independent samples</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsphave identical average (expected) values. This test assumes that the
<br>&nbsp &nbsp &nbsp &nbsp &nbsppopulations have identical variances by default.
<br>&nbsp
<br>@@ -3980,76 +5951,199 @@ def ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppopulation variance [2]_.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 0.11.0
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe 'omit' option is not currently available for permutation tests or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspone-sided asympyotic tests.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppermutations : non-negative int, np.inf, or None (default), optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf 0 or None (default), use the t-distribution to calculate p-values.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOtherwise, `permutations` is  the number of random permutations that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be used to estimate p-values using a permutation test. If</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`permutations` equals or exceeds the number of distinct partitions of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe pooled data, an exact test is performed instead (i.e. each</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistinct partition is used exactly once). See Notes for details.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPseudorandom number generator state used to generate permutations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(used only when `permutations` is not None).</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the means of the distributions underlying the samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare unequal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the mean of the distribution underlying the first sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis less than the mean of the distribution underlying the second</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the mean of the distribution underlying the first</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample is greater than the mean of the distribution underlying</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe second sample.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptrim : float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf nonzero, performs a trimmed (Yuen's) t-test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the fraction of elements to be trimmed from each end of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput samples. If 0 (default), no elements will be trimmed from either</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspside. The number of trimmed elements from each tail is the floor of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrim times the number of elements. Valid range is [0, .5).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float or array
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculated t-statistic.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float or array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe two-tailed p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWe can use this test, if we observe two independent samples from</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe same or different population, e.g. exam scores of boys and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgirls or of two ethnic groups. The test measures whether the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaverage (expected) value differs significantly across samples. If</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwe observe a large p-value, for example larger than 0.05 or 0.1,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthen we cannot reject the null hypothesis of identical average scores.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf the p-value is smaller than the threshold, e.g. 1%, 5% or 10%,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthen we reject the null hypothesis of equal averages.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSuppose we observe two independent samples, e.g. flower petal lengths, and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwe are considering whether the two samples were drawn from the same</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppopulation (e.g. the same species of flower or two species with similar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppetal characteristics) or two different populations.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe t-test quantifies the difference between the arithmetic means</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the two samples. The p-value quantifies the probability of observing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspas or more extreme values assuming the null hypothesis, that the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsamples are drawn from populations with the same population means, is true.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspour observation is not so unlikely to have occurred by chance. Therefore,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwe do not reject the null hypothesis of equal population means.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf the p-value is smaller than our threshold, then we have evidence</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspagainst the null hypothesis of equal population means.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspBy default, the p-value is determined by comparing the t-statistic of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspobserved data against a theoretical t-distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen ``1 < permutations < binom(n, k)``, where</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* ``k`` is the number of observations in `a`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* ``n`` is the total number of observations in `a` and `b`, and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp* ``binom(n, k)`` is the binomial coefficient (``n`` choose ``k``),</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe data are pooled (concatenated), randomly assigned to either group `a`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspor `b`, and the t-statistic is calculated. This process is performed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprepeatedly (`permutation` times), generating a distribution of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt-statistic under the null hypothesis, and the t-statistic of the observed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata is compared to this distribution to determine the p-value. When</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``permutations >= binom(n, k)``, an exact test is performed: the data are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppartitioned between the groups in each distinct way exactly once.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe permutation test can be computationally expensive and not necessarily</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmore accurate than the analytical test, but it does not make strong</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassumptions about the shape of the underlying distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUse of trimming is commonly referred to as the trimmed t-test. At times</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcalled Yuen's t-test, this is an extension of Welch's t-test, with the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdifference being the use of winsorized means in calculation of the variance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand the trimmed sample size in calculation of the statistic. Trimming is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreccomended if the underlying distribution is long-tailed or contaminated</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith outliers [4]_.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] http://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] http://en.wikipedia.org/wiki/Welch%27s_t_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] http://en.wikipedia.org/wiki/Resampling_%28statistics%29</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [4] Yuen, Karen K. "The Two-Sample Trimmed t for Unequal Population</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariances." Biometrika, vol. 61, no. 1, 1974, pp. 165-170. JSTOR,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwww.jstor.org/stable/2334299. Accessed 30 Mar. 2021.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [5] Yuen, Karen K., and W. J. Dixon. "The Approximate Behaviour and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPerformance of the Two-Sample Trimmed t." Biometrika, vol. 60,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspno. 2, 1973, pp. 369-374. JSTOR, www.jstor.org/stable/2334550.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAccessed 30 Mar. 2021.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(12345678)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspTest with sample with identical means:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs2 = stats.norm.rvs(loc=5,scale=10,size=500)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1,rvs2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.26833823296239279, 0.78849443369564776)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1,rvs2, equal_var = False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.26833823296239279, 0.78849452749500748)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952038870015)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs2, equal_var=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952553131064)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`ttest_ind` underestimates p for unequal variances:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs3)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-0.46580283298287162, 0.64145827413436174)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs3, equal_var = False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-0.46580283298287162, 0.64149646246569292)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-1.6370984482905417, pvalue=0.1019251574705033)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs3, equal_var=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-1.637098448290542, pvalue=0.10202110497954867)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWhen n1 != n2, the equal variance t-statistic is no longer equal to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen ``n1 != n2``, the equal variance t-statistic is no longer equal to the</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspunequal variance t-statistic:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs4)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-0.99882539442782481, 0.3182832709103896)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs4, equal_var = False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-0.69712570584654099, 0.48716927725402048)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-1.9481646859513422, pvalue=0.05186270935842703)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs4, equal_var=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-1.3146566100751664, pvalue=0.1913495266513811)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspT-test with different means, variance, and n:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs5)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-1.4679669854490653, 0.14263895620529152)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs5, equal_var = False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-0.94365973617132992, 0.34744170334794122)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-2.8415950600298774, pvalue=0.0046418707568707885)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs5, equal_var=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-1.8686598649188084, pvalue=0.06434714193919686)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen performing a permutation test, more permutations typically yields</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmore accurate results. Use a ``np.random.Generator`` to ensure</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreproducibility:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(rvs1, rvs5, permutations=10000,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                 random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=-2.8415950600298774, pvalue=0.0052)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTake these two samples, one of which has an extreme tail.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> a = (56, 128.6, 12, 123.8, 64.34, 78, 763.3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> b = (1.1, 2.9, 4.2)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUse the `trim` keyword to perform a trimmed (Yuen) t-test. For example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspusing 20% trimming, ``trim=.2``, the test will reduce the impact of one</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(``np.floor(trim*len(a))``) element from each tail of sample `a`. It will</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphave no effect on sample `b` because ``np.floor(trim*len(b))`` is 0.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_ind(a, b, trim=.2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_indResult(statistic=3.4463884028073513,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalue=0.01369338726499547)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not (0 <= trim < .5):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Trimming percentage should be 0 <= `trim` < .5.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, b, axis = _chk2_asarray(a, b, axis)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# check both a and b
<br>@@ -4060,35 +6154,246 @@ def ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = 'omit'
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == 'omit':
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif permutations or trim != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("nan-containing/masked inputs with "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"nan_policy='omit' are currently not "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"supported by permutation tests or "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"trimmed tests.")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = ma.masked_invalid(a)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb = ma.masked_invalid(b)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_ind(a, b, axis, equal_var)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_ind(a, b, axis, equal_var, alternative)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif a.size == 0 or b.size == 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn Ttest_indResult(np.nan, np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _ttest_nans(a, b, axis, Ttest_indResult)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif permutations is not None and permutations != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif trim != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Permutations are currently not supported "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"with trimming.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif permutations < 0 or (np.isfinite(permutations) and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspint(permutations) != permutations):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Permutations must be a non-negative integer.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres = _permutation_ttest(a, b, permutations=permutations,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis, equal_var=equal_var,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy=nan_policy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state=random_state,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative=alternative)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspv1 = np.var(a, axis, ddof=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspv2 = np.var(b, axis, ddof=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn1 = a.shape[axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn2 = b.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn1 = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn2 = b.shape[axis]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif trim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspv1 = np.var(a, axis, ddof=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspv2 = np.var(b, axis, ddof=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm1 = np.mean(a, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm2 = np.mean(b, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspv1, m1, n1 = _ttest_trim_var_mean_len(a, trim, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspv2, m2, n2 = _ttest_trim_var_mean_len(b, trim, axis)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif equal_var:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _equal_var_ttest_denom(v1, n1, v2, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif equal_var:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _equal_var_ttest_denom(v1, n1, v2, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _unequal_var_ttest_denom(v1, n1, v2, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres = _ttest_ind_from_stats(m1, m2, denom, df, alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn Ttest_indResult(*res)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _ttest_trim_var_mean_len(a, trim, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Variance, mean, and length of winsorized input along specified axis"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# for use with `ttest_ind` when trimming.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# further calculations in this test assume that the inputs are sorted.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# From [4] Section 1 "Let x_1, ..., x_n be n ordered observations..."</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = np.sort(a, axis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `g` is the number of elements to be replaced on each tail, converted</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# from a percentage amount of trimming</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspg = int(n * trim)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Calculate the Winsorized variance of the input samples according to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# specified `g`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspv = _calculate_winsorized_variance(a, g, axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the total number of elements in the trimmed samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn -= 2 * g</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# calculate the g-times trimmed mean, as defined in [4] (1-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm = trim_mean(a, trim, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn v, m, n</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _calculate_winsorized_variance(a, g, axis):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculates g-times winsorized variance along specified axis"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# it is expected that the input `a` is sorted along the correct axis</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif g == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.var(a, ddof=1, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# move the intended axis to the end that way it is easier to manipulate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_win = np.moveaxis(a, axis, -1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# save where NaNs are for later use.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnans_indices = np.any(np.isnan(a_win), axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Winsorization and variance calculation are done in one step in [4]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (1-3), but here winsorization is done first; replace the left and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# right sides with the repeating value. This can be see in effect in (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# 1-3) in [4], where the leftmost and rightmost tails are replaced with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `(g + 1) * x_{g + 1}` on the left and `(g + 1) * x_{n - g}` on the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# right. Zero-indexing turns `g + 1` to `g`, and `n - g` to `- g - 1` in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# array indexing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_win[..., :g] = a_win[..., [g]]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa_win[..., -g:] = a_win[..., [-g - 1]]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Determine the variance. In [4], the degrees of freedom is expressed as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `h - 1`, where `h = n - 2g` (unnumbered equations in Section 1, end of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# page 369, beginning of page 370). This is converted to NumPy's format,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `n - ddof` for use with with `np.var`. The result is converted to an</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# array to accommodate indexing later.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvar_win = np.asarray(np.var(a_win, ddof=(2 * g + 1), axis=-1))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# with `nan_policy='propagate'`, NaNs may be completely trimmed out</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# because they were sorted into the tail of the array. In these cases,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# replace computed variances with `np.nan`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvar_win[nans_indices] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn var_win</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _data_partitions(data, permutations, size_a, axis=-1, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""All partitions of data into sets of given lengths, ignoring order"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state = check_random_state(random_state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif axis < 0:  # we'll be adding a new dimension at the end</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = data.ndim + axis</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# prepare permutation indices</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsize = data.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# number of distinct combinations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn_max = special.comb(size, size_a)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif permutations < n_max:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindices = np.array([random_state.permutation(size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(permutations)]).T</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, denom = _unequal_var_ttest_denom(v1, n1, v2, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermutations = n_max</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindices = np.array([np.concatenate(z)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor z in _all_partitions(size_a, size-size_a)]).T</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata = data.swapaxes(axis, -1)   # so we can index along a new dimension</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata = data[..., indices]        # generate permutations</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata = data.swapaxes(-2, axis)   # restore original axis order</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata = np.moveaxis(data, -1, 0)  # permutations indexed along axis 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn data, permutations</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _calc_t_stat(a, b, equal_var, axis=-1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate the t statistic along the given dimension."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspna = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnb = b.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspavg_a = np.mean(a, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspavg_b = np.mean(b, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvar_a = np.var(a, axis=axis, ddof=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvar_b = np.var(b, axis=axis, ddof=1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not equal_var:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdenom = _unequal_var_ttest_denom(var_a, na, var_b, nb)[1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdenom = _equal_var_ttest_denom(var_a, na, var_b, nb)[1]</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspres = _ttest_ind_from_stats(np.mean(a, axis), np.mean(b, axis), denom, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn (avg_a-avg_b)/denom</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn Ttest_indResult(*res)</span>
<br>&nbsp
<br><span style="color:red">- Ttest_relResult = namedtuple('Ttest_relResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+def _permutation_ttest(a, b, permutations, axis=0, equal_var=True,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy='propagate', random_state=None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative="two-sided"):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCalculates the T-test for the means of TWO INDEPENDENT samples of scores</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspusing permutation methods.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis test is similar to `stats.ttest_ind`, except it doesn't rely on an</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspapproximate normality assumption since it uses a permutation test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis function is only called from ttest_ind when permutations is not None.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa, b : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe arrays must be broadcastable, except along the dimension</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcorresponding to `axis` (the zeroth, by default).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe axis over which to operate on a and b.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppermutations: int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of permutations used to calculate p-value. If greater than or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequal to the number of distinct permutations, perform an exact test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspequal_var: bool, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, an equal variance (Welch's) t-test is conducted.  Otherwise,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspan ordinary t-test is conducted.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None the `numpy.random.Generator` singleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``Generator`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` instance then that instance is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPseudorandom number generator state used for generating random</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppermutations.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float or array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculated t-statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float or array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value.</span>
<br>&nbsp
<br><span style="color:red">- def ttest_rel(a, b, axis=0, nan_policy='propagate'):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate the T-test on TWO RELATED samples of scores, a and b.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom_state = check_random_state(random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt_stat_observed = _calc_t_stat(a, b, equal_var, axis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspna = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmat = _broadcast_concatenate((a, b), axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmat = np.moveaxis(mat, axis, -1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmat_perm, permutations = _data_partitions(mat, permutations, size_a=na,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state=random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = mat_perm[..., :na]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspb = mat_perm[..., na:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt_stat = _calc_t_stat(a, b, equal_var)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcompare = {"less": np.less_equal,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"greater": np.greater_equal,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"two-sided": lambda x, y: (x <= -np.abs(y)) | (x >= np.abs(y))}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Calculate the p-values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcmps = compare[alternative](t_stat, t_stat_observed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalues = cmps.sum(axis=0) / permutations</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# nans propagate naturally in statistic calculation, but need to be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# propagated manually into pvalues</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nan_policy == 'propagate' and np.isnan(t_stat_observed).any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.ndim(pvalues) == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalues = np.float64(np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppvalues[np.isnan(t_stat_observed)] = np.nan</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn (t_stat_observed, pvalues)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _get_len(a, axis, msg):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = a.shape[axis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept IndexError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise np.AxisError(axis, a.ndim, msg) from None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn n</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Ttest_relResult = namedtuple('Ttest_relResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is a two-sided test for the null hypothesis that 2 related or</span>
<br><span style="color:green">+def ttest_rel(a, b, axis=0, nan_policy='propagate', alternative="two-sided"):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate the t-test on TWO RELATED samples of scores, a and b.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a test for the null hypothesis that two related or</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsprepeated samples have identical average (expected) values.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>@@ -4099,20 +6404,37 @@ def ttest_rel(a, b, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to compute test. If None, compute over the whole
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrays, `a`, and `b`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': the means of the distributions underlying the samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare unequal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the mean of the distribution underlying the first sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis less than the mean of the distribution underlying the second</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the mean of the distribution underlying the first</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample is greater than the mean of the distribution underlying</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe second sample.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float or array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt-statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt-statistic.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float or array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-tailed p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples for the use are scores of the same set of student in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples for use are scores of the same set of student in</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdifferent exams, or repeated sampling from the same units. The
<br>&nbsp &nbsp &nbsp &nbsp &nbsptest measures whether the average score differs significantly
<br>&nbsp &nbsp &nbsp &nbsp &nbspacross samples (e.g. exams). If we observe a large p-value, for
<br>@@ -4129,17 +6451,17 @@ def ttest_rel(a, b, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(12345678) # fix random seed to get same numbers</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs2 = (stats.norm.rvs(loc=5,scale=10,size=500) +</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp...         stats.norm.rvs(scale=0.2,size=500))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_rel(rvs1,rvs2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.24101764965300962, 0.80964043445811562)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs3 = (stats.norm.rvs(loc=8,scale=10,size=500) +</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp...         stats.norm.rvs(scale=0.2,size=500))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.ttest_rel(rvs1,rvs3)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(-3.9995108708727933, 7.3082402191726459e-005)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs2 = (stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...         + stats.norm.rvs(scale=0.2, size=500, random_state=rng))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_rel(rvs1, rvs2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_relResult(statistic=-0.4549717054410304, pvalue=0.6493274702088672)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs3 = (stats.norm.rvs(loc=8, scale=10, size=500, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...         + stats.norm.rvs(scale=0.2, size=500, random_state=rng))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ttest_rel(rvs1, rvs3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTtest_relResult(statistic=-5.879467544540889, pvalue=7.540777129099917e-09)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, b, axis = _chk2_asarray(a, b, axis)
<br>@@ -4156,179 +6478,30 @@ def ttest_rel(a, b, axis=0, nan_policy='propagate'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = ma.mask_or(ma.getmask(a), ma.getmask(b))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaa = ma.array(a, mask=m, copy=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbb = ma.array(b, mask=m, copy=True)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_rel(aa, bb, axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.ttest_rel(aa, bb, axis, alternative)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif a.shape[axis] != b.shape[axis]:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspna = _get_len(a, axis, "first argument")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnb = _get_len(b, axis, "second argument")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif na != nb:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('unequal length arrays')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif a.size == 0 or b.size == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.nan, np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif na == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _ttest_nans(a, b, axis, Ttest_relResult)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = a.shape[axis]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdf = float(n - 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdf = n - 1</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspd = (a - b).astype(np.float64)
<br>&nbsp &nbsp &nbsp &nbsp &nbspv = np.var(d, axis, ddof=1)
<br>&nbsp &nbsp &nbsp &nbsp &nbspdm = np.mean(d, axis)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdenom = np.sqrt(v / float(n))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdenom = np.sqrt(v / n)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore', invalid='ignore'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = np.divide(dm, denom)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt, prob = _ttest_finish(df, t, alternative)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn Ttest_relResult(t, prob)
<br>&nbsp
<br><span style="color:red">- KstestResult = namedtuple('KstestResult', ('statistic', 'pvalue'))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br><span style="color:red">- def kstest(rvs, cdf, args=(), N=20, alternative='two-sided', mode='approx'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspPerform the Kolmogorov-Smirnov test for goodness of fit.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis performs a test of the distribution G(x) of an observed</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprandom variable against a given distribution F(x). Under the null</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsphypothesis the two distributions are identical, G(x)=F(x). The</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspalternative hypothesis can be either 'two-sided' (default), 'less'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspor 'greater'. The KS test is only valid for continuous distributions.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprvs : str, array or callable</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a string, it should be the name of a distribution in `scipy.stats`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf an array, it should be a 1-D array of observations of random</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariables.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a callable, it should be a function to generate random variables;</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit is required to have a keyword argument `size`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcdf : str or callable</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a string, it should be the name of a distribution in `scipy.stats`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `rvs` is a string then `cdf` can be False or the same as `rvs`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a callable, that callable is used to calculate the cdf.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspargs : tuple, sequence, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDistribution parameters, used if `rvs` or `cdf` are strings.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspN : int, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSample size if `rvs` is string or callable.  Default is 20.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less','greater'}, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis (see explanation above).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 'two-sided'.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmode : 'approx' (default) or 'asymp', optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the distribution used for calculating the p-value.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- 'approx' : use approximation to exact distribution of test statistic</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- 'asymp' : use asymptotic distribution of test statistic</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKS test statistic, either D, D+ or D-.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppvalue :  float</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOne-tailed or two-tailed p-value.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIn the one-sided test, the alternative is that the empirical</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcumulative distribution function of the random variable is "less"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspor "greater" than the cumulative distribution function F(x) of the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsphypothesis, ``G(x)<=F(x)``, resp. ``G(x)>=F(x)``.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x = np.linspace(-15, 15, 9)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x, 'norm')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.44435602715924361, 0.038850142705171065)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321) # set random seed to get the same result</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest('norm', False, N=100)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.058352892479417884, 0.88531190944151261)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe above lines are equivalent to:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.norm.rvs(size=100), 'norm')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.058352892479417884, 0.88531190944151261)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp*Test against one-sided alternative hypothesis*</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspShift distribution to larger values, so that ``cdf_dgp(x) < norm.cdf(x)``:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(loc=0.2, size=100)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x,'norm', alternative = 'less')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.12464329735846891, 0.040989164077641749)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReject equal distribution against alternative hypothesis: less</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x,'norm', alternative = 'greater')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.0072115233216311081, 0.98531158590396395)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspDon't reject equal distribution against alternative hypothesis: greater</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x,'norm', mode='asymp')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.12464329735846891, 0.08944488871182088)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp*Testing t distributed random variables against normal distribution*</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWith 100 degrees of freedom the t distribution looks close to the normal</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdistribution, and the K-S test does not reject the hypothesis that the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsample came from the normal distribution:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.t.rvs(100,size=100),'norm')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.072018929165471257, 0.67630062862479168)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspWith 3 degrees of freedom the t distribution looks sufficiently different</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfrom the normal distribution, that we can reject the hypothesis that the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsample came from the normal distribution at the 10% level:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(987654321)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.t.rvs(3,size=100),'norm')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.131016895759829, 0.058826222555312224)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(rvs, string_types):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (not cdf) or (cdf == rvs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcdf = getattr(distributions, rvs).cdf</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs = getattr(distributions, rvs).rvs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise AttributeError("if rvs is string, cdf has to be the "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"same distribution")</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(cdf, string_types):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcdf = getattr(distributions, cdf).cdf</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif callable(rvs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwds = {'size': N}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = np.sort(rvs(*args, **kwds))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = np.sort(rvs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspN = len(vals)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcdfvals = cdf(vals, *args)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# to not break compatibility with existing code</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative == 'two_sided':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative = 'two-sided'</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative in ['two-sided', 'greater']:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDplus = (np.arange(1.0, N + 1)/N - cdfvals).max()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif alternative == 'greater':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(Dplus, distributions.ksone.sf(Dplus, N))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative in ['two-sided', 'less']:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDmin = (cdfvals - np.arange(0.0, N)/N).max()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif alternative == 'less':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(Dmin, distributions.ksone.sf(Dmin, N))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative == 'two-sided':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = np.max([Dplus, Dmin])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mode == 'asymp':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(D, distributions.kstwobign.sf(D * np.sqrt(N)))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mode == 'approx':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval_two = distributions.kstwobign.sf(D * np.sqrt(N))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif N > 2666 or pval_two > 0.80 - N*0.3/1000:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(D, pval_two)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(D, 2 * distributions.ksone.sf(D, N))</span>
<br><span style="color:red">- </span>
<br>&nbsp
<br>&nbsp# Map from names to lambda_ values used in power_divergence().
<br>&nbsp_power_div_lambda_names = {
<br>@@ -4342,10 +6515,9 @@ _power_div_lambda_names = {
<br>&nbsp
<br>&nbsp
<br>&nbspdef _count(a, axis=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCount the number of non-masked elements of an array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Count the number of non-masked elements of an array.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis function behaves like np.ma.count(), but is much faster</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis function behaves like `np.ma.count`, but is much faster</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor ndarrays.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif hasattr(a, 'count'):
<br>@@ -4361,12 +6533,20 @@ def _count(a, axis=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum = a.shape[axis]
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn num
<br>&nbsp
<br><span style="color:green">+</span>
<br><span style="color:green">+def _m_broadcast_to(a, shape):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.ma.isMaskedArray(a):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.ma.masked_array(np.broadcast_to(a, shape),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=np.broadcast_to(a.mask, shape))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.broadcast_to(a, shape, subok=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspPower_divergenceResult = namedtuple('Power_divergenceResult',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('statistic', 'pvalue'))
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCressie-Read power divergence statistic and goodness of fit test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Cressie-Read power divergence statistic and goodness of fit test.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis function tests the null hypothesis that the categorical data
<br>&nbsp &nbsp &nbsp &nbsp &nbsphas the given frequencies, using the Cressie-Read power divergence
<br>@@ -4390,21 +6570,23 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspapply the test.  If axis is None, all values in `f_obs` are treated
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas a single data set.  Default is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsplambda_ : float or str, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`lambda_` gives the power in the Cressie-Read power divergence</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic.  The default is 1.  For convenience, `lambda_` may be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassigned one of the following strings, in which case the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcorresponding numerical value is used::</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspString              Value   Description</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"pearson"             1     Pearson's chi-squared statistic.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn this case, the function is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequivalent to `stats.chisquare`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"log-likelihood"      0     Log-likelihood ratio. Also known as</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe G-test [3]_.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"freeman-tukey"      -1/2   Freeman-Tukey statistic.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"mod-log-likelihood" -1     Modified log-likelihood ratio.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"neyman"             -2     Neyman's statistic.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"cressie-read"        2/3   The power recommended in [5]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe power in the Cressie-Read power divergence statistic.  The default</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis 1.  For convenience, `lambda_` may be assigned one of the following</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrings, in which case the corresponding numerical value is used:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"pearson"`` (value 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPearson's chi-squared statistic. In this case, the function is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequivalent to `chisquare`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"log-likelihood"`` (value 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog-likelihood ratio. Also known as the G-test [3]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"freeman-tukey"`` (value -1/2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFreeman-Tukey statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"mod-log-likelihood"`` (value -1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspModified log-likelihood ratio.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"neyman"`` (value -2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNeyman's statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* ``"cressie-read"`` (value 2/3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe power recommended in [5]_.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -4425,6 +6607,10 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspcategory are too small.  A typical rule is that all of the observed
<br>&nbsp &nbsp &nbsp &nbsp &nbspand expected frequencies should be at least 5.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlso, the sum of the observed and expected frequencies must be the same</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor the test to be valid; `power_divergence` raises an error if the sums</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdo not agree within a relative tolerance of ``1e-8``.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspWhen `lambda_` is less than zero, the formula for the statistic involves
<br>&nbsp &nbsp &nbsp &nbsp &nbspdividing by `f_obs`, so a warning or error may be generated if any value
<br>&nbsp &nbsp &nbsp &nbsp &nbspin `f_obs` is 0.
<br>@@ -4449,9 +6635,10 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] Lowry, Richard.  "Concepts and Applications of Inferential
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics". Chapter 8. http://faculty.vassar.edu/lowry/ch8pt1.html</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] "Chi-squared test", http://en.wikipedia.org/wiki/Chi-squared_test</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [3] "G-test", http://en.wikipedia.org/wiki/G-test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics". Chapter 8.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://web.archive.org/web/20171015035606/http://faculty.vassar.edu/lowry/ch8pt1.html</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] "Chi-squared test", https://en.wikipedia.org/wiki/Chi-squared_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] "G-test", https://en.wikipedia.org/wiki/G-test</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [4] Sokal, R. R. and Rohlf, F. J. "Biometry: the principles and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppractice of statistics in biological research", New York: Freeman
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(1981)
<br>@@ -4461,7 +6648,6 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(See `chisquare` for more examples.)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspWhen just `f_obs` is given, it is assumed that the expected frequencies
<br>@@ -4519,39 +6705,50 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Convert the input argument `lambda_` to a numerical value.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(lambda_, string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(lambda_, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif lambda_ not in _power_div_lambda_names:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnames = repr(list(_power_div_lambda_names.keys()))[1:-1]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("invalid string for lambda_: {0!r}.  Valid strings "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"are {1}".format(lambda_, names))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("invalid string for lambda_: {0!r}. "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"Valid strings are {1}".format(lambda_, names))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda_ = _power_div_lambda_names[lambda_]
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif lambda_ is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda_ = 1
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspf_obs = np.asanyarray(f_obs)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspf_obs_float = f_obs.astype(np.float64)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif f_exp is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp = np.atleast_1d(np.asanyarray(f_exp))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp = np.asanyarray(f_exp)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbshape = _broadcast_shapes(f_obs_float.shape, f_exp.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_obs_float = _m_broadcast_to(f_obs_float, bshape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp = _m_broadcast_to(f_exp, bshape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprtol = 1e-8  # to pass existing tests</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_obs_sum = f_obs_float.sum(axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp_sum = f_exp.sum(axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprelative_diff = (np.abs(f_obs_sum - f_exp_sum) /</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.minimum(f_obs_sum, f_exp_sum))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdiff_gt_tol = (relative_diff > rtol).any()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif diff_gt_tol:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = (f"For each axis slice, the sum of the observed "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"frequencies must agree with the sum of the "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"expected frequencies to a relative tolerance "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"of {rtol}, but the percent differences are:\n"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"{relative_diff}")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(msg)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute the equivalent of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#   f_exp = f_obs.mean(axis=axis, keepdims=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Older versions of numpy do not have the 'keepdims' argument, so</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# we have to do a little work to achieve the same result.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Ignore 'invalid' errors so the edge case of a data set with length 0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# is handled without spurious warnings.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp = np.atleast_1d(f_obs.mean(axis=axis))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduced_shape = list(f_obs.shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduced_shape[axis] = 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp.shape = reduced_shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf_exp = f_obs.mean(axis=axis, keepdims=True)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# `terms` is the array of terms that are summed along `axis` to create
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# the test statistic.  We use some specialized code for a few special
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# cases of lambda_.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif lambda_ == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Pearson's chi-squared statistic
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspterms = (f_obs - f_exp)**2 / f_exp</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspterms = (f_obs_float - f_exp)**2 / f_exp</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif lambda_ == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Log-likelihood ratio (i.e. G-test)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspterms = 2.0 * special.xlogy(f_obs, f_obs / f_exp)
<br>@@ -4573,10 +6770,9 @@ def power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None):
<br>&nbsp
<br>&nbsp
<br>&nbspdef chisquare(f_obs, f_exp=None, ddof=0, axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCalculate a one-way chi square test.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Calculate a one-way chi-square test.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe chi square test tests the null hypothesis that the categorical data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe chi-square test tests the null hypothesis that the categorical data</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsphas the given frequencies.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>@@ -4608,28 +6804,42 @@ def chisquare(f_obs, f_exp=None, ddof=0, axis=0):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppower_divergence</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmstats.chisquare</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.power_divergence</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.fisher_exact : Fisher exact test on a 2x2 contingency table.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.barnard_exact : An unconditional exact test. An alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto chi-squared test for small sample sizes.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis test is invalid when the observed or expected frequencies in each
<br>&nbsp &nbsp &nbsp &nbsp &nbspcategory are too small.  A typical rule is that all of the observed
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspand expected frequencies should be at least 5.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand expected frequencies should be at least 5. According to [3]_, the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptotal number of samples is recommended to be greater than 13,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspotherwise exact tests (such as Barnard's Exact test) should be used</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbecause they do not overreject.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlso, the sum of the observed and expected frequencies must be the same</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor the test to be valid; `chisquare` raises an error if the sums do not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspagree within a relative tolerance of ``1e-8``.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe default degrees of freedom, k-1, are for the case when no parameters
<br>&nbsp &nbsp &nbsp &nbsp &nbspof the distribution are estimated. If p parameters are estimated by
<br>&nbsp &nbsp &nbsp &nbsp &nbspefficient maximum likelihood then the correct degrees of freedom are
<br>&nbsp &nbsp &nbsp &nbsp &nbspk-1-p. If the parameters are estimated in a different way, then the
<br>&nbsp &nbsp &nbsp &nbsp &nbspdof can be between k-1-p and k-1. However, it is also possible that
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthe asymptotic distribution is not a chisquare, in which case this</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptest is not appropriate.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe asymptotic distribution is not chi-square, in which case this test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis not appropriate.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] Lowry, Richard.  "Concepts and Applications of Inferential
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics". Chapter 8. http://faculty.vassar.edu/lowry/ch8pt1.html</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] "Chi-squared test", http://en.wikipedia.org/wiki/Chi-squared_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics". Chapter 8.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] "Chi-squared test", https://en.wikipedia.org/wiki/Chi-squared_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] Pearson, Karl. "On the criterion that a given system of deviations from the probable</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the case of a correlated system of variables is such that it can be reasonably</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupposed to have arisen from random sampling", Philosophical Magazine. Series 5. 50</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(1900), pp. 157-175.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -4661,125 +6871,849 @@ def chisquare(f_obs, f_exp=None, ddof=0, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> chisquare(obs.ravel())
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(23.31034482758621, 0.015975692534127565)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`ddof` is the change to make to the default degrees of freedom.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`ddof` is the change to make to the default degrees of freedom.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(2.0, 0.73575888234288467)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe calculation of the p-values is done by broadcasting the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspchi-squared statistic with `ddof`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistics, we use ``axis=1``:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...           axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda_="pearson")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+KstestResult = namedtuple('KstestResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _compute_dplus(cdfvals):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Computes D+ as used in the Kolmogorov-Smirnov test.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdfvals: array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspSorted array of CDF values between 0 and 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspMaximum distance of the CDF values below Uniform(0, 1)</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = len(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn (np.arange(1.0, n + 1) / n - cdfvals).max()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _compute_dminus(cdfvals):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Computes D- as used in the Kolmogorov-Smirnov test.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdfvals: array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspSorted array of CDF values between 0 and 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspMaximum distance of the CDF values above Uniform(0, 1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn = len(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn (cdfvals - np.arange(0.0, n)/n).max()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def ks_1samp(x, cdf, args=(), alternative='two-sided', mode='auto'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPerforms the one-sample Kolmogorov-Smirnov test for goodness of fit.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis test compares the underlying distribution F(x) of a sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspagainst a given continuous distribution G(x). See Notes for a description</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the available null and alternative hypotheses.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa 1-D array of observations of iid random variables.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdf : callable</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallable used to calculate the cdf.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspargs : tuple, sequence, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDistribution parameters, used with `cdf`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the null and alternative hypotheses. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPlease see explanations in the Notes below.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmode : {'auto', 'exact', 'approx', 'asymp'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the distribution used for calculating the p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'auto'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'auto' : selects one of the other options.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'exact' : uses the exact distribution of test statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'approx' : approximates the two-sided probability with twice</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe one-sided probability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'asymp': uses asymptotic distribution of test statistic</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKS test statistic, either D, D+ or D- (depending on the value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof 'alternative')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue :  float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOne-tailed or two-tailed p-value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspks_2samp, kstest</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThere are three options for the null and corresponding alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphypothesis that can be selected using the `alternative` parameter.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `two-sided`: The null hypothesis is that the two distributions are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical, F(x)=G(x) for all x; the alternative is that they are not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `less`: The null hypothesis is that F(x) >= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) < G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `greater`: The null hypothesis is that F(x) <= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) > G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNote that the alternative hypotheses describe the *CDFs* of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunderlying distributions, not the observed values. For example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuppose x1 ~ F and x2 ~ G. If F(x) > G(x) for all x, the values in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx1 tend to be less than those in x2.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.linspace(-15, 15, 9)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(x, stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(0.44435602715924361, 0.038850142705171065)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(stats.norm.rvs(size=100, random_state=rng),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.165471391799..., pvalue=0.007331283245...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Test against one-sided alternative hypothesis*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspShift distribution to larger values, so that `` CDF(x) < norm.cdf(x)``:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(loc=0.2, size=100, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(x, stats.norm.cdf, alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.100203351482..., pvalue=0.125544644447...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReject null hypothesis in favor of alternative hypothesis: less</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(x, stats.norm.cdf, alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.018749806388..., pvalue=0.920581859791...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReject null hypothesis in favor of alternative hypothesis: greater</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(x, stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.100203351482..., pvalue=0.250616879765...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDon't reject null hypothesis in favor of alternative hypothesis: two-sided</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Testing t distributed random variables against normal distribution*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWith 100 degrees of freedom the t distribution looks close to the normal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution, and the K-S test does not reject the hypothesis that the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample came from the normal distribution:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(stats.t.rvs(100,size=100, random_state=rng),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.064273776544..., pvalue=0.778737758305...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWith 3 degrees of freedom the t distribution looks sufficiently different</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom the normal distribution, that we can reject the hypothesis that the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample came from the normal distribution at the 10% level:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.ks_1samp(stats.t.rvs(3,size=100, random_state=rng),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.128678487493..., pvalue=0.066569081515...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative = {'t': 'two-sided', 'g': 'greater', 'l': 'less'}.get(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative.lower()[0], alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative not in ['two-sided', 'greater', 'less']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Unexpected alternative %s" % alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.ma.is_masked(x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x.compressed()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspN = len(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = np.sort(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdfvals = cdf(x, *args)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == 'greater':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDplus = _compute_dplus(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(Dplus, distributions.ksone.sf(Dplus, N))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == 'less':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDminus = _compute_dminus(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KstestResult(Dminus, distributions.ksone.sf(Dminus, N))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# alternative == 'two-sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDplus = _compute_dplus(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDminus = _compute_dminus(cdfvals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspD = np.max([Dplus, Dminus])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode == 'auto':  # Always select exact</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'exact'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode == 'exact':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.kstwo.sf(D, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif mode == 'asymp':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.kstwobign.sf(D * np.sqrt(N))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# mode == 'approx'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 2 * distributions.ksone.sf(D, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprob = np.clip(prob, 0, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn KstestResult(D, prob)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+Ks_2sampResult = KstestResult</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _compute_prob_inside_method(m, n, g, h):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCount the proportion of paths that stay strictly inside two diagonal lines.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm > 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn > 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspg : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspg is greatest common divisor of m and n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsph : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0 <= h <= lcm(m,n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspp : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe proportion of paths that stay inside the two lines.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCount the integer lattice paths from (0, 0) to (m, n) which satisfy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp|x/m - y/n| < h / lcm(m, n).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe paths make steps of size +1 in either positive x or positive y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdirections.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe generally follow Hodges' treatment of Drion/Gnedenko/Korolyuk.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspHodges, J.L. Jr.,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"The Significance Probability of the Smirnov Two-Sample Test,"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArkiv fiur Matematik, 3, No. 43 (1958), 469-86.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Probability is symmetrical in m, n.  Computation below uses m >= n.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif m < n:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm, n = n, m</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmg = m // g</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspng = n // g</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Count the integer lattice paths from (0, 0) to (m, n) which satisfy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# |nx/g - my/g| < h.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Compute matrix A such that:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#  A(x, 0) = A(0, y) = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#  A(x, y) = A(x, y-1) + A(x-1, y), for x,y>=1, except that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#  A(x, y) = 0 if |x/m - y/n|>= h</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Probability is A(m, n)/binom(m+n, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Optimizations exist for m==n, m==n*p.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Only need to preserve a single column of A, and only a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# sliding window of it.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# minj keeps track of the slide.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspminj, maxj = 0, min(int(np.ceil(h / mg)), n + 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcurlen = maxj - minj</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Make a vector long enough to hold maximum window needed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplenA = min(2 * maxj + 2, n + 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# This is an integer calculation, but the entries are essentially</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# binomial coefficients, hence grow quickly.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Scaling after each column is computed avoids dividing by a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# large binomial coefficient at the end, but is not sufficient to avoid</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the large dyanamic range which appears during the calculation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Instead we rescale based on the magnitude of the right most term in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the column and keep track of an exponent separately and apply</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# it at the end of the calculation.  Similarly when multiplying by</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# the binomial coefficint</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdtype = np.float64</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA = np.zeros(lenA, dtype=dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Initialize the first column</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA[minj:maxj] = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexpnt = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor i in range(1, m + 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Generate the next column.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# First calculate the sliding window</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplastminj, lastlen = minj, curlen</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspminj = max(int(np.floor((ng * i - h) / mg)) + 1, 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspminj = min(minj, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxj = min(int(np.ceil((ng * i + h) / mg)), n + 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif maxj <= minj:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Now fill in the values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA[0:maxj - minj] = np.cumsum(A[minj - lastminj:maxj - lastminj])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcurlen = maxj - minj</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif lastlen > curlen:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Set some carried-over elements to 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA[maxj - minj:maxj - minj + (lastlen - curlen)] = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Rescale if the right most value is over 2**900</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = A[maxj - minj - 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, valexpt = math.frexp(val)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif valexpt > 900:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Scaling to bring down to about 2**800 appears</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sufficient for sizes under 10000.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalexpt -= 800</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA = np.ldexp(A, -valexpt)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpnt += valexpt</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspval = A[maxj - minj - 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Now divide by the binomial (m+n)!/m!/n!</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor i in range(1, n + 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = (val * i) / (m + i)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, valexpt = math.frexp(val)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif valexpt < -128:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = np.ldexp(val, -valexpt)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpnt += valexpt</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Finally scale if needed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.ldexp(val, expnt)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _compute_prob_outside_square(n, h):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the proportion of paths that pass outside the two diagonal lines.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn > 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsph : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0 <= h <= n</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspp : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe proportion of paths that pass outside the lines x-y = +/-h.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Compute Pr(D_{n,n} >= h/n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Prob = 2 * ( binom(2n, n-h) - binom(2n, n-2a) + binom(2n, n-3a) - ... )</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# / binom(2n, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# This formulation exhibits subtractive cancellation.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Instead divide each term by binom(2n, n), then factor common terms</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# and use a Horner-like algorithm</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# P = 2 * A0 * (1 - A1*(1 - A2*(1 - A3*(1 - A4*(...)))))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspP = 0.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspk = int(np.floor(n / h))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhile k >= 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp1 = 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Each of the Ai terms has numerator and denominator with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# h simple terms.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor j in range(h):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp1 = (n - k * h - j) * p1 / (n + k * h + j + 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspP = p1 * (1.0 - P)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk -= 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn 2 * P</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _count_paths_outside_method(m, n, g, h):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Count the number of paths that pass outside the specified diagonal.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(2.0, 0.73575888234288467)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspm : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm > 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn > 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspg : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspg is greatest common divisor of m and n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsph : integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0 <= h <= lcm(m,n)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe calculation of the p-values is done by broadcasting the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspchi-squared statistic with `ddof`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspp : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe number of paths that go low.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculation may overflow - check for a finite answer.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRaises</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFloatingPointError: Raised if the intermediate computation goes outside</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe range of a float.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstatistics, we use ``axis=1``:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCount the integer lattice paths from (0, 0) to (m, n), which at some</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppoint (x, y) along the path, satisfy:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspm*y <= n*x - h*g</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe paths make steps of size +1 in either positive x or positive y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdirections.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> chisquare([16, 18, 16, 14, 12, 12],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp...           axis=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe generally follow Hodges' treatment of Drion/Gnedenko/Korolyuk.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspHodges, J.L. Jr.,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"The Significance Probability of the Smirnov Two-Sample Test,"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArkiv fiur Matematik, 3, No. 43 (1958), 469-86.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda_="pearson")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Compute #paths which stay lower than x/m-y/n = h/lcm(m,n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# B(x, y) = #{paths from (0,0) to (x,y) without</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#             previously crossing the boundary}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp#         = binom(x, y) - #{paths which already reached the boundary}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Multiply by the number of path extensions going from (x, y) to (m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Sum.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Probability is symmetrical in m, n.  Computation below assumes m >= n.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif m < n:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm, n = n, m</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmg = m // g</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspng = n // g</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Not every x needs to be considered.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# xj holds the list of x values to be checked.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Wherever n*x/m + ng*h crosses an integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplxj = n + (mg-h)//mg</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxj = [(h + mg * j + ng-1)//ng for j in range(lxj)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# B is an array just holding a few values of B(x,y), the ones needed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# B[j] == B(x_j, j)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif lxj == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.round(special.binom(m + n, n))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspB = np.zeros(lxj)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspB[0] = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Compute the B(x, y) terms</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The binomial coefficient is an integer, but special.binom()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# may return a float. Round it to the nearest integer.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor j in range(1, lxj):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBj = np.round(special.binom(xj[j] + j, j))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(Bj):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise FloatingPointError()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(j):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbin = np.round(special.binom(xj[j] - xj[i] + j - i, j-i))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBj -= bin * B[i]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspB[j] = Bj</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(Bj):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise FloatingPointError()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Compute the number of path extensions...</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnum_paths = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor j in range(lxj):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbin = np.round(special.binom((m-xj[j]) + (n - j), n-j))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspterm = B[j] * bin</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(term):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise FloatingPointError()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_paths += term</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.round(num_paths)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _attempt_exact_2kssamp(n1, n2, g, d, alternative):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Attempts to compute the exact 2sample probability.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn1, n2 are the sample sizes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspg is the gcd(n1, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd is the computed max difference in ECDFs</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns (success, d, probability)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplcm = (n1 // g) * n2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsph = int(np.round(d * lcm))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd = h * 1.0 / lcm</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif h == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn True, d, 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsaw_fp_error, prob = False, np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif alternative == 'two-sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n1 == n2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = _compute_prob_outside_square(n1, h)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 1 - _compute_prob_inside_method(n1, n2, g, h)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n1 == n2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# prob = binom(2n, n-h) / binom(2n, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Evaluating in that form incurs roundoff errors</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# from special.binom. Instead calculate directly</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspjrange = np.arange(h)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = np.prod((n1 - jrange) / (n1 + jrange + 1.0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum_paths = _count_paths_outside_method(n1, n2, g, h)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbin = special.binom(n1 + n2, n1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(bin) or not np.isfinite(num_paths)\</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor num_paths > bin:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsaw_fp_error = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = num_paths / bin</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept FloatingPointError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsaw_fp_error = True</span>
<br>&nbsp
<br><span style="color:red">- Ks_2sampResult = namedtuple('Ks_2sampResult', ('statistic', 'pvalue'))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif saw_fp_error:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn False, d, np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not (0 <= prob <= 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn False, d, prob</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn True, d, prob</span>
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def ks_2samp(data1, data2):</span>
<br><span style="color:green">+def ks_2samp(data1, data2, alternative='two-sided', mode='auto'):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the Kolmogorov-Smirnov statistic on 2 samples.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPerforms the two-sample Kolmogorov-Smirnov test for goodness of fit.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is a two-sided test for the null hypothesis that 2 independent samples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspare drawn from the same continuous distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis test compares the underlying continuous distributions F(x) and G(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof two independent samples.  See Notes for a description</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the available null and alternative hypotheses.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdata1, data2 : sequence of 1-D ndarrays</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo arrays of sample observations assumed to be drawn from a continuous</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution, sample sizes can be different</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata1, data2 : array_like, 1-Dimensional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo arrays of sample observations assumed to be drawn from a continuous</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution, sample sizes can be different.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the null and alternative hypotheses. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPlease see explanations in the Notes below.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmode : {'auto', 'exact', 'asymp'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the method used for calculating the p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'auto'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'auto' : use 'exact' for small size arrays, 'asymp' for large</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'exact' : use exact distribution of test statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'asymp' : use asymptotic distribution of test statistic</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKS statistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKS statistic.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-tailed p-value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOne-tailed or two-tailed p-value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkstest, ks_1samp, epps_singleton_2samp, anderson_ksamp</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis tests whether 2 samples are drawn from the same distribution. Note</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspthat, like in the case of the one-sample K-S test, the distribution is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspassumed to be continuous.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThere are three options for the null and corresponding alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphypothesis that can be selected using the `alternative` parameter.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `two-sided`: The null hypothesis is that the two distributions are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical, F(x)=G(x) for all x; the alternative is that they are not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `less`: The null hypothesis is that F(x) >= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) < G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `greater`: The null hypothesis is that F(x) <= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) > G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNote that the alternative hypotheses describe the *CDFs* of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunderlying distributions, not the observed values. For example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuppose x1 ~ F and x2 ~ G. If F(x) > G(x) for all x, the values in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx1 tend to be less than those in x2.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf the KS statistic is small or the p-value is high, then we cannot</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreject the null hypothesis in favor of the alternative.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf the mode is 'auto', the computation is exact if the sample sizes are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspless than 10000.  For larger sizes, the computation uses the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKolmogorov-Smirnov distributions to compute an approximate value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe 'two-sided' 'exact' computation computes the complementary probability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand then subtracts from 1.  As such, the minimum probability it can return</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis about 1e-16.  While the algorithm itself is exact, numerical</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsperrors may accumulate for large sample sizes.   It is most suited to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsituations in which one of the sample sizes is only a few thousand.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis is the two-sided test, one-sided tests are not implemented.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe test uses the two-sided asymptotic Kolmogorov-Smirnov distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe generally follow Hodges' treatment of Drion/Gnedenko/Korolyuk [1]_.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf the K-S statistic is small or the p-value is high, then we cannot</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreject the hypothesis that the distributions of the two samples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspare the same.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] Hodges, J.L. Jr.,  "The Significance Probability of the Smirnov</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo-Sample Test," Arkiv fiur Matematik, 3, No. 43 (1958), 469-86.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(12345678)  #fix random seed to get the same result</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> n1 = 200  # size of first sample
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> n2 = 300  # size of second sample
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor a different distribution, we can reject the null hypothesis since the
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue is below 1%:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ks_2samp(rvs1, rvs2)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.20833333333333337, 4.6674975515806989e-005)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.24833333333333332, pvalue=5.846586728086578e-07)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor a slightly different distribution, we cannot reject the null hypothesis
<br>&nbsp &nbsp &nbsp &nbsp &nbspat a 10% or lower alpha since the p-value at 0.144 is higher than 10%
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ks_2samp(rvs1, rvs3)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.10333333333333333, 0.14498781825751686)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.07833333333333334, pvalue=0.4379658456442945)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor an identical distribution, we cannot reject the null hypothesis since
<br>&nbsp &nbsp &nbsp &nbsp &nbspthe p-value is high, 41%:
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0, random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.ks_2samp(rvs1, rvs4)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(0.07999999999999996, 0.41126949729859719)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.12166666666666667, pvalue=0.05401863039081145)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode not in ['auto', 'exact', 'asymp']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Invalid value for mode: {mode}')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative = {'t': 'two-sided', 'g': 'greater', 'l': 'less'}.get(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative.lower()[0], alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative not in ['two-sided', 'less', 'greater']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Invalid value for alternative: {alternative}')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMAX_AUTO_N = 10000  # 'auto' will attempt to be exact if n1,n2 <= MAX_AUTO_N</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.ma.is_masked(data1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata1 = data1.compressed()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.ma.is_masked(data2):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata2 = data2.compressed()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata1 = np.sort(data1)
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata2 = np.sort(data2)
<br>&nbsp &nbsp &nbsp &nbsp &nbspn1 = data1.shape[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbspn2 = data2.shape[0]
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif min(n1, n2) == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Data passed to ks_2samp must not be empty')</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata_all = np.concatenate([data1, data2])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcdf1 = np.searchsorted(data1, data_all, side='right') / (1.0*n1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcdf2 = np.searchsorted(data2, data_all, side='right') / (1.0*n2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspd = np.max(np.absolute(cdf1 - cdf2))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Note: d absolute not signed distance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspen = np.sqrt(n1 * n2 / float(n1 + n2))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexcept:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# using searchsorted solves equal data problem</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdf1 = np.searchsorted(data1, data_all, side='right') / n1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdf2 = np.searchsorted(data2, data_all, side='right') / n2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcddiffs = cdf1 - cdf2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Ensure sign of minS is not negative.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspminS = np.clip(-np.min(cddiffs), 0, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmaxS = np.max(cddiffs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalt2Dvalue = {'less': minS, 'greater': maxS, 'two-sided': max(minS, maxS)}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspd = alt2Dvalue[alternative]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspg = gcd(n1, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn1g = n1 // g</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspn2g = n2 // g</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprob = -np.inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsporiginal_mode = mode</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode == 'auto':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'exact' if max(n1, n2) <= MAX_AUTO_N else 'asymp'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif mode == 'exact':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If lcm(n1, n2) is too big, switch from exact to asymp</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n1g >= np.iinfo(np.int32).max / n2g:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'asymp'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"Exact ks_2samp calculation not possible with samples sizes "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"{n1} and {n2}. Switching to 'asymp'.", RuntimeWarning)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode == 'exact':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuccess, d, prob = _attempt_exact_2kssamp(n1, n2, g, d, alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not success:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'asymp'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif original_mode == 'exact':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(f"ks_2samp: Exact calculation unsuccessful. "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"Switching to mode={mode}.", RuntimeWarning)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif mode == 'asymp':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# The product n1*n2 is large.  Use Smirnov's asymptoptic formula.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Ensure float to avoid overflow in multiplication</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sorted because the one-sided formula is not symmetric in n1, n2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm, n = sorted([float(n1), float(n2)], reverse=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspen = m * n / (m + n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif alternative == 'two-sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = distributions.kstwo.sf(d, np.round(en))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = np.sqrt(en) * d</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use Hodges' suggested approximation Eqn 5.3</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Requires m to be the larger of (n1, n2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpt = -2 * z**2 - 2 * z * (m + 2*n)/np.sqrt(m*n*(m+n))/3.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprob = np.exp(expt)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprob = np.clip(prob, 0, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn KstestResult(d, prob)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _parse_kstest_args(data1, data2, args, N):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# kstest allows many different variations of arguments.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Pull out the parsing into a separate function</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (xvals, yvals, )  # 2sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (xvals, cdf function,..)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (xvals, name of distribution, ...)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# (name of distribution, name of distribution, ...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Returns xvals, yvals, cdf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# where cdf is a cdf function, or None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# and yvals is either an array_like of values, or None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# and xvals is array_like.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprvsfunc, cdf = None, None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(data1, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvsfunc = getattr(distributions, data1).rvs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif callable(data1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvsfunc = data1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(data2, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcdf = getattr(distributions, data2).cdf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata2 = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif callable(data2):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcdf = data2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata2 = None</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata1 = np.sort(rvsfunc(*args, size=N) if rvsfunc else data1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn data1, data2, cdf</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def kstest(rvs, cdf, args=(), N=20, alternative='two-sided', mode='auto'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPerforms the (one-sample or two-sample) Kolmogorov-Smirnov test for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgoodness of fit.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe one-sample test compares the underlying distribution F(x) of a sample</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspagainst a given distribution G(x). The two-sample test compares the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunderlying distributions of two independent samples. Both tests are valid</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsponly for continuous distributions.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprvs : str, array_like, or callable</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf an array, it should be a 1-D array of observations of random</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariables.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a callable, it should be a function to generate random variables;</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit is required to have a keyword argument `size`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a string, it should be the name of a distribution in `scipy.stats`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich will be used to generate random variables.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcdf : str, array_like or callable</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf array_like, it should be a 1-D array of observations of random</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariables, and the two-sample test is performed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(and rvs must be array_like).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a callable, that callable is used to calculate the cdf.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf a string, it should be the name of a distribution in `scipy.stats`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich will be used as the cdf function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspargs : tuple, sequence, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDistribution parameters, used if `rvs` or `cdf` are strings or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallables.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspN : int, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSample size if `rvs` is string or callable.  Default is 20.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the null and alternative hypotheses. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPlease see explanations in the Notes below.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmode : {'auto', 'exact', 'approx', 'asymp'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the distribution used for calculating the p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'auto'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'auto' : selects one of the other options.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'exact' : uses the exact distribution of test statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'approx' : approximates the two-sided probability with twice the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspone-sided probability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'asymp': uses asymptotic distribution of test statistic</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn Ks_2sampResult(d, prob)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKS test statistic, either D, D+ or D-.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue :  float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOne-tailed or two-tailed p-value.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspks_2samp</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThere are three options for the null and corresponding alternative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphypothesis that can be selected using the `alternative` parameter.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `two-sided`: The null hypothesis is that the two distributions are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical, F(x)=G(x) for all x; the alternative is that they are not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspidentical.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `less`: The null hypothesis is that F(x) >= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) < G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp- `greater`: The null hypothesis is that F(x) <= G(x) for all x; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative is that F(x) > G(x) for at least one x.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNote that the alternative hypotheses describe the *CDFs* of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspunderlying distributions, not the observed values. For example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuppose x1 ~ F and x2 ~ G. If F(x) > G(x) for all x, the values in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx1 tend to be less than those in x2.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.linspace(-15, 15, 9)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x, 'norm')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.444356027159..., pvalue=0.038850140086...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.norm.rvs(size=100, random_state=rng), stats.norm.cdf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.165471391799..., pvalue=0.007331283245...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe above lines are equivalent to:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.norm.rvs, 'norm', N=100)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.113810164200..., pvalue=0.138690052319...)  # may vary</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Test against one-sided alternative hypothesis*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspShift distribution to larger values, so that ``CDF(x) < norm.cdf(x)``:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = stats.norm.rvs(loc=0.2, size=100, random_state=rng)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x, 'norm', alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.1002033514..., pvalue=0.1255446444...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReject null hypothesis in favor of alternative hypothesis: less</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x, 'norm', alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.018749806388..., pvalue=0.920581859791...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDon't reject null hypothesis in favor of alternative hypothesis: greater</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(x, 'norm')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.100203351482..., pvalue=0.250616879765...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp*Testing t distributed random variables against normal distribution*</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWith 100 degrees of freedom the t distribution looks close to the normal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution, and the K-S test does not reject the hypothesis that the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample came from the normal distribution:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.t.rvs(100, size=100, random_state=rng), 'norm')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.064273776544..., pvalue=0.778737758305...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWith 3 degrees of freedom the t distribution looks sufficiently different</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom the normal distribution, that we can reject the hypothesis that the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsample came from the normal distribution at the 10% level:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> stats.kstest(stats.t.rvs(3, size=100, random_state=rng), 'norm')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKstestResult(statistic=0.128678487493..., pvalue=0.066569081515...)</span>
<br>&nbsp
<br><span style="color:red">- def tiecorrect(rankvals):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTie correction factor for ties in the Mann-Whitney U and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspKruskal-Wallis H tests.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# to not break compatibility with existing code</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == 'two_sided':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalternative = 'two-sided'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative not in ['two-sided', 'greater', 'less']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Unexpected alternative %s" % alternative)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxvals, yvals, cdf = _parse_kstest_args(rvs, cdf, args, N)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif cdf:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn ks_1samp(xvals, cdf, args=args, alternative=alternative,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode=mode)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn ks_2samp(xvals, yvals, alternative=alternative, mode=mode)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def tiecorrect(rankvals):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Tie correction factor for Mann-Whitney U and Kruskal-Wallis H tests.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsprankvals : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA 1-D sequence of ranks.  Typically this will be the array
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturned by `stats.rankdata`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturned by `~scipy.stats.rankdata`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -4817,105 +7751,12 @@ def tiecorrect(rankvals):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn 1.0 if size < 2 else 1.0 - (cnt**3 - cnt).sum() / (size**3 - size)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- MannwhitneyuResult = namedtuple('MannwhitneyuResult', ('statistic', 'pvalue'))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- def mannwhitneyu(x, y, use_continuity=True, alternative=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the Mann-Whitney rank test on samples x and y.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx, y : array_like</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of samples, should be one-dimensional.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspuse_continuity : bool, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhether a continuity correction (1/2.) should be taken into</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaccount. Default is True.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspalternative : None (deprecated), 'less', 'two-sided', or 'greater'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhether to get the p-value for the one-sided hypothesis ('less'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor 'greater') or for the two-sided hypothesis ('two-sided').</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to None, which results in a p-value half the size of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe 'two-sided' p-value and a different U statistic. The</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault behavior is not the same as using 'less' or 'greater':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit only exists for backward compatibility and is deprecated.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe Mann-Whitney U statistic, equal to min(U for x, U for y) if</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`alternative` is equal to None (deprecated; exists for backward</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompatibility), and U for y otherwise.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppvalue : float</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp-value assuming an asymptotic normal distribution. One-sided or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-sided, depending on the choice of `alternative`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspUse only when the number of observation in each sample is > 20 and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspyou have 2 independent samples of ranks. Mann-Whitney U is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsignificant if the u-obtained is LESS THAN or equal to the critical</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvalue of U.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis test corrects for ties and by default uses a continuity correction.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/Mann-Whitney_U_test</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] H.B. Mann and D.R. Whitney, "On a Test of Whether one of Two Random</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariables is Stochastically Larger than the Other," The Annals of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMathematical Statistics, vol. 18, no. 1, pp. 50-60, 1947.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn("Calling `mannwhitneyu` without specifying "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"`alternative` is deprecated.", DeprecationWarning)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx = np.asarray(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspy = np.asarray(y)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn1 = len(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspn2 = len(y)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspranked = rankdata(np.concatenate((x, y)))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprankx = ranked[0:n1]  # get the x-ranks</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspu1 = n1*n2 + (n1*(n1+1))/2.0 - np.sum(rankx, axis=0)  # calc U for x</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspu2 = n1*n2 - u1  # remainder is U for y</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspT = tiecorrect(ranked)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif T == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('All numbers are identical in mannwhitneyu')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsd = np.sqrt(T * n1 * n2 * (n1+n2+1) / 12.0)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmeanrank = n1*n2/2.0 + 0.5 * use_continuity</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative is None or alternative == 'two-sided':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbigu = max(u1, u2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif alternative == 'less':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbigu = u1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif alternative == 'greater':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbigu = u2</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("alternative should be None, 'less', 'greater' "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"or 'two-sided'")</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspz = (bigu - meanrank) / sd</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This behavior, equal to half the size of the two-sided</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# p-value, is deprecated.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = distributions.norm.sf(abs(z))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif alternative == 'two-sided':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = 2 * distributions.norm.sf(abs(z))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = distributions.norm.sf(z)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspu = u2</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# This behavior is deprecated.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif alternative is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspu = min(u1, u2)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn MannwhitneyuResult(u, p)</span>
<br><span style="color:red">- </span>
<br>&nbspRanksumsResult = namedtuple('RanksumsResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def ranksums(x, y):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the Wilcoxon rank-sum statistic for two samples.</span>
<br><span style="color:green">+@_axis_nan_policy_factory(RanksumsResult, n_samples=2)</span>
<br><span style="color:green">+def ranksums(x, y, alternative='two-sided'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the Wilcoxon rank-sum statistic for two samples.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe Wilcoxon rank-sum test tests the null hypothesis that two sets
<br>&nbsp &nbsp &nbsp &nbsp &nbspof measurements are drawn from the same distribution.  The alternative
<br>@@ -4930,19 +7771,51 @@ def ranksums(x, y):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspx,y : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe data from the two samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe data from the two samples.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis. Default is 'two-sided'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided': one of the distributions (underlying `x` or `y`) is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstochastically greater than the other.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': the distribution underlying `x` is stochastically less</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthan the distribution underlying `y`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': the distribution underlying `x` is stochastically greater</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthan the distribution underlying `y`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.7.0</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe test statistic under the large-sample approximation that the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprank sum statistic is normally distributed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprank sum statistic is normally distributed.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe two-sided p-value of the test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value of the test.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] http://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe can test the hypothesis that two independent unequal-sized samples are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdrawn from the same distribution with computing the Wilcoxon rank-sum</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import ranksums</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> sample1 = rng.uniform(-1, 1, 200)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> sample2 = rng.uniform(-0.5, 1.5, 300) # a shifted distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ranksums(sample1, sample2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRanksumsResult(statistic=-7.887059, pvalue=3.09390448e-15)  # may vary</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ranksums(sample1, sample2, alternative='less')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRanksumsResult(statistic=-7.750585297581713, pvalue=4.573497606342543e-15) # may vary</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ranksums(sample1, sample2, alternative='greater')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRanksumsResult(statistic=-7.750585297581713, pvalue=0.9999999999999954) # may vary</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe p-value of less than ``0.05`` indicates that this test rejects the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphypothesis at the 5% significance level.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspx, y = map(np.asarray, (x, y))
<br>@@ -4954,47 +7827,52 @@ def ranksums(x, y):
<br>&nbsp &nbsp &nbsp &nbsp &nbsps = np.sum(x, axis=0)
<br>&nbsp &nbsp &nbsp &nbsp &nbspexpected = n1 * (n1+n2+1) / 2.0
<br>&nbsp &nbsp &nbsp &nbsp &nbspz = (s - expected) / np.sqrt(n1*n2*(n1+n2+1)/12.0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprob = 2 * distributions.norm.sf(abs(z))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspz, prob = _normtest_finish(z, alternative)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn RanksumsResult(z, prob)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspKruskalResult = namedtuple('KruskalResult', ('statistic', 'pvalue'))
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def kruskal(*args, **kwargs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the Kruskal-Wallis H-test for independent samples</span>
<br><span style="color:green">+@_axis_nan_policy_factory(KruskalResult, n_samples=None)</span>
<br><span style="color:green">+def kruskal(*args, nan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the Kruskal-Wallis H-test for independent samples.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe Kruskal-Wallis H-test tests the null hypothesis that the population
<br>&nbsp &nbsp &nbsp &nbsp &nbspmedian of all of the groups are equal.  It is a non-parametric version of
<br>&nbsp &nbsp &nbsp &nbsp &nbspANOVA.  The test works on 2 or more independent samples, which may have
<br>&nbsp &nbsp &nbsp &nbsp &nbspdifferent sizes.  Note that rejecting the null hypothesis does not
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspindicate which of the groups differs.  Post-hoc comparisons between</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindicate which of the groups differs.  Post hoc comparisons between</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspgroups are required to determine which groups are different.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspsample1, sample2, ... : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTwo or more arrays with the sample measurements can be given as
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparguments.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparguments. Samples must be one-dimensional.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan. 'propagate' returns nan,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'raise' throws an error, 'omit' performs the calculations ignoring nan</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues. Default is 'propagate'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe Kruskal-Wallis H statistic, corrected for ties</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe Kruskal-Wallis H statistic, corrected for ties.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe p-value for the test using the assumption that H has a chi
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsquare distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsquare distribution. The p-value returned is the survival function of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe chi square distribution evaluated at H.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspf_oneway : 1-way ANOVA</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspf_oneway : 1-way ANOVA.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmannwhitneyu : Mann-Whitney rank test on two samples.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfriedmanchisquare : Friedman test for repeated measurements</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfriedmanchisquare : Friedman test for repeated measurements.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -5007,7 +7885,7 @@ def kruskal(*args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] W. H. Kruskal & W. W. Wallis, "Use of Ranks in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOne-Criterion Variance Analysis", Journal of the American Statistical
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAssociation, Vol. 47, Issue 260, pp. 583-621, 1952.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] http://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] https://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -5015,16 +7893,17 @@ def kruskal(*args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [1, 3, 5, 7, 9]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> y = [2, 4, 6, 8, 10]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.kruskal(x, y)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspKruskalResult(statistic=0.27272727272727337, pvalue=0.60150813444058948)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [1, 1, 1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> y = [2, 2, 2]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> z = [2, 2]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.kruskal(x, y, z)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspKruskalResult(statistic=7.0, pvalue=0.030197383422318501)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspKruskalResult(statistic=7.0, pvalue=0.0301973834223185)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspargs = list(map(np.asarray, args))
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspnum_groups = len(args)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif num_groups < 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Need at least two groups in stats.kruskal()")
<br>@@ -5032,16 +7911,13 @@ def kruskal(*args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor arg in args:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif arg.size == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn KruskalResult(np.nan, np.nan)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif arg.ndim != 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Samples must be one-dimensional.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = np.asarray(list(map(len, args)))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif 'nan_policy' in kwargs.keys():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif kwargs['nan_policy'] not in ('propagate', 'raise', 'omit'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("nan_policy must be 'propagate', "</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"'raise' or'omit'")</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = kwargs['nan_policy']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = 'propagate'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nan_policy not in ('propagate', 'raise', 'omit'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("nan_policy must be 'propagate', 'raise' or 'omit'")</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspcontains_nan = False
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor arg in args:
<br>@@ -5068,9 +7944,9 @@ def kruskal(*args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspj = np.insert(np.cumsum(n), 0, 0)
<br>&nbsp &nbsp &nbsp &nbsp &nbspssbn = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor i in range(num_groups):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspssbn += _square_of_sums(ranked[j[i]:j[i+1]]) / float(n[i])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspssbn += _square_of_sums(ranked[j[i]:j[i+1]]) / n[i]</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptotaln = np.sum(n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptotaln = np.sum(n, dtype=float)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsph = 12.0 / (totaln * (totaln + 1)) * ssbn - 3 * (totaln + 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbspdf = num_groups - 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsph /= ties
<br>@@ -5083,8 +7959,7 @@ FriedmanchisquareResult = namedtuple('FriedmanchisquareResult',
<br>&nbsp
<br>&nbsp
<br>&nbspdef friedmanchisquare(*args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the Friedman test for repeated measurements</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the Friedman test for repeated measurements.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe Friedman test tests the null hypothesis that repeated measurements of
<br>&nbsp &nbsp &nbsp &nbsp &nbspthe same individuals have the same distribution.  It is often used
<br>@@ -5102,10 +7977,10 @@ def friedmanchisquare(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe test statistic, correcting for ties</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe test statistic, correcting for ties.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalue : float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe associated p-value assuming that the test statistic has a chi</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsquared distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe associated p-value assuming that the test statistic has a chi</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsquared distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -5115,12 +7990,13 @@ def friedmanchisquare(*args):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] http://en.wikipedia.org/wiki/Friedman_test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/Friedman_test</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspk = len(args)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif k < 3:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Less than 3 levels.  Friedman test not appropriate.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('At least 3 sets of measurements must be given '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'for Friedman test, got {}.'.format(k))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspn = len(args[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor i in range(1, k):
<br>@@ -5135,11 +8011,11 @@ def friedmanchisquare(*args):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Handle ties
<br>&nbsp &nbsp &nbsp &nbsp &nbspties = 0
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor i in range(len(data)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreplist, repnum = find_repeats(array(data[i]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor d in data:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreplist, repnum = find_repeats(array(d))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor t in repnum:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspties += t * (t*t - 1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspc = 1 - ties / float(k*(k*k - 1)*n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspc = 1 - ties / (k*(k*k - 1)*n)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspssbn = np.sum(data.sum(axis=0)**2)
<br>&nbsp &nbsp &nbsp &nbsp &nbspchisq = (12.0 / (k*n*(k+1)) * ssbn - 3*n*(k+1)) / c
<br>@@ -5147,31 +8023,179 @@ def friedmanchisquare(*args):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn FriedmanchisquareResult(chisq, distributions.chi2.sf(chisq, k - 1))
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+BrunnerMunzelResult = namedtuple('BrunnerMunzelResult',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('statistic', 'pvalue'))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def brunnermunzel(x, y, alternative="two-sided", distribution="t",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy='propagate'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Compute the Brunner-Munzel test on samples x and y.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Brunner-Munzel test is a nonparametric test of the null hypothesis that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhen values are taken one by one from each group, the probabilities of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgetting large values in both groups are equal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUnlike the Wilcoxon-Mann-Whitney's U test, this does not require the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspassumption of equivariance of two groups. Note that this does not assume</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe distributions are same. This test works on two independent samples,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhich may have different sizes.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx, y : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of samples, should be one-dimensional.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalternative : {'two-sided', 'less', 'greater'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the alternative hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'two-sided'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'two-sided'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'less': one-sided</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'greater': one-sided</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution : {'t', 'normal'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to get the p-value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 't'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 't': get the p-value by t-distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'normal': get the p-value by standard normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnan_policy : {'propagate', 'raise', 'omit'}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines how to handle when input contains nan.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following options are available (default is 'propagate'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'propagate': returns nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'raise': throws an error</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'omit': performs the calculations ignoring nan values</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe Brunner-Munzer W statistic.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppvalue : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp-value assuming an t distribution. One-sided or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptwo-sided, depending on the choice of `alternative` and `distribution`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmannwhitneyu : Mann-Whitney rank test on two samples.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspBrunner and Munzel recommended to estimate the p-value by t-distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhen the size of data is 50 or less. If the size is lower than 10, it would</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbe better to use permuted Brunner Munzel test (see [2]_).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] Brunner, E. and Munzel, U. "The nonparametric Benhrens-Fisher</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspproblem: Asymptotic theory and a small-sample approximation".</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBiometrical Journal. Vol. 42(2000): 17-25.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] Neubert, K. and Brunner, E. "A studentized permutation test for the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnon-parametric Behrens-Fisher problem". Computational Statistics and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspData Analysis. Vol. 51(2007): 5192-5204.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy import stats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x1 = [1,2,1,1,1,1,1,1,1,1,2,4,1,1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x2 = [3,3,4,3,1,2,3,1,1,5,4]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> w, p_value = stats.brunnermunzel(x1, x2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> w</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp3.1374674823029505</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> p_value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.0057862086661515377</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = np.asarray(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy = np.asarray(y)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# check both x and y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcnx, npx = _contains_nan(x, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcny, npy = _contains_nan(y, nan_policy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcontains_nan = cnx or cny</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif npx == "omit" or npy == "omit":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan_policy = "omit"</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif contains_nan and nan_policy == "propagate":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn BrunnerMunzelResult(np.nan, np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif contains_nan and nan_policy == "omit":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = ma.masked_invalid(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = ma.masked_invalid(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn mstats_basic.brunnermunzel(x, y, alternative, distribution)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnx = len(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspny = len(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif nx == 0 or ny == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn BrunnerMunzelResult(np.nan, np.nan)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankc = rankdata(np.concatenate((x, y)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankcx = rankc[0:nx]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankcy = rankc[nx:nx+ny]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankcx_mean = np.mean(rankcx)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankcy_mean = np.mean(rankcy)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankx = rankdata(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspranky = rankdata(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprankx_mean = np.mean(rankx)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspranky_mean = np.mean(ranky)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSx = np.sum(np.power(rankcx - rankx - rankcx_mean + rankx_mean, 2.0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSx /= nx - 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSy = np.sum(np.power(rankcy - ranky - rankcy_mean + ranky_mean, 2.0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSy /= ny - 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwbfn = nx * ny * (rankcy_mean - rankcx_mean)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwbfn /= (nx + ny) * np.sqrt(nx * Sx + ny * Sy)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif distribution == "t":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf_numer = np.power(nx * Sx + ny * Sy, 2.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf_denom = np.power(nx * Sx, 2.0) / (nx - 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf_denom += np.power(ny * Sy, 2.0) / (ny - 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf = df_numer / df_denom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = distributions.t.cdf(wbfn, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif distribution == "normal":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = distributions.norm.cdf(wbfn)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"distribution should be 't' or 'normal'")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif alternative == "greater":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppass</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == "less":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = 1 - p</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif alternative == "two-sided":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = 2 * np.min([p, 1-p])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"alternative should be 'less', 'greater' or 'two-sided'")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn BrunnerMunzelResult(wbfn, p)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspdef combine_pvalues(pvalues, method='fisher', weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspMethods for combining the p-values of independent tests bearing upon the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsame hypothesis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCombine p-values from independent tests bearing upon the same hypothesis.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalues : array_like, 1-D
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of p-values assumed to come from independent tests.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmethod : {'fisher', 'stouffer'}, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspName of method to use to combine p-values. The following methods are</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspavailable:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "fisher": Fisher's method (Fisher's combined probability test),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe default.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "stouffer": Stouffer's Z-score method.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod : {'fisher', 'pearson', 'tippett', 'stouffer',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'mudholkar_george'}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspName of method to use to combine p-values.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following methods are available (default is 'fisher'):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'fisher': Fisher's method (Fisher's combined probability test), the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsum of the logarithm of the p-values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'pearson': Pearson's method (similar to Fisher's but uses sum of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomplement of the p-values inside the logarithms)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'tippett': Tippett's method (minimum of p-values)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'stouffer': Stouffer's Z-score method</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'mudholkar_george': the difference of Fisher's and Pearson's methods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdivided by 2</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspweights : array_like, 1-D, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOptional array of weights used only for Stouffer's Z-score method.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspstatistic: float
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe statistic calculated by the specified method:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "fisher": The chi-squared statistic</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "stouffer": The Z-score</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe statistic calculated by the specified method.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppval: float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe combined p-value.
<br>&nbsp
<br>@@ -5182,7 +8206,17 @@ def combine_pvalues(pvalues, method='fisher', weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspStouffer's Z-score method [2]_ uses Z-scores rather than p-values. The
<br>&nbsp &nbsp &nbsp &nbsp &nbspadvantage of Stouffer's method is that it is straightforward to introduce
<br>&nbsp &nbsp &nbsp &nbsp &nbspweights, which can make Stouffer's method more powerful than Fisher's
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmethod when the p-values are from studies of different size [3]_ [4]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod when the p-values are from studies of different size [6]_ [7]_.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe Pearson's method uses :math:`log(1-p_i)` inside the sum whereas Fisher's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod uses :math:`log(p_i)` [4]_. For Fisher's and Pearson's method, the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsum of the logarithms is multiplied by -2 in the implementation. This</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspquantity has a chi-square distribution that determines the p-value. The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`mudholkar_george` method is the difference of the Fisher's and Pearson's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptest statistics, each of which include the -2 factor [4]_. However, the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`mudholkar_george` method does not include these -2 factors. The test</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatistic of `mudholkar_george` is the sum of logisitic random variables and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspequation 3.6 in [3]_ is used to approximate the p-value based on Student's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspt-distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspFisher's method may be extended to combine p-values from dependent tests
<br>&nbsp &nbsp &nbsp &nbsp &nbsp[5]_. Extensions such as Brown's method and Kost's method are not currently
<br>@@ -5193,14 +8227,18 @@ def combine_pvalues(pvalues, method='fisher', weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] https://en.wikipedia.org/wiki/Fisher%27s_method
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] http://en.wikipedia.org/wiki/Fisher's_method#Relation_to_Stouffer.27s_Z-score_method</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [3] Whitlock, M. C. "Combining probability from independent tests: the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [3] George, E. O., and G. S. Mudholkar. "On the convolution of logistic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variables." Metrika 30.1 (1983): 1-13.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [4] Heard, N. and Rubin-Delanchey, P. "Choosing between methods of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcombining p-values."  Biometrika 105.1 (2018): 239-246.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [5] Whitlock, M. C. "Combining probability from independent tests: the</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted Z-method is superior to Fisher's approach." Journal of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEvolutionary Biology 18, no. 5 (2005): 1368-1373.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [4] Zaykin, Dmitri V. "Optimally weighted Z-test is a powerful method</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [6] Zaykin, Dmitri V. "Optimally weighted Z-test is a powerful method</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor combining probabilities in meta-analysis." Journal of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEvolutionary Biology 24, no. 8 (2011): 1836-1841.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [5] https://en.wikipedia.org/wiki/Extensions_of_Fisher%27s_method</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [7] https://en.wikipedia.org/wiki/Extensions_of_Fisher%27s_method</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsppvalues = np.asarray(pvalues)
<br>@@ -5208,9 +8246,21 @@ def combine_pvalues(pvalues, method='fisher', weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("pvalues is not 1-D")
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif method == 'fisher':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspXsq = -2 * np.sum(np.log(pvalues))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.chi2.sf(Xsq, 2 * len(pvalues))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (Xsq, pval)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic = -2 * np.sum(np.log(pvalues))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.chi2.sf(statistic, 2 * len(pvalues))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif method == 'pearson':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic = -2 * np.sum(np.log1p(-pvalues))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.chi2.sf(statistic, 2 * len(pvalues))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif method == 'mudholkar_george':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnormalizing_factor = np.sqrt(3/len(pvalues))/np.pi</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic = -np.sum(np.log(pvalues)) + np.sum(np.log1p(-pvalues))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnu = 5 * len(pvalues) + 4</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspapprox_factor = np.sqrt(nu / (nu - 2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.t.sf(statistic * normalizing_factor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* approx_factor, nu)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif method == 'tippett':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic = np.min(pvalues)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.beta.sf(statistic, 1, len(pvalues))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif method == 'stouffer':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif weights is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights = np.ones_like(pvalues)
<br>@@ -5222,29 +8272,22 @@ def combine_pvalues(pvalues, method='fisher', weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("weights is not 1-D")
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspZi = distributions.norm.isf(pvalues)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspZ = np.dot(weights, Zi) / np.linalg.norm(weights)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.norm.sf(Z)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatistic = np.dot(weights, Zi) / np.linalg.norm(weights)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppval = distributions.norm.sf(statistic)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (Z, pval)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"Invalid method '%s'. Options are 'fisher' or 'stouffer'", method)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- #####################################</span>
<br><span style="color:red">- #      PROBABILITY CALCULATIONS     #</span>
<br><span style="color:red">- #####################################</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"Invalid method '%s'. Options are 'fisher', 'pearson', \</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'mudholkar_george', 'tippett', 'or 'stouffer'", method)</span>
<br>&nbsp
<br><span style="color:red">- </span>
<br><span style="color:red">- def _betai(a, b, x):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx = np.asarray(x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx = np.where(x < 1.0, x, 1.0)  # if x > 1 then return 1.0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn special.betainc(a, b, x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn (statistic, pval)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp#####################################
<br>&nbsp#       STATISTICAL DISTANCES       #
<br>&nbsp#####################################
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspr"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspCompute the first Wasserstein distance between two 1D distributions.
<br>@@ -5303,7 +8346,7 @@ def wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] "Wasserstein metric", http://en.wikipedia.org/wiki/Wasserstein_metric</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] "Wasserstein metric", https://en.wikipedia.org/wiki/Wasserstein_metric</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [2] Ramdas, Garcia, Cuturi "On Wasserstein Two Sample Testing and Related
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFamilies of Nonparametric Tests" (2015). :arXiv:`1509.02237`.
<br>&nbsp
<br>@@ -5317,13 +8360,13 @@ def wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> wasserstein_distance([3.4, 3.9, 7.5, 7.8], [4.5, 1.4],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...                      [1.4, 0.9, 3.1, 7.2], [3.2, 3.5])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp4.0781331438047861
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn _cdf_distance(1, u_values, v_values, u_weights, v_weights)
<br>&nbsp
<br>&nbsp
<br>&nbspdef energy_distance(u_values, v_values, u_weights=None, v_weights=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCompute the energy distance between two 1D distributions.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Compute the energy distance between two 1D distributions.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.0.0
<br>&nbsp
<br>@@ -5359,7 +8402,7 @@ def energy_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(resp. :math:`v`).
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspAs shown in [2]_, for one-dimensional real-valued variables, the energy
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdistance is linked to the non-distribution-free version of the Cramer-von</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistance is linked to the non-distribution-free version of the Cramér-von</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspMises distance:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. math::
<br>@@ -5367,7 +8410,7 @@ def energy_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD(u, v) = \sqrt{2} l_2(u, v) = \left( 2 \int_{-\infty}^{+\infty} (U-V)^2
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\right)^{1/2}
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNote that the common Cramer-von Mises criterion uses the distribution-free</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNote that the common Cramér-von Mises criterion uses the distribution-free</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspversion of the distance. See [2]_ (section 2), for more details about both
<br>&nbsp &nbsp &nbsp &nbsp &nbspversions of the distance.
<br>&nbsp
<br>@@ -5398,6 +8441,7 @@ def energy_distance(u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> energy_distance([0.7, 7.4, 2.4, 6.8], [1.4, 8. ],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp...                 [2.1, 4.2, 7.4, 8. ], [7.6, 8.8])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.88003340976158217
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn np.sqrt(2) * _cdf_distance(2, u_values, v_values,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspu_weights, v_weights)
<br>@@ -5445,6 +8489,7 @@ def _cdf_distance(p, u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMunos "The Cramer Distance as a Solution to Biased Wasserstein
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspGradients" (2017). :arXiv:`1705.10743`.
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspu_values, u_weights = _validate_distribution(u_values, u_weights)
<br>&nbsp &nbsp &nbsp &nbsp &nbspv_values, v_weights = _validate_distribution(v_values, v_weights)
<br>@@ -5458,7 +8503,7 @@ def _cdf_distance(p, u_values, v_values, u_weights=None, v_weights=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Compute the differences between pairs of successive values of u and v.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdeltas = np.diff(all_values)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Get the repective positions of the values of u and v among the values of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Get the respective positions of the values of u and v among the values of</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# both distributions.
<br>&nbsp &nbsp &nbsp &nbsp &nbspu_cdf_indices = u_values[u_sorter].searchsorted(all_values[:-1], 'right')
<br>&nbsp &nbsp &nbsp &nbsp &nbspv_cdf_indices = v_values[v_sorter].searchsorted(all_values[:-1], 'right')
<br>@@ -5507,6 +8552,7 @@ def _validate_distribution(values, weights):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValues as ndarray.
<br>&nbsp &nbsp &nbsp &nbsp &nbspweights : ndarray
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWeights as ndarray.
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Validate the value array.
<br>&nbsp &nbsp &nbsp &nbsp &nbspvalues = np.asarray(values, dtype=float)
<br>@@ -5539,8 +8585,7 @@ RepeatedResults = namedtuple('RepeatedResults', ('values', 'counts'))
<br>&nbsp
<br>&nbsp
<br>&nbspdef find_repeats(arr):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspFind repeats and repeat counts.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Find repeats and repeat counts.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -5564,10 +8609,10 @@ def find_repeats(arr):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.find_repeats([2, 1, 2, 3, 2, 2, 5])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRepeatedResults(values=array([ 2.]), counts=array([4]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRepeatedResults(values=array([2.]), counts=array([4]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> stats.find_repeats([[10, 20, 1, 2], [5, 5, 4, 4]])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRepeatedResults(values=array([ 4.,  5.]), counts=array([2, 2]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRepeatedResults(values=array([4.,  5.]), counts=array([2, 2]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Note: always copies.
<br>@@ -5575,8 +8620,7 @@ def find_repeats(arr):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _sum_of_squares(a, axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSquare each element of the input array, and return the sum(s) of that.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Square each element of the input array, and return the sum(s) of that.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -5591,18 +8635,18 @@ def _sum_of_squares(a, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsum_of_squares : ndarray
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe sum along the given axis for (a**2).
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_square_of_sums : The square(s) of the sum(s) (the opposite of
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`_sum_of_squares`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`_sum_of_squares`).</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(a*a, axis)
<br>&nbsp
<br>&nbsp
<br>&nbspdef _square_of_sums(a, axis=0):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSum elements of the input array, and return the square(s) of that sum.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Sum elements of the input array, and return the square(s) of that sum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -5617,9 +8661,10 @@ def _square_of_sums(a, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsquare_of_sums : float or ndarray
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe square of the sum over `axis`.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_sum_of_squares : The sum of squares (the opposite of `square_of_sums`).
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa, axis = _chk_asarray(a, axis)
<br>&nbsp &nbsp &nbsp &nbsp &nbsps = np.sum(a, axis)
<br>@@ -5629,9 +8674,12 @@ def _square_of_sums(a, axis=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn float(s) * s
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def rankdata(a, method='average'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspAssign ranks to data, dealing with ties appropriately.</span>
<br><span style="color:green">+def rankdata(a, method='average', *, axis=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Assign ranks to data, dealing with ties appropriately.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspBy default (``axis=None``), the data array is first flattened, and a flat</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray of ranks is returned. Separately reshape the rank array to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape of the data array if desired (see Examples).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspRanks begin at 1.  The `method` argument controls how ranks are assigned
<br>&nbsp &nbsp &nbsp &nbsp &nbspto equal values.  See [1]_ for further discussion of ranking methods.
<br>@@ -5639,39 +8687,36 @@ def rankdata(a, method='average'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbspa : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe array of values to be ranked.  The array is first flattened.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmethod : str, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe array of values to be ranked.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod : {'average', 'min', 'max', 'dense', 'ordinal'}, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe method used to assign ranks to tied elements.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe options are 'average', 'min', 'max', 'dense' and 'ordinal'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe following methods are available (default is 'average'):</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'average':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe average of the ranks that would have been assigned to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'average': The average of the ranks that would have been assigned to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall the tied values is assigned to each value.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'min':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe minimum of the ranks that would have been assigned to all</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'min': The minimum of the ranks that would have been assigned to all</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe tied values is assigned to each value.  (This is also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreferred to as "competition" ranking.)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'max':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe maximum of the ranks that would have been assigned to all</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'max': The maximum of the ranks that would have been assigned to all</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe tied values is assigned to each value.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dense':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLike 'min', but the rank of the next highest element is assigned</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe rank immediately after those assigned to the tied elements.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ordinal':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAll values are given a distinct rank, corresponding to the order</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat the values occur in `a`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe default is 'average'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'dense': Like 'min', but the rank of the next highest element is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassigned the rank immediately after those assigned to the tied</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelements.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* 'ordinal': All values are given a distinct rank, corresponding to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe order that the values occur in `a`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : {None, int}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis along which to perform the ranking. If ``None``, the data array</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis first flattened.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspranks : ndarray
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array of length equal to the size of `a`, containing rank</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array of size equal to the size of `a`, containing rank</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscores.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [1] "Ranking", http://en.wikipedia.org/wiki/Ranking</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] "Ranking", https://en.wikipedia.org/wiki/Ranking</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -5686,10 +8731,28 @@ def rankdata(a, method='average'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsparray([ 1,  2,  3,  2])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> rankdata([0, 2, 3, 2], method='ordinal')
<br>&nbsp &nbsp &nbsp &nbsp &nbsparray([ 1,  2,  4,  3])
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rankdata([[0, 2], [3, 2]]).reshape(2,2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[1. , 2.5],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[4. , 2.5]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rankdata([[0, 2, 2], [3, 2, 5]], axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[1. , 2.5, 2.5],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[2. , 1. , 3. ]])</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif method not in ('average', 'min', 'max', 'dense', 'ordinal'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('unknown method "{0}"'.format(method))
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif axis is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = np.asarray(a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# The return values of `normalize_axis_index` are ignored.  The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# call validates `axis`, even though we won't use it.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# use scipy._lib._util._normalize_axis_index when available</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.core.multiarray.normalize_axis_index(axis, a.ndim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdt = np.float64 if method == 'average' else np.int_</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.empty(a.shape, dtype=dt)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.apply_along_axis(rankdata, axis, a, method)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsparr = np.ravel(np.asarray(a))
<br>&nbsp &nbsp &nbsp &nbsp &nbspalgo = 'mergesort' if method == 'ordinal' else 'quicksort'
<br>&nbsp &nbsp &nbsp &nbsp &nbspsorter = np.argsort(arr, kind=algo)
<br></p>
</div>
<br><br><br>_____________________________________ERROR_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>25308</th>
      <td>test\test_unary_ufuncs.py</td>
      <td>1176</td>
      <td>_i0_helper</td>
      <td>1166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>1172</td>
      <td>scipy.special.i0</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>25317</th>
      <td>test\test_unary_ufuncs.py</td>
      <td>1270</td>
      <td>test_special_ndtr_vs_scipy</td>
      <td>1265</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>1269</td>
      <td>scipy.special.ndtr</td>
      <td>ERROR</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p></p>
</div>
<br><br><br>_____________________________________scipy/stats/_distn_infrastructure.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>27472</th>
      <td>test\distributions\test_distributions.py</td>
      <td>1319</td>
      <td>test_poisson_log_prob</td>
      <td>1312</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>1318</td>
      <td>scipy.stats.poisson.logpmf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27788</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2214</td>
      <td>test_gamma_shape</td>
      <td>2198</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2213</td>
      <td>scipy.stats.gamma.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27798</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2236</td>
      <td>test_gamma_gpu_shape</td>
      <td>2220</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2235</td>
      <td>scipy.stats.gamma.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27810</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2278</td>
      <td>test_pareto</td>
      <td>2260</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2277</td>
      <td>scipy.stats.pareto.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27820</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2307</td>
      <td>test_gumbel</td>
      <td>2291</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2306</td>
      <td>scipy.stats.gumbel_r.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27840</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2374</td>
      <td>test_fishersnedecor</td>
      <td>2356</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2373</td>
      <td>scipy.stats.f.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27847</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2401</td>
      <td>test_chi2_shape</td>
      <td>2387</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2400</td>
      <td>scipy.stats.chi2.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27853</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2431</td>
      <td>test_studentT</td>
      <td>2414</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2430</td>
      <td>scipy.stats.t.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27855</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2453</td>
      <td>test_studentT_log_prob</td>
      <td>2444</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2452</td>
      <td>scipy.stats.t.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
    <tr>
      <th>27875</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2504</td>
      <td>test_beta_log_prob</td>
      <td>2496</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2503</td>
      <td>scipy.stats.beta.logpdf</td>
      <td>scipy/stats/_distn_infrastructure.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/scipy/stats/_distn_infrastructure.py b/scipy/stats/_distn_infrastructure.py
<br>index 0e396b7f4..da3444878 100644
<br><span style="color:red">- -- a/scipy/stats/_distn_infrastructure.py</span>
<br><span style="color:green">+++ b/scipy/stats/_distn_infrastructure.py</span>
<br>@@ -2,25 +2,25 @@
<br>&nbsp# Author:  Travis Oliphant  2002-2011 with contributions from
<br>&nbsp#          SciPy Developers 2004-2011
<br>&nbsp#
<br><span style="color:red">- from __future__ import division, print_function, absolute_import</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- from scipy._lib.six import string_types, exec_, PY3</span>
<br><span style="color:red">- from scipy._lib._util import getargspec_no_self as _getargspec</span>
<br><span style="color:green">+from scipy._lib._util import getfullargspec_no_self as _getfullargspec</span>
<br>&nbsp
<br>&nbspimport sys
<br>&nbspimport keyword
<br>&nbspimport re
<br>&nbspimport types
<br>&nbspimport warnings
<br><span style="color:green">+import inspect</span>
<br><span style="color:green">+from itertools import zip_longest</span>
<br>&nbsp
<br><span style="color:red">- from scipy.misc import doccer</span>
<br><span style="color:green">+from scipy._lib import doccer</span>
<br><span style="color:green">+from scipy._lib._util import _lazywhere</span>
<br>&nbspfrom ._distr_params import distcont, distdiscrete
<br><span style="color:red">- from scipy._lib._util import check_random_state, _lazywhere, _lazyselect</span>
<br><span style="color:red">- from scipy._lib._util import _valarray as valarray</span>
<br><span style="color:green">+from scipy._lib._util import check_random_state</span>
<br>&nbsp
<br><span style="color:red">- from scipy.special import (comb, chndtr, entr, rel_entr, kl_div, xlogy, ive)</span>
<br><span style="color:green">+from scipy.special import (comb, chndtr, entr, xlogy, ive)</span>
<br>&nbsp
<br><span style="color:red">- # for root finding for discrete distribution ppf, and max likelihood estimation</span>
<br><span style="color:green">+# for root finding for continuous distribution ppf, and max likelihood</span>
<br><span style="color:green">+# estimation</span>
<br>&nbspfrom scipy import optimize
<br>&nbsp
<br>&nbsp# for functions of continuous distributions (e.g. moments, entropy, cdf)
<br>@@ -29,23 +29,17 @@ from scipy import integrate
<br>&nbsp# to approximate the pdf of a continuous distribution given its cdf
<br>&nbspfrom scipy.misc import derivative
<br>&nbsp
<br><span style="color:red">- from numpy import (arange, putmask, ravel, take, ones, shape, ndarray,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspproduct, reshape, zeros, floor, logical_and, log, sqrt, exp)</span>
<br><span style="color:green">+# for scipy.stats.entropy. Attempts to import just that function or file</span>
<br><span style="color:green">+# have cause import problems</span>
<br><span style="color:green">+from scipy import stats</span>
<br>&nbsp
<br><span style="color:red">- from numpy import (place, argsort, argmax, vectorize,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspasarray, nan, inf, isinf, NINF, empty)</span>
<br><span style="color:green">+from numpy import (arange, putmask, ravel, ones, shape, ndarray, zeros, floor,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogical_and, log, sqrt, place, argmax, vectorize, asarray,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnan, inf, isinf, NINF, empty)</span>
<br>&nbsp
<br>&nbspimport numpy as np
<br><span style="color:red">- </span>
<br>&nbspfrom ._constants import _XMAX
<br>&nbsp
<br><span style="color:red">- if PY3:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef instancemethod(func, obj, cls):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn types.MethodType(func, obj)</span>
<br><span style="color:red">- else:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinstancemethod = types.MethodType</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br>&nbsp# These are the docstring parts used for substitution in specific
<br>&nbsp# distribution docstrings
<br>&nbsp
<br>@@ -54,92 +48,95 @@ docheaders = {'methods': """\nMethods\n-------\n""",
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'examples': """\nExamples\n--------\n"""}
<br>&nbsp
<br>&nbsp_doc_rvs = """\
<br><span style="color:red">- ``rvs(%(shapes)s, loc=0, scale=1, size=1, random_state=None)``</span>
<br><span style="color:green">+rvs(%(shapes)s, loc=0, scale=1, size=1, random_state=None)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspRandom variates.
<br>&nbsp"""
<br>&nbsp_doc_pdf = """\
<br><span style="color:red">- ``pdf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+pdf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspProbability density function.
<br>&nbsp"""
<br>&nbsp_doc_logpdf = """\
<br><span style="color:red">- ``logpdf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+logpdf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspLog of the probability density function.
<br>&nbsp"""
<br>&nbsp_doc_pmf = """\
<br><span style="color:red">- ``pmf(k, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+pmf(k, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspProbability mass function.
<br>&nbsp"""
<br>&nbsp_doc_logpmf = """\
<br><span style="color:red">- ``logpmf(k, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+logpmf(k, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspLog of the probability mass function.
<br>&nbsp"""
<br>&nbsp_doc_cdf = """\
<br><span style="color:red">- ``cdf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+cdf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspCumulative distribution function.
<br>&nbsp"""
<br>&nbsp_doc_logcdf = """\
<br><span style="color:red">- ``logcdf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+logcdf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspLog of the cumulative distribution function.
<br>&nbsp"""
<br>&nbsp_doc_sf = """\
<br><span style="color:red">- ``sf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+sf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspSurvival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).
<br>&nbsp"""
<br>&nbsp_doc_logsf = """\
<br><span style="color:red">- ``logsf(x, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+logsf(x, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspLog of the survival function.
<br>&nbsp"""
<br>&nbsp_doc_ppf = """\
<br><span style="color:red">- ``ppf(q, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+ppf(q, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspPercent point function (inverse of ``cdf`` --- percentiles).
<br>&nbsp"""
<br>&nbsp_doc_isf = """\
<br><span style="color:red">- ``isf(q, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+isf(q, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspInverse survival function (inverse of ``sf``).
<br>&nbsp"""
<br>&nbsp_doc_moment = """\
<br><span style="color:red">- ``moment(n, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+moment(n, %(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspNon-central moment of order n
<br>&nbsp"""
<br>&nbsp_doc_stats = """\
<br><span style="color:red">- ``stats(%(shapes)s, loc=0, scale=1, moments='mv')``</span>
<br><span style="color:green">+stats(%(shapes)s, loc=0, scale=1, moments='mv')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspMean('m'), variance('v'), skew('s'), and/or kurtosis('k').
<br>&nbsp"""
<br>&nbsp_doc_entropy = """\
<br><span style="color:red">- ``entropy(%(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+entropy(%(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(Differential) entropy of the RV.
<br>&nbsp"""
<br>&nbsp_doc_fit = """\
<br><span style="color:red">- ``fit(data, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+fit(data)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameter estimates for generic data.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee `scipy.stats.rv_continuous.fit <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html#scipy.stats.rv_continuous.fit>`__ for detailed documentation of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkeyword arguments.</span>
<br>&nbsp"""
<br>&nbsp_doc_expect = """\
<br><span style="color:red">- ``expect(func, args=(%(shapes_)s), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)``</span>
<br><span style="color:green">+expect(func, args=(%(shapes_)s), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspExpected value of a function (of one argument) with respect to the distribution.
<br>&nbsp"""
<br>&nbsp_doc_expect_discrete = """\
<br><span style="color:red">- ``expect(func, args=(%(shapes_)s), loc=0, lb=None, ub=None, conditional=False)``</span>
<br><span style="color:green">+expect(func, args=(%(shapes_)s), loc=0, lb=None, ub=None, conditional=False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspExpected value of a function (of one argument) with respect to the distribution.
<br>&nbsp"""
<br>&nbsp_doc_median = """\
<br><span style="color:red">- ``median(%(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+median(%(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspMedian of the distribution.
<br>&nbsp"""
<br>&nbsp_doc_mean = """\
<br><span style="color:red">- ``mean(%(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+mean(%(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspMean of the distribution.
<br>&nbsp"""
<br>&nbsp_doc_var = """\
<br><span style="color:red">- ``var(%(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+var(%(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspVariance of the distribution.
<br>&nbsp"""
<br>&nbsp_doc_std = """\
<br><span style="color:red">- ``std(%(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:green">+std(%(shapes)s, loc=0, scale=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspStandard deviation of the distribution.
<br>&nbsp"""
<br>&nbsp_doc_interval = """\
<br><span style="color:red">- ``interval(alpha, %(shapes)s, loc=0, scale=1)``</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspEndpoints of the range that contains alpha percent of the distribution</span>
<br><span style="color:green">+interval(alpha, %(shapes)s, loc=0, scale=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspEndpoints of the range that contains fraction alpha [0, 1] of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdistribution</span>
<br>&nbsp"""
<br>&nbsp_doc_allmethods = ''.join([docheaders['methods'], _doc_rvs, _doc_pdf,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_doc_logpdf, _doc_cdf, _doc_logcdf, _doc_sf,
<br>@@ -169,7 +166,7 @@ Examples
<br>&nbsp>>> import matplotlib.pyplot as plt
<br>&nbsp>>> fig, ax = plt.subplots(1, 1)
<br>&nbsp
<br><span style="color:red">- Calculate a few first moments:</span>
<br><span style="color:green">+Calculate the first four moments:</span>
<br>&nbsp
<br>&nbsp%(set_vals_stmt)s
<br>&nbsp>>> mean, var, skew, kurt = %(name)s.stats(%(shapes)s, moments='mvsk')
<br>@@ -202,7 +199,7 @@ Generate random numbers:
<br>&nbsp
<br>&nbspAnd compare the histogram:
<br>&nbsp
<br><span style="color:red">- >>> ax.hist(r, normed=True, histtype='stepfilled', alpha=0.2)</span>
<br><span style="color:green">+>>> ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)</span>
<br>&nbsp>>> ax.legend(loc='best', frameon=False)
<br>&nbsp>>> plt.show()
<br>&nbsp
<br>@@ -213,7 +210,9 @@ The probability density above is defined in the "standardized" form. To shift
<br>&nbspand/or scale the distribution use the ``loc`` and ``scale`` parameters.
<br>&nbspSpecifically, ``%(name)s.pdf(x, %(shapes)s, loc, scale)`` is identically
<br>&nbspequivalent to ``%(name)s.pdf(y, %(shapes)s) / scale`` with
<br><span style="color:red">- ``y = (x - loc) / scale``.</span>
<br><span style="color:green">+``y = (x - loc) / scale``. Note that shifting the location of a distribution</span>
<br><span style="color:green">+does not make it a "noncentral" distribution; noncentral generalizations of</span>
<br><span style="color:green">+some distributions are available in separate classes.</span>
<br>&nbsp"""
<br>&nbsp
<br>&nbsp_doc_default = ''.join([_doc_default_longsummary,
<br>@@ -296,7 +295,7 @@ Examples
<br>&nbsp>>> import matplotlib.pyplot as plt
<br>&nbsp>>> fig, ax = plt.subplots(1, 1)
<br>&nbsp
<br><span style="color:red">- Calculate a few first moments:</span>
<br><span style="color:green">+Calculate the first four moments:</span>
<br>&nbsp
<br>&nbsp%(set_vals_stmt)s
<br>&nbsp>>> mean, var, skew, kurt = %(name)s.stats(%(shapes)s, moments='mvsk')
<br>@@ -356,11 +355,6 @@ docdict_discrete['default'] = _doc_default_disc
<br>&nbspfor obj in [s for s in dir() if s.startswith('_doc_')]:
<br>&nbsp &nbsp &nbsp &nbsp &nbspexec('del ' + obj)
<br>&nbspdel obj
<br><span style="color:red">- try:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdel s</span>
<br><span style="color:red">- except NameError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# in Python 3, loop variables are not visible after the loop</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppass</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _moment(data, n, mu=None):
<br>@@ -413,9 +407,7 @@ def _skew(data):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _kurtosis(data):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkurtosis is fourth central moment / variance**2 - 3</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""kurtosis is fourth central moment / variance**2 - 3."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata = np.ravel(data)
<br>&nbsp &nbsp &nbsp &nbsp &nbspmu = data.mean()
<br>&nbsp &nbsp &nbsp &nbsp &nbspm2 = ((data - mu)**2).mean()
<br>@@ -423,8 +415,21 @@ def _kurtosis(data):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn m4 / m2**2 - 3
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+def _fit_determine_optimizer(optimizer):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not callable(optimizer) and isinstance(optimizer, str):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not optimizer.startswith('fmin_'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = "fmin_"+optimizer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif optimizer == 'fmin_':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = 'fmin'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = getattr(optimize, optimizer)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept AttributeError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("%s is not a valid optimizer" % optimizer) from e</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn optimizer</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp# Frozen RV class
<br><span style="color:red">- class rv_frozen(object):</span>
<br><span style="color:green">+class rv_frozen:</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, dist, *args, **kwds):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.args = args
<br>@@ -433,10 +438,8 @@ class rv_frozen(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# create a new instance
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.dist = dist.__class__(**dist._updated_ctor_param())
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# a, b may be set in _argcheck, depending on *args, **kwds. Ouch.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes, _, _ = self.dist._parse_args(*args, **kwds)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.dist._argcheck(*shapes)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.a, self.b = self.dist.a, self.dist.b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.a, self.b = self.dist._get_support(*shapes)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef random_state(self):
<br>@@ -519,34 +522,61 @@ class rv_frozen(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.dist.expect(func, a, loc, scale, lb, ub,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconditional, **kwds)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef support(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.dist.support(*self.args, **self.kwds)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br><span style="color:red">- # This should be rewritten</span>
<br>&nbspdef argsreduce(cond, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Return the sequence of ravel(args[i]) where ravel(condition) is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspTrue in 1D.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Clean arguments to:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp1. Ensure all arguments are iterable (arrays of dimension at least one</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2. If cond != True and size > 1, ravel(args[i]) where ravel(condition) is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTrue, in 1D.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturn list of processed arguments.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> import numpy as np</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> rand = np.random.random_sample</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> A = rand((4, 5))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> A = rng.random((4, 5))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> B = 2
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> C = rand((1, 5))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> C = rng.random((1, 5))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> cond = np.ones(A.shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> [A1, B1, C1] = argsreduce(cond, A, B, C)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> A1.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(4, 5)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> B1.shape
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(20,)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(1,)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> C1.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(1, 5)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> cond[2,:] = 0
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> [A2, B2, C2] = argsreduce(cond, A, B, C)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> B2.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> [A1, B1, C1] = argsreduce(cond, A, B, C)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> A1.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(15,)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> B1.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(1,)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> C1.shape</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(15,)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# some distributions assume arguments are iterable.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspnewargs = np.atleast_1d(*args)
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# np.atleast_1d returns an array if only one argument, or a list of arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# if more than one argument.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(newargs, list):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnewargs = [newargs, ]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexpand_arr = (cond == cond)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn [np.extract(cond, arr1 * expand_arr) for arr1 in newargs]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.all(cond):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Nothing to do</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn newargs</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsps = cond.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# np.extract returns flattened arrays, which are not broadcastable together</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# unless they are either the same size or size == 1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn [(arg if np.size(arg) == 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse np.extract(cond, np.broadcast_to(arg, s)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor arg in newargs]</span>
<br>&nbsp
<br>&nbsp
<br>&nbspparse_arg_template = """
<br>@@ -562,50 +592,78 @@ def _parse_args_stats(self, %(shape_arg_str)s %(locscale_in)s, moments='mv'):
<br>&nbsp
<br>&nbsp
<br>&nbsp# Both the continuous and discrete distributions depend on ncx2.
<br><span style="color:red">- # I think the function name ncx2 is an abbreviation for noncentral chi squared.</span>
<br><span style="color:green">+# The function name ncx2 is an abbreviation for noncentral chi squared.</span>
<br>&nbsp
<br>&nbspdef _ncx2_log_pdf(x, df, nc):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# We use (xs**2 + ns**2)/2 = (xs - ns)**2/2  + xs*ns, and include the factor</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# of exp(-xs*ns) into the ive function to improve numerical stability</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# at large values of xs. See also `rice.pdf`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We use (xs**2 + ns**2)/2 = (xs - ns)**2/2  + xs*ns, and include the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# factor of exp(-xs*ns) into the ive function to improve numerical</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# stability at large values of xs. See also `rice.pdf`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdf2 = df/2.0 - 1.0
<br>&nbsp &nbsp &nbsp &nbsp &nbspxs, ns = np.sqrt(x), np.sqrt(nc)
<br>&nbsp &nbsp &nbsp &nbsp &nbspres = xlogy(df2/2.0, x/nc) - 0.5*(xs - ns)**2
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspres += np.log(ive(df2, xs*ns) / 2.0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn res</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorr = ive(df2, xs*ns) / 2.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Return res + np.log(corr) avoiding np.log(0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn _lazywhere(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcorr > 0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(res, corr),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf=lambda r, c: r + np.log(c),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfillvalue=-np.inf)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _ncx2_pdf(x, df, nc):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn np.exp(_ncx2_log_pdf(x, df, nc))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Copy of _ncx2_log_pdf avoiding np.log(0) when corr = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdf2 = df/2.0 - 1.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxs, ns = np.sqrt(x), np.sqrt(nc)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspres = xlogy(df2/2.0, x/nc) - 0.5*(xs - ns)**2</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorr = ive(df2, xs*ns) / 2.0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.exp(res) * corr</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _ncx2_cdf(x, df, nc):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn chndtr(x, df, nc)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class rv_generic(object):</span>
<br><span style="color:green">+class rv_generic:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Class which encapsulates common functionality between rv_discrete
<br>&nbsp &nbsp &nbsp &nbsp &nbspand rv_continuous.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(rv_generic, self).__init__()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# figure out if _stats signature has 'moments' keyword
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsign = _getargspec(self._stats)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._stats_has_moments = ((sign[2] is not None) or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('moments' in sign[0]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsig = _getfullargspec(self._stats)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._stats_has_moments = ((sig.varkw is not None) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('moments' in sig.args) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('moments' in sig.kwonlyargs))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = check_random_state(seed)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# For historical reasons, `size` was made an attribute that was read</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# inside _rvs().  The code is being changed so that 'size'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# is an argument</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# to self._rvs(). However some external (non-SciPy) distributions</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# have not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# been updated.  Maintain backwards compatibility by checking if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the self._rvs() signature has the 'size' keyword, or a **kwarg,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# and if not set self._size inside self.rvs()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# before calling self._rvs().</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargspec = inspect.getfullargspec(self._rvs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._rvs_uses_size_attribute = (argspec.varkw is None and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'size' not in argspec.args and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'size' not in argspec.kwonlyargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Warn on first use only</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._rvs_size_warned = False</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef random_state(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp""" Get or set the RandomState object for generating random variates.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis can be either None or an existing RandomState object.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Get or set the generator object for generating random variates.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), use the RandomState singleton used by np.random.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf already a RandomState instance, use it.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf an int, use a new RandomState instance seeded with seed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._random_state
<br>@@ -614,22 +672,53 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef random_state(self, seed):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = check_random_state(seed)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef __getstate__(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._updated_ctor_param(), self._random_state</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __setstate__(self, state):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspctor_param, r = state</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__init__(**ctor_param)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = r</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__dict__.update(state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# attaches the dynamically created methods on each instance.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if a subclass overrides rv_generic.__setstate__, or implements</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# it's own _attach_methods, then it must make sure that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# _attach_argparser_methods is called.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_methods()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept ValueError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# reconstitute an old pickle scipy<1.6, that contains</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# (_ctor_param, random_state) as state</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ctor_param = state[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = state[1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__init__()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _attach_methods(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Attaches dynamically created methods to the rv_* instance.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis method must be overridden by subclasses, and must itself call</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_attach_argparser_methods. This method is called in __init__ in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubclasses, and in __setstate__</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise NotImplementedError</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _attach_argparser_methods(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspGenerates the argument-parsing functions dynamically and attaches</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthem to the instance.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspShould be called from `_attach_methods`, typically in __init__ and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspduring unpickling (__setstate__)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspns = {}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexec(self._parse_arg_template, ns)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# NB: attach to the instance, not class</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor name in ['_parse_args', '_parse_args_stats', '_parse_args_rvs']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsetattr(self, name, types.MethodType(ns[name], self))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _construct_argparser(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself, meths_to_inspect, locscale_in, locscale_out):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Construct the parser for the shape arguments.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Construct the parser string for the shape arguments.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspGenerates the argument-parsing functions dynamically and attaches</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthem to the instance.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIs supposed to be called in __init__ of a class for each distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis method should be called in __init__ of a class for each</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution. It creates the `_parse_arg_template` attribute that is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen used by `_attach_argparser_methods` to dynamically create and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspattach the `_parse_args`, `_parse_args_stats`, `_parse_args_rvs`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethods to the instance.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf self.shapes is a non-empty string, interprets it as a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomma-separated list of shape parameters.
<br>@@ -641,7 +730,7 @@ class rv_generic(object):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.shapes:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sanitize the user-supplied shapes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(self.shapes, string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(self.shapes, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('shapes must be a string.')
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes = self.shapes.replace(',', ' ').split()
<br>@@ -658,7 +747,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# are shapes.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes_list = []
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor meth in meths_to_inspect:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes_args = _getargspec(meth)   # NB: does not contain self</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes_args = _getfullargspec(meth)  # NB does not contain self</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = shapes_args.args[1:]       # peel off 'x', too
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif args:
<br>@@ -668,9 +757,12 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shapes_args.varargs is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'*args are not allowed w/out explicit shapes')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shapes_args.keywords is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shapes_args.varkw is not None:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'**kwds are not allowed w/out explicit shapes')
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shapes_args.kwonlyargs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kwonly args are not allowed w/out explicit shapes')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shapes_args.defaults is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('defaults are not allowed for shapes')
<br>&nbsp
<br>@@ -690,13 +782,9 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_in=locscale_in,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_out=locscale_out,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspns = {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexec_(parse_arg_template % dct, ns)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# NB: attach to the instance, not class</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor name in ['_parse_args', '_parse_args_stats', '_parse_args_rvs']:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsetattr(self, name,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstancemethod(ns[name], self, self.__class__)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# this string is used by _attach_argparser_methods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._parse_arg_template = parse_arg_template % dct</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shapes = ', '.join(shapes) if shapes else None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not hasattr(self, 'numargs'):
<br>@@ -732,13 +820,18 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.shapes is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# necessary because we use %(shapes)s in two forms (w w/o ", ")
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = self.__doc__.replace("%(shapes)s, ", "")
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, tempdict)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, tempdict)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept TypeError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise Exception("Unable to construct docstring for "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"distribution \"%s\": %s" %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.name, repr(e))) from e</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# correct for empty shapes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = self.__doc__.replace('(, ', '(').replace(', )', ')')
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _construct_default_doc(self, longname=None, extradoc=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdocdict=None, discrete='continuous'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdocdict=None, discrete='continuous'):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Construct instance docstring from the default template."""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif longname is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplongname = 'A'
<br>@@ -778,12 +871,13 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _stats(self, *args, **kwds):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn None, None, None, None
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp#  Central moments</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Noncentral moments (also known as the moment about the origin).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Expressed in LaTeX, munp would be $\mu'_{n}$, i.e. "mu-sub-n-prime".</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The primed mu is a widely used notation for the noncentral moment.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _munp(self, n, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Silence floating point warnings from integration.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspolderr = np.seterr(all='ignore')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = self.generic_moment(n, *args)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.seterr(**olderr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(all='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = self.generic_moment(n, *args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _argcheck_rvs(self, *args, **kwargs):
<br>@@ -849,7 +943,8 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor (bcdim, szdim) in zip(bcast_shape, size_)])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not ok:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("size does not match the broadcast shape of "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"the parameters.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"the parameters. %s, %s, %s" % (size, size_,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbcast_shape))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparam_bcast = all_bcast[:-2]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc_bcast = all_bcast[-2]
<br>@@ -857,9 +952,9 @@ class rv_generic(object):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn param_bcast, loc_bcast, scale_bcast, size_
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## These are the methods you must define (standard form functions)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## NB: generic _pdf, _logpdf, _cdf are different for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## rv_continuous and rv_discrete hence are defined in there</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# These are the methods you must define (standard form functions)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# NB: generic _pdf, _logpdf, _cdf are different for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# rv_continuous and rv_discrete hence are defined in there</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _argcheck(self, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Default check for correct values on args and keywords.
<br>&nbsp
<br>@@ -872,31 +967,59 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = logical_and(cond, (asarray(arg) > 0))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn cond
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _support_mask(self, x):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (self.a <= x) & (x <= self.b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _get_support(self, *args, **kwargs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Return the support of the (unscaled, unshifted) distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp*Must* be overridden by distributions which have support dependent</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupon the shape parameters of the distribution.  Any such override</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp*must not* set or change any of the class members, as these members</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare shared amongst all instances of the distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparg1, arg2, ... : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe shape parameter(s) for the distribution (see docstring of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstance object for more information).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b : numeric (float, or int or +/-np.inf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspend-points of the distribution's support for the specified</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape parameters.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.a, self.b</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _support_mask(self, x, *args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (a <= x) & (x <= b)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _open_support_mask(self, x):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (self.a < x) & (x < self.b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _open_support_mask(self, x, *args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (a < x) & (x < b)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _rvs(self, *args):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This method must handle self._size being a tuple, and it must</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# properly broadcast *args and self._size.  self._size might be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _rvs(self, *args, size=None, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This method must handle size being a tuple, and it must</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# properly broadcast *args and size.  size might be</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# an empty tuple, which means a scalar random variate is to be
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# generated.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp## Use basic inverse cdf algorithm for RV generation as default.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = self._random_state.random_sample(self._size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use basic inverse cdf algorithm for RV generation as default.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = random_state.uniform(size=size)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspY = self._ppf(U, *args)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn Y
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logcdf(self, x, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._cdf(x, *args))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._cdf(x, *args))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _sf(self, x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn 1.0-self._cdf(x, *args)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logsf(self, x, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._sf(x, *args))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._sf(x, *args))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _ppf(self, q, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._ppfvec(q, *args)
<br>@@ -907,8 +1030,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# These are actually called, and should not be overwritten if you
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# want to keep error checking.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom variates of given type.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Random variates of given type.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -921,10 +1043,15 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScale parameter (default=1).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize : int or tuple of ints, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefining number of random variates (default is 1).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : None or int or ``np.random.RandomState`` instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf int or RandomState, use it for drawing the random variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, rely on ``self.random_state``.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -945,13 +1072,24 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# extra gymnastics needed for a custom random_state
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif rndm is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state_saved = self._random_state
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = check_random_state(rndm)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# `size` should just be an argument to _rvs(), but for, um,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# historical reasons, it is made an attribute that is read</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# by _rvs().</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._size = size</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = self._rvs(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = check_random_state(rndm)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._random_state</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Maintain backwards compatibility by setting self._size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# for distributions that still need it.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._rvs_uses_size_attribute:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._rvs_size_warned:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwarnings.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'The signature of {self._rvs} does not contain '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'a "size" keyword.  Such signatures are deprecated.',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.VisibleDeprecationWarning)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._rvs_size_warned = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._size = size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = random_state</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = self._rvs(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = self._rvs(*args, size=size, random_state=random_state)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = vals * scale + loc
<br>&nbsp
<br>@@ -969,8 +1107,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef stats(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSome statistics of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Some statistics of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1001,7 +1138,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = self._argcheck(*args) & (scale > 0) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = []
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault = valarray(shape(cond), self.badvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault = np.full(shape(cond), fill_value=self.badvalue)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use only entries that are valid in calculation
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(cond):
<br>@@ -1034,10 +1171,9 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2p = self._munp(2, *goodargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mu is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu = self._munp(1, *goodargs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2 = mu2p - mu * mu</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(mu):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if mean is inf then var is also inf</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2 = np.inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if mean is inf then var is also inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2 = np.where(np.isfinite(mu), mu2p - mu**2, np.inf)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout0 = default.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(out0, cond, mu2 * scale * scale)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.append(out0)
<br>@@ -1051,7 +1187,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2p = self._munp(2, *goodargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu2 = mu2p - mu * mu
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu3 = mu3p - 3 * mu * mu2 - mu**3</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu3 = (-mu*mu - 3*mu2)*mu + mu3p</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspg1 = mu3 / np.power(mu2, 1.5)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout0 = default.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(out0, cond, g1)
<br>@@ -1068,18 +1204,15 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mu3 is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu3p = self._munp(3, *goodargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu3 = mu3p - 3 * mu * mu2 - mu**3</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu3 = (-mu * mu - 3 * mu2) * mu + mu3p</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(invalid='ignore'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu4 = mu4p - 4 * mu * mu3 - 6 * mu * mu * mu2 - mu**4</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu4 = ((-mu**2 - 6*mu2) * mu - 4*mu3)*mu + mu4p</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspg2 = mu4 / mu2**2.0 - 3.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout0 = default.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(out0, cond, g2)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.append(out0)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:  # no valid args
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = []</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor _ in moments:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout0 = default.copy()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.append(out0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = [default.copy() for _ in moments]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(output) == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output[0]
<br>@@ -1087,8 +1220,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tuple(output)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDifferential entropy of the RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Differential entropy of the RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1111,17 +1243,19 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# NB: for discrete distributions scale=1 by construction in _parse_args
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale = map(asarray, (loc, scale))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond0), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0), self.badvalue)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodargs = argsreduce(cond0, *args)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond0, self.vecentropy(*goodargs) + log(scale))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodargs = argsreduce(cond0, scale, *args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodscale = goodargs[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodargs = goodargs[1:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond0, self.vecentropy(*goodargs) + log(goodscale))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef moment(self, n, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn-th order non-central moment of distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""n-th order non-central moment of distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1136,9 +1270,17 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale parameter (default=1)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not (self._argcheck(*args) and (scale > 0)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes, loc, scale = self._parse_args(*args, **kwds)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = np.broadcast_arrays(*(*shapes, loc, scale))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp*shapes, loc, scale = args</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspi0 = np.logical_and(self._argcheck(*shapes), scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspi1 = np.logical_and(i0, loc == 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspi2 = np.logical_and(i0, loc != 0)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = argsreduce(i0, *shapes, loc, scale)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp*shapes, loc, scale = args</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (floor(n) != n):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Moment must be an integer.")
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (n < 0):
<br>@@ -1149,25 +1291,49 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmdict = {'moments': {1: 'm', 2: 'v', 3: 'vs', 4: 'vk'}[n]}
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmdict = {}
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu, mu2, g1, g2 = self._stats(*args, **mdict)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = _moment_from_stats(n, mu, mu2, g1, g2, self._munp, args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu, mu2, g1, g2 = self._stats(*shapes, **mdict)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = np.empty(loc.shape)  # val needs to be indexed by loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval[...] = _moment_from_stats(n, mu, mu2, g1, g2, self._munp, shapes)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Convert to transformed  X = L + S*Y
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# E[X^n] = E[(L+S*Y)^n] = L^n sum(comb(n, k)*(S/L)^k E[Y^k], k=0...n)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif loc == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn scale**n * val</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = 0</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfac = float(scale) / float(loc)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = zeros(i0.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(result, ~i0, self.badvalue)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif i1.any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres1 = scale[loc == 0]**n * val[loc == 0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(result, i1, res1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif i2.any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmom = [mu, mu2, g1, g2]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrs = [i for i in mom if i is not None]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspidx = [i for i in range(4) if mom[i] is not None]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif any(idx):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrs = argsreduce(loc != 0, *arrs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspj = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in idx:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmom[i] = arrs[j]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspj += 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu, mu2, g1, g2 = mom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = argsreduce(loc != 0, *shapes, loc, scale, val)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp*shapes, loc, scale, val = args</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres2 = zeros(loc.shape, dtype='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfac = scale / loc</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor k in range(n):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalk = _moment_from_stats(k, mu, mu2, g1, g2, self._munp, args)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult += comb(n, k, exact=True)*(fac**k) * valk</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult += fac**n * val</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn result * loc**n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalk = _moment_from_stats(k, mu, mu2, g1, g2, self._munp,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres2 += comb(n, k, exact=True)*fac**k * valk</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres2 += fac**n * val</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres2 *= loc**n</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(result, i2, res2)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif result.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn result.item()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn result</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef median(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMedian of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Median of the distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1186,15 +1352,14 @@ class rv_generic(object):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee Also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstats.distributions.rv_discrete.ppf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprv_discrete.ppf</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInverse of the CDF
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.ppf(0.5, *args, **kwds)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mean(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1219,8 +1384,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn res
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef var(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariance of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1245,8 +1409,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn res
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef std(self, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStandard deviation of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Standard deviation of the distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1269,8 +1432,7 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn res
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef interval(self, alpha, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspConfidence interval with equal areas around the median.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Confidence interval with equal areas around the median.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1301,18 +1463,69 @@ class rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb = self.ppf(q2, *args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn a, b
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef support(self, *args, **kwargs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Support of the distribution.</span>
<br>&nbsp
<br><span style="color:red">- ##  continuous random variables: implement maybe later</span>
<br><span style="color:red">- ##</span>
<br><span style="color:red">- ##  hf  --- Hazard Function (PDF / SF)</span>
<br><span style="color:red">- ##  chf  --- Cumulative hazard function (-log(SF))</span>
<br><span style="color:red">- ##  psf --- Probability sparsity function (reciprocal of the pdf) in</span>
<br><span style="color:red">- ##                units of percent-point-function (as a function of q).</span>
<br><span style="color:red">- ##                Also, the derivative of the percent-point function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparg1, arg2, ... : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe shape parameter(s) for the distribution (see docstring of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstance object for more information).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc : array_like, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocation parameter, Default is 0.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale : array_like, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale parameter, Default is 1.</span>
<br>&nbsp
<br><span style="color:red">- class rv_continuous(rv_generic):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspend-points of the distribution's support.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparrs = np.broadcast_arrays(*args, loc, scale)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = arrs[:-2], arrs[-2], arrs[-1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = self._argcheck(*args) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif cond.all():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _a * scale + loc, _b * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif cond.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.badvalue, self.badvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# promote bounds to at least float to fill in the badvalue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = np.asarray(_a).astype('d'), np.asarray(_b).astype('d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout_a, out_b = _a * scale + loc, _b * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(out_a, 1-cond, self.badvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(out_b, 1-cond, self.badvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out_a, out_b</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _get_fixed_fit_value(kwds, names):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGiven names such as `['f0', 'fa', 'fix_a']`, check that there is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspat most one non-None value in `kwds` associaed with those names.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturn that value, or None if none of the names occur in `kwds`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAs a side effect, all occurrences of those names in `kwds` are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspremoved.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA generic continuous random variable class meant for subclassing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvals = [(name, kwds.pop(name)) for name in names if name in kwds]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif len(vals) > 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprepeated = [name for name, val in vals]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("fit method got multiple keyword arguments to "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"specify the same fixed parameter: " +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp', '.join(repeated))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn vals[0][1] if vals else None</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+#  continuous random variables: implement maybe later</span>
<br><span style="color:green">+#</span>
<br><span style="color:green">+#  hf  --- Hazard Function (PDF / SF)</span>
<br><span style="color:green">+#  chf  --- Cumulative hazard function (-log(SF))</span>
<br><span style="color:green">+#  psf --- Probability sparsity function (reciprocal of the pdf) in</span>
<br><span style="color:green">+#                units of percent-point-function (as a function of q).</span>
<br><span style="color:green">+#                Also, the derivative of the percent-point function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class rv_continuous(rv_generic):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""A generic continuous random variable class meant for subclassing.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`rv_continuous` is a base class to construct specific distribution classes
<br>&nbsp &nbsp &nbsp &nbsp &nbspand instances for continuous random variables. It cannot be used
<br>@@ -1351,12 +1564,15 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis string is used as the last part of the docstring returned when a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubclass has no docstring of its own. Note: `extradoc` exists for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackwards compatibility, do not use for new subclasses.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspseed : None or int or ``numpy.random.RandomState`` instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspMethods
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -1382,13 +1598,14 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspfit
<br>&nbsp &nbsp &nbsp &nbsp &nbspfit_loc_scale
<br>&nbsp &nbsp &nbsp &nbsp &nbspnnlf
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsupport</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbspPublic methods of an instance of a distribution class (e.g., ``pdf``,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp``cdf``) check their arguments and pass valid arguments to private,
<br>&nbsp &nbsp &nbsp &nbsp &nbspcomputational methods (``_pdf``, ``_cdf``). For ``pdf(x)``, ``x`` is valid
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif it is within the support of a distribution, ``self.a <= x <= self.b``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif it is within the support of the distribution.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspWhether a shape parameter is valid is decided by an ``_argcheck`` method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(which defaults to checking that its arguments are strictly positive.)
<br>&nbsp
<br>@@ -1401,12 +1618,29 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspIf positive argument checking is not correct for your RV
<br>&nbsp &nbsp &nbsp &nbsp &nbspthen you will also need to re-define the ``_argcheck`` method.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor most of the scipy.stats distributions, the support interval doesn't</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdepend on the shape parameters. ``x`` being in the support interval is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspequivalent to ``self.a <= x <= self.b``.  If either of the endpoints of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe support do depend on the shape parameters, then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspi) the distribution must implement the ``_get_support`` method; and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspii) those dependent endpoints must be omitted from the distribution's</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcall to the ``rv_continuous`` initializer.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspCorrect, but potentially slow defaults exist for the remaining
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethods but for speed and/or accuracy you can over-ride::
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_logpdf, _cdf, _logcdf, _ppf, _rvs, _isf, _sf, _logsf
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspRarely would you override ``_isf``, ``_sf`` or ``_logsf``, but you could.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe default method ``_rvs`` relies on the inverse of the cdf, ``_ppf``,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspapplied to a uniform random variate. In order to generate random variates</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspefficiently, either the default ``_ppf`` needs to be overwritten (e.g.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif the inverse cdf can expressed in an explicit form) or a sampling</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod needs to be implemented in a custom ``_rvs`` method.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf possible, you should override ``_isf``, ``_sf`` or ``_logsf``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe main reason would be to improve numerical accuracy: for example,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe survival function ``_sf`` is computed as ``1 - _cdf`` which can</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspresult in loss of precision if ``_cdf(x)`` is close to one.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp**Methods that can be overwritten by subclasses**
<br>&nbsp &nbsp &nbsp &nbsp &nbsp::
<br>@@ -1421,6 +1655,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_munp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_entropy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_argcheck
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_get_support</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThere are additional (internal and private) generic methods that can
<br>&nbsp &nbsp &nbsp &nbsp &nbspbe useful for cross-checking and for debugging, but might work in all
<br>@@ -1442,7 +1677,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsplocation, and scale parameters returning a "frozen" continuous RV object:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsprv = generic(<shape(s)>, loc=0, scale=1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrozen RV object with the same methods but holding the given shape,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`rv_frozen` object with the same methods but holding the given shape,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocation, and scale fixed
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp**Statistics**
<br>@@ -1488,7 +1723,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbadvalue=None, name=None, longname=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes=None, extradoc=None, seed=None):
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(rv_continuous, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# save the ctor parameters, cf generic freeze
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ctor_param = dict(
<br>@@ -1511,25 +1746,12 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.xtol = xtol
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moment_type = momtype
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shapes = shapes
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.extradoc = extradoc</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_argparser(meths_to_inspect=[self._pdf, self._cdf],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_in='loc=0, scale=1',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_out='loc, scale')
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# nin correction</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec = vectorize(self._ppf_single, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec.nin = self.numargs + 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.vecentropy = vectorize(self._entropy, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec = vectorize(self._cdf_single, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec.nin = self.numargs + 1</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.extradoc = extradoc</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif momtype == 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = vectorize(self._mom0_sc, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = vectorize(self._mom1_sc, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Because of the *args argument of _mom0_sc, vectorize cannot count the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# number of arguments correctly.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment.nin = self.numargs + 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_methods()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif longname is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif name[0] in ['aeiouAEIOU']:
<br>@@ -1549,11 +1771,43 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = dict(distcont)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_doc(docdict, dct.get(self.name))
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __getstate__(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = self.__dict__.copy()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# these methods will be remade in __setstate__</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# _random_state attribute is taken care of by rv_generic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspattrs = ["_parse_args", "_parse_args_stats", "_parse_args_rvs",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"_cdfvec", "_ppfvec", "vecentropy", "generic_moment"]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[dct.pop(attr, None) for attr in attrs]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dct</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _attach_methods(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAttaches dynamically created methods to the rv_continuous instance.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# _attach_methods is responsible for calling _attach_argparser_methods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_argparser_methods()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# nin correction</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec = vectorize(self._ppf_single, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec.nin = self.numargs + 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.vecentropy = vectorize(self._entropy, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec = vectorize(self._cdf_single, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec.nin = self.numargs + 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.moment_type == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = vectorize(self._mom0_sc, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = vectorize(self._mom1_sc, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Because of the *args argument of _mom0_sc, vectorize cannot count the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# number of arguments correctly.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment.nin = self.numargs + 1</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _updated_ctor_param(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp""" Return the current version of _ctor_param, possibly updated by user.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Return the current version of _ctor_param, possibly updated by user.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUsed by freezing and pickling.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKeep this in sync with the signature of __init__.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUsed by freezing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKeep this in sync with the signature of __init__.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = self._ctor_param.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct['a'] = self.a
<br>@@ -1569,25 +1823,21 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.cdf(*(x, )+args)-q
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _ppf_single(self, q, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = right = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.a > -np.inf:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = self.a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.b < np.inf:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright = self.b</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfactor = 10.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not left:  # i.e. self.a = -inf</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = -1.*factor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft, right = self._get_support(*args)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(left):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = min(-factor, right)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile self._ppf_to_solve(left, q, *args) > 0.:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright = left</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft *= factor</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# left is now such that cdf(left) < q</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not right:  # i.e. self.b = inf</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright = factor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft, right = left * factor, left</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# left is now such that cdf(left) <= q</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if right has changed, then cdf(right) > q</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(right):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright = max(factor, left)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile self._ppf_to_solve(right, q, *args) < 0.:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft = right</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspright *= factor</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# right is now such that cdf(right) > q</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft, right = right, right * factor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# right is now such that cdf(right) >= q</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn optimize.brentq(self._ppf_to_solve,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspleft, right, args=(q,)+args, xtol=self.xtol)
<br>@@ -1597,7 +1847,8 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x**m * self.pdf(x, *args)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mom0_sc(self, m, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn integrate.quad(self._mom_integ0, self.a, self.b,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn integrate.quad(self._mom_integ0, _a, _b,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs=(m,)+args)[0]
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# moment calculated using ppf
<br>@@ -1610,22 +1861,22 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _pdf(self, x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn derivative(self._cdf, x, dx=1e-5, args=args, order=5)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## Could also define any of these</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Could also define any of these</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._pdf(x, *args))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cdf_single(self, x, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn integrate.quad(self._pdf, self.a, x, args=args)[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn integrate.quad(self._pdf, _a, x, args=args)[0]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cdf(self, x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._cdfvec(x, *args)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## generic _argcheck, _logcdf, _sf, _logsf, _ppf, _isf, _rvs are defined</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp## in rv_generic</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# generic _argcheck, _logcdf, _sf, _logsf, _ppf, _isf, _rvs are defined</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# in rv_generic</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, x, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability density function at x of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Probability density function at x of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1651,7 +1902,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._support_mask(x) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._support_mask(x, *args) & (scale > 0)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspputmask(output, (1-cond0)+np.isnan(x), self.badvalue)
<br>@@ -1664,8 +1915,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, x, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the probability density function at x of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the probability density function at x of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis uses a more numerically accurate calculation if available.
<br>&nbsp
<br>@@ -1693,7 +1943,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._support_mask(x) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._support_mask(x, *args) & (scale > 0)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -1731,11 +1981,12 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, loc, scale = map(asarray, (x, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x) & (scale > 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (x >= self.b) & cond0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x, *args) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (x >= np.asarray(_b)) & cond0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0)+np.isnan(x), self.badvalue)
<br>@@ -1748,8 +1999,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logcdf(self, x, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the cumulative distribution function at x of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the cumulative distribution function at x of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1772,11 +2022,12 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, loc, scale = map(asarray, (x, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x) & (scale > 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (x >= self.b) & cond0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x, *args) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (x >= _b) & cond0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -1790,8 +2041,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef sf(self, x, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSurvival function (1 - `cdf`) at x of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Survival function (1 - `cdf`) at x of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1814,11 +2064,12 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, loc, scale = map(asarray, (x, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x) & (scale > 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (x <= self.a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x, *args) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (x <= _a)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0)+np.isnan(x), self.badvalue)
<br>@@ -1831,8 +2082,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logsf(self, x, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the survival function of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the survival function of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns the log of the "survival function," defined as (1 - `cdf`),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspevaluated at `x`.
<br>@@ -1858,11 +2108,12 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, loc, scale = map(asarray, (x, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtyp = np.find_common_type([x.dtype, np.float64], [])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray((x - loc)/scale, dtype=dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x) & (scale > 0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (x <= self.a)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = self._open_support_mask(x, *args) & (scale > 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (x <= _a)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), dtyp)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -1876,8 +2127,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef ppf(self, q, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPercent point function (inverse of `cdf`) at q of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Percent point function (inverse of `cdf`) at q of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1900,15 +2150,16 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq, loc, scale = map(asarray, (q, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (0 < q) & (q < 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (q == 0)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond3 = cond0 & (q == 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = valarray(shape(cond), value=self.badvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = np.full(shape(cond), fill_value=self.badvalue)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower_bound = self.a * scale + loc</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper_bound = self.b * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower_bound = _a * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper_bound = _b * scale + loc</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2, argsreduce(cond2, lower_bound)[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond3, argsreduce(cond3, upper_bound)[0])
<br>&nbsp
<br>@@ -1921,8 +2172,7 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef isf(self, q, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInverse survival function (inverse of `sf`) at q of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Inverse survival function (inverse of `sf`) at q of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1945,15 +2195,16 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, scale = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq, loc, scale = map(asarray, (q, loc, scale))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (0 < q) & (q < 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = cond0 & (q == 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond3 = cond0 & (q == 0)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = valarray(shape(cond), value=self.badvalue)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = np.full(shape(cond), fill_value=self.badvalue)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower_bound = self.a * scale + loc</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper_bound = self.b * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower_bound = _a * scale + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper_bound = _b * scale + loc</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2, argsreduce(cond2, lower_bound)[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond3, argsreduce(cond3, upper_bound)[0])
<br>&nbsp
<br>@@ -1973,29 +2224,29 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = theta[-2]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = theta[-1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(theta[:-2])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept IndexError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Not enough input arguments.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept IndexError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Not enough input arguments.") from e</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn loc, scale, args
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef nnlf(self, theta, x):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'''Return negative loglikelihood function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Negative loglikelihood function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameters (including loc and scale).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'''</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale, args = self._unpack_loc_scale(theta)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._argcheck(*args) or scale <= 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn inf
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = asarray((x-loc) / scale)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_log_scale = len(x) * log(scale)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(~self._support_mask(x)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(~self._support_mask(x, *args)):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn inf
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._nnlf(x, *args) + n_log_scale
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _nnlf_and_penalty(self, x, args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = ~self._support_mask(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = ~self._support_mask(x, *args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_bad = np.count_nonzero(cond0, axis=0)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n_bad > 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = argsreduce(~cond0, x)[0]
<br>@@ -2008,10 +2259,11 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn -np.sum(logpdf, axis=0)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _penalized_nnlf(self, theta, x):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp''' Return penalized negative loglikelihood function,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Penalized negative loglikelihood function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspi.e., - sum (log pdf(x, theta), axis=0) + penalty
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhere theta are the parameters (including loc and scale)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'''</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhere theta are the parameters (including loc and scale)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale, args = self._unpack_loc_scale(theta)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._argcheck(*args) or scale <= 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn inf
<br>@@ -2019,29 +2271,31 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_log_scale = len(x) * log(scale)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._nnlf_and_penalty(x, args) + n_log_scale
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# return starting point for fit (shape arguments + loc + scale)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _fitstart(self, data, args=None):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Starting point for fit (shape arguments + loc + scale)."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif args is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = (1.0,)*self.numargs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale = self._fit_loc_scale_support(data, *args)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn args + (loc, scale)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Return the (possibly reduced) function to optimize in order to find MLE</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp#  estimates for the .fit method</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _reduce_func(self, args, kwds):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# First of all, convert fshapes params to fnum: eg for stats.beta,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# shapes='a, b'. To fix `a`, can specify either `f1` or `fa`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Convert the latter into the former.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _reduce_func(self, args, kwds, data=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn the (possibly reduced) function to optimize in order to find MLE</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspestimates for the .fit method.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Convert fixed shape parameters to the standard numeric form: e.g. for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# stats.beta, shapes='a, b'. To fix `a`, the caller can give a value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# for `f0`, `fa` or 'fix_a'.  The following converts the latter two</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# into the first (numeric) form.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes = []</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.shapes:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes = self.shapes.replace(',', ' ').split()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor j, s in enumerate(shapes):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = kwds.pop('f' + s, None) or kwds.pop('fix_' + s, None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkey = 'f' + str(j)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnames = [key, 'f' + s, 'fix_' + s]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval = _get_fixed_fit_value(kwds, names)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif val is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkey = 'f%d' % j</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif key in kwds:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Duplicate entry for %s." % key)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwds[key] = val</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwds[key] = val</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = list(args)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNargs = len(args)
<br>@@ -2055,8 +2309,23 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0.append(args[n])
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethods = {"mle", "mm"}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod = kwds.pop('method', "mle").lower()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif method == "mm":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_params = len(shapes) + 2 - len(fixedn)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexponents = (np.arange(1, n_params+1))[:, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_moments = np.sum(data[None, :]**exponents/len(data), axis=1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef objective(theta, x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._moment_error(theta, x, data_moments)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif method == "mle":</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobjective = self._penalized_nnlf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Method '{0}' not available; must be one of {1}"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.format(method, methods))</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(fixedn) == 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunc = self._penalized_nnlf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunc = objective</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprestore = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(fixedn) == Nargs:
<br>@@ -2076,16 +2345,33 @@ class rv_continuous(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef func(theta, x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnewtheta = restore(args[:], theta)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._penalized_nnlf(newtheta, x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn objective(newtheta, x)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x0, func, restore, args
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _moment_error(self, theta, x, data_moments):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale, args = self._unpack_loc_scale(theta)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._argcheck(*args) or scale <= 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn inf</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdist_moments = np.array([self.moment(i+1, *args, loc=loc, scale=scale)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(len(data_moments))])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(np.isnan(dist_moments)):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Method of moments encountered a non-finite "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"distribution moment and cannot continue. "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"Consider trying method='MLE'.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (((data_moments - dist_moments) /</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.maximum(np.abs(data_moments), 1e-8))**2).sum()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef fit(self, data, *args, **kwds):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn MLEs for shape (if applicable), location, and scale</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameters from data.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn estimates of shape (if applicable), location, and scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameters from data. The default estimation method is Maximum</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLikelihood Estimation (MLE), but Method of Moments (MM)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis also available.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMLE stands for Maximum Likelihood Estimate.  Starting estimates for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStarting estimates for</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe fit are given by input arguments; for any arguments not provided
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith starting estimates, ``self._fitstart(data)`` is called to generate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuch.
<br>@@ -2098,19 +2384,21 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata : array_like
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspData to use in calculating the MLEs.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs : floats, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspData to use in estimating the distribution parameters.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparg1, arg2, arg3,... : floats, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStarting value(s) for any shape-characterizing arguments (those not
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprovided will be determined by a call to ``_fitstart(data)``).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNo default value.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwds : floats, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStarting values for the location and scale parameters; no default.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `loc`: initial guess of the distribution's location parameter.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `scale`: initial guess of the distribution's scale parameter.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecial keyword arguments are recognized as holding certain
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameters fixed:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- f0...fn : hold respective shape parameters fixed.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAlternatively, shape parameters to fix can be specified by name.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor example, if ``self.shapes == "a, b"``, ``fa``and ``fix_a``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor example, if ``self.shapes == "a, b"``, ``fa`` and ``fix_a``</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare equivalent to ``f0``, and ``fb`` and ``fix_b`` are
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspequivalent to ``f1``.
<br>&nbsp
<br>@@ -2118,26 +2406,54 @@ class rv_continuous(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- fscale : hold scale parameter fixed to specified value.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- optimizer : The optimizer to use.  The optimizer must take ``func``,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- optimizer : The optimizer to use.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe optimizer must take ``func``,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand starting position as the first two arguments,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplus ``args`` (for extra arguments to pass to the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction to be optimized) and ``disp=0`` to suppress
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput as keyword arguments.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- method : The method to use. The default is "MLE" (Maximum</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLikelihood Estimate); "MM" (Method of Moments)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis also available.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmle_tuple : tuple of floats</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMLEs for any shape parameters (if applicable), followed by those</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor location and scale. For most random variables, shape statistics</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameter_tuple : tuple of floats</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEstimates for any shape parameters (if applicable),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfollowed by those for location and scale.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor most random variables, shape statistics</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be returned, but there are exceptions (e.g. ``norm``).
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis fit is computed by maximizing a log-likelihood function, with</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppenalty applied for samples outside of range of the distribution. The</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturned answer is not guaranteed to be the globally optimal MLE, it</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWith ``method="MLE"`` (default), the fit is computed by minimizing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe negative log-likelihood function. A large, finite penalty</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(rather than infinite negative log-likelihood) is applied for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobservations beyond the support of the distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWith ``method="MM"``, the fit is computed by minimizing the L2 norm</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the relative errors between the first *k* raw (about zero) data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoments and the corresponding distribution moments, where *k* is the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumber of non-fixed parameters.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMore precisely, the objective function is::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(((data_moments - dist_moments)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp/ np.maximum(np.abs(data_moments), 1e-8))**2).sum()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhere the constant ``1e-8`` avoids division by zero in case of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvanishing data moments. Typically, this error norm can be reduced to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspzero.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that the standard method of moments can produce parameters for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich some data are outside the support of the fitted distribution;</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis implementation does nothing to prevent this.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor either method,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe returned answer is not guaranteed to be globally optimal; it</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmay only be locally optimal, or the optimization may fail altogether.
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf the data contain any of ``np.nan``, ``np.inf``, or ``-np.inf``,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `fit` method will raise a ``RuntimeError``.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -2149,7 +2465,8 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> a, b = 1., 2.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> x = beta.rvs(a, b, size=1000)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNow we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNow we can fit all four parameters (``a``, ``b``, ``loc``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand ``scale``):</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> a1, b1, loc1, scale1 = beta.fit(x)
<br>&nbsp
<br>@@ -2177,10 +2494,17 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> loc1, scale1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(0.92087172783841631, 2.0015750750324668)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata = np.asarray(data)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod = kwds.get('method', "mle").lower()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# memory for method of moments</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNarg = len(args)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif Narg > self.numargs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("Too many input arguments.")
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(data).all():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise RuntimeError("The data contains non-finite values.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstart = [None]*2
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (Narg < self.numargs) or not ('loc' in kwds and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scale' in kwds):
<br>@@ -2190,33 +2514,40 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = kwds.pop('loc', start[-2])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = kwds.pop('scale', start[-1])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs += (loc, scale)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0, func, restore, args = self._reduce_func(args, kwds)</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0, func, restore, args = self._reduce_func(args, kwds, data=data)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = kwds.pop('optimizer', optimize.fmin)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# convert string to function in scipy.optimize
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not callable(optimizer) and isinstance(optimizer, string_types):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not optimizer.startswith('fmin_'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = "fmin_"+optimizer</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif optimizer == 'fmin_':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = 'fmin'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = getattr(optimize, optimizer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept AttributeError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("%s is not a valid optimizer" % optimizer)</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = _fit_determine_optimizer(optimizer)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# by now kwds must be empty, since everybody took what they needed
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif kwds:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("Unknown arguments: %s." % kwds)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In some cases, method of moments can be done with fsolve/root</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# instead of an optimizer, but sometimes no solution exists,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# especially when the user fixes parameters. Minimizing the sum</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# of squares of the error generalizes to these cases.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = optimizer(func, x0, args=(ravel(data),), disp=0)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspobj = func(vals, data)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif restore is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = restore(args, vals)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = tuple(vals)
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, scale, shapes = self._unpack_loc_scale(vals)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not (np.all(self._argcheck(*shapes)) and scale > 0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise Exception("Optimization converged to parameters that are "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"outside the range allowed by the distribution.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif method == 'mm':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isfinite(obj):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise Exception("Optimization failed: either a data moment "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"or fitted distribution moment is "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"non-finite.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _fit_loc_scale_support(self, data, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEstimate loc and scale parameters from data accounting for support.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Estimate loc and scale parameters from data accounting for support.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2241,14 +2572,16 @@ class rv_continuous(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute the support according to the shape parameters.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = self.a, self.b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = _a, _b</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupport_width = b - a
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If the support is empty then return the moment-based estimates.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif support_width <= 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn loc_hat, scale_hat
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute the proposed support according to the loc and scale estimates.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute the proposed support according to the loc and scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# estimates.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_hat = loc_hat + a * scale_hat
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb_hat = loc_hat + b * scale_hat
<br>&nbsp
<br>@@ -2316,36 +2649,44 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn entr(val)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# upper limit is often inf, so suppress warnings when integrating
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspolderr = np.seterr(over='ignore')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = integrate.quad(integ, self.a, self.b)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.seterr(**olderr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(over='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = integrate.quad(integ, _a, _b)[0]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isnan(h):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn h
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# try with different limits if integration problems
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplow, upp = self.ppf([1e-10, 1. - 1e-10], *args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(self.b):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(_b):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper = upp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper = self.b</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(self.a):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper = _b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(_a):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower = low
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower = self.a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower = _a</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn integrate.quad(integ, lower, upper)[0]
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconditional=False, **kwds):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Calculate expected value of a function with respect to the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution by numerical integration.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe expected value of a function ``f(x)`` with respect to a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution ``dist`` is defined as::
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspubound</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspE[x] = Integral(f(x) * dist.pdf(x))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplbound</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspE[f(x)] = Integral(f(x) * dist.pdf(x)),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhere ``ub`` and ``lb`` are arguments and ``x`` has the ``dist.pdf(x)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution. If the bounds ``lb`` and ``ub`` correspond to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupport of the distribution, e.g. ``[-inf, inf]`` in the default</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcase, then the integral is the unrestricted expectation of ``f(x)``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAlso, the function ``f(x)`` may be defined such that ``f(x)`` is ``0``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutside a finite interval in which case the expectation is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcalculated within the finite range ``[lb, ub]``.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2377,12 +2718,38 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe integration behavior of this function is inherited from
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`integrate.quad`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`scipy.integrate.quad`. Neither this function nor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`scipy.integrate.quad` can verify whether the integral exists or is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfinite. For example ``cauchy(0).mean()`` returns ``np.nan`` and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``cauchy(0).expect()`` returns ``0.0``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe function is not vectorized.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTo understand the effect of the bounds of integration consider</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import expon</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.6321205588285578</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis is close to</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> expon(1).cdf(2.0) - expon(1).cdf(0.0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.6321205588285577</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf ``conditional=True``</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0, conditional=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1.0000000000000002</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe slight deviation from 1 is due to numerical integration.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplockwds = {'loc': loc,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scale': scale}
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._argcheck(*args)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif func is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef fun(x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x * self.pdf(x, *args, **lockwds)
<br>@@ -2390,9 +2757,9 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef fun(x, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn func(x) * self.pdf(x, *args, **lockwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif lb is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb = loc + self.a * scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb = loc + _a * scale</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ub is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub = loc + self.b * scale</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub = loc + _b * scale</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif conditional:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinvfac = (self.sf(lb, *args, **lockwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- self.sf(ub, *args, **lockwds))
<br>@@ -2400,9 +2767,8 @@ class rv_continuous(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinvfac = 1.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwds['args'] = args
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Silence floating point warnings from integration.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspolderr = np.seterr(all='ignore')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = integrate.quad(fun, lb, ub, **kwds)[0] / invfac</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.seterr(**olderr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith np.errstate(all='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = integrate.quad(fun, lb, ub, **kwds)[0] / invfac</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn vals
<br>&nbsp
<br>&nbsp
<br>@@ -2411,16 +2777,19 @@ def _drv2_moment(self, n, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Non-central moment of discrete distribution."""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef fun(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.power(x, n) * self._pmf(x, *args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn _expect(fun, self.a, self.b, self.ppf(0.5, *args), self.inc)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn _expect(fun, _a, _b, self.ppf(0.5, *args), self.inc)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _drv2_ppfsingle(self, q, *args):  # Use basic bisection algorithm
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspb = self.b</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspa = self.a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspb = _b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspa = _a</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinf(b):            # Be sure ending point is > q
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb = int(max(100*q, 10))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif b >= self.b:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif b >= _b:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqb = 1.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbreak
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqb = self._cdf(b, *args)
<br>@@ -2433,7 +2802,7 @@ def _drv2_ppfsingle(self, q, *args):  # Use basic bisection algorithm
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinf(a):    # be sure starting point < q
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = int(min(-100*q, -10))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhile 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a <= self.a:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a <= _a:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqb = 0.0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbreak
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqa = self._cdf(a, *args)
<br>@@ -2450,10 +2819,6 @@ def _drv2_ppfsingle(self, q, *args):  # Use basic bisection algorithm
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (qb == q):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn b
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif b <= a+1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# testcase: return wrong number at lower index</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# python -c "from scipy.stats import zipf;print zipf.ppf(0.01, 2)" wrong</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# python -c "from scipy.stats import zipf;print zipf.ppf([0.01, 0.61, 0.77, 0.83], 2)"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# python -c "from scipy.stats import logser;print logser.ppf([0.1, 0.66, 0.86, 0.93], 0.6)"</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif qa > q:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -2476,56 +2841,12 @@ def _drv2_ppfsingle(self, q, *args):  # Use basic bisection algorithm
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn c
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def entropy(pk, qk=None, base=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Calculate the entropy of a distribution for given probability values.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf only probabilities `pk` are given, the entropy is calculated as</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp``S = -sum(pk * log(pk), axis=0)``.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf `qk` is not None, then compute the Kullback-Leibler divergence</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp``S = sum(pk * log(pk / qk), axis=0)``.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis routine will normalize `pk` and `qk` if they don't sum to 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppk : sequence</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefines the (discrete) distribution. ``pk[i]`` is the (possibly</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspunnormalized) probability of event ``i``.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspqk : sequence, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSequence against which the relative entropy is computed. Should be in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe same format as `pk`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase : float, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe logarithmic base to use, defaults to ``e`` (natural logarithm).</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspS : float</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe calculated entropy.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppk = asarray(pk)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppk = 1.0*pk / np.sum(pk, axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif qk is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvec = entr(pk)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqk = asarray(qk)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(qk) != len(pk):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("qk and pk must have same length.")</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspqk = 1.0*qk / np.sum(qk, axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvec = rel_entr(pk, qk)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspS = np.sum(vec, axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif base is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspS /= log(base)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn S</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br>&nbsp# Must over-ride one of _pmf or _cdf or pass in
<br>&nbsp#  x_k, p(x_k) lists in initialization
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass rv_discrete(rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA generic discrete random variable class meant for subclassing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""A generic discrete random variable class meant for subclassing.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`rv_discrete` is a base class to construct specific distribution classes
<br>&nbsp &nbsp &nbsp &nbsp &nbspand instances for discrete random variables. It can also be used
<br>@@ -2541,8 +2862,9 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspmoment_tol : float, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe tolerance for the generic calculation of moments.
<br>&nbsp &nbsp &nbsp &nbsp &nbspvalues : tuple of two array_like, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``(xk, pk)`` where ``xk`` are integers with non-zero</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprobabilities ``pk``  with ``sum(pk) = 1``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``(xk, pk)`` where ``xk`` are integers and ``pk`` are the non-zero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprobabilities between 0 and 1 with ``sum(pk) = 1``. ``xk``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand ``pk`` must have the same shape.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinc : integer, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIncrement for the support of the distribution.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 1. (other values have not been tested)
<br>@@ -2566,12 +2888,15 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis string is used as the last part of the docstring returned when a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubclass has no docstring of its own. Note: `extradoc` exists for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackwards compatibility, do not use for new subclasses.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspseed : None or int or ``numpy.random.RandomState`` instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspMethods
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -2594,11 +2919,10 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspvar
<br>&nbsp &nbsp &nbsp &nbsp &nbspinterval
<br>&nbsp &nbsp &nbsp &nbsp &nbsp__call__
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsupport</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis class is similar to `rv_continuous`. Whether a shape parameter is
<br>&nbsp &nbsp &nbsp &nbsp &nbspvalid is decided by an ``_argcheck`` method (which defaults to checking
<br>&nbsp &nbsp &nbsp &nbsp &nbspthat its arguments are strictly positive.)
<br>@@ -2636,7 +2960,6 @@ class rv_discrete(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspCustom made discrete distribution:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy import stats
<br>@@ -2656,8 +2979,8 @@ class rv_discrete(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __new__(cls, a=0, b=inf, name=None, badvalue=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoment_tol=1e-8, values=None, inc=1, longname=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes=None, extradoc=None, seed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoment_tol=1e-8, values=None, inc=1, longname=None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes=None, extradoc=None, seed=None):</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif values is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# dispatch to a subclass
<br>@@ -2670,7 +2993,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoment_tol=1e-8, values=None, inc=1, longname=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes=None, extradoc=None, seed=None):
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(rv_discrete, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# cf generic freeze
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ctor_param = dict(
<br>@@ -2685,8 +3008,6 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.b = b
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moment_tol = moment_tol
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.inc = inc
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec = vectorize(self._cdf_single, otypes='d')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.vecentropy = vectorize(self._entropy)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shapes = shapes
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif values is not None:
<br>@@ -2696,25 +3017,39 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_in='loc=0',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# scale=1 for discrete RVs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_out='loc, 1')
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_methods()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_docstrings(name, longname, extradoc)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __getstate__(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = self.__dict__.copy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# these methods will be remade in __setstate__</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspattrs = ["_parse_args", "_parse_args_stats", "_parse_args_rvs",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"_cdfvec", "_ppfvec", "generic_moment"]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[dct.pop(attr, None) for attr in attrs]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dct</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _attach_methods(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Attaches dynamically created methods to the rv_discrete instance."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec = vectorize(self._cdf_single, otypes='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.vecentropy = vectorize(self._entropy)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# _attach_methods is responsible for calling _attach_argparser_methods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_argparser_methods()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# nin correction needs to be after we know numargs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# correct nin for generic moment vectorization
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_vec_generic_moment = vectorize(_drv2_moment, otypes='d')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_vec_generic_moment.nin = self.numargs + 2
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = instancemethod(_vec_generic_moment,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself, rv_discrete)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.generic_moment = types.MethodType(_vec_generic_moment, self)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# correct nin for ppf vectorization
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_vppf = vectorize(_drv2_ppfsingle, otypes='d')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_vppf.nin = self.numargs + 2
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec = instancemethod(_vppf,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself, rv_discrete)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._ppfvec = types.MethodType(_vppf, self)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# now that self.numargs is defined, we can adjust nin
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cdfvec.nin = self.numargs + 1
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_docstrings(name, longname, extradoc)</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _construct_docstrings(self, name, longname, extradoc):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif name is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname = 'Distribution'
<br>@@ -2746,10 +3081,10 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'optional\n        scale parameter (default=1)', '')
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _updated_ctor_param(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp""" Return the current version of _ctor_param, possibly updated by user.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Return the current version of _ctor_param, possibly updated by user.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUsed by freezing and pickling.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKeep this in sync with the signature of __init__.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspUsed by freezing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspKeep this in sync with the signature of __init__.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = self._ctor_param.copy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct['a'] = self.a
<br>@@ -2772,7 +3107,8 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn log(self._pmf(k, *args))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cdf_single(self, k, *args):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = arange(int(self.a), k+1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = arange(int(_a), k+1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(self._pmf(m, *args), axis=0)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cdf(self, x, *args):
<br>@@ -2782,8 +3118,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# generic _logcdf, _sf, _logsf, _ppf, _isf, _rvs defined in rv_generic
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, *args, **kwargs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom variates of given type.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Random variates of given type.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2793,12 +3128,17 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc : array_like, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLocation parameter (default=0).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize : int or tuple of ints, optional
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefining number of random variates (Default is 1).  Note that `size`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefining number of random variates (Default is 1). Note that `size`</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphas to be given as keyword, not as positional argument.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : None or int or ``np.random.RandomState`` instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf int or RandomState, use it for drawing the random variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None, rely on ``self.random_state``.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -2807,11 +3147,10 @@ class rv_discrete(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['discrete'] = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn super(rv_discrete, self).rvs(*args, **kwargs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn super().rvs(*args, **kwargs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pmf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability mass function at k of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Probability mass function at k of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2832,9 +3171,10 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray((k-loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k <= self.b) & self._nonzero(k, *args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k <= _b) & self._nonzero(k, *args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0) + np.isnan(k), self.badvalue)
<br>@@ -2846,8 +3186,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpmf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the probability mass function at k of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the probability mass function at k of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2868,9 +3207,10 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray((k-loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k <= self.b) & self._nonzero(k, *args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k <= _b) & self._nonzero(k, *args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -2883,8 +3223,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef cdf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCumulative distribution function of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Cumulative distribution function of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2905,14 +3244,15 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray((k-loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k < self.b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k >= self.b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k < _b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k >= _b)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), 'd')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0) + np.isnan(k), self.badvalue)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2*(cond0 == cond0), 1.0)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0) + np.isnan(k), self.badvalue)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(cond):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodargs = argsreduce(cond, *((k,)+args))
<br>@@ -2922,8 +3262,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logcdf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the cumulative distribution function at k of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the cumulative distribution function at k of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2944,10 +3283,11 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray((k-loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k < self.b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k >= self.b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k < _b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k >= _b)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -2962,8 +3302,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef sf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSurvival function (1 - `cdf`) at k of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Survival function (1 - `cdf`) at k of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2984,10 +3323,11 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray(k-loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k < self.b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k < self.a) & cond0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k < _b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k < _a) & cond0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = zeros(shape(cond), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (1-cond0) + np.isnan(k), self.badvalue)
<br>@@ -3000,8 +3340,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logsf(self, k, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the survival function of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the survival function of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns the log of the "survival function," defined as 1 - `cdf`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspevaluated at `k`.
<br>@@ -3025,10 +3364,11 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk, loc = map(asarray, (k, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk = asarray(k-loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= self.a) & (k < self.b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k < self.a) & cond0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (k >= _a) & (k < _b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (k < _a) & cond0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = empty(shape(cond), 'd')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput.fill(NINF)
<br>@@ -3042,8 +3382,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef ppf(self, q, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPercent point function (inverse of `cdf`) at q of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Percent point function (inverse of `cdf`) at q of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3064,14 +3403,15 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq, loc = map(asarray, (q, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (q > 0) & (q < 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (q == 1) & cond0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = valarray(shape(cond), value=self.badvalue, typecode='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = np.full(shape(cond), fill_value=self.badvalue, dtype='d')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# output type 'd' to handle nin and inf
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (q == 0)*(cond == cond), self.a-1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2, self.b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (q == 0)*(cond == cond), _a-1 + loc)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2, _b + loc)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(cond):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgoodargs = argsreduce(cond, *((q,)+args+(loc,)))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc, goodargs = goodargs[-1], goodargs[:-1]
<br>@@ -3082,8 +3422,7 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef isf(self, q, *args, **kwds):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInverse survival function (inverse of `sf`) at q of the given RV.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Inverse survival function (inverse of `sf`) at q of the given RV.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3104,16 +3443,20 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs, loc, _ = self._parse_args(*args, **kwds)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq, loc = map(asarray, (q, loc))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs = tuple(map(asarray, args))
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond0 = self._argcheck(*args) & (loc == loc)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond1 = (q > 0) & (q < 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond2 = (q == 1) & cond0
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond3 = (q == 0) & cond0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond0 & cond1
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# same problem as with ppf; copied from ppf and changed
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = valarray(shape(cond), value=self.badvalue, typecode='d')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = np.full(shape(cond), fill_value=self.badvalue, dtype='d')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# output type 'd' to handle nin and inf
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, (q == 0)*(cond == cond), self.b)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2, self.a-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplower_bound = _a - 1 + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupper_bound = _b + loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond2*(cond == cond), lower_bound)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplace(output, cond3*(cond == cond), upper_bound)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# call place only if at least 1 valid argument
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(cond):
<br>@@ -3128,16 +3471,17 @@ class rv_discrete(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _entropy(self, *args):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(self, 'pk'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn entropy(self.pk)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn stats.entropy(self.pk)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _expect(lambda x: entr(self.pmf(x, *args)),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.a, self.b, self.ppf(0.5, *args), self.inc)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b, self.ppf(0.5, *args), self.inc)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef expect(self, func=None, args=(), loc=0, lb=None, ub=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconditional=False, maxcount=1000, tolerance=1e-10, chunksize=32):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCalculate expected value of a function with respect to the distribution
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor discrete distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor discrete distribution by numerical summation.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3152,12 +3496,12 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is 0.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb, ub : int, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLower and upper bound for the summation, default is set to the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupport of the distribution, inclusive (``ul <= k <= ub``).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupport of the distribution, inclusive (``lb <= k <= ub``).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconditional : bool, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf true then the expectation is corrected by the conditional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprobability of the summation interval. The return value is the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpectation of the function, `func`, conditional on being in
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe given interval (k such that ``ul <= k <= ub``).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe given interval (k such that ``lb <= k <= ub``).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is False.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxcount : int, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMaximal number of terms to evaluate (to avoid an endless loop for
<br>@@ -3175,12 +3519,14 @@ class rv_discrete(rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor heavy-tailed distributions, the expected value may or may not exist,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepending on the function, `func`. If it does exist, but the sum converges</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor heavy-tailed distributions, the expected value may or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmay not exist,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepending on the function, `func`. If it does exist, but the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsum converges</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspslowly, the accuracy of the result may be rather low. For instance, for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp``zipf(4)``, accuracy for mean, variance in example is only 1e-5.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspincreasing `maxcount` and/or `chunksize` may improve the result, but may also</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmake zipf very slow.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspincreasing `maxcount` and/or `chunksize` may improve the result,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut may also make zipf very slow.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe function is not vectorized.
<br>&nbsp
<br>@@ -3197,13 +3543,13 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# might be problems(?) with correct self.a, self.b at this stage maybe
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# not anymore, seems to work now with _pmf
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._argcheck(*args)  # (re)generate scalar self.a and self.b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_a, _b = self._get_support(*args)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif lb is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb = self.a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb = _a</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplb = lb - loc   # convert bound for standardized distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ub is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub = self.b</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub = _b</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspub = ub - loc   # convert bound for standardized distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif conditional:
<br>@@ -3211,6 +3557,10 @@ class rv_discrete(rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinvfac = 1.0
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self, rv_sample):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres = self._expect(fun, lb, ub)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn res / invfac</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# iterate over the support, starting from the median
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0 = self.ppf(0.5, *args)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspres = _expect(fun, lb, ub, x0, self.inc, maxcount, tolerance, chunksize)
<br>@@ -3220,7 +3570,6 @@ class rv_discrete(rv_generic):
<br>&nbspdef _expect(fun, lb, ub, x0, inc, maxcount=1000, tolerance=1e-10,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspchunksize=32):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Helper for computing the expectation value of `fun`."""
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# short-circuit if the support size is small enough
<br>&nbsp &nbsp &nbsp &nbsp &nbspif (ub - lb) <= chunksize:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupp = np.arange(lb, ub+1, inc)
<br>@@ -3262,7 +3611,8 @@ def _expect(fun, lb, ub, x0, inc, maxcount=1000, tolerance=1e-10,
<br>&nbspdef _iter_chunked(x0, x1, chunksize=4, inc=1):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Iterate from x0 to x1 in chunks of chunksize and steps inc.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx0 must be finite, x1 need not be. In the latter case, the iterator is infinite.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx0 must be finite, x1 need not be. In the latter case, the iterator is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinfinite.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspHandles both x0 < x1 and x0 > x1. In the latter case, iterates downwards
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(make sure to set inc < 0.)
<br>&nbsp
<br>@@ -3296,7 +3646,7 @@ def _iter_chunked(x0, x1, chunksize=4, inc=1):
<br>&nbspclass rv_sample(rv_discrete):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""A 'sample' discrete distribution defined by the support and values.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe ctor ignores most of the arguments, only needs the `values` argument.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe ctor ignores most of the arguments, only needs the `values` argument.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, a=0, b=inf, name=None, badvalue=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoment_tol=1e-8, values=None, inc=1, longname=None,
<br>@@ -3323,8 +3673,10 @@ class rv_sample(rv_discrete):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxk, pk = values
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(xk) != len(pk):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("xk and pk need to have the same length.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.shape(xk) != np.shape(pk):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("xk and pk must have the same shape.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.less(pk, 0.0).any():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All elements of pk must be non-negative.")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.allclose(np.sum(pk), 1):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The sum of provided pk is not 1.")
<br>&nbsp
<br>@@ -3333,16 +3685,50 @@ class rv_sample(rv_discrete):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.pk = np.take(np.ravel(pk), indx, 0)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.a = self.xk[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.b = self.xk[-1]
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.qvals = np.cumsum(self.pk, axis=0)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shapes = ' '   # bypass inspection
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_argparser(meths_to_inspect=[self._pmf],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_in='loc=0',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# scale=1 for discrete RVs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplocscale_out='loc, 1')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_methods()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._construct_docstrings(name, longname, extradoc)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __getstate__(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdct = self.__dict__.copy()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# these methods will be remade in rv_generic.__setstate__,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# which calls rv_generic._attach_methods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspattrs = ["_parse_args", "_parse_args_stats", "_parse_args_rvs"]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[dct.pop(attr, None) for attr in attrs]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dct</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _attach_methods(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Attaches dynamically created argparser methods."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._attach_argparser_methods()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _get_support(self, *args):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Return the support of the (unscaled, unshifted) distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparg1, arg2, ... : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe shape parameter(s) for the distribution (see docstring of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstance object for more information).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b : numeric (float, or int or +/-np.inf)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspend-points of the distribution's support.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.a, self.b</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _pmf(self, x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.select([x == k for k in self.xk],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[np.broadcast_arrays(p, x)[0] for p in self.pk], 0)
<br>@@ -3357,11 +3743,11 @@ class rv_sample(rv_discrete):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindx = argmax(sqq >= qq, axis=-1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.xk[indx]
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _rvs(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _rvs(self, size=None, random_state=None):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Need to define it explicitly, otherwise .rvs() with size=None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# fails due to explicit broadcasting in _ppf
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = self._random_state.random_sample(self._size)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._size is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = random_state.uniform(size=size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size is None:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = np.array(U, ndmin=1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspY = self._ppf(U)[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -3369,16 +3755,59 @@ class rv_sample(rv_discrete):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn Y
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _entropy(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn entropy(self.pk)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn stats.entropy(self.pk)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef generic_moment(self, n):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = asarray(n)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(self.xk**n[np.newaxis, ...] * self.pk, axis=0)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _expect(self, fun, lb, ub, *args, **kwds):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# ignore all args, just do a brute force summation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsupp = self.xk[(lb <= self.xk) & (self.xk <= ub)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvals = fun(supp)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.sum(vals)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br><span style="color:red">- def get_distribution_names(namespace_pairs, rv_base_class):</span>
<br><span style="color:green">+def _check_shape(argshape, size):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCollect names of statistical distributions and their generators.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis is a utility function used by `_rvs()` in the class geninvgauss_gen.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIt compares the tuple argshape to the tuple size.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspargshape : tuple of integers</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspShape of the arguments.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsize : tuple of integers or integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSize argument of rvs().</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe function returns two tuples, scalar_shape and bc.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscalar_shape : tuple</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspShape to which the 1-d array of random variates returned by</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_rvs_scalar() is converted when it is copied into the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput array of _rvs().</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbc : tuple of booleans</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbc is an tuple the same length as size. bc[j] is True if the data</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassociated with that index is generated in one call of _rvs_scalar().</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscalar_shape = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbc = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor argdim, sizedim in zip_longest(argshape[::-1], size[::-1],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfillvalue=1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif sizedim > argdim or (argdim == sizedim == 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscalar_shape.append(sizedim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbc.append(True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbc.append(False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tuple(scalar_shape[::-1]), tuple(bc[::-1])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def get_distribution_names(namespace_pairs, rv_base_class):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Collect names of statistical distributions and their generators.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br></p>
</div>
<br><br><br>_____________________________________scipy/special/_logsumexp.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>27595</th>
      <td>test\distributions\test_distributions.py</td>
      <td>1765</td>
      <td>test_mixture_same_family_log_prob</td>
      <td>1753</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>1764</td>
      <td>scipy.special.logsumexp</td>
      <td>scipy/special/_logsumexp.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/scipy/special/_logsumexp.py b/scipy/special/_logsumexp.py
<br>index e2c299809..50e37f0ed 100644
<br><span style="color:red">- -- a/scipy/special/_logsumexp.py</span>
<br><span style="color:green">+++ b/scipy/special/_logsumexp.py</span>
<br>@@ -1,9 +1,8 @@
<br><span style="color:red">- from __future__ import division, print_function, absolute_import</span>
<br><span style="color:red">- </span>
<br>&nbspimport numpy as np
<br>&nbspfrom scipy._lib._util import _asarray_validated
<br>&nbsp
<br><span style="color:red">- __all__ = ["logsumexp"]</span>
<br><span style="color:green">+__all__ = ["logsumexp", "softmax", "log_softmax"]</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspdef logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the log of the sum of exponentials of input elements.
<br>@@ -35,6 +34,7 @@ def logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspas NaN. Default is False (no sign information).
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 0.16.0
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>&nbsp &nbsp &nbsp &nbsp &nbspres : ndarray
<br>@@ -52,7 +52,7 @@ def logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-----
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspNumpy has a logaddexp function which is very similar to `logsumexp`, but</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNumPy has a logaddexp function which is very similar to `logsumexp`, but</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsponly handles two arguments. `logaddexp.reduce` is similar to this
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunction, but may be less stable.
<br>&nbsp
<br>@@ -91,7 +91,7 @@ def logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspa = _asarray_validated(a, check_finite=False)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif b is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = np.broadcast_arrays(a,b)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa, b = np.broadcast_arrays(a, b)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.any(b == 0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa = a + 0.  # promote to at least float
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa[b == 0] = -np.inf
<br>@@ -125,3 +125,159 @@ def logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out, sgn
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def softmax(x, axis=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSoftmax function</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe softmax function transforms each element of a collection by</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcomputing the exponential of each element divided by the sum of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexponentials of all the elements. That is, if `x` is a one-dimensional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnumpy array::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsoftmax(x) = np.exp(x)/sum(np.exp(x))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int or tuple of ints, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis to compute values along. Default is None and softmax will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomputed over the entire array `x`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsps : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array the same shape as `x`. The result will sum to 1 along the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspecified axis.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe formula for the softmax function :math:`\sigma(x)` for a vector</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`x = \{x_0, x_1, ..., x_{n-1}\}` is</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math:: \sigma(x)_j = \frac{e^{x_j}}{\sum_k e^{x_k}}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe `softmax` function is the gradient of `logsumexp`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.2.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.special import softmax</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> np.set_printoptions(precision=5)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.array([[1, 0.5, 0.2, 3],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [1,  -1,   7, 3],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...               [2,  12,  13, 3]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the softmax transformation over the entire array.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m = softmax(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[  4.48309e-06,   2.71913e-06,   2.01438e-06,   3.31258e-05],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  4.48309e-06,   6.06720e-07,   1.80861e-03,   3.31258e-05],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  1.21863e-05,   2.68421e-01,   7.29644e-01,   3.31258e-05]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m.sum()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp1.0000000000000002</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the softmax transformation along the first axis (i.e., the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcolumns).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m = softmax(x, axis=0)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[  2.11942e-01,   1.01300e-05,   2.75394e-06,   3.33333e-01],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  2.11942e-01,   2.26030e-06,   2.47262e-03,   3.33333e-01],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  5.76117e-01,   9.99988e-01,   9.97525e-01,   3.33333e-01]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m.sum(axis=0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([ 1.,  1.,  1.,  1.])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCompute the softmax transformation along the second axis (i.e., the rows).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m = softmax(x, axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[  1.05877e-01,   6.42177e-02,   4.75736e-02,   7.82332e-01],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  2.42746e-03,   3.28521e-04,   9.79307e-01,   1.79366e-02],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  1.22094e-05,   2.68929e-01,   7.31025e-01,   3.31885e-05]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> m.sum(axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([ 1.,  1.,  1.])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# compute in log space for numerical stability</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn np.exp(x - logsumexp(x, axis=axis, keepdims=True))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def log_softmax(x, axis=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspLogarithm of softmax function::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_softmax(x) = log(softmax(x))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInput array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis : int or tuple of ints, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAxis to compute values along. Default is None and softmax will be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomputed over the entire array `x`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsps : ndarray or scalar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn array with the same shape as `x`. Exponential of the result will</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsum to 1 along the specified axis. If `x` is a scalar, a scalar is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturned.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`log_softmax` is more accurate than ``np.log(softmax(x))`` with inputs that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmake `softmax` saturate (see examples below).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.5.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.special import log_softmax</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.special import softmax</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> np.set_printoptions(precision=5)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = np.array([1000.0, 1.0])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y = log_softmax(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([   0., -999.])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> with np.errstate(divide='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...   y = np.log(softmax(x))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> y</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([  0., -inf])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = _asarray_validated(x, check_finite=False)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx_max = np.amax(x, axis=axis, keepdims=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif x_max.ndim > 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_max[~np.isfinite(x_max)] = 0</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif not np.isfinite(x_max):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_max = 0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptmp = x - x_max</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexp_tmp = np.exp(tmp)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# suppress warnings about log of zero</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith np.errstate(divide='ignore'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsps = np.sum(exp_tmp, axis=axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = np.log(s)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspout = tmp - out</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn out</span>
<br></p>
</div>
<br><br><br>_____________________________________scipy/stats/_multivariate.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>27860</th>
      <td>test\distributions\test_distributions.py</td>
      <td>2472</td>
      <td>test_dirichlet_log_prob</td>
      <td>2464</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2471</td>
      <td>scipy.stats.dirichlet.logpdf</td>
      <td>scipy/stats/_multivariate.py</td>
    </tr>
  </tbody>
</table>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/scipy/stats/_multivariate.py b/scipy/stats/_multivariate.py
<br>index 41dd35830..5bdf66be7 100644
<br><span style="color:red">- -- a/scipy/stats/_multivariate.py</span>
<br><span style="color:green">+++ b/scipy/stats/_multivariate.py</span>
<br>@@ -1,15 +1,16 @@
<br>&nbsp#
<br>&nbsp# Author: Joris Vankerschaver 2013
<br>&nbsp#
<br><span style="color:red">- from __future__ import division, print_function, absolute_import</span>
<br><span style="color:red">- </span>
<br>&nbspimport math
<br>&nbspimport numpy as np
<br><span style="color:green">+from numpy import asarray_chkfinite, asarray</span>
<br>&nbspimport scipy.linalg
<br><span style="color:red">- from scipy.misc import doccer</span>
<br><span style="color:red">- from scipy.special import gammaln, psi, multigammaln, xlogy, entr</span>
<br><span style="color:green">+from scipy._lib import doccer</span>
<br><span style="color:green">+from scipy.special import gammaln, psi, multigammaln, xlogy, entr, betaln</span>
<br>&nbspfrom scipy._lib._util import check_random_state
<br>&nbspfrom scipy.linalg.blas import drot
<br><span style="color:green">+from scipy.linalg.misc import LinAlgError</span>
<br><span style="color:green">+from scipy.linalg.lapack import get_lapack_funcs</span>
<br>&nbsp
<br>&nbspfrom ._discrete_distns import binom
<br>&nbspfrom . import mvn
<br>@@ -23,7 +24,9 @@ __all__ = ['multivariate_normal',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'special_ortho_group',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ortho_group',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'random_correlation',
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'unitary_group']</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'unitary_group',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'multivariate_t',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'multivariate_hypergeom']</span>
<br>&nbsp
<br>&nbsp_LOG_2PI = np.log(2 * np.pi)
<br>&nbsp_LOG_2 = np.log(2)
<br>@@ -31,17 +34,22 @@ _LOG_PI = np.log(np.pi)
<br>&nbsp
<br>&nbsp
<br>&nbsp_doc_random_state = """\
<br><span style="color:red">- random_state : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf int or RandomState, use it for drawing the random variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+random_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp"""
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef _squeeze_output(out):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspRemove single-dimensional entries from array and convert to scalar,
<br>&nbsp &nbsp &nbsp &nbsp &nbspif necessary.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspout = out.squeeze()
<br>&nbsp &nbsp &nbsp &nbsp &nbspif out.ndim == 0:
<br>@@ -50,8 +58,7 @@ def _squeeze_output(out):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _eigvalsh_to_eps(spectrum, cond=None, rcond=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspDetermine which eigenvalues are "small" given the spectrum.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Determine which eigenvalues are "small" given the spectrum.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis is for compatibility across various linear algebra functions
<br>&nbsp &nbsp &nbsp &nbsp &nbspthat should agree about whether or not a Hermitian matrix is numerically
<br>@@ -85,8 +92,7 @@ def _eigvalsh_to_eps(spectrum, cond=None, rcond=None):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _pinv_1d(v, eps=1e-5):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA helper function for computing the pseudoinverse.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""A helper function for computing the pseudoinverse.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -104,7 +110,7 @@ def _pinv_1d(v, eps=1e-5):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([0 if abs(x) <= eps else 1/x for x in v], dtype=float)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class _PSD(object):</span>
<br><span style="color:green">+class _PSD:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspCompute coordinated functions of a symmetric positive semidefinite matrix.
<br>&nbsp
<br>@@ -175,25 +181,25 @@ class _PSD(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._pinv
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class multi_rv_generic(object):</span>
<br><span style="color:green">+class multi_rv_generic:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspClass which encapsulates common functionality between all multivariate
<br>&nbsp &nbsp &nbsp &nbsp &nbspdistributions.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(multi_rv_generic, self).__init__()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = check_random_state(seed)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp@property
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef random_state(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp""" Get or set the RandomState object for generating random variates.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis can be either None or an existing RandomState object.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp""" Get or set the Generator object for generating random variates.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), use the RandomState singleton used by np.random.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf already a RandomState instance, use it.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf an int, use a new RandomState instance seeded with seed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._random_state
<br>@@ -209,7 +215,7 @@ class multi_rv_generic(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._random_state
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class multi_rv_frozen(object):</span>
<br><span style="color:green">+class multi_rv_frozen:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspClass which encapsulates common functionality between all frozen
<br>&nbsp &nbsp &nbsp &nbsp &nbspmultivariate distributions.
<br>@@ -222,6 +228,7 @@ class multi_rv_frozen(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef random_state(self, seed):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist._random_state = check_random_state(seed)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsp_mvn_doc_default_callparams = """\
<br>&nbspmean : array_like, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbspMean of the distribution (default zero)
<br>@@ -256,9 +263,9 @@ mvn_docdict_noparams = {
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state
<br>&nbsp}
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass multivariate_normal_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA multivariate normal random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A multivariate normal random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe `mean` keyword specifies the mean. The `cov` keyword specifies the
<br>&nbsp &nbsp &nbsp &nbsp &nbspcovariance matrix.
<br>@@ -342,15 +349,13 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(multivariate_normal_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, mvn_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, mean=None, cov=1, allow_singular=False, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen multivariate normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multivariate normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `multivariate_normal_frozen` for more information.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multivariate_normal_frozen(mean, cov,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspallow_singular=allow_singular,
<br>@@ -360,9 +365,7 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInfer dimensionality from mean or covariance matrix, ensure that
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean and covariance are full vector resp. matrix.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Try to infer dimensionality
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mean is None:
<br>@@ -379,9 +382,11 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = mean.size
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.isscalar(dim):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Dimension of random variable must be a scalar.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Dimension of random variable must be "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"a scalar.")</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check input sizes and return full arrays for mean and cov if necessary</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check input sizes and return full arrays for mean and cov if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# necessary</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mean is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = np.zeros(dim)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = np.asarray(mean, dtype=float)
<br>@@ -395,7 +400,8 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcov.shape = (1, 1)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mean.ndim != 1 or mean.shape[0] != dim:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'mean' must be a vector of length %d." % dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'mean' must be a vector of length %d." %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif cov.ndim == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcov = cov * np.eye(dim)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif cov.ndim == 1:
<br>@@ -420,7 +426,6 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAdjust quantiles array so that last axis labels the components of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach data point.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x, dtype=float)
<br>&nbsp
<br>@@ -435,7 +440,8 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, mean, prec_U, log_det_cov, rank):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate normal probability density function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray
<br>@@ -462,8 +468,7 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn -0.5 * (rank * _LOG_2PI + log_det_cov + maha)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, x, mean=None, cov=1, allow_singular=False):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the multivariate normal probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate normal probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -488,8 +493,7 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, x, mean=None, cov=1, allow_singular=False):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMultivariate normal probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Multivariate normal probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -514,7 +518,8 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cdf(self, x, mean, cov, maxpts, abseps, releps):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate normal cumulative distribution function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray
<br>@@ -523,11 +528,11 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcov : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCovariance matrix of the distribution
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts: integer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts : integer</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe maximum number of points to use for integration
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps: float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps : float</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAbsolute error tolerance
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps: float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps : float</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRelative error tolerance
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>@@ -547,20 +552,19 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logcdf(self, x, mean=None, cov=1, allow_singular=False, maxpts=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps=1e-5, releps=1e-5):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the multivariate normal cumulative distribution function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate normal cumulative distribution function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvn_doc_default_callparams)s
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts: integer, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts : integer, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe maximum number of points to use for integration
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default `1000000*dim`)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAbsolute error tolerance (default 1e-5)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRelative error tolerance (default 1e-5)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>@@ -586,20 +590,19 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef cdf(self, x, mean=None, cov=1, allow_singular=False, maxpts=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps=1e-5, releps=1e-5):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMultivariate normal cumulative distribution function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Multivariate normal cumulative distribution function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvn_doc_default_callparams)s
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts: integer, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts : integer, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe maximum number of points to use for integration
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default `1000000*dim`)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAbsolute error tolerance (default 1e-5)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRelative error tolerance (default 1e-5)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>@@ -624,8 +627,7 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, mean=None, cov=1, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a multivariate normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a multivariate normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -652,8 +654,7 @@ class multivariate_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self, mean=None, cov=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the differential entropy of the multivariate normal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the differential entropy of the multivariate normal.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -680,8 +681,7 @@ multivariate_normal = multivariate_normal_gen()
<br>&nbspclass multivariate_normal_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, mean=None, cov=1, allow_singular=False, seed=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts=None, abseps=1e-5, releps=1e-5):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen multivariate normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multivariate normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -692,19 +692,22 @@ class multivariate_normal_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspallow_singular : bool, optional
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf this flag is True then tolerate a singular
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcovariance matrix (default False).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts: integer, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaxpts : integer, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe maximum number of points to use for integration of the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcumulative distribution function (default `1000000*dim`)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabseps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAbsolute error tolerance for the cumulative distribution function
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default 1e-5)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps: float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreleps : float, optional</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRelative error tolerance for the cumulative distribution function
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default 1e-5)
<br>&nbsp
<br>@@ -753,8 +756,7 @@ class multivariate_normal_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.rvs(self.mean, self.cov, size, random_state)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspComputes the differential entropy of the multivariate normal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Computes the differential entropy of the multivariate normal.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -766,12 +768,14 @@ class multivariate_normal_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprank = self.cov_info.rank
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn 0.5 * (rank * (_LOG_2PI + 1) + log_pdet)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsp# Set frozen generator docstrings from corresponding docstrings in
<br>&nbsp# multivariate_normal_gen and fill in default strings in class docstrings
<br>&nbspfor name in ['logpdf', 'pdf', 'logcdf', 'cdf', 'rvs']:
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod = multivariate_normal_gen.__dict__[name]
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod_frozen = multivariate_normal_frozen.__dict__[name]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(method.__doc__, mvn_docdict_noparams)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(method.__doc__,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmvn_docdict_noparams)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__, mvn_docdict_params)
<br>&nbsp
<br>&nbsp_matnorm_doc_default_callparams = """\
<br>@@ -811,9 +815,10 @@ matnorm_docdict_noparams = {
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'_matnorm_doc_callparams_note': _matnorm_doc_frozen_callparams_note,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state
<br>&nbsp}
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspclass matrix_normal_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA matrix normal random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A matrix normal random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe `mean` keyword specifies the mean. The `rowcov` keyword specifies the
<br>&nbsp &nbsp &nbsp &nbsp &nbspamong-row covariance matrix. The 'colcov' keyword specifies the
<br>@@ -909,15 +914,15 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> equiv_cov = np.kron(V,U)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> multivariate_normal.pdf(vectorised_X, mean=equiv_mean, cov=equiv_cov)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp0.023410202050005054
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(matrix_normal_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, matnorm_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, mean=None, rowcov=1, colcov=1, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen matrix normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen matrix normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `matrix_normal_frozen` for more information.
<br>&nbsp
<br>@@ -928,7 +933,6 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInfer dimensionality from mean or covariance matrices. Handle
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefaults. Ensure compatible dimensions.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Process mean
<br>@@ -979,13 +983,13 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Ensure mean and covariances compatible
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mean is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif meanshape[0] != numrows:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Arrays `mean` and `rowcov` must have the"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"same number of rows.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Arrays `mean` and `rowcov` must have the "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"same number of rows.")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif meanshape[1] != numcols:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Arrays `mean` and `colcov` must have the"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"same number of columns.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Arrays `mean` and `colcov` must have the "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"same number of columns.")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = np.zeros((numrows,numcols))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = np.zeros((numrows, numcols))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdims = (numrows, numcols)
<br>&nbsp
<br>@@ -995,19 +999,19 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAdjust quantiles array so that last two axes labels the components of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach data point.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspX = np.asarray(X, dtype=float)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif X.ndim == 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspX = X[np.newaxis, :]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif X.shape[-2:] != dims:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The shape of array `X` is not compatible "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"with the distribution parameters.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"with the distribution parameters.")</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn X
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, dims, X, mean, row_prec_rt, log_det_rowcov,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcol_prec_rt, log_det_colcov):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the matrix normal probability density function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdims : tuple
<br>@@ -1043,8 +1047,7 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp+ numrows*log_det_colcov + maha)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, X, mean=None, rowcov=1, colcov=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the matrix normal probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the matrix normal probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1072,8 +1075,7 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, X, mean=None, rowcov=1, colcov=1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMatrix normal probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Matrix normal probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1094,8 +1096,7 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(self.logpdf(X, mean, rowcov, colcov))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, mean=None, rowcov=1, colcov=1, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a matrix normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a matrix normal distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1121,44 +1122,50 @@ class matrix_normal_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprowchol = scipy.linalg.cholesky(rowcov, lower=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcolchol = scipy.linalg.cholesky(colcov, lower=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd_norm = random_state.standard_normal(size=(dims[1],size,dims[0]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstd_norm = random_state.standard_normal(size=(dims[1], size, dims[0]))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsproll_rvs = np.tensordot(colchol, np.dot(std_norm, rowchol.T), 1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = np.rollaxis(roll_rvs.T, axis=1, start=0) + mean[np.newaxis,:,:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = np.rollaxis(roll_rvs.T, axis=1, start=0) + mean[np.newaxis, :, :]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size == 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#out = np.squeeze(out, axis=0)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = out.reshape(mean.shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspmatrix_normal = matrix_normal_gen()
<br>&nbsp
<br>&nbsp
<br>&nbspclass matrix_normal_frozen(multi_rv_frozen):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef __init__(self, mean=None, rowcov=1, colcov=1, seed=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen matrix normal distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Create a frozen matrix normal distribution.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_matnorm_doc_default_callparams)s</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf int or RandomState, use it for drawing the random variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_matnorm_doc_default_callparams)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import matrix_normal</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> distn = matrix_normal(mean=np.zeros((3,3)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> X = distn.rvs(); X</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[-0.02976962,  0.93339138, -0.09663178],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.67405524,  0.28250467, -0.93308929],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.31144782,  0.74535536,  1.30412916]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> distn.pdf(X)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp2.5160642368346784e-05</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> distn.logpdf(X)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-10.590229595124615</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, mean=None, rowcov=1, colcov=1, seed=None):</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import matrix_normal</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> distn = matrix_normal(mean=np.zeros((3,3)))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> X = distn.rvs(); X</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([[-0.02976962,  0.93339138, -0.09663178],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.67405524,  0.28250467, -0.93308929],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.31144782,  0.74535536,  1.30412916]])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> distn.pdf(X)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2.5160642368346784e-05</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> distn.logpdf(X)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-10.590229595124615</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist = matrix_normal_gen(seed)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.dims, self.mean, self.rowcov, self.colcov = \
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist._process_parameters(mean, rowcov, colcov)
<br>@@ -1185,7 +1192,8 @@ class matrix_normal_frozen(multi_rv_frozen):
<br>&nbspfor name in ['logpdf', 'pdf', 'rvs']:
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod = matrix_normal_gen.__dict__[name]
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod_frozen = matrix_normal_frozen.__dict__[name]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(method.__doc__, matnorm_docdict_noparams)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(method.__doc__,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatnorm_docdict_noparams)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__, matnorm_docdict_params)
<br>&nbsp
<br>&nbsp_dirichlet_doc_default_callparams = """\
<br>@@ -1208,13 +1216,14 @@ dirichlet_docdict_noparams = {
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state
<br>&nbsp}
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspdef _dirichlet_check_parameters(alpha):
<br>&nbsp &nbsp &nbsp &nbsp &nbspalpha = np.asarray(alpha)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif np.min(alpha) <= 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("All parameters must be greater than 0")
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif alpha.ndim != 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Parameter vector 'a' must be one dimensional, "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"but a.shape = %s." % (alpha.shape, ))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"but a.shape = %s." % (alpha.shape, ))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn alpha
<br>&nbsp
<br>&nbsp
<br>@@ -1237,26 +1246,38 @@ def _dirichlet_check_input(alpha, x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The input must be one dimensional or a two "
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"dimensional matrix containing the entries.")
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif np.min(x) <= 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Each entry in 'x' must be greater than zero.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.min(x) < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Each entry in 'x' must be greater than or equal "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"to zero.")</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif np.max(x) > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Each entry in 'x' must be smaller or equal one.")
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Check x_i > 0 or alpha_i > 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspxeq0 = (x == 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspalphalt1 = (alpha < 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif x.shape != alpha.shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspalphalt1 = np.repeat(alphalt1, x.shape[-1], axis=-1).reshape(x.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspchk = np.logical_and(xeq0, alphalt1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif np.sum(chk):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Each entry in 'x' must be greater than zero if its "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"alpha is less than one.")</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif (np.abs(np.sum(x, 0) - 1.0) > 10e-10).any():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("The input vector 'x' must lie within the normal "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"simplex. but np.sum(x, 0) = %s." % np.sum(x, 0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"simplex. but np.sum(x, 0) = %s." % np.sum(x, 0))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x
<br>&nbsp
<br>&nbsp
<br>&nbspdef _lnB(alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspInternal helper function to compute the log of the useful quotient</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Internal helper function to compute the log of the useful quotient.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. math::
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspB(\alpha) = \frac{\prod_{i=1}{K}\Gamma(\alpha_i)}{\Gamma\left(\sum_{i=1}^{K}\alpha_i\right)}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspB(\alpha) = \frac{\prod_{i=1}{K}\Gamma(\alpha_i)}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp{\Gamma\left(\sum_{i=1}^{K} \alpha_i \right)}</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1272,10 +1293,9 @@ def _lnB(alpha):
<br>&nbsp
<br>&nbsp
<br>&nbspclass dirichlet_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA Dirichlet random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A Dirichlet random variable.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe `alpha` keyword specifies the concentration parameters of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe ``alpha`` keyword specifies the concentration parameters of the</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdistribution.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 0.15.0
<br>@@ -1316,8 +1336,11 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsupport on the simplex defined by
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. math::
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\sum_{i=1}^{K} x_i \le 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\sum_{i=1}^{K} x_i = 1</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere :math:`0 < x_i < 1`.</span>
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf the quantiles don't lie within the simplex, a ValueError is raised.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe probability density function for `dirichlet` is
<br>&nbsp
<br>@@ -1340,17 +1363,52 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe array returned by the rvs function is transposed
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith respect to the format expected by the pdf and logpdf.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import dirichlet</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspGenerate a dirichlet random variable</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> quantiles = np.array([0.2, 0.2, 0.6])  # specify quantiles</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> alpha = np.array([0.4, 5, 15])  # specify concentration parameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.pdf(quantiles, alpha)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.2843831684937255</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe same PDF but following a log scale</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.logpdf(quantiles, alpha)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-1.2574327653159187</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspOnce we specify the dirichlet distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwe can then calculate quantities of interest</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.mean(alpha)  # get the mean of the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.01960784, 0.24509804, 0.73529412])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.var(alpha) # get variance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.00089829, 0.00864603, 0.00909517])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.entropy(alpha)  # calculate the differential entropy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-4.3280162474082715</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWe can also return random samples from the distribution</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.rvs(alpha, size=1, random_state=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[0.00766178, 0.24670518, 0.74563305]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> dirichlet.rvs(alpha, size=2, random_state=2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[0.01639427, 0.1292273 , 0.85437844],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[0.00156917, 0.19033695, 0.80809388]])</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(dirichlet_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, dirichlet_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, alpha, seed=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dirichlet_frozen(alpha, seed=seed)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the Dirichlet probability density function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray
<br>@@ -1365,11 +1423,10 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplnB = _lnB(alpha)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn - lnB + np.sum((np.log(x.T) * (alpha - 1)).T, 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn - lnB + np.sum((xlogy(alpha - 1, x.T)).T, 0)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, x, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the Dirichlet probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the Dirichlet probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1390,8 +1447,7 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, x, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe Dirichlet probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""The Dirichlet probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1412,8 +1468,7 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mean(self, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the mean of the dirichlet distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the mean of the dirichlet distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1431,8 +1486,7 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef var(self, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the variance of the dirichlet distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the variance of the dirichlet distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1452,8 +1506,7 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self, alpha):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the differential entropy of the dirichlet distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the differential entropy of the dirichlet distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1477,8 +1530,7 @@ class dirichlet_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, alpha, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a Dirichlet distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a Dirichlet distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1565,14 +1617,15 @@ wishart_docdict_noparams = {
<br>&nbsp
<br>&nbsp
<br>&nbspclass wishart_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA Wishart random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A Wishart random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe `df` keyword specifies the degrees of freedom. The `scale` keyword
<br>&nbsp &nbsp &nbsp &nbsp &nbspspecifies the scale matrix, which must be symmetric and positive definite.
<br>&nbsp &nbsp &nbsp &nbsp &nbspIn this context, the scale matrix is often interpreted in terms of a
<br>&nbsp &nbsp &nbsp &nbsp &nbspmultivariate normal precision matrix (the inverse of the covariance
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmatrix).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmatrix). These arguments must satisfy the relationship</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``df > scale.ndim - 1``, but see notes on using the `rvs` method with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``df < scale.ndim``.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspMethods
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -1638,6 +1691,12 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdistribution :math:`W_1(\nu, 1)` collapses to the :math:`\chi^2(\nu)`
<br>&nbsp &nbsp &nbsp &nbsp &nbspdistribution.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe algorithm [2]_ implemented by the `rvs` method may</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspproduce numerically singular matrices with :math:`p - 1 < \nu < p`; the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspuser may wish to check for this condition and generate replacement samples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspas necessary.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. versionadded:: 0.16.0
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>@@ -1664,15 +1723,13 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(wishart_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, wishart_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, df=None, scale=None, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `wishart_frozen` for more information.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn wishart_frozen(df, scale, seed)
<br>&nbsp
<br>@@ -1682,7 +1739,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = np.asarray(scale, dtype=float)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale.ndim == 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = scale[np.newaxis,np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = scale[np.newaxis, np.newaxis]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif scale.ndim == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = np.diag(scale)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif scale.ndim == 2 and not scale.shape[0] == scale.shape[1]:
<br>@@ -1699,9 +1756,9 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf = dim
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif not np.isscalar(df):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Degrees of freedom must be a scalar.")
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif df < dim:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Degrees of freedom cannot be less than dimension"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" of scale matrix, but df = %d" % df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif df <= dim - 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Degrees of freedom must be greater than the "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"dimension of scale matrix minus 1.")</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim, df, scale
<br>&nbsp
<br>@@ -1757,7 +1814,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn n, shape
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, dim, df, scale, log_det_scale, C):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the Wishart probability density function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray
<br>@@ -1786,13 +1844,13 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# gives us a 1-dim vector of determinants
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Retrieve tr(scale^{-1} x)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_det_x = np.zeros(x.shape[-1])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale_inv_x = np.zeros(x.shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_inv_x = np.zeros(x.shape[-1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_det_x = np.empty(x.shape[-1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale_inv_x = np.empty(x.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_inv_x = np.empty(x.shape[-1])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(x.shape[-1]):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, log_det_x[i] = self._cholesky_logdet(x[:,:,i])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale_inv_x[:,:,i] = scipy.linalg.cho_solve((C, True), x[:,:,i])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_inv_x[i] = scale_inv_x[:,:,i].trace()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, log_det_x[i] = self._cholesky_logdet(x[:, :, i])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale_inv_x[:, :, i] = scipy.linalg.cho_solve((C, True), x[:, :, i])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_inv_x[i] = scale_inv_x[:, :, i].trace()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Log PDF
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = ((0.5 * (df - dim - 1) * log_det_x - 0.5 * tr_scale_inv_x) -
<br>@@ -1802,8 +1860,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, x, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the Wishart probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the Wishart probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1832,8 +1889,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, x, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWishart probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Wishart probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1855,7 +1911,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(self.logpdf(x, df, scale))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mean(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -1871,8 +1928,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn df * scale
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mean(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1888,7 +1944,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mode(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mode of the Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -1908,8 +1965,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mode(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMode of the Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mode of the Wishart distribution</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOnly valid if the degrees of freedom are greater than the dimension of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe scale matrix.
<br>@@ -1928,7 +1984,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out) if out is not None else out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _var(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -1948,8 +2005,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn var
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef var(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariance of the Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -1976,8 +2032,15 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of the scale matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf : int
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : np.random.RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandomState used for drawing the random variates.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----
<br>@@ -1991,14 +2054,15 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=n*n_tril).reshape(shape+(n_tril,))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Random chi-square variates for diagonal elements
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariances = np.r_[[random_state.chisquare(df-(i+1)+1, size=n)**0.5</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(dim)]].reshape((dim,) + shape[::-1]).T</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariances = (np.r_[[random_state.chisquare(df-(i+1)+1, size=n)**0.5</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(dim)]].reshape((dim,) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape[::-1]).T)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Create the A matri(ces) - lower triangular
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA = np.zeros(shape + (dim, dim))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Input the covariances
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize_idx = tuple([slice(None,None,None)]*len(shape))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize_idx = tuple([slice(None, None, None)]*len(shape))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptril_idx = np.tril_indices(dim, k=-1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA[size_idx + tril_idx] = covariances
<br>&nbsp
<br>@@ -2009,7 +2073,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn A
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _rvs(self, n, shape, dim, df, C, random_state):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn : integer
<br>@@ -2020,8 +2085,6 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of the scale matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf : int
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale : ndarray</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScale matrix</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspC : ndarray
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCholesky factorization of the scale matrix, lower triangular.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_random_state)s
<br>@@ -2055,8 +2118,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn A
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, df, scale, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2087,7 +2149,8 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _entropy(self, dim, df, log_det_scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the differential entropy of the Wishart.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -2114,8 +2177,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the differential entropy of the Wishart.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the differential entropy of the Wishart.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2136,8 +2198,7 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._entropy(dim, df, log_det_scale)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _cholesky_logdet(self, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute Cholesky decomposition and determine (log(det(scale)).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute Cholesky decomposition and determine (log(det(scale)).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2160,12 +2221,13 @@ class wishart_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc_decomp = scipy.linalg.cholesky(scale, lower=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogdet = 2 * np.sum(np.log(c_decomp.diagonal()))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn c_decomp, logdet
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspwishart = wishart_gen()
<br>&nbsp
<br>&nbsp
<br>&nbspclass wishart_frozen(multi_rv_frozen):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCreate a frozen Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Create a frozen Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2173,12 +2235,15 @@ class wishart_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom of the distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbspscale : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScale matrix of the distribution
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, df, scale, seed=None):
<br>@@ -2218,6 +2283,7 @@ class wishart_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist._entropy(self.dim, self.df, self.log_det_scale)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsp# Set frozen generator docstrings from corresponding docstrings in
<br>&nbsp# Wishart and fill in default strings in class docstrings
<br>&nbspfor name in ['logpdf', 'pdf', 'mean', 'mode', 'var', 'rvs', 'entropy']:
<br>@@ -2228,9 +2294,6 @@ for name in ['logpdf', 'pdf', 'mean', 'mode', 'var', 'rvs', 'entropy']:
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__, wishart_docdict_params)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- from numpy import asarray_chkfinite, asarray</span>
<br><span style="color:red">- from scipy.linalg.misc import LinAlgError</span>
<br><span style="color:red">- from scipy.linalg.lapack import get_lapack_funcs</span>
<br>&nbspdef _cho_inv_batch(a, check_finite=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspInvert the matrices a_i, using a Cholesky factorization of A, where
<br>@@ -2254,7 +2317,7 @@ def _cho_inv_batch(a, check_finite=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbspx : array
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspArray of inverses of the matrices ``a_i``.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspscipy.linalg.cholesky : Cholesky factorization of a matrix
<br>&nbsp
<br>@@ -2266,10 +2329,9 @@ def _cho_inv_batch(a, check_finite=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(a1.shape) < 2 or a1.shape[-2] != a1.shape[-1]:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('expected square matrix in last two dimensions')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppotrf, potri = get_lapack_funcs(('potrf','potri'), (a1,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppotrf, potri = get_lapack_funcs(('potrf', 'potri'), (a1,))</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptril_idx = np.tril_indices(a.shape[-2], k=-1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptriu_idx = np.triu_indices(a.shape[-2], k=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptriu_rows, triu_cols = np.triu_indices(a.shape[-2], k=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor index in np.ndindex(a1.shape[:-2]):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Cholesky decomposition
<br>@@ -2290,14 +2352,13 @@ def _cho_inv_batch(a, check_finite=True):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' potrf' % -info)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Make symmetric (dpotri only fills in the lower triangle)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa1[index][triu_idx] = a1[index][tril_idx]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa1[index][triu_rows, triu_cols] = a1[index][triu_cols, triu_rows]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn a1
<br>&nbsp
<br>&nbsp
<br>&nbspclass invwishart_gen(wishart_gen):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspAn inverse Wishart random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""An inverse Wishart random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThe `df` keyword specifies the degrees of freedom. The `scale` keyword
<br>&nbsp &nbsp &nbsp &nbsp &nbspspecifies the scale matrix, which must be symmetric and positive definite.
<br>@@ -2373,8 +2434,9 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] M.L. Eaton, "Multivariate Statistics: A Vector Space Approach",
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWiley, 1983.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp.. [2] M.C. Jones, "Generating Inverse Wishart Matrices", Communications in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspStatistics - Simulation and Computation, vol. 14.2, pp.511-514, 1985.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] M.C. Jones, "Generating Inverse Wishart Matrices", Communications</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin Statistics - Simulation and Computation, vol. 14.2, pp.511-514,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1985.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -2395,12 +2457,11 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(invwishart_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, wishart_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, df=None, scale=None, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen inverse Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `invwishart_frozen` for more information.
<br>&nbsp
<br>@@ -2408,7 +2469,8 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn invwishart_frozen(df, scale, seed)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, dim, df, scale, log_det_scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the inverse Wishart probability density function.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray
<br>@@ -2429,21 +2491,19 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcalled directly; use 'logpdf' instead.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_det_x = np.zeros(x.shape[-1])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#scale_x_inv = np.zeros(x.shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_det_x = np.empty(x.shape[-1])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_inv = np.copy(x).T
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_cho_inv_batch(x_inv)  # works in-place
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_inv = 1./x_inv
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_x_inv = np.zeros(x.shape[-1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_x_inv = np.empty(x.shape[-1])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(x.shape[-1]):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspC, lower = scipy.linalg.cho_factor(x[:,:,i], lower=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspC, lower = scipy.linalg.cho_factor(x[:, :, i], lower=True)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_det_x[i] = 2 * np.sum(np.log(C.diagonal()))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#scale_x_inv[:,:,i] = scipy.linalg.cho_solve((C, True), scale).T</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptr_scale_x_inv[i] = np.dot(scale, x_inv[i]).trace()
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Log PDF
<br>@@ -2454,8 +2514,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpdf(self, x, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the inverse Wishart probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the inverse Wishart probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2481,15 +2540,13 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pdf(self, x, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInverse Wishart probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Inverse Wishart probability density function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEach quantile must be a symmetric positive definite matrix.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>@@ -2505,7 +2562,8 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(self.logpdf(x, df, scale))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mean(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the inverse Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -2525,8 +2583,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mean(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the inverse Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOnly valid if the degrees of freedom are greater than the dimension of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe scale matrix plus one.
<br>@@ -2546,7 +2603,8 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out) if out is not None else out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _mode(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mode of the inverse Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -2562,8 +2620,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn scale / (df + dim + 1)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mode(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMode of the inverse Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mode of the inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2580,7 +2637,8 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _var(self, dim, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the inverse Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int
<br>@@ -2603,8 +2661,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn var
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef var(self, df, scale):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariance of the inverse Wishart distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOnly valid if the degrees of freedom are greater than the dimension of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe scale matrix plus three.
<br>@@ -2623,7 +2680,8 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(out) if out is not None else out
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _rvs(self, n, shape, dim, df, C, random_state):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from an inverse Wishart distribution.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn : integer
<br>@@ -2646,8 +2704,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Get random draws A such that A ~ W(df, I)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA = super(invwishart_gen, self)._standard_rvs(n, shape, dim,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf, random_state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA = super()._standard_rvs(n, shape, dim, df, random_state)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Calculate SA = (CA)'^{-1} (CA)^{-1} ~ iW(df, scale)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeye = np.eye(dim)
<br>@@ -2672,8 +2729,7 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn A
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, df, scale, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from an inverse Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from an inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2711,12 +2767,13 @@ class invwishart_gen(wishart_gen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Need to find reference for inverse Wishart entropy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise AttributeError
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspinvwishart = invwishart_gen()
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass invwishart_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, df, scale, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen inverse Wishart distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen inverse Wishart distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -2724,12 +2781,12 @@ class invwishart_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom of the distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScale matrix of the distribution
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`}, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None the `numpy.random.Generator` singleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``Generator`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` instance then that instance is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist = invwishart_gen(seed)
<br>@@ -2781,6 +2838,7 @@ class invwishart_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Need to find reference for inverse Wishart entropy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise AttributeError
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsp# Set frozen generator docstrings from corresponding docstrings in
<br>&nbsp# inverse Wishart and fill in default strings in class docstrings
<br>&nbspfor name in ['logpdf', 'pdf', 'mean', 'mode', 'var', 'rvs']:
<br>@@ -2821,9 +2879,9 @@ multinomial_docdict_noparams = {
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state
<br>&nbsp}
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass multinomial_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA multinomial random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A multinomial random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspMethods
<br>&nbsp &nbsp &nbsp &nbsp &nbsp-------
<br>@@ -2920,37 +2978,37 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee also
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbspscipy.stats.binom : The binomial distribution.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy.random.multinomial : Sampling from the multinomial distribution.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnumpy.random.Generator.multinomial : Sampling from the multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.multivariate_hypergeom :</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe multivariate hypergeometric distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""  # noqa: E501</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(multinomial_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = \
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdoccer.docformat(self.__doc__, multinomial_docdict_params)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, n, p, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `multinomial_frozen` for more information.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multinomial_frozen(n, p, seed)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(self, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn: n_, p_, npcond.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Returns: n_, p_, npcond.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn_ and p_ are arrays of the correct shape; npcond is a boolean array
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflagging values out of the domain.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp = np.array(p, dtype=np.float64, copy=True)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp[...,-1] = 1. - p[...,:-1].sum(axis=-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspp[..., -1] = 1. - p[..., :-1].sum(axis=-1)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# true for bad p
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppcond = np.any(p < 0, axis=-1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppcond |= np.any(p > 1, axis=-1)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = np.array(n, dtype=np.int, copy=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = np.array(n, dtype=np.int_, copy=True)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# true for bad n
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspncond = n <= 0
<br>@@ -2958,20 +3016,20 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn n, p, ncond | pcond
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_quantiles(self, x, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn: x_, xcond.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Returns: x_, xcond.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_ is an int array; xcond is a boolean array flagging values out of the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdomain.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxx = np.asarray(x, dtype=np.int)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxx = np.asarray(x, dtype=np.int_)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif xx.ndim == 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("x must be an array.")
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif xx.size != 0 and not xx.shape[-1] == p.shape[-1]:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Size of each quantile should be size of p: "
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"received %d, but expected %d." % (xx.shape[-1], p.shape[-1]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"received %d, but expected %d." %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(xx.shape[-1], p.shape[-1]))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# true for x out of the domain
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = np.any(xx != x, axis=-1)
<br>@@ -2995,14 +3053,12 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn gammaln(n+1) + np.sum(xlogy(x, p) - gammaln(x+1), axis=-1)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef logpmf(self, x, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the Multinomial probability mass function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the Multinomial probability mass function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEach quantile must be a symmetric positive definite matrix.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>@@ -3029,14 +3085,12 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(result, npcond_, np.NAN)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef pmf(self, x, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMultinomial probability mass function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Multinomial probability mass function.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEach quantile must be a symmetric positive definite matrix.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns
<br>@@ -3051,8 +3105,7 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(self.logpmf(x, n, p))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef mean(self, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the Multinomial distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the Multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3068,8 +3121,7 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(result, npcond, np.NAN)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef cov(self, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCovariance matrix of the multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Covariance matrix of the multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3087,13 +3139,12 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# change the diagonal
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(p.shape[-1]):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult[...,i, i] += n*p[..., i]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult[..., i, i] += n*p[..., i]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(result, npcond, np.nan)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef entropy(self, n, p):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the entropy of the multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr"""Compute the entropy of the multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe entropy is computed using this expression:
<br>&nbsp
<br>@@ -3127,13 +3178,12 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx.shape += (1,)*new_axes_needed
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspterm2 = np.sum(binom.pmf(x, n, p)*gammaln(x+1),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=(-1, -1-new_axes_needed))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=(-1, -1-new_axes_needed))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(term1 + term2, npcond, np.nan)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, n, p, size=None, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a Multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a Multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3158,9 +3208,9 @@ class multinomial_gen(multi_rv_generic):
<br>&nbsp
<br>&nbspmultinomial = multinomial_gen()
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass multinomial_frozen(multi_rv_frozen):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCreate a frozen Multinomial distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""Create a frozen Multinomial distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3168,12 +3218,15 @@ class multinomial_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumber of trials
<br>&nbsp &nbsp &nbsp &nbsp &nbspp: array_like
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprobability of a trial falling into each category; should sum to 1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat instance is used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, n, p, seed=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist = multinomial_gen(seed)
<br>@@ -3203,6 +3256,7 @@ class multinomial_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, size=1, random_state=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.rvs(self.n, self.p, size, random_state)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsp# Set frozen generator docstrings from corresponding docstrings in
<br>&nbsp# multinomial and fill in default strings in class docstrings
<br>&nbspfor name in ['logpmf', 'pmf', 'mean', 'cov', 'rvs']:
<br>@@ -3211,11 +3265,11 @@ for name in ['logpmf', 'pmf', 'mean', 'cov', 'rvs']:
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__, multinomial_docdict_noparams)
<br>&nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultinomial_docdict_params)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultinomial_docdict_params)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbspclass special_ortho_group_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA matrix-valued SO(N) random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A matrix-valued SO(N) random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturn a random rotation matrix, drawn from the Haar distribution
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(the only uniform distribution on SO(n)).
<br>@@ -3233,7 +3287,7 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of matrices
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis class is wrapping the random_rot code from the MDP Toolkit,
<br>&nbsp &nbsp &nbsp &nbsp &nbsphttps://github.com/mdp-toolkit/mdp-toolkit
<br>&nbsp
<br>@@ -3244,9 +3298,10 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspmatrices with an application to condition estimators", SIAM Journal
<br>&nbsp &nbsp &nbsp &nbsp &nbspon Numerical Analysis, 17(3), pp. 403-409, 1980.
<br>&nbsp &nbsp &nbsp &nbsp &nbspFor more information see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsphttp://en.wikipedia.org/wiki/Orthogonal_matrix#Randomization</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphttps://en.wikipedia.org/wiki/Orthogonal_matrix#Randomization</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSee also the similar `ortho_group`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee also the similar `ortho_group`. For a random rotation in three</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdimensions, see `scipy.spatial.transform.Rotation.random`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3265,26 +3320,25 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis generates one random matrix from SO(3). It is orthogonal and
<br>&nbsp &nbsp &nbsp &nbsp &nbsphas a determinant of 1.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsportho_group, scipy.spatial.transform.Rotation.random</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(special_ortho_group_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __call__(self, dim=None, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen SO(N) distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen SO(N) distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `special_ortho_group_frozen` for more information.
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn special_ortho_group_frozen(dim, seed=seed)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(self, dim):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension N must be specified; it cannot be inferred.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Dimension N must be specified; it cannot be inferred."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim is None or not np.isscalar(dim) or dim <= 1 or dim != int(dim):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("""Dimension of rotation must be specified,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand must be a scalar greater than 1.""")
<br>@@ -3292,8 +3346,7 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, dim, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from SO(N).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from SO(N).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3308,6 +3361,8 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom size N-dimensional matrices, dimension (size, dim, dim)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = int(size)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([self.rvs(dim, size=1, random_state=random_state)
<br>@@ -3315,44 +3370,43 @@ class special_ortho_group_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = self._process_parameters(dim)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH = np.eye(dim)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = np.ones((dim,))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor n in range(1, dim):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = random_state.normal(size=(dim-n+1,))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD[n-1] = np.sign(x[0])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx[0] -= D[n-1]*np.sqrt((x*x).sum())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = np.empty((dim,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor n in range(dim-1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = random_state.normal(size=(dim-n,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnorm2 = np.dot(x, x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0 = x[0].item()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD[n] = np.sign(x[0]) if x[0] != 0 else 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx[0] += D[n]*np.sqrt(norm2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx /= np.sqrt((norm2 - x0**2 + x[0]**2) / 2.)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Householder transformation
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspHx = (np.eye(dim-n+1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- 2.*np.outer(x, x)/(x*x).sum())</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmat = np.eye(dim)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmat[n-1:, n-1:] = Hx</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH = np.dot(H, mat)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Fix the last sign such that the determinant is 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD[-1] = (-1)**(1-(dim % 2))*D.prod()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH[:, n:] -= np.outer(np.dot(H[:, n:], x), x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD[-1] = (-1)**(dim-1)*D[:-1].prod()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Equivalent to np.dot(np.diag(D), H) but faster, apparently
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH = (D*H.T).T
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn H
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspspecial_ortho_group = special_ortho_group_gen()
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass special_ortho_group_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, dim=None, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCreate a frozen SO(N) distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen SO(N) distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : scalar
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of matrices
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : None or int or np.random.RandomState instance, optional</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis parameter defines the RandomState object to use for drawing</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom variates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf None (or np.random), the global np.random state is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf integer, it is used to seed the local RandomState instance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault is None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : {None, int, `numpy.random.Generator`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`numpy.random.RandomState`}, optional</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingleton is used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is an int, a new ``RandomState`` instance is used,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseeded with `seed`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `seed` is already a ``Generator`` or ``RandomState`` instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen that instance is used.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3367,9 +3421,9 @@ class special_ortho_group_frozen(multi_rv_frozen):
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, size=1, random_state=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.rvs(self.dim, size, random_state)
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass ortho_group_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA matrix-valued O(N) random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A matrix-valued O(N) random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturn a random orthogonal matrix, drawn from the O(N) Haar
<br>&nbsp &nbsp &nbsp &nbsp &nbspdistribution (the only uniform distribution on O(N)).
<br>@@ -3387,7 +3441,7 @@ class ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of matrices
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis class is closely related to `special_ortho_group`.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSome care is taken to avoid numerical error, as per the paper by Mezzadri.
<br>@@ -3417,14 +3471,11 @@ class ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(ortho_group_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(self, dim):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension N must be specified; it cannot be inferred.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Dimension N must be specified; it cannot be inferred."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim is None or not np.isscalar(dim) or dim <= 1 or dim != int(dim):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Dimension of rotation must be specified,"
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"and must be a scalar greater than 1.")
<br>@@ -3432,8 +3483,7 @@ class ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, dim, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from O(N).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from O(N).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3448,6 +3498,8 @@ class ortho_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom size N-dimensional matrices, dimension (size, dim, dim)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = int(size)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([self.rvs(dim, size=1, random_state=random_state)
<br>@@ -3455,27 +3507,25 @@ class ortho_group_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = self._process_parameters(dim)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH = np.eye(dim)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor n in range(1, dim):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = random_state.normal(size=(dim-n+1,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor n in range(dim):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = random_state.normal(size=(dim-n,))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnorm2 = np.dot(x, x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx0 = x[0].item()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# random sign, 50/50, but chosen carefully to avoid roundoff error
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = np.sign(x[0])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx[0] += D*np.sqrt((x*x).sum())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = np.sign(x[0]) if x[0] != 0 else 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx[0] += D * np.sqrt(norm2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx /= np.sqrt((norm2 - x0**2 + x[0]**2) / 2.)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Householder transformation
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspHx = -D*(np.eye(dim-n+1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- 2.*np.outer(x, x)/(x*x).sum())</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmat = np.eye(dim)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmat[n-1:, n-1:] = Hx</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH = np.dot(H, mat)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspH[:, n:] = -D * (H[:, n:] - np.outer(np.dot(H[:, n:], x), x))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn H
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsportho_group = ortho_group_gen()
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass random_correlation_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA random correlation matrix.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A random correlation matrix.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturn a random correlation matrix, given a vector of eigenvalues.
<br>&nbsp
<br>@@ -3493,7 +3543,7 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspEigenvalues of correlation matrix.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspGenerates a random correlation matrix following a numerically stable
<br>&nbsp &nbsp &nbsp &nbsp &nbspalgorithm spelled out by Davies & Higham. This algorithm uses a single O(N)
<br>@@ -3511,14 +3561,13 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import random_correlation
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> np.random.seed(514)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp>>> x = random_correlation.rvs((.5, .8, 1.2, 1.5))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rng = np.random.default_rng()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x = random_correlation.rvs((.5, .8, 1.2, 1.5), random_state=rng)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> x
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsparray([[ 1.        , -0.20387311,  0.18366501, -0.04953711],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.20387311,  1.        , -0.24351129,  0.06703474],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ 0.18366501, -0.24351129,  1.        ,  0.38530195],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.04953711,  0.06703474,  0.38530195,  1.        ]])</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[ 1.        , -0.07198934, -0.20411041, -0.24385796],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.07198934,  1.        ,  0.12968613, -0.29471382],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.20411041,  0.12968613,  1.        ,  0.2828693 ],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-0.24385796, -0.29471382,  0.2828693 ,  1.        ]])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> import scipy.linalg
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> e, v = scipy.linalg.eigh(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp>>> e
<br>@@ -3527,7 +3576,7 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(random_correlation_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(self, eigs, tol):
<br>@@ -3535,7 +3584,8 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = eigs.size
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif eigs.ndim != 1 or eigs.shape[0] != dim or dim <= 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'eigs' must be a vector of length greater than 1.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'eigs' must be a vector of length "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"greater than 1.")</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.fabs(np.sum(eigs) - dim) > tol:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Sum of eigenvalues must equal dimensionality.")
<br>@@ -3547,12 +3597,12 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim, eigs
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _givens_to_1(self, aii, ajj, aij):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Computes a 2x2 Givens matrix to put 1's on the diagonal for the input matrix.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Computes a 2x2 Givens matrix to put 1's on the diagonal.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe input matrix is a 2x2 symmetric matrix M = [ aii aij ; aij ajj ].
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe output matrix g is a 2x2 anti-symmetric matrix of the form [ c s ; -s c ];</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe elements c and s are returned.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe output matrix g is a 2x2 anti-symmetric matrix of the form</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ c s ; -s c ];  the elements c and s are returned.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspApplying the output matrix to the input matrix (as b=g.T M g)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults in a matrix with bii=1, provided tr(M) - det(M) >= 1
<br>@@ -3586,12 +3636,13 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdimensionality. Note: modifies input matrix
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Check requirements for in-place Givens
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not (m.flags.c_contiguous and m.dtype == np.float64 and m.shape[0] == m.shape[1]):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not (m.flags.c_contiguous and m.dtype == np.float64 and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm.shape[0] == m.shape[1]):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError()
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd = m.shape[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(d-1):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m[i,i] == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m[i, i] == 1:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontinue
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif m[i, i] > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor j in range(i+1, d):
<br>@@ -3602,7 +3653,7 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m[j, j] > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbreak
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc, s = self._givens_to_1(m[i,i], m[j,j], m[i,j])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc, s = self._givens_to_1(m[i, i], m[j, j], m[i, j])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use BLAS to apply Givens rotations in-place. Equivalent to:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# g = np.eye(d)
<br>@@ -3620,8 +3671,7 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn m
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, eigs, random_state=None, tol=1e-13, diag_tol=1e-7):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random correlation matrices</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random correlation matrices.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3660,11 +3710,12 @@ class random_correlation_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn m
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbsprandom_correlation = random_correlation_gen()
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspclass unitary_group_gen(multi_rv_generic):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspA matrix-valued U(N) random variable.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A matrix-valued U(N) random variable.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturn a random unitary matrix.
<br>&nbsp
<br>@@ -3681,13 +3732,13 @@ class unitary_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of matrices
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspNotes
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis class is similar to `ortho_group`.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReferences
<br>&nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>&nbsp &nbsp &nbsp &nbsp &nbsp.. [1] F. Mezzadri, "How to generate random matrices from the classical
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompact groups", arXiv:math-ph/0609050v2.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcompact groups", :arXiv:`math-ph/0609050v2`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspExamples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp--------
<br>@@ -3699,19 +3750,17 @@ class unitary_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[  1.13231364e-17,   1.00000000e+00,  -1.46845020e-16],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[ -2.86852790e-16,  -1.46845020e-16,   1.00000000e+00]])
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThis generates one random matrix from U(3). The dot product confirms that it is unitary up to machine precision.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis generates one random matrix from U(3). The dot product confirms that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspit is unitary up to machine precision.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper(unitary_group_gen, self).__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(self, dim):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension N must be specified; it cannot be inferred.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Dimension N must be specified; it cannot be inferred."""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim is None or not np.isscalar(dim) or dim <= 1 or dim != int(dim):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Dimension of rotation must be specified,"
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"and must be a scalar greater than 1.")
<br>@@ -3719,8 +3768,7 @@ class unitary_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef rvs(self, dim, size=1, random_state=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from U(N).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from U(N).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------
<br>@@ -3735,6 +3783,8 @@ class unitary_group_gen(multi_rv_generic):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom size N-dimensional matrices, dimension (size, dim, dim)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = int(size)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.array([self.rvs(dim, size=1, random_state=random_state)
<br>@@ -3742,13 +3792,915 @@ class unitary_group_gen(multi_rv_generic):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = self._process_parameters(dim)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = 1/math.sqrt(2)*(random_state.normal(size=(dim,dim)) +</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1j*random_state.normal(size=(dim,dim)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = 1/math.sqrt(2)*(random_state.normal(size=(dim, dim)) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1j*random_state.normal(size=(dim, dim)))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq, r = scipy.linalg.qr(z)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd = r.diagonal()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspq *= d/abs(d)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn q
<br>&nbsp
<br><span style="color:green">+</span>
<br>&nbspunitary_group = unitary_group_gen()
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mvt_doc_default_callparams = \</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+loc : array_like, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspLocation of the distribution. (default ``0``)</span>
<br><span style="color:green">+shape : array_like, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspPositive semidefinite matrix of the distribution. (default ``1``)</span>
<br><span style="color:green">+df : float, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspDegrees of freedom of the distribution; must be greater than zero.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIf ``np.inf`` then results are multivariate normal. The default is ``1``.</span>
<br><span style="color:green">+allow_singular : bool, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhether to allow a singular matrix. (default ``False``)</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mvt_doc_callparams_note = \</span>
<br><span style="color:green">+"""Setting the parameter `loc` to ``None`` is equivalent to having `loc`</span>
<br><span style="color:green">+be the zero-vector. The parameter `shape` can be a scalar, in which case</span>
<br><span style="color:green">+the shape matrix is the identity times that value, a vector of</span>
<br><span style="color:green">+diagonal entries for the shape matrix, or a two-dimensional array_like.</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mvt_doc_frozen_callparams_note = \</span>
<br><span style="color:green">+"""See class definition for a detailed description of parameters."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+mvt_docdict_params = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_mvt_doc_default_callparams': _mvt_doc_default_callparams,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_mvt_doc_callparams_note': _mvt_doc_callparams_note,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state</span>
<br><span style="color:green">+}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+mvt_docdict_noparams = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_mvt_doc_default_callparams': "",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_mvt_doc_callparams_note': _mvt_doc_frozen_callparams_note,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state</span>
<br><span style="color:green">+}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class multivariate_t_gen(multi_rv_generic):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A multivariate t-distributed random variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe `loc` parameter specifies the location. The `shape` parameter specifies</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspthe positive semidefinite shape matrix. The `df` parameter specifies the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdegrees of freedom.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspIn addition to calling the methods below, the object itself may be called</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspas a function to fix the location, shape matrix, and degrees of freedom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspparameters, returning a "frozen" multivariate t-distribution random.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMethods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``pdf(x, loc=None, shape=1, df=1, allow_singular=False)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``logpdf(x, loc=None, shape=1, df=1, allow_singular=False)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``rvs(loc=None, shape=1, df=1, size=1, random_state=None)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a multivariate t-distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_mvt_doc_default_callparams)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_doc_random_state)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_mvt_doc_callparams_note)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe matrix `shape` must be a (symmetric) positive semidefinite matrix. The</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdeterminant and inverse of `shape` are computed as the pseudo-determinant</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand pseudo-inverse, respectively, so that `shape` does not need to have</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfull rank.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe probability density function for `multivariate_t` is</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf(x) = \frac{\Gamma(\nu + p)/2}{\Gamma(\nu/2)\nu^{p/2}\pi^{p/2}|\Sigma|^{1/2}}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\left[1 + \frac{1}{\nu} (\mathbf{x} - \boldsymbol{\mu})^{\top}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\boldsymbol{\Sigma}^{-1}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(\mathbf{x} - \boldsymbol{\mu}) \right]^{-(\nu + p)/2},</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere :math:`p` is the dimension of :math:`\mathbf{x}`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`\boldsymbol{\mu}` is the :math:`p`-dimensional location,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`\boldsymbol{\Sigma}` the :math:`p \times p`-dimensional shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmatrix, and :math:`\nu` is the degrees of freedom.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> import matplotlib.pyplot as plt</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multivariate_t</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> x, y = np.mgrid[-1:3:.01, -2:1.5:.01]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> pos = np.dstack((x, y))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rv = multivariate_t([1.0, -0.5], [[2.1, 0.3], [0.3, 1.5]], df=2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> fig, ax = plt.subplots(1, 1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> ax.set_aspect('equal')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> plt.contourf(x, y, rv.pdf(pos))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Initialize a multivariate t-distributed random variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed : Random state.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, mvt_docdict_params)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._random_state = check_random_state(seed)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __call__(self, loc=None, shape=1, df=1, allow_singular=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multivariate t-distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `multivariate_t_frozen` for parameters.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif df == np.inf:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multivariate_normal_frozen(mean=loc, cov=shape,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspallow_singular=allow_singular,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed=seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multivariate_t_frozen(loc=loc, shape=shape, df=df,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspallow_singular=allow_singular, seed=seed)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef pdf(self, x, loc=None, shape=1, df=1, allow_singular=False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Multivariate t-distribution probability density function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPoints at which to evaluate the probability density function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvt_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppdf : Probability density function evaluated at `x`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multivariate_t</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [0.4, 5]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> loc = [0, 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> shape = [[1, 0.1], [0.1, 1]]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> df = 7</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> multivariate_t.pdf(x, loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([0.00075713])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim, loc, shape, df = self._process_parameters(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = self._process_quantiles(x, dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape_info = _PSD(shape, allow_singular=allow_singular)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogpdf = self._logpdf(x, loc, shape_info.U, shape_info.log_pdet, df,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim, shape_info.rank)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(logpdf)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef logpdf(self, x, loc=None, shape=1, df=1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate t-distribution probability density function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPoints at which to evaluate the log of the probability density</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvt_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogpdf : Log of the probability density function evaluated at `x`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multivariate_t</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [0.4, 5]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> loc = [0, 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> shape = [[1, 0.1], [0.1, 1]]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> df = 7</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> multivariate_t.logpdf(x, loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([-7.1859802])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppdf : Probability density function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim, loc, shape, df = self._process_parameters(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = self._process_quantiles(x, dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape_info = _PSD(shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._logpdf(x, loc, shape_info.U, shape_info.log_pdet, df, dim,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape_info.rank)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _logpdf(self, x, loc, prec_U, log_pdet, df, dim, rank):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Utility method `pdf`, `logpdf` for parameters.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPoints at which to evaluate the log of the probability density</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLocation of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprec_U : ndarray</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA decomposition such that `np.dot(prec_U, prec_U.T)` is the inverse</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the shape matrix.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_pdet : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLogarithm of the determinant of the shape matrix.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf : float</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDegrees of freedom of the distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim : int</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDimension of the quantiles x.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprank : int</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRank of the shape matrix.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAs this function does no argument checking, it should not be called</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdirectly; use 'logpdf' instead.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif df == np.inf:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multivariate_normal._logpdf(x, loc, prec_U, log_pdet, rank)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdev = x - loc</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaha = np.square(np.dot(dev, prec_U)).sum(axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspt = 0.5 * (df + dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA = gammaln(t)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspB = gammaln(0.5 * df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspC = dim/2. * np.log(df * np.pi)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspD = 0.5 * log_pdet</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspE = -t * np.log(1 + (1./df) * maha)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(A - B - C - D + E)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef rvs(self, loc=None, shape=1, df=1, size=1, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a multivariate t-distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvt_doc_default_callparams)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize : integer, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of samples to draw (default 1).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_random_state)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs : ndarray or scalar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom variates of size (`size`, `P`), where `P` is the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdimension of the random variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multivariate_t</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> x = [0.4, 5]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> loc = [0, 1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> shape = [[1, 0.1], [0.1, 1]]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> df = 7</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> multivariate_t.rvs(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([[0.93477495, 3.00408716]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# For implementation details, see equation (3):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#    Hofert, "On Sampling from the Multivariatet Distribution", 2013</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#     http://rjournal.github.io/archive/2013-2/hofert.pdf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp#</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim, loc, shape, df = self._process_parameters(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif random_state is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprng = check_random_state(random_state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprng = self._random_state</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isinf(df):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.ones(size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = rng.chisquare(df, size=size) / df</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = rng.multivariate_normal(np.zeros(dim), shape, size=size)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsamples = loc + z / np.sqrt(x)[..., None]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _squeeze_output(samples)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _process_quantiles(self, x, dim):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAdjust quantiles array so that last axis labels the components of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspeach data point.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x[np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif x.ndim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x[:, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = x[np.newaxis, :]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _process_parameters(self, loc, shape, df):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInfer dimensionality from location array and shape matrix, handle</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefaults, and ensure compatible dimensions.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif loc is None and shape is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = np.asarray(0, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = np.asarray(1, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif loc is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = np.asarray(shape, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape.ndim < 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = shape.shape[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = np.zeros(dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif shape is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = np.asarray(loc, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = loc.size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = np.eye(dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = np.asarray(shape, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc = np.asarray(loc, dtype=float)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = loc.size</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploc.shape = (1,)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape.shape = (1, 1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif loc.ndim != 1 or loc.shape[0] != dim:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'loc' must be a vector of length %d." %</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = shape * np.eye(dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif shape.ndim == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = np.diag(shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif shape.ndim == 2 and shape.shape != (dim, dim):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprows, cols = shape.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif rows != cols:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("Array 'cov' must be square if it is two dimensional,"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" but cov.shape = %s." % str(shape.shape))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = ("Dimension mismatch: array 'cov' is of shape %s,"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" but 'loc' is a vector of length %d.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmsg = msg % (str(shape.shape), len(loc))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(msg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif shape.ndim > 2:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("Array 'cov' must be at most two-dimensional,"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" but cov.ndim = %d" % shape.ndim)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Process degrees of freedom.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif df is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf = 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif df <= 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("'df' must be greater than zero.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif np.isnan(df):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("'df' is 'nan' but must be greater than zero or 'np.inf'.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dim, loc, shape, df</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class multivariate_t_frozen(multi_rv_frozen):</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, loc=None, shape=1, df=1, allow_singular=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multivariate t distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_mvt_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> loc = np.zeros(3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> shape = np.eye(3)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> df = 10</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> dist = multivariate_t(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> dist.rvs()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([[ 0.81412036, -1.53612361,  0.42199647]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp>>> dist.pdf([1, 1, 1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray([0.01237803])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist = multivariate_t_gen(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim, loc, shape, df = self._dist._process_parameters(loc, shape, df)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.dim, self.loc, self.shape, self.df = dim, loc, shape, df</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shape_info = _PSD(shape, allow_singular=allow_singular)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef logpdf(self, x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = self._dist._process_quantiles(x, self.dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspU = self.shape_info.U</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplog_pdet = self.shape_info.log_pdet</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist._logpdf(x, self.loc, U, log_pdet, self.df, self.dim,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.shape_info.rank)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef pdf(self, x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn np.exp(self.logpdf(x))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef rvs(self, size=1, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.rvs(loc=self.loc,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=self.shape,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdf=self.df,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=size,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state=random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+multivariate_t = multivariate_t_gen()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+# Set frozen generator docstrings from corresponding docstrings in</span>
<br><span style="color:green">+# matrix_normal_gen and fill in default strings in class docstrings</span>
<br><span style="color:green">+for name in ['logpdf', 'pdf', 'rvs']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod = multivariate_t_gen.__dict__[name]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen = multivariate_t_frozen.__dict__[name]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(method.__doc__,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmvt_docdict_noparams)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__, mvt_docdict_params)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mhg_doc_default_callparams = """\</span>
<br><span style="color:green">+m : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe number of each type of object in the population.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThat is, :math:`m[i]` is the number of objects of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptype :math:`i`.</span>
<br><span style="color:green">+n : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe number of samples taken from the population.</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mhg_doc_callparams_note = """\</span>
<br><span style="color:green">+`m` must be an array of positive integers. If the quantile</span>
<br><span style="color:green">+:math:`i` contains values out of the range :math:`[0, m_i]`</span>
<br><span style="color:green">+where :math:`m_i` is the number of objects of type :math:`i`</span>
<br><span style="color:green">+in the population or if the parameters are inconsistent with one</span>
<br><span style="color:green">+another (e.g. ``x.sum() != n``), methods return the appropriate</span>
<br><span style="color:green">+value (e.g. ``0`` for ``pmf``). If `m` or `n` contain negative</span>
<br><span style="color:green">+values, the result will contain ``nan`` there.</span>
<br><span style="color:green">+"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mhg_doc_frozen_callparams = ""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+_mhg_doc_frozen_callparams_note = \</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""See class definition for a detailed description of parameters."""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+mhg_docdict_params = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_default_callparams': _mhg_doc_default_callparams,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_callparams_note': _mhg_doc_callparams_note,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state</span>
<br><span style="color:green">+}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+mhg_docdict_noparams = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_default_callparams': _mhg_doc_frozen_callparams,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_callparams_note': _mhg_doc_frozen_callparams_note,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'_doc_random_state': _doc_random_state</span>
<br><span style="color:green">+}</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class multivariate_hypergeom_gen(multi_rv_generic):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr"""A multivariate hypergeometric random variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMethods</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``pmf(x, m, n)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability mass function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``logpmf(x, m, n)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the probability mass function.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``rvs(m, n, size=1, random_state=None)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDraw random samples from a multivariate hypergeometric</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``mean(m, n)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMean of the multivariate hypergeometric distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``var(m, n)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspVariance of the multivariate hypergeometric distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``cov(m, n)``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCompute the covariance matrix of the multivariate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphypergeometric distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_doc_random_state)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp%(_doc_callparams_note)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe probability mass function for `multivariate_hypergeom` is</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. math::</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspP(X_1 = x_1, X_2 = x_2, \ldots, X_k = x_k) = \frac{\binom{m_1}{x_1}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\binom{m_2}{x_2} \cdots \binom{m_k}{x_k}}{\binom{M}{n}}, \\ \quad</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(x_1, x_2, \ldots, x_k) \in \mathbb{N}^k \text{ with }</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp\sum_{i=1}^k x_i = n</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhere :math:`m_i` are the number of objects of type :math:`i`, :math:`M`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis the total number of objects in the population (sum of all the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`m_i`), and :math:`n` is the size of the sample to be taken</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom the population.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. versionadded:: 1.6.0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspExamples</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTo evaluate the probability mass function of the multivariate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsphypergeometric distribution, with a dichotomous population of size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`10` and :math:`20`, at a sample of size :math:`12` with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp:math:`8` objects of the first type and :math:`4` objects of the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsecond type, use:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import multivariate_hypergeom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> multivariate_hypergeom.pmf(x=[8, 4], m=[10, 20], n=12)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.0025207176631464523</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe `multivariate_hypergeom` distribution is identical to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcorresponding `hypergeom` distribution (tiny numerical differences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnotwithstanding) when only two types (good and bad) of objects</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspare present in the population as in the example above. Consider</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspanother example for a comparison with the hypergeometric distribution:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> from scipy.stats import hypergeom</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> multivariate_hypergeom.pmf(x=[3, 1], m=[10, 5], n=4)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.4395604395604395</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> hypergeom.pmf(k=3, M=15, n=4, N=10)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.43956043956044005</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThe functions ``pmf``, ``logpmf``, ``mean``, ``var``, ``cov``, and ``rvs``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsupport broadcasting, under the convention that the vector parameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(``x``, ``m``, and ``n``) are interpreted as if each row along the last</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis is a single object. For instance, we can combine the previous two</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcalls to `multivariate_hypergeom` as</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> multivariate_hypergeom.pmf(x=[[8, 4], [3, 1]], m=[[10, 20], [10, 5]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp...                            n=[12, 4])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([0.00252072, 0.43956044])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThis broadcasting also works for ``cov``, where the output objects are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsquare matrices of size ``m.shape[-1]``. For example:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> multivariate_hypergeom.cov(m=[[7, 9], [10, 15]], n=[8, 12])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray([[[ 1.05, -1.05],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-1.05,  1.05]],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[[ 1.56, -1.56],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[-1.56,  1.56]]])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspThat is, ``result[0]`` is equal to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp``multivariate_hypergeom.cov(m=[7, 9], n=8)`` and ``result[1]`` is equal</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspto ``multivariate_hypergeom.cov(m=[10, 15], n=12)``.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAlternatively, the object may be called (as a function) to fix the `m`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspand `n` parameters, returning a "frozen" multivariate hypergeometric</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprandom variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rv = multivariate_hypergeom(m=[10, 20], n=12)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp>>> rv.pmf(x=[8, 4])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp0.0025207176631464523</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSee Also</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp--------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.hypergeom : The hypergeometric distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspscipy.stats.multinomial : The multinomial distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReferences</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [1] The Multivariate Hypergeometric Distribution,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttp://www.randomservices.org/random/urn/MultiHypergeometric.html</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp.. [2] Thomas J. Sargent and John Stachurski, 2020,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMultivariate Hypergeometric Distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://python.quantecon.org/_downloads/pdf/multi_hyper.pdf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, seed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuper().__init__(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.__doc__ = doccer.docformat(self.__doc__, mhg_docdict_params)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __call__(self, m, n, seed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a frozen multivariate_hypergeom distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `multivariate_hypergeom_frozen` for more information.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn multivariate_hypergeom_frozen(m, n, seed=seed)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _process_parameters(self, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = np.asarray(m)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = np.asarray(n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm = m.astype(int)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif n.size == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n.astype(int)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.issubdtype(m.dtype, np.integer):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("'m' must an array of integers.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.issubdtype(n.dtype, np.integer):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("'n' must an array of integers.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("'m' must be an array with"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" at least one dimension.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n[..., np.newaxis]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm, n = np.broadcast_arrays(m, n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n[..., 0]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmcond = m < 0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = m.sum(axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspncond = (n < 0) | (n > M)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn M, m, n, mcond, ncond, np.any(mcond, axis=-1) | ncond</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _process_quantiles(self, x, M, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = np.asarray(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not np.issubdtype(x.dtype, np.integer):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError("'x' must an array of integers.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError("'x' must be an array with"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp" at least one dimension.")</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not x.shape[-1] == m.shape[-1]:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f"Size of each quantile must be size of 'm': "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"received {x.shape[-1]}, "</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf"but expected {m.shape[-1]}.")</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n[..., np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = M[..., np.newaxis]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, m, n, M = np.broadcast_arrays(x, m, n, M)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn, M = n[..., 0], M[..., 0]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxcond = (x < 0) | (x > m)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (x, M, m, n, xcond,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.any(xcond, axis=-1) | (x.sum(axis=-1) != n))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _checkresult(self, result, cond, bad_value):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = np.asarray(result)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif cond.ndim != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult[cond] = bad_value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif cond:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn bad_value</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif result.ndim == 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn result[()]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn result</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef _logpmf(self, x, M, m, n, mxcond, ncond):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This equation of the pmf comes from the relation,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# n combine r = beta(n+1, 1) / beta(r+1, n-r+1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum = np.zeros_like(m, dtype=np.float_)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspden = np.zeros_like(n, dtype=np.float_)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm, x = m[~mxcond], x[~mxcond]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, n = M[~ncond], n[~ncond]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum[~mxcond] = (betaln(m+1, 1) - betaln(x+1, m-x+1))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspden[~ncond] = (betaln(M+1, 1) - betaln(n+1, M-n+1))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum[mxcond] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspden[ncond] = np.nan</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnum = num.sum(axis=-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn num - den</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef logpmf(self, x, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Log of the multivariate hypergeometric probability mass function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogpmf : ndarray or scalar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLog of the probability mass function evaluated at `x`</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_callparams_note)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, m, n, mcond, ncond, mncond = self._process_parameters(m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(x, M, m, n, xcond,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxcond_reduced) = self._process_quantiles(x, M, m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmxcond = mcond | xcond</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspncond = ncond | np.zeros(n.shape, dtype=np.bool_)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = self._logpmf(x, M, m, n, mxcond, ncond)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# replace values for which x was out of the domain; broadcast</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# xcond to the right shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspxcond_ = xcond_reduced | np.zeros(mncond.shape, dtype=np.bool_)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = self._checkresult(result, xcond_, np.NINF)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# replace values bad for n or m; broadcast</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# mncond to the right shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmncond_ = mncond | np.zeros(xcond_reduced.shape, dtype=np.bool_)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(result, mncond_, np.nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef pmf(self, x, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Multivariate hypergeometric probability mass function.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspQuantiles, with the last axis of `x` denoting the components.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppmf : ndarray or scalar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspProbability density function evaluated at `x`</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_callparams_note)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = np.exp(self.logpmf(x, m, n))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn out</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef mean(self, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Mean of the multivariate hypergeometric distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean : array_like or scalar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe mean of the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, m, n, _, _, mncond = self._process_parameters(m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, n = M[..., np.newaxis], n[..., np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = (M == 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = np.ma.masked_array(M, mask=cond)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmu = n*(m/M)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmncond = (mncond[..., np.newaxis] |</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros(mu.shape, dtype=np.bool_))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(mu, mncond, np.nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef var(self, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Variance of the multivariate hypergeometric distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe variances of the components of the distribution.  This is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe diagonal of the covariance matrix of the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, m, n, _, _, mncond = self._process_parameters(m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, n = M[..., np.newaxis], n[..., np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = (M == 0) & (M-1 == 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = np.ma.masked_array(M, mask=cond)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = n * m/M * (M-m)/M * (M-n)/(M-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmncond = (mncond[..., np.newaxis] |</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros(output.shape, dtype=np.bool_))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(output, mncond, np.nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef cov(self, m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Covariance matrix of the multivariate hypergeometric distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcov : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe covariance matrix of the distribution</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# see [1]_ for the formula and [2]_ for implementation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# cov( x_i,x_j ) = -n * (M-n)/(M-1) * (K_i*K_j) / (M**2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, m, n, _, _, mncond = self._process_parameters(m, n)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = M[..., np.newaxis, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n[..., np.newaxis, np.newaxis]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = (M == 0) & (M-1 == 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM = np.ma.masked_array(M, mask=cond)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = (-n * (M-n)/(M-1) *</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.einsum("...i,...j->...ij", m, m) / (M**2))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# check for empty arrays</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, n = M[..., 0, 0], n[..., 0, 0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcond = cond[..., 0, 0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim = m.shape[-1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# diagonal entries need to be computed differently</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(dim):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput[..., i, i] = (n * (M-n) * m[..., i]*(M-m[..., i]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput[..., i, i] = output[..., i, i] / (M-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput[..., i, i] = output[..., i, i] / (M**2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif m.size != 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmncond = (mncond[..., np.newaxis, np.newaxis] |</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros(output.shape, dtype=np.bool_))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._checkresult(output, mncond, np.nan)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef rvs(self, m, n, size=None, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Draw random samples from a multivariate hypergeometric distribution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspParameters</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp----------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_default_callparams)s</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize : integer or iterable of integers, optional</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumber of samples to draw. Default is ``None``, in which case a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsingle variate is returned as an array with shape ``m.shape``.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_random_state)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturns</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-------</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs : array_like</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRandom variates of shape ``size`` or ``m.shape``</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(if ``size=None``).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNotes</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-----</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp%(_doc_callparams_note)s</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAlso note that NumPy's `multivariate_hypergeometric` sampler is not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused as it doesn't support broadcasting.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspM, m, n, _, _, _ = self._process_parameters(m, n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state = self._get_random_state(random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size is not None and isinstance(size, int):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize = (size, )</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif size is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs = np.empty(m.shape, dtype=m.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs = np.empty(size + (m.shape[-1], ), dtype=m.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprem = M</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This sampler has been taken from numpy gh-13794</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# https://github.com/numpy/numpy/pull/13794</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor c in range(m.shape[-1] - 1):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprem = rem - m[..., c]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs[..., c] = ((n != 0) *</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state.hypergeometric(m[..., c], rem,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn + (n == 0),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=size))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspn = n - rvs[..., c]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprvs[..., m.shape[-1] - 1] = n</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn rvs</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+multivariate_hypergeom = multivariate_hypergeom_gen()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+class multivariate_hypergeom_frozen(multi_rv_frozen):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef __init__(self, m, n, seed=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist = multivariate_hypergeom_gen(seed)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.M, self.m, self.n,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.mcond, self.ncond,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.mncond) = self._dist._process_parameters(m, n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# monkey patch self._dist</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _process_parameters(m, n):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (self.M, self.m, self.n,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.mcond, self.ncond,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.mncond)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._dist._process_parameters = _process_parameters</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef logpmf(self, x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.logpmf(x, self.m, self.n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef pmf(self, x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.pmf(x, self.m, self.n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef mean(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.mean(self.m, self.n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef var(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.var(self.m, self.n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef cov(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.cov(self.m, self.n)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdef rvs(self, size=1, random_state=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._dist.rvs(self.m, self.n,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=size,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprandom_state=random_state)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+# Set frozen generator docstrings from corresponding docstrings in</span>
<br><span style="color:green">+# multivariate_hypergeom and fill in default strings in class docstrings</span>
<br><span style="color:green">+for name in ['logpmf', 'pmf', 'mean', 'var', 'cov', 'rvs']:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod = multivariate_hypergeom_gen.__dict__[name]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen = multivariate_hypergeom_frozen.__dict__[name]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod_frozen.__doc__ = doccer.docformat(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod.__doc__, mhg_docdict_noparams)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmethod.__doc__ = doccer.docformat(method.__doc__,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmhg_docdict_params)</span>
<br></p>
</div>
<br><br><br>
<br>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
</body>
</html>