
    <!DOCTYPE html>
    <html>
    <head>
    <style>
    .collapsible {
      background-color: #777;
      color: white;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: none;
      text-align: left;
      outline: none;
      font-size: 15px;
    }

    .active, .collapsible:hover {
      background-color: #555;
    }

    .content {
      padding: 0 18px;
      display: none;
      overflow: hidden;
      background-color: #f1f1f1;
    }
    </style>
    </head>
    <body>

_____________________________________tensorflow\python\keras\backend.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13418</th>
      <td>keras\backend_test.py</td>
      <td>55</td>
      <td>compare_single_input_op_to_numpy</td>
      <td>34</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13423</th>
      <td>keras\backend_test.py</td>
      <td>84</td>
      <td>compare_single_input_op_to_numpy</td>
      <td>34</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13427</th>
      <td>keras\backend_test.py</td>
      <td>141</td>
      <td>test_learning_phase_scope</td>
      <td>135</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>137</td>
      <td>keras.backend.learning_phase</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13428</th>
      <td>keras\backend_test.py</td>
      <td>145</td>
      <td>test_learning_phase_scope</td>
      <td>135</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>137</td>
      <td>keras.backend.learning_phase</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13429</th>
      <td>keras\backend_test.py</td>
      <td>149</td>
      <td>test_learning_phase_scope</td>
      <td>135</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>137</td>
      <td>keras.backend.learning_phase</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13430</th>
      <td>keras\backend_test.py</td>
      <td>153</td>
      <td>test_int_shape</td>
      <td>151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>152</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13431</th>
      <td>keras\backend_test.py</td>
      <td>156</td>
      <td>test_int_shape</td>
      <td>151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>152</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13432</th>
      <td>keras\backend_test.py</td>
      <td>156</td>
      <td>test_int_shape</td>
      <td>151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>155</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13433</th>
      <td>keras\backend_test.py</td>
      <td>171</td>
      <td>test_is_keras_tensor</td>
      <td>169</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>170</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13434</th>
      <td>keras\backend_test.py</td>
      <td>173</td>
      <td>test_is_keras_tensor</td>
      <td>169</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>170</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13436</th>
      <td>keras\backend_test.py</td>
      <td>179</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>178</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13437</th>
      <td>keras\backend_test.py</td>
      <td>182</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>178</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13439</th>
      <td>keras\backend_test.py</td>
      <td>184</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>178</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13441</th>
      <td>keras\backend_test.py</td>
      <td>184</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>183</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13443</th>
      <td>keras\backend_test.py</td>
      <td>211</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>203</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13446</th>
      <td>keras\backend_test.py</td>
      <td>213</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>203</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13450</th>
      <td>keras\backend_test.py</td>
      <td>218</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>203</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13451</th>
      <td>keras\backend_test.py</td>
      <td>218</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>216</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13456</th>
      <td>keras\backend_test.py</td>
      <td>222</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>203</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13457</th>
      <td>keras\backend_test.py</td>
      <td>222</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>216</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13463</th>
      <td>keras\backend_test.py</td>
      <td>227</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>203</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13464</th>
      <td>keras\backend_test.py</td>
      <td>227</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>216</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13465</th>
      <td>keras\backend_test.py</td>
      <td>227</td>
      <td>test_function_tf_feed_symbols</td>
      <td>196</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>225</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13473</th>
      <td>keras\backend_test.py</td>
      <td>341</td>
      <td>test_zeros</td>
      <td>337</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>340</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13474</th>
      <td>keras\backend_test.py</td>
      <td>341</td>
      <td>test_zeros</td>
      <td>337</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>339</td>
      <td>keras.backend.zeros</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13475</th>
      <td>keras\backend_test.py</td>
      <td>347</td>
      <td>test_ones</td>
      <td>343</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>346</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13476</th>
      <td>keras\backend_test.py</td>
      <td>347</td>
      <td>test_ones</td>
      <td>343</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>345</td>
      <td>keras.backend.ones</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13477</th>
      <td>keras\backend_test.py</td>
      <td>353</td>
      <td>test_eye</td>
      <td>349</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>352</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13478</th>
      <td>keras\backend_test.py</td>
      <td>353</td>
      <td>test_eye</td>
      <td>349</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>351</td>
      <td>keras.backend.eye</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13479</th>
      <td>keras\backend_test.py</td>
      <td>360</td>
      <td>test_zeros_like</td>
      <td>355</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>359</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13480</th>
      <td>keras\backend_test.py</td>
      <td>360</td>
      <td>test_zeros_like</td>
      <td>355</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>358</td>
      <td>keras.backend.zeros_like</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13481</th>
      <td>keras\backend_test.py</td>
      <td>360</td>
      <td>test_zeros_like</td>
      <td>355</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>357</td>
      <td>keras.backend.zeros</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13482</th>
      <td>keras\backend_test.py</td>
      <td>367</td>
      <td>test_ones_like</td>
      <td>362</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>366</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13483</th>
      <td>keras\backend_test.py</td>
      <td>367</td>
      <td>test_ones_like</td>
      <td>362</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>365</td>
      <td>keras.backend.ones_like</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13484</th>
      <td>keras\backend_test.py</td>
      <td>367</td>
      <td>test_ones_like</td>
      <td>362</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>364</td>
      <td>keras.backend.zeros</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13485</th>
      <td>keras\backend_test.py</td>
      <td>373</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>372</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13486</th>
      <td>keras\backend_test.py</td>
      <td>373</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>371</td>
      <td>keras.backend.random_uniform_variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13487</th>
      <td>keras\backend_test.py</td>
      <td>374</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>372</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13488</th>
      <td>keras\backend_test.py</td>
      <td>374</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>371</td>
      <td>keras.backend.random_uniform_variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13489</th>
      <td>keras\backend_test.py</td>
      <td>375</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>372</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13490</th>
      <td>keras\backend_test.py</td>
      <td>375</td>
      <td>test_random_uniform_variable</td>
      <td>369</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>371</td>
      <td>keras.backend.random_uniform_variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13491</th>
      <td>keras\backend_test.py</td>
      <td>382</td>
      <td>test_random_normal_variable</td>
      <td>377</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>381</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13492</th>
      <td>keras\backend_test.py</td>
      <td>382</td>
      <td>test_random_normal_variable</td>
      <td>377</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>379</td>
      <td>keras.backend.random_normal_variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13493</th>
      <td>keras\backend_test.py</td>
      <td>383</td>
      <td>test_random_normal_variable</td>
      <td>377</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>381</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13494</th>
      <td>keras\backend_test.py</td>
      <td>383</td>
      <td>test_random_normal_variable</td>
      <td>377</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>379</td>
      <td>keras.backend.random_normal_variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13495</th>
      <td>keras\backend_test.py</td>
      <td>389</td>
      <td>test_count_params</td>
      <td>385</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>388</td>
      <td>keras.backend.count_params</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13496</th>
      <td>keras\backend_test.py</td>
      <td>389</td>
      <td>test_count_params</td>
      <td>385</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>387</td>
      <td>keras.backend.zeros</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13497</th>
      <td>keras\backend_test.py</td>
      <td>396</td>
      <td>test_constant</td>
      <td>391</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>395</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13498</th>
      <td>keras\backend_test.py</td>
      <td>396</td>
      <td>test_constant</td>
      <td>391</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>394</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13501</th>
      <td>keras\backend_test.py</td>
      <td>402</td>
      <td>test_sparse_variable</td>
      <td>398</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>401</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13503</th>
      <td>keras\backend_test.py</td>
      <td>405</td>
      <td>test_sparse_variable</td>
      <td>398</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>404</td>
      <td>keras.backend.to_dense</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13504</th>
      <td>keras\backend_test.py</td>
      <td>405</td>
      <td>test_sparse_variable</td>
      <td>398</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>401</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13506</th>
      <td>keras\backend_test.py</td>
      <td>409</td>
      <td>test_placeholder</td>
      <td>407</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>408</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13507</th>
      <td>keras\backend_test.py</td>
      <td>411</td>
      <td>test_placeholder</td>
      <td>407</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>408</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13508</th>
      <td>keras\backend_test.py</td>
      <td>411</td>
      <td>test_placeholder</td>
      <td>407</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>410</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13509</th>
      <td>keras\backend_test.py</td>
      <td>420</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>419</td>
      <td>keras.backend.dot</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13510</th>
      <td>keras\backend_test.py</td>
      <td>420</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>417</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13511</th>
      <td>keras\backend_test.py</td>
      <td>420</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>418</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13512</th>
      <td>keras\backend_test.py</td>
      <td>425</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>419</td>
      <td>keras.backend.dot</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13513</th>
      <td>keras\backend_test.py</td>
      <td>425</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>424</td>
      <td>keras.backend.dot</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13514</th>
      <td>keras\backend_test.py</td>
      <td>425</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>417</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13515</th>
      <td>keras\backend_test.py</td>
      <td>425</td>
      <td>test_dot</td>
      <td>416</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>418</td>
      <td>keras.backend.placeholder</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13516</th>
      <td>keras\backend_test.py</td>
      <td>431</td>
      <td>test_batch_dot</td>
      <td>427</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>430</td>
      <td>keras.backend.batch_dot</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13517</th>
      <td>keras\backend_test.py</td>
      <td>431</td>
      <td>test_batch_dot</td>
      <td>427</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>428</td>
      <td>keras.backend.ones</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13518</th>
      <td>keras\backend_test.py</td>
      <td>431</td>
      <td>test_batch_dot</td>
      <td>427</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>429</td>
      <td>keras.backend.ones</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13519</th>
      <td>keras\backend_test.py</td>
      <td>523</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13521</th>
      <td>keras\backend_test.py</td>
      <td>528</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13522</th>
      <td>keras\backend_test.py</td>
      <td>528</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13524</th>
      <td>keras\backend_test.py</td>
      <td>532</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13525</th>
      <td>keras\backend_test.py</td>
      <td>532</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13526</th>
      <td>keras\backend_test.py</td>
      <td>532</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13528</th>
      <td>keras\backend_test.py</td>
      <td>537</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13529</th>
      <td>keras\backend_test.py</td>
      <td>537</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13530</th>
      <td>keras\backend_test.py</td>
      <td>537</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13531</th>
      <td>keras\backend_test.py</td>
      <td>537</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13533</th>
      <td>keras\backend_test.py</td>
      <td>541</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13534</th>
      <td>keras\backend_test.py</td>
      <td>541</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13535</th>
      <td>keras\backend_test.py</td>
      <td>541</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13536</th>
      <td>keras\backend_test.py</td>
      <td>541</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13537</th>
      <td>keras\backend_test.py</td>
      <td>541</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13539</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13540</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13541</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13542</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13543</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13544</th>
      <td>keras\backend_test.py</td>
      <td>545</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13546</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13547</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13548</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13549</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13550</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13551</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13552</th>
      <td>keras\backend_test.py</td>
      <td>549</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13554</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13555</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13556</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13557</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13558</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13559</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13560</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13561</th>
      <td>keras\backend_test.py</td>
      <td>553</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13563</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13564</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13565</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13566</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13567</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13568</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13569</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13570</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13571</th>
      <td>keras\backend_test.py</td>
      <td>557</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13573</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13574</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13575</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13576</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13577</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13578</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13579</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13580</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13581</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13582</th>
      <td>keras\backend_test.py</td>
      <td>561</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13584</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13585</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13586</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13587</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13588</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13589</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13590</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13591</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13592</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13593</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13594</th>
      <td>keras\backend_test.py</td>
      <td>565</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>564</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13596</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13597</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13598</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13599</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13600</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13601</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13602</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13603</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13604</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13605</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13606</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>564</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13607</th>
      <td>keras\backend_test.py</td>
      <td>569</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>568</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13609</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13610</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13611</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13612</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13613</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13614</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13615</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13616</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13617</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13618</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13619</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>564</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13620</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>568</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13621</th>
      <td>keras\backend_test.py</td>
      <td>573</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>572</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13623</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13624</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>526</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13625</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>531</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13626</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>535</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13627</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>540</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13628</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>544</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13629</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>548</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13630</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>552</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13631</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>556</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13632</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13633</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>564</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13634</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>568</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13635</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>572</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13636</th>
      <td>keras\backend_test.py</td>
      <td>577</td>
      <td>test_relu</td>
      <td>518</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>576</td>
      <td>keras.backend.relu</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13638</th>
      <td>keras\backend_test.py</td>
      <td>593</td>
      <td>test_concatenate</td>
      <td>589</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>592</td>
      <td>keras.backend.concatenate</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13639</th>
      <td>keras\backend_test.py</td>
      <td>593</td>
      <td>test_concatenate</td>
      <td>589</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>590</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13640</th>
      <td>keras\backend_test.py</td>
      <td>593</td>
      <td>test_concatenate</td>
      <td>589</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>591</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13641</th>
      <td>keras\backend_test.py</td>
      <td>612</td>
      <td>test_resize_images</td>
      <td>603</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>608</td>
      <td>keras.backend.resize_images</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13642</th>
      <td>keras\backend_test.py</td>
      <td>612</td>
      <td>test_resize_images</td>
      <td>603</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>607</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13643</th>
      <td>keras\backend_test.py</td>
      <td>620</td>
      <td>test_resize_images</td>
      <td>603</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>608</td>
      <td>keras.backend.resize_images</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13644</th>
      <td>keras\backend_test.py</td>
      <td>620</td>
      <td>test_resize_images</td>
      <td>603</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>616</td>
      <td>keras.backend.resize_images</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13645</th>
      <td>keras\backend_test.py</td>
      <td>620</td>
      <td>test_resize_images</td>
      <td>603</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>607</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13646</th>
      <td>keras\backend_test.py</td>
      <td>640</td>
      <td>test_resize_volumes</td>
      <td>629</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>635</td>
      <td>keras.backend.resize_volumes</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13647</th>
      <td>keras\backend_test.py</td>
      <td>640</td>
      <td>test_resize_volumes</td>
      <td>629</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>634</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13648</th>
      <td>keras\backend_test.py</td>
      <td>649</td>
      <td>test_resize_volumes</td>
      <td>629</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>635</td>
      <td>keras.backend.resize_volumes</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13649</th>
      <td>keras\backend_test.py</td>
      <td>649</td>
      <td>test_resize_volumes</td>
      <td>629</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>644</td>
      <td>keras.backend.resize_volumes</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13650</th>
      <td>keras\backend_test.py</td>
      <td>649</td>
      <td>test_resize_volumes</td>
      <td>629</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>634</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13651</th>
      <td>keras\backend_test.py</td>
      <td>662</td>
      <td>test_repeat_elements</td>
      <td>659</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>661</td>
      <td>keras.backend.repeat_elements</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13652</th>
      <td>keras\backend_test.py</td>
      <td>662</td>
      <td>test_repeat_elements</td>
      <td>659</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>660</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13653</th>
      <td>keras\backend_test.py</td>
      <td>667</td>
      <td>test_repeat_elements</td>
      <td>659</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>661</td>
      <td>keras.backend.repeat_elements</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13654</th>
      <td>keras\backend_test.py</td>
      <td>667</td>
      <td>test_repeat_elements</td>
      <td>659</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>666</td>
      <td>keras.backend.repeat_elements</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13655</th>
      <td>keras\backend_test.py</td>
      <td>667</td>
      <td>test_repeat_elements</td>
      <td>659</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>660</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13656</th>
      <td>keras\backend_test.py</td>
      <td>672</td>
      <td>test_repeat</td>
      <td>669</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>671</td>
      <td>keras.backend.repeat</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13657</th>
      <td>keras\backend_test.py</td>
      <td>672</td>
      <td>test_repeat</td>
      <td>669</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>670</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13658</th>
      <td>keras\backend_test.py</td>
      <td>836</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>833</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13659</th>
      <td>keras\backend_test.py</td>
      <td>836</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>832</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13661</th>
      <td>keras\backend_test.py</td>
      <td>841</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>833</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13662</th>
      <td>keras\backend_test.py</td>
      <td>841</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>838</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13663</th>
      <td>keras\backend_test.py</td>
      <td>841</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>832</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>keras\backend_test.py</td>
      <td>847</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>833</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13666</th>
      <td>keras\backend_test.py</td>
      <td>847</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>838</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13667</th>
      <td>keras\backend_test.py</td>
      <td>847</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>845</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13668</th>
      <td>keras\backend_test.py</td>
      <td>847</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>832</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13670</th>
      <td>keras\backend_test.py</td>
      <td>853</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>833</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13671</th>
      <td>keras\backend_test.py</td>
      <td>853</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>838</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13672</th>
      <td>keras\backend_test.py</td>
      <td>853</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>845</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13673</th>
      <td>keras\backend_test.py</td>
      <td>853</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>851</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13674</th>
      <td>keras\backend_test.py</td>
      <td>853</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>832</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13676</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>833</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13677</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>838</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13678</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>845</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13679</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>851</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13680</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>857</td>
      <td>keras.backend.pool2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13681</th>
      <td>keras\backend_test.py</td>
      <td>859</td>
      <td>test_pool2d</td>
      <td>830</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>832</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13683</th>
      <td>keras\backend_test.py</td>
      <td>880</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>877</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13684</th>
      <td>keras\backend_test.py</td>
      <td>880</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>876</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13686</th>
      <td>keras\backend_test.py</td>
      <td>885</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>877</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13687</th>
      <td>keras\backend_test.py</td>
      <td>885</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>882</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13688</th>
      <td>keras\backend_test.py</td>
      <td>885</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>876</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13690</th>
      <td>keras\backend_test.py</td>
      <td>891</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>877</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13691</th>
      <td>keras\backend_test.py</td>
      <td>891</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>882</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13692</th>
      <td>keras\backend_test.py</td>
      <td>891</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>889</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13693</th>
      <td>keras\backend_test.py</td>
      <td>891</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>876</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13695</th>
      <td>keras\backend_test.py</td>
      <td>897</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>877</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13696</th>
      <td>keras\backend_test.py</td>
      <td>897</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>882</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13697</th>
      <td>keras\backend_test.py</td>
      <td>897</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>889</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13698</th>
      <td>keras\backend_test.py</td>
      <td>897</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>895</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13699</th>
      <td>keras\backend_test.py</td>
      <td>897</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>876</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13701</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>877</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13702</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>882</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13703</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>889</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13704</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>895</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13705</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>901</td>
      <td>keras.backend.pool3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13706</th>
      <td>keras\backend_test.py</td>
      <td>903</td>
      <td>test_pool3d</td>
      <td>874</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>876</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13708</th>
      <td>keras\backend_test.py</td>
      <td>912</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>910</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13709</th>
      <td>keras\backend_test.py</td>
      <td>912</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>907</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13711</th>
      <td>keras\backend_test.py</td>
      <td>912</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>909</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13713</th>
      <td>keras\backend_test.py</td>
      <td>918</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>910</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13714</th>
      <td>keras\backend_test.py</td>
      <td>918</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>916</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13715</th>
      <td>keras\backend_test.py</td>
      <td>918</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>907</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13717</th>
      <td>keras\backend_test.py</td>
      <td>918</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>909</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13719</th>
      <td>keras\backend_test.py</td>
      <td>924</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>910</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13720</th>
      <td>keras\backend_test.py</td>
      <td>924</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>916</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13721</th>
      <td>keras\backend_test.py</td>
      <td>924</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>922</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13722</th>
      <td>keras\backend_test.py</td>
      <td>924</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>907</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13724</th>
      <td>keras\backend_test.py</td>
      <td>924</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>909</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13726</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>910</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13727</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>916</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13728</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>922</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13729</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>928</td>
      <td>keras.backend.conv1d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13730</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>907</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13732</th>
      <td>keras\backend_test.py</td>
      <td>930</td>
      <td>test_conv1d</td>
      <td>905</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>909</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13735</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>989</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13736</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>942</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13739</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>963</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13744</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>990</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13746</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>974</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13750</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>980</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13754</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>1039</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13756</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>1011</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13758</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>1016</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13761</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>1040</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13763</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>1011</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13765</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>1016</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13766</th>
      <td>keras\backend_test.py</td>
      <td>1051</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1049</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13767</th>
      <td>keras\backend_test.py</td>
      <td>1051</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1046</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13769</th>
      <td>keras\backend_test.py</td>
      <td>1051</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1048</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13771</th>
      <td>keras\backend_test.py</td>
      <td>1057</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1049</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13772</th>
      <td>keras\backend_test.py</td>
      <td>1057</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1055</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13773</th>
      <td>keras\backend_test.py</td>
      <td>1057</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1046</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13775</th>
      <td>keras\backend_test.py</td>
      <td>1057</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1048</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13777</th>
      <td>keras\backend_test.py</td>
      <td>1063</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1049</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13778</th>
      <td>keras\backend_test.py</td>
      <td>1063</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1055</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13779</th>
      <td>keras\backend_test.py</td>
      <td>1063</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1061</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13780</th>
      <td>keras\backend_test.py</td>
      <td>1063</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1046</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13782</th>
      <td>keras\backend_test.py</td>
      <td>1063</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1048</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13784</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1049</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13785</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1055</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13786</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1061</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13787</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1067</td>
      <td>keras.backend.conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13788</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1046</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13790</th>
      <td>keras\backend_test.py</td>
      <td>1069</td>
      <td>test_conv2d</td>
      <td>1044</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1048</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13792</th>
      <td>keras\backend_test.py</td>
      <td>1088</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1086</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13793</th>
      <td>keras\backend_test.py</td>
      <td>1088</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1081</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13795</th>
      <td>keras\backend_test.py</td>
      <td>1088</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1084</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13797</th>
      <td>keras\backend_test.py</td>
      <td>1088</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1085</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13799</th>
      <td>keras\backend_test.py</td>
      <td>1094</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1086</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13800</th>
      <td>keras\backend_test.py</td>
      <td>1094</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1092</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13801</th>
      <td>keras\backend_test.py</td>
      <td>1094</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1081</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13803</th>
      <td>keras\backend_test.py</td>
      <td>1094</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1084</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13805</th>
      <td>keras\backend_test.py</td>
      <td>1094</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1085</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13807</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1086</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13808</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1092</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13809</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1098</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13810</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1081</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13812</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1084</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13814</th>
      <td>keras\backend_test.py</td>
      <td>1100</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1085</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13816</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1086</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13817</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1092</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13818</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1098</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13819</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1104</td>
      <td>keras.backend.separable_conv2d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13820</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1081</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13822</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1084</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13824</th>
      <td>keras\backend_test.py</td>
      <td>1106</td>
      <td>test_separable_conv2d</td>
      <td>1079</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1085</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13826</th>
      <td>keras\backend_test.py</td>
      <td>1123</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1121</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13827</th>
      <td>keras\backend_test.py</td>
      <td>1123</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1118</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13829</th>
      <td>keras\backend_test.py</td>
      <td>1123</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1120</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13831</th>
      <td>keras\backend_test.py</td>
      <td>1129</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1121</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13832</th>
      <td>keras\backend_test.py</td>
      <td>1129</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1127</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13833</th>
      <td>keras\backend_test.py</td>
      <td>1129</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1118</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13835</th>
      <td>keras\backend_test.py</td>
      <td>1129</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1120</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13837</th>
      <td>keras\backend_test.py</td>
      <td>1135</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1121</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13838</th>
      <td>keras\backend_test.py</td>
      <td>1135</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1127</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13839</th>
      <td>keras\backend_test.py</td>
      <td>1135</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1133</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13840</th>
      <td>keras\backend_test.py</td>
      <td>1135</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1118</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13842</th>
      <td>keras\backend_test.py</td>
      <td>1135</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1120</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13844</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1121</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13845</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1127</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13846</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1133</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13847</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1139</td>
      <td>keras.backend.conv3d</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13848</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1118</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13850</th>
      <td>keras\backend_test.py</td>
      <td>1141</td>
      <td>test_conv3d</td>
      <td>1116</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1120</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13852</th>
      <td>keras\backend_test.py</td>
      <td>1202</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1198</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13854</th>
      <td>keras\backend_test.py</td>
      <td>1202</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1167</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13856</th>
      <td>keras\backend_test.py</td>
      <td>1202</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1168</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13858</th>
      <td>keras\backend_test.py</td>
      <td>1202</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1184</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13861</th>
      <td>keras\backend_test.py</td>
      <td>1204</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1198</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13863</th>
      <td>keras\backend_test.py</td>
      <td>1204</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1167</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13865</th>
      <td>keras\backend_test.py</td>
      <td>1204</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1168</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13867</th>
      <td>keras\backend_test.py</td>
      <td>1204</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>1184</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13870</th>
      <td>keras\backend_test.py</td>
      <td>1212</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1198</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13872</th>
      <td>keras\backend_test.py</td>
      <td>1212</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1167</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13874</th>
      <td>keras\backend_test.py</td>
      <td>1212</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1168</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13876</th>
      <td>keras\backend_test.py</td>
      <td>1212</td>
      <td>test_rnn</td>
      <td>1151</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1184</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13879</th>
      <td>keras\backend_test.py</td>
      <td>1298</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1294</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13881</th>
      <td>keras\backend_test.py</td>
      <td>1298</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1260</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13883</th>
      <td>keras\backend_test.py</td>
      <td>1298</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1261</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13885</th>
      <td>keras\backend_test.py</td>
      <td>1298</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1279</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13888</th>
      <td>keras\backend_test.py</td>
      <td>1300</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1294</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13890</th>
      <td>keras\backend_test.py</td>
      <td>1300</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1260</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13892</th>
      <td>keras\backend_test.py</td>
      <td>1300</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1261</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13894</th>
      <td>keras\backend_test.py</td>
      <td>1300</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1279</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13897</th>
      <td>keras\backend_test.py</td>
      <td>1312</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1294</td>
      <td>keras.backend.rnn</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13899</th>
      <td>keras\backend_test.py</td>
      <td>1312</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1260</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13901</th>
      <td>keras\backend_test.py</td>
      <td>1312</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1261</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13903</th>
      <td>keras\backend_test.py</td>
      <td>1312</td>
      <td>test_rnn_additional_states</td>
      <td>1244</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1279</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13906</th>
      <td>keras\backend_test.py</td>
      <td>1364</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13907</th>
      <td>keras\backend_test.py</td>
      <td>1364</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13909</th>
      <td>keras\backend_test.py</td>
      <td>1364</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13911</th>
      <td>keras\backend_test.py</td>
      <td>1364</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13913</th>
      <td>keras\backend_test.py</td>
      <td>1365</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13914</th>
      <td>keras\backend_test.py</td>
      <td>1365</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13916</th>
      <td>keras\backend_test.py</td>
      <td>1365</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13918</th>
      <td>keras\backend_test.py</td>
      <td>1365</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13920</th>
      <td>keras\backend_test.py</td>
      <td>1366</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13921</th>
      <td>keras\backend_test.py</td>
      <td>1366</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13923</th>
      <td>keras\backend_test.py</td>
      <td>1366</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13925</th>
      <td>keras\backend_test.py</td>
      <td>1366</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13927</th>
      <td>keras\backend_test.py</td>
      <td>1372</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13928</th>
      <td>keras\backend_test.py</td>
      <td>1372</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13929</th>
      <td>keras\backend_test.py</td>
      <td>1372</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13931</th>
      <td>keras\backend_test.py</td>
      <td>1372</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13933</th>
      <td>keras\backend_test.py</td>
      <td>1372</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13935</th>
      <td>keras\backend_test.py</td>
      <td>1373</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13936</th>
      <td>keras\backend_test.py</td>
      <td>1373</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13937</th>
      <td>keras\backend_test.py</td>
      <td>1373</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13939</th>
      <td>keras\backend_test.py</td>
      <td>1373</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13941</th>
      <td>keras\backend_test.py</td>
      <td>1373</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13943</th>
      <td>keras\backend_test.py</td>
      <td>1374</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13944</th>
      <td>keras\backend_test.py</td>
      <td>1374</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13945</th>
      <td>keras\backend_test.py</td>
      <td>1374</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13947</th>
      <td>keras\backend_test.py</td>
      <td>1374</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13949</th>
      <td>keras\backend_test.py</td>
      <td>1374</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13951</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13952</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13953</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1378</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13954</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13956</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13958</th>
      <td>keras\backend_test.py</td>
      <td>1380</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13960</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13961</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13962</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1378</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13963</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13965</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13967</th>
      <td>keras\backend_test.py</td>
      <td>1381</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13969</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1362</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13970</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1370</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13971</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1378</td>
      <td>keras.backend.normalize_batch_in_training</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13972</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1355</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13974</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1360</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13976</th>
      <td>keras\backend_test.py</td>
      <td>1382</td>
      <td>test_normalize_batch_in_training</td>
      <td>1353</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1361</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13978</th>
      <td>keras\backend_test.py</td>
      <td>1428</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1421</td>
      <td>keras.backend.ctc_decode</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13979</th>
      <td>keras\backend_test.py</td>
      <td>1428</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1406</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13980</th>
      <td>keras\backend_test.py</td>
      <td>1428</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1409</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13981</th>
      <td>keras\backend_test.py</td>
      <td>1434</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>1429</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13982</th>
      <td>keras\backend_test.py</td>
      <td>1434</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>1421</td>
      <td>keras.backend.ctc_decode</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13983</th>
      <td>keras\backend_test.py</td>
      <td>1434</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>1406</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13984</th>
      <td>keras\backend_test.py</td>
      <td>1434</td>
      <td>test_ctc_decode</td>
      <td>1387</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>1409</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13985</th>
      <td>keras\backend_test.py</td>
      <td>1496</td>
      <td>test_random_binomial</td>
      <td>1492</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1495</td>
      <td>keras.backend.random_binomial</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13986</th>
      <td>keras\backend_test.py</td>
      <td>1503</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1502</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13987</th>
      <td>keras\backend_test.py</td>
      <td>1503</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1501</td>
      <td>keras.backend.truncated_normal</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13988</th>
      <td>keras\backend_test.py</td>
      <td>1504</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1502</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13989</th>
      <td>keras\backend_test.py</td>
      <td>1504</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1501</td>
      <td>keras.backend.truncated_normal</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13990</th>
      <td>keras\backend_test.py</td>
      <td>1505</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1502</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13991</th>
      <td>keras\backend_test.py</td>
      <td>1505</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1501</td>
      <td>keras.backend.truncated_normal</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13992</th>
      <td>keras\backend_test.py</td>
      <td>1506</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1502</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>13993</th>
      <td>keras\backend_test.py</td>
      <td>1506</td>
      <td>test_truncated_normal</td>
      <td>1498</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>1501</td>
      <td>keras.backend.truncated_normal</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14006</th>
      <td>keras\constraints_test.py</td>
      <td>69</td>
      <td>test_max_norm</td>
      <td>51</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>67</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14007</th>
      <td>keras\initializers_test.py</td>
      <td>39</td>
      <td>_runner</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>33</td>
      <td>keras.backend.get_value</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14008</th>
      <td>keras\initializers_test.py</td>
      <td>39</td>
      <td>_runner</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>32</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14009</th>
      <td>keras\initializers_test.py</td>
      <td>39</td>
      <td>_runner</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>38</td>
      <td>keras.backend.get_value</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14010</th>
      <td>keras\initializers_test.py</td>
      <td>39</td>
      <td>_runner</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>32</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14011</th>
      <td>keras\initializers_test.py</td>
      <td>39</td>
      <td>_runner</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>37</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14030</th>
      <td>keras\losses_test.py</td>
      <td>105</td>
      <td>test_categorical_hinge</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>104</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14031</th>
      <td>keras\losses_test.py</td>
      <td>105</td>
      <td>test_categorical_hinge</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>102</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14032</th>
      <td>keras\losses_test.py</td>
      <td>105</td>
      <td>test_categorical_hinge</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>100</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14151</th>
      <td>keras\models_test.py</td>
      <td>391</td>
      <td>assert_optimizer_iterations_increases</td>
      <td>369</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>383</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14922</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>759</td>
      <td>test_upsampling_2d</td>
      <td>712</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>743</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14933</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>816</td>
      <td>test_upsampling_3d</td>
      <td>762</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>796</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14946</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>879</td>
      <td>test_cropping_2d</td>
      <td>841</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>871</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14953</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>900</td>
      <td>test_cropping_2d</td>
      <td>841</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>871</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14955</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>900</td>
      <td>test_cropping_2d</td>
      <td>841</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>898</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>14964</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>955</td>
      <td>test_cropping_3d</td>
      <td>909</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>943</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15003</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>114</td>
      <td>test_regularizer</td>
      <td>88</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>111</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15029</th>
      <td>keras\layers\embeddings_test.py</td>
      <td>81</td>
      <td>test_embedding_correctness</td>
      <td>72</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>80</td>
      <td>keras.backend.eval</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15030</th>
      <td>keras\layers\embeddings_test.py</td>
      <td>81</td>
      <td>test_embedding_correctness</td>
      <td>72</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>79</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15033</th>
      <td>keras\layers\embeddings_test.py</td>
      <td>93</td>
      <td>test_eager_gpu_cpu</td>
      <td>84</td>
      <td>assertAllEqual</td>
      <td>1</td>
      <td>87</td>
      <td>keras.backend.constant</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15049</th>
      <td>keras\layers\gru_test.py</td>
      <td>164</td>
      <td>test_regularizers_GRU</td>
      <td>146</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>162</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15089</th>
      <td>keras\layers\local_test.py</td>
      <td>316</td>
      <td>test_make_2d</td>
      <td>282</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>314</td>
      <td>keras.backend.get_value</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15090</th>
      <td>keras\layers\local_test.py</td>
      <td>316</td>
      <td>test_make_2d</td>
      <td>282</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>306</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15107</th>
      <td>keras\layers\lstm_test.py</td>
      <td>178</td>
      <td>test_regularizers_LSTM</td>
      <td>161</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>176</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
    <tr>
      <th>15462</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>164</td>
      <td>test_regularizers_SimpleRNN</td>
      <td>146</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>162</td>
      <td>keras.backend.variable</td>
      <td>tensorflow\python\keras\backend.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 74264656a3345712d0c1310721d23424bb813ff1

 <br>Commit message: Made error message in keras.backend.bias_add match check<br><br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/backend.py b/tensorflow/python/keras/backend.py
<br>index a5b077be984..d2423365cc2 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/backend.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/backend.py</span>
<br>@@ -15,11 +15,8 @@
<br>&nbsp# pylint: disable=protected-access
<br>&nbsp# pylint: disable=redefined-outer-name
<br>&nbsp# pylint: disable=redefined-builtin
<br><span style="color:red">- """Keras backend API.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+"""Keras backend API."""</span>
<br>&nbsp
<br>&nbspimport collections
<br>&nbspimport itertools
<br>@@ -35,12 +32,8 @@ import numpy as np
<br>&nbspfrom tensorflow.core.protobuf import config_pb2
<br>&nbspfrom tensorflow.python import tf2
<br>&nbspfrom tensorflow.python.client import session as session_module
<br><span style="color:red">- from tensorflow.python.distribute import distribute_coordinator as dc</span>
<br><span style="color:red">- from tensorflow.python.distribute import distribute_coordinator_context as dc_context</span>
<br>&nbspfrom tensorflow.python.distribute import distribution_strategy_context
<br>&nbspfrom tensorflow.python.eager import context
<br><span style="color:red">- from tensorflow.python.eager import function as eager_function</span>
<br><span style="color:red">- from tensorflow.python.eager import lift_to_graph</span>
<br>&nbspfrom tensorflow.python.eager.context import get_config
<br>&nbspfrom tensorflow.python.framework import composite_tensor
<br>&nbspfrom tensorflow.python.framework import config
<br>@@ -54,6 +47,7 @@ from tensorflow.python.framework import tensor_shape
<br>&nbspfrom tensorflow.python.framework import tensor_spec
<br>&nbspfrom tensorflow.python.framework import tensor_util
<br>&nbspfrom tensorflow.python.keras import backend_config
<br><span style="color:green">+from tensorflow.python.keras.distribute import distribute_coordinator_utils as dc</span>
<br>&nbspfrom tensorflow.python.keras.engine import keras_tensor
<br>&nbspfrom tensorflow.python.keras.utils import control_flow_util
<br>&nbspfrom tensorflow.python.keras.utils import object_identity
<br>@@ -134,7 +128,7 @@ class _DummyEagerGraph(threading.local):
<br>&nbsp &nbsp &nbspweak references.
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspclass _WeakReferencableClass(object):</span>
<br><span style="color:green">+&nbsp &nbspclass _WeakReferencableClass:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""This dummy class is needed for two reasons.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp- We need something that supports weak references. Basic types like string
<br>@@ -318,6 +312,9 @@ def clear_session():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_GRAPH_LEARNING_PHASES.setdefault(graph)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_GRAPH_VARIABLES.pop(graph, None)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_GRAPH_TF_OPTIMIZERS.pop(graph, None)
<br><span style="color:green">+&nbsp &nbspif context.executing_eagerly():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Clear pending nodes in eager executors, kernel caches and step_containers.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcontext.context().clear_kernel_cache()</span>
<br>&nbsp
<br>&nbsp# Inject the clear_session function to keras_deps to remove the dependency
<br>&nbsp# from TFLite to Keras.
<br>@@ -840,7 +837,7 @@ def get_default_graph_uid_map():
<br>&nbsp# DEVICE MANIPULATION
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class _TfDeviceCaptureOp(object):</span>
<br><span style="color:green">+class _TfDeviceCaptureOp:</span>
<br>&nbsp &nbsp &nbsp"""Class for capturing the TF device scope."""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self):
<br>@@ -1044,7 +1041,8 @@ def name_scope(name):
<br>&nbsp &nbsp &nbspreturn ops.name_scope_v2(name)
<br>&nbsp
<br>&nbsp# Export V1 version.
<br><span style="color:red">- keras_export(v1=['keras.backend.name_scope'])(ops.name_scope_v1)</span>
<br><span style="color:green">+_v1_name_scope = ops.name_scope_v1</span>
<br><span style="color:green">+keras_export(v1=['keras.backend.name_scope'])(_v1_name_scope)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.backend.variable')
<br>@@ -1106,6 +1104,7 @@ def track_tf_optimizer(tf_optimizer):
<br>&nbsp &nbsp &nbspoptimizers.add(tf_optimizer)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@keras_export('keras.__internal__.backend.track_variable', v1=[])</span>
<br>&nbspdef track_variable(v):
<br>&nbsp &nbsp &nbsp"""Tracks the given variable for initialization."""
<br>&nbsp &nbsp &nbspif context.executing_eagerly():
<br>@@ -1184,6 +1183,7 @@ def _get_variables(graph=None):
<br>&nbsp &nbsp &nbspreturn variables
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@keras_export('keras.__internal__.backend.initialize_variables', v1=[])</span>
<br>&nbspdef _initialize_variables(session):
<br>&nbsp &nbsp &nbsp"""Utility to initialize uninitialized variables on the fly."""
<br>&nbsp &nbsp &nbspvariables = _get_variables(get_graph())
<br>@@ -1280,7 +1280,7 @@ def is_keras_tensor(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras_tensor.KerasTensor)):
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`. Expected a symbolic tensor instance.')
<br><span style="color:red">- &nbsp &nbspif keras_tensor.keras_tensors_enabled():</span>
<br><span style="color:green">+&nbsp &nbspif ops.executing_eagerly_outside_functions():</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn isinstance(x, keras_tensor.KerasTensor)
<br>&nbsp &nbsp &nbspreturn hasattr(x, '_keras_history')
<br>&nbsp
<br>@@ -1310,7 +1310,6 @@ def placeholder(shape=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[guide](https://www.tensorflow.org/guide/ragged_tensors).
<br>&nbsp
<br>&nbsp &nbsp &nbspRaises:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If called with eager execution</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If called with sparse = True and ragged = True.
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>@@ -1333,11 +1332,10 @@ def placeholder(shape=None,
<br>&nbsp &nbsp &nbspif not shape:
<br>&nbsp &nbsp &nbsp &nbsp &nbspif ndim:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = (None,) * ndim
<br><span style="color:red">- &nbsp &nbspif keras_tensor.keras_tensors_enabled():</span>
<br><span style="color:green">+&nbsp &nbspif ops.executing_eagerly_outside_functions():</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif sparse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspec = sparse_tensor.SparseTensorSpec(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=shape, dtype=dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = keras_tensor.SparseKerasTensor(spec, name=name)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif ragged:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_rank = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(1, len(shape)):
<br>@@ -1349,12 +1347,10 @@ def placeholder(shape=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_rank = i
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspec = ragged_tensor.RaggedTensorSpec(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=shape, dtype=dtype, ragged_rank=ragged_rank)
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = keras_tensor.RaggedKerasTensor(spec, name=name)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspec = tensor_spec.TensorSpec(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=shape, dtype=dtype, name=name)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = keras_tensor.KerasTensor(spec, name=name)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx = keras_tensor.keras_tensor_from_type_spec(spec, name=name)</span>
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith get_graph().as_default():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif sparse:
<br>@@ -1379,8 +1375,7 @@ def placeholder(shape=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# (intended to be used with keras.backend.function)
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom tensorflow.python.keras.engine import input_layer  # pylint: disable=g-import-not-at-top
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = input_layer.Input(tensor=x)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif keras_tensor.keras_tensors_enabled():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx._is_backend_placeholder = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx._is_backend_placeholder = True</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspreturn x
<br>&nbsp
<br>@@ -1395,7 +1390,7 @@ def is_placeholder(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspBoolean.
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsptry:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif keras_tensor.keras_tensors_enabled():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn hasattr(x, '_is_backend_placeholder')
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom tensorflow.python.keras.utils import tf_utils  # pylint: disable=g-import-not-at-top
<br>&nbsp &nbsp &nbsp &nbsp &nbspif tf_utils.is_extension_type(x):
<br>@@ -1487,10 +1482,7 @@ def ndim(x):
<br>&nbsp &nbsp &nbsp2
<br>&nbsp
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspdims = x.shape._dims</span>
<br><span style="color:red">- &nbsp &nbspif dims is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn len(dims)</span>
<br><span style="color:red">- &nbsp &nbspreturn None</span>
<br><span style="color:green">+&nbsp &nbspreturn x.shape.rank</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.backend.dtype')
<br>@@ -1527,6 +1519,19 @@ def dtype(x):
<br>&nbsp &nbsp &nbspreturn x.dtype.base_dtype.name
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@doc_controls.do_not_generate_docs</span>
<br><span style="color:green">+def dtype_numpy(x):</span>
<br><span style="color:green">+&nbsp &nbsp"""Returns the numpy dtype of a Keras tensor or variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Tensor or variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy.dtype, dtype of `x`.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspreturn dtypes_module.as_dtype(x.dtype).as_numpy_dtype</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp@keras_export('keras.backend.eval')
<br>&nbsp@doc_controls.do_not_generate_docs
<br>&nbspdef eval(x):
<br>@@ -1932,9 +1937,13 @@ def moving_average_update(x, value, momentum):
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe updated variable.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspzero_debias = not tf2.enabled()</span>
<br><span style="color:red">- &nbsp &nbspreturn moving_averages.assign_moving_average(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, value, momentum, zero_debias=zero_debias)</span>
<br><span style="color:green">+&nbsp &nbspif tf2.enabled():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmomentum = math_ops.cast(momentum, x.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspvalue = math_ops.cast(value, x.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn x.assign(x * momentum + value * (1 - momentum))</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn moving_averages.assign_moving_average(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx, value, momentum, zero_debias=True)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp# LINEAR ALGEBRA
<br>@@ -3188,8 +3197,11 @@ def resize_images(x, height_factor, width_factor, data_format,
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Invalid `data_format` argument: %s' % (data_format,))
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsporiginal_shape = int_shape(x)</span>
<br><span style="color:red">- &nbsp &nbspnew_shape = array_ops.shape(x)[rows:cols + 1]</span>
<br><span style="color:green">+&nbsp &nbspnew_shape = x.shape[rows:cols + 1]</span>
<br><span style="color:green">+&nbsp &nbspif new_shape.is_fully_defined():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnew_shape = constant_op.constant(new_shape.as_list(), dtype='int32')</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnew_shape = array_ops.shape_v2(x)[rows:cols + 1]</span>
<br>&nbsp &nbsp &nbspnew_shape *= constant_op.constant(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.array([height_factor, width_factor], dtype='int32'))
<br>&nbsp
<br>@@ -3207,21 +3219,6 @@ def resize_images(x, height_factor, width_factor, data_format,
<br>&nbsp &nbsp &nbspif data_format == 'channels_first':
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = permute_dimensions(x, [0, 3, 1, 2])
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspif original_shape[rows] is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnew_height = None</span>
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnew_height = original_shape[rows] * height_factor</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspif original_shape[cols] is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnew_width = None</span>
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnew_width = original_shape[cols] * width_factor</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspif data_format == 'channels_first':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput_shape = (None, None, new_height, new_width)</span>
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput_shape = (None, new_height, new_width, None)</span>
<br><span style="color:red">- &nbsp &nbspx.set_shape(output_shape)</span>
<br>&nbsp &nbsp &nbspreturn x
<br>&nbsp
<br>&nbsp
<br>@@ -3704,7 +3701,7 @@ _VALUE_SET_CODE_STRING = """
<br>&nbspdef get_value(x):
<br>&nbsp &nbsp &nbsp"""Returns the value of a variable.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp`backend.get_value` is the compliment of `backend.set_value`, and provides</span>
<br><span style="color:green">+&nbsp &nbsp`backend.get_value` is the complement of `backend.set_value`, and provides</span>
<br>&nbsp &nbsp &nbspa generic interface for reading from variables while abstracting away the
<br>&nbsp &nbsp &nbspdifferences between TensorFlow 1.x and 2.x semantics.
<br>&nbsp
<br>@@ -3716,7 +3713,7 @@ def get_value(x):
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA Numpy array.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspif not tensor_util.is_tensor(x):</span>
<br><span style="color:green">+&nbsp &nbspif not tensor_util.is_tf_type(x):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x
<br>&nbsp &nbsp &nbspif context.executing_eagerly() or isinstance(x, ops.EagerTensor):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x.numpy()
<br>@@ -3728,7 +3725,8 @@ def get_value(x):
<br>&nbsp
<br>&nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# This method of evaluating works inside the Keras FuncGraph.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn eval_in_eager_or_function(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith ops.init_scope():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x.numpy()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspwith x.graph.as_default():
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x.eval(session=get_session((x,)))
<br>@@ -3764,7 +3762,7 @@ def batch_get_value(tensors):
<br>&nbspdef set_value(x, value):
<br>&nbsp &nbsp &nbsp"""Sets the value of a variable, from a Numpy array.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp`backend.set_value` is the compliment of `backend.get_value`, and provides</span>
<br><span style="color:green">+&nbsp &nbsp`backend.set_value` is the complement of `backend.get_value`, and provides</span>
<br>&nbsp &nbsp &nbspa generic interface for assigning to variables while abstracting away the
<br>&nbsp &nbsp &nbspdifferences between TensorFlow 1.x and 2.x semantics.
<br>&nbsp
<br>@@ -3775,7 +3773,7 @@ def set_value(x, value):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue: Value to set the tensor to, as a Numpy array
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(of the same shape).
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspvalue = np.asarray(value, dtype=dtype(x))</span>
<br><span style="color:green">+&nbsp &nbspvalue = np.asarray(value, dtype=dtype_numpy(x))</span>
<br>&nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbspx.assign(value)
<br>&nbsp &nbsp &nbspelse:
<br>@@ -3810,14 +3808,14 @@ def batch_set_value(tuples):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor x, value in tuples:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx.assign(np.asarray(value, dtype=dtype(x)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx.assign(np.asarray(value, dtype=dtype_numpy(x)))</span>
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith get_graph().as_default():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif tuples:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassign_ops = []
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_dict = {}
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor x, value in tuples:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue = np.asarray(value, dtype=dtype(x))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue = np.asarray(value, dtype=dtype_numpy(x))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_dtype = dtypes_module.as_dtype(x.dtype.name.split('_')[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(x, '_assign_placeholder'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassign_placeholder = x._assign_placeholder
<br>@@ -3845,7 +3843,7 @@ set_value.__doc__ = set_value.__doc__.format(snippet=_VALUE_SET_CODE_STRING)
<br>&nbsp@keras_export('keras.backend.print_tensor')
<br>&nbsp@dispatch.add_dispatch_support
<br>&nbsp@doc_controls.do_not_generate_docs
<br><span style="color:red">- def print_tensor(x, message=''):</span>
<br><span style="color:green">+def print_tensor(x, message='', summarize=3):</span>
<br>&nbsp &nbsp &nbsp"""Prints `message` and the tensor value when evaluated.
<br>&nbsp
<br>&nbsp &nbsp &nbspNote that `print_tensor` returns a new tensor identical to `x`
<br>@@ -3863,23 +3861,29 @@ def print_tensor(x, message=''):
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Tensor to print.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmessage: Message to print jointly with the tensor.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummarize: The first and last `summarize` elements within each dimension</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare recursively printed per Tensor. If None, then the first 3 and last</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp3 elements of each dimension are printed for each tensor. If set to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp-1, it will print all elements of every tensor.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe same tensor `x`, unchanged.
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif isinstance(x, ops.Tensor) and hasattr(x, 'graph'):
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith get_graph().as_default():
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspop = logging_ops.print_v2(message, x, output_stream=sys.stdout)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspop = logging_ops.print_v2(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmessage, x, output_stream=sys.stdout, summarize=summarize)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith ops.control_dependencies([op]):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn array_ops.identity(x)
<br>&nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogging_ops.print_v2(message, x, output_stream=sys.stdout)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging_ops.print_v2(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmessage, x, output_stream=sys.stdout, summarize=summarize)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn x
<br>&nbsp
<br>&nbsp# GRAPH MANIPULATION
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class GraphExecutionFunction(object):</span>
<br><span style="color:green">+class GraphExecutionFunction:</span>
<br>&nbsp &nbsp &nbsp"""Runs a computation graph.
<br>&nbsp
<br>&nbsp &nbsp &nbspIt's possible to pass arguments to `tf.Session.run()` via `session_kwargs`.
<br>@@ -3980,7 +3984,7 @@ class GraphExecutionFunction(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconnection = callable_opts.tensor_connection.add()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x.dtype != y.dtype:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = math_ops.cast(y, dtype=x.dtype)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_tensor = ops._as_graph_element(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_tensor = _as_graph_element(y)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif from_tensor is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_tensor = y
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconnection.from_tensor = from_tensor.name  # Data tensor
<br>@@ -4035,7 +4039,7 @@ class GraphExecutionFunction(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif value is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontinue
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif tensor_util.is_tensor(value):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif tensor_util.is_tf_type(value):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Case: feeding symbolic tensor.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfeed_symbols.append(tensor)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsymbol_vals.append(value)
<br>@@ -4051,7 +4055,7 @@ class GraphExecutionFunction(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.feed_dict:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor key in sorted(self.feed_dict.keys()):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_vals.append(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.asarray(self.feed_dict[key], dtype=key.dtype.base_dtype.name))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.asarray(self.feed_dict[key], dtype=key.dtype.as_numpy_dtype))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Refresh callable if anything has changed.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif (self._callable_fn is None or feed_arrays != self._feed_arrays or
<br>@@ -4076,76 +4080,6 @@ class GraphExecutionFunction(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn nest.map_structure(self._eval_if_composite, output_structure)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def eval_in_eager_or_function(outputs):</span>
<br><span style="color:red">- &nbsp &nbsp"""Method to evaluate a tensor in eager or in a tf.function.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspIn the case of a tf.function, it will lift the tensor out of the function</span>
<br><span style="color:red">- &nbsp &nbspand try to evaluate that piece of the graph.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspWarning: Do not add new usages of this function.</span>
<br><span style="color:red">- &nbsp &nbspTODO(b/150169018): delete this function once _keras_history_helper is no</span>
<br><span style="color:red">- &nbsp &nbsplonger needed, after Keras switches to KerasTensors and op layers</span>
<br><span style="color:red">- &nbsp &nbspwork via dispatch.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspArgs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs: tensors to fetch.</span>
<br><span style="color:red">- &nbsp &nbspReturns:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe value of the tensors (as numpy arrays).</span>
<br><span style="color:red">- &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbspoutputs_structure = outputs</span>
<br><span style="color:red">- &nbsp &nbspoutputs = nest.flatten(outputs, expand_composites=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspgraphs = {</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspi.graph</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in nest.flatten([outputs])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(i, 'graph')</span>
<br><span style="color:red">- &nbsp &nbsp}</span>
<br><span style="color:red">- &nbsp &nbspif len(graphs) > 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspraise ValueError('Cannot create an execution function which is comprised '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'of elements from multiple graphs.')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspsource_graph = graphs.pop()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspwith _scratch_graph() as exec_graph:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspglobal_graph = get_graph()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif source_graph not in (exec_graph, global_graph):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Unknown graph. Aborting.')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif source_graph is global_graph and exec_graph is not global_graph:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinit_tensors = outputs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplifted_map = lift_to_graph.lift_to_graph(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensors=init_tensors,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgraph=exec_graph,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsources=[],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadd_sources=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphandle_captures=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbase_graph=source_graph)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = [lifted_map[i] for i in outputs]</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp# Consolidate updates</span>
<br><span style="color:red">- &nbsp &nbspwith exec_graph.as_default():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs = cast_variables_to_tensor(outputs)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexec_graph.inputs = exec_graph.internal_captures</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexec_graph.outputs = outputs</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgraph_fn = eager_function.ConcreteFunction(exec_graph)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspgraph_fn._num_positional_args = 0</span>
<br><span style="color:red">- &nbsp &nbspgraph_fn._arg_keywords = []</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspoutputs = graph_fn()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp# EagerTensor.numpy() will often make a copy to ensure memory safety.</span>
<br><span style="color:red">- &nbsp &nbsp# However in this case `outputs` is not directly returned, so it is always</span>
<br><span style="color:red">- &nbsp &nbsp# safe to reuse the underlying buffer without checking. In such a case the</span>
<br><span style="color:red">- &nbsp &nbsp# private numpy conversion method is preferred to guarantee performance.</span>
<br><span style="color:red">- &nbsp &nbspreturn nest.pack_sequence_as(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs_structure,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[x._numpy() for x in outputs],  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpand_composites=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br>&nbsp@keras_export('keras.backend.function')
<br>&nbsp@doc_controls.do_not_generate_docs
<br>&nbspdef function(inputs, outputs, updates=None, name=None, **kwargs):
<br>@@ -4180,7 +4114,8 @@ def function(inputs, outputs, updates=None, name=None, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspouts = model(model_inputs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif wrap_outputs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspouts = [outs]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tf_utils.to_numpy_or_python_type(outs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn tf_utils.sync_to_numpy_or_python_type(outs)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn func
<br>&nbsp
<br>&nbsp &nbsp &nbspif kwargs:
<br>@@ -4722,7 +4657,7 @@ def in_train_phase(x, alt, training=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsptraining = learning_phase()
<br>&nbsp
<br>&nbsp &nbsp &nbsp# TODO(b/138862903): Handle the case when training is tensor.
<br><span style="color:red">- &nbsp &nbspif not tensor_util.is_tensor(training):</span>
<br><span style="color:green">+&nbsp &nbspif not tensor_util.is_tf_type(training):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif training == 1 or training is True:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif callable(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn x()
<br>@@ -4872,7 +4807,7 @@ def softplus(x):
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA tensor.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspreturn nn.softplus(x)</span>
<br><span style="color:green">+&nbsp &nbspreturn math_ops.softplus(x)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.backend.softsign')
<br>@@ -6069,7 +6004,7 @@ def bias_add(x, bias, data_format=None):
<br>&nbsp &nbsp &nbspif len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Unexpected bias dimensions %d, expect to be 1 or %d dimensions' %
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(len(bias_shape), ndim(x)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(len(bias_shape), ndim(x) - 1))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspif len(bias_shape) == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbspif data_format == 'channels_first':
<br>@@ -6515,7 +6450,7 @@ def configure_and_create_distributed_session(distribution_strategy):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmaster = distribution_strategy.extended._tpu_cluster_resolver.master()  # pylint: disable=protected-access
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsession = session_module.Session(config=session_config, target=master)
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworker_context = dc_context.get_current_worker_context()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspworker_context = dc.get_current_worker_context()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif worker_context:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdc_session_config = worker_context.session_config
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Merge the default session config to the one from distribute
<br>@@ -6533,16 +6468,21 @@ def configure_and_create_distributed_session(distribution_strategy):
<br>&nbsp &nbsp &nbspif distribution_strategy.extended._in_multi_worker_mode():
<br>&nbsp &nbsp &nbsp &nbsp &nbspdc.run_distribute_coordinator(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_create_session,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode='independent_worker')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy)</span>
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_create_session(distribution_strategy)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+def _is_tpu_strategy_class(clz):</span>
<br><span style="color:green">+&nbsp &nbspis_tpu_strat = lambda k: k.__name__.startswith('TPUStrategy')</span>
<br><span style="color:green">+&nbsp &nbspif is_tpu_strat(clz):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn True</span>
<br><span style="color:green">+&nbsp &nbspreturn py_any(map(_is_tpu_strategy_class, clz.__bases__))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbspdef is_tpu_strategy(strategy):
<br><span style="color:red">- &nbsp &nbsp"""We're executing TPU Strategy."""</span>
<br><span style="color:red">- &nbsp &nbspreturn (strategy is not None and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrategy.__class__.__name__.startswith('TPUStrategy'))</span>
<br><span style="color:green">+&nbsp &nbsp"""Returns whether input is a TPUStrategy instance or subclass instance."""</span>
<br><span style="color:green">+&nbsp &nbspreturn _is_tpu_strategy_class(strategy.__class__)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef cast_variables_to_tensor(tensors):
<br>@@ -6556,7 +6496,7 @@ def cast_variables_to_tensor(tensors):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _is_symbolic_tensor(x):
<br><span style="color:red">- &nbsp &nbspreturn tensor_util.is_tensor(x) and not isinstance(x, ops.EagerTensor)</span>
<br><span style="color:green">+&nbsp &nbspreturn tensor_util.is_tf_type(x) and not isinstance(x, ops.EagerTensor)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef convert_inputs_if_ragged(inputs):
<br>@@ -6582,12 +6522,20 @@ def convert_inputs_if_ragged(inputs):
<br>&nbsp &nbsp &nbspreturn inputs, nested_row_lengths
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- def maybe_convert_to_ragged(is_ragged_input, output, nested_row_lengths):</span>
<br><span style="color:green">+def maybe_convert_to_ragged(is_ragged_input, output, nested_row_lengths,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgo_backwards=False):</span>
<br>&nbsp &nbsp &nbsp"""Converts any ragged input back to its initial structure."""
<br>&nbsp &nbsp &nbspif not is_ragged_input:
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspreturn ragged_tensor.RaggedTensor.from_tensor(output, nested_row_lengths)</span>
<br><span style="color:green">+&nbsp &nbspif go_backwards:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Reverse based on the timestep dim, so that nested_row_lengths will mask</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# from the correct direction. Return the reverse ragged tensor.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutput = reverse(output, [1])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspragged = ragged_tensor.RaggedTensor.from_tensor(output, nested_row_lengths)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn reverse(ragged, [1])</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn ragged_tensor.RaggedTensor.from_tensor(output, nested_row_lengths)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspclass ContextValueCache(weakref.WeakKeyDictionary):
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\engine\input_layer.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13435</th>
      <td>keras\backend_test.py</td>
      <td>173</td>
      <td>test_is_keras_tensor</td>
      <td>169</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>172</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14019</th>
      <td>keras\integration_test.py</td>
      <td>221</td>
      <td>test_vector_classification_shared_sequential</td>
      <td>194</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>214</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14023</th>
      <td>keras\integration_test.py</td>
      <td>222</td>
      <td>test_vector_classification_shared_sequential</td>
      <td>194</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>214</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14103</th>
      <td>keras\models_test.py</td>
      <td>118</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>99</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14104</th>
      <td>keras\models_test.py</td>
      <td>118</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>100</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14114</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>99</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14115</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>100</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14126</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>99</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14127</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>100</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14137</th>
      <td>keras\models_test.py</td>
      <td>154</td>
      <td>test_clone_functional_model_with_masking</td>
      <td>141</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>144</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14268</th>
      <td>keras\engine\saving_test.py</td>
      <td>62</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14273</th>
      <td>keras\engine\saving_test.py</td>
      <td>62</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14278</th>
      <td>keras\engine\saving_test.py</td>
      <td>76</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14284</th>
      <td>keras\engine\saving_test.py</td>
      <td>76</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>keras\engine\saving_test.py</td>
      <td>85</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14296</th>
      <td>keras\engine\saving_test.py</td>
      <td>85</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14301</th>
      <td>keras\engine\saving_test.py</td>
      <td>89</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14309</th>
      <td>keras\engine\saving_test.py</td>
      <td>89</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14314</th>
      <td>keras\engine\saving_test.py</td>
      <td>94</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14323</th>
      <td>keras\engine\saving_test.py</td>
      <td>94</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14366</th>
      <td>keras\engine\saving_test.py</td>
      <td>478</td>
      <td>test_functional_model_saving</td>
      <td>444</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>449</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14372</th>
      <td>keras\engine\saving_test.py</td>
      <td>478</td>
      <td>test_functional_model_saving</td>
      <td>444</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>449</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14379</th>
      <td>keras\engine\saving_test.py</td>
      <td>589</td>
      <td>test_saving_model_with_long_layer_names</td>
      <td>554</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>565</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14385</th>
      <td>keras\engine\saving_test.py</td>
      <td>589</td>
      <td>test_saving_model_with_long_layer_names</td>
      <td>554</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>565</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14389</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>600</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14390</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>609</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14396</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>600</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14397</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>609</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14401</th>
      <td>keras\engine\saving_test.py</td>
      <td>667</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>645</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14408</th>
      <td>keras\engine\saving_test.py</td>
      <td>667</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>645</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14411</th>
      <td>keras\engine\saving_test.py</td>
      <td>675</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>645</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14419</th>
      <td>keras\engine\saving_test.py</td>
      <td>675</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>645</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14546</th>
      <td>keras\engine\topology_test.py</td>
      <td>353</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>346</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14548</th>
      <td>keras\engine\topology_test.py</td>
      <td>354</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>347</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14551</th>
      <td>keras\engine\topology_test.py</td>
      <td>358</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>346</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14553</th>
      <td>keras\engine\topology_test.py</td>
      <td>358</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>347</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14555</th>
      <td>keras\engine\topology_test.py</td>
      <td>362</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>346</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14556</th>
      <td>keras\engine\topology_test.py</td>
      <td>362</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>347</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14560</th>
      <td>keras\engine\topology_test.py</td>
      <td>368</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>364</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14561</th>
      <td>keras\engine\topology_test.py</td>
      <td>368</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>365</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14564</th>
      <td>keras\engine\topology_test.py</td>
      <td>369</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>347</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14565</th>
      <td>keras\engine\topology_test.py</td>
      <td>369</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>364</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14566</th>
      <td>keras\engine\topology_test.py</td>
      <td>369</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>365</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14568</th>
      <td>keras\engine\topology_test.py</td>
      <td>389</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>385</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14572</th>
      <td>keras\engine\topology_test.py</td>
      <td>394</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>392</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14575</th>
      <td>keras\engine\topology_test.py</td>
      <td>399</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>385</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14584</th>
      <td>keras\engine\topology_test.py</td>
      <td>442</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>403</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14587</th>
      <td>keras\engine\topology_test.py</td>
      <td>443</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>403</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14591</th>
      <td>keras\engine\topology_test.py</td>
      <td>447</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>403</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14593</th>
      <td>keras\engine\topology_test.py</td>
      <td>448</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>404</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14596</th>
      <td>keras\engine\topology_test.py</td>
      <td>449</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>403</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14599</th>
      <td>keras\engine\topology_test.py</td>
      <td>450</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>404</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14612</th>
      <td>keras\engine\topology_test.py</td>
      <td>551</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>546</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14613</th>
      <td>keras\engine\topology_test.py</td>
      <td>551</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>547</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14620</th>
      <td>keras\engine\topology_test.py</td>
      <td>758</td>
      <td>test_basic_masking</td>
      <td>754</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>755</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14644</th>
      <td>keras\engine\topology_test.py</td>
      <td>880</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>868</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14645</th>
      <td>keras\engine\topology_test.py</td>
      <td>880</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>872</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14653</th>
      <td>keras\engine\topology_test.py</td>
      <td>886</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>868</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14654</th>
      <td>keras\engine\topology_test.py</td>
      <td>886</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>872</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14660</th>
      <td>keras\engine\topology_test.py</td>
      <td>914</td>
      <td>test_multi_output_model_with_none_masking</td>
      <td>888</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>907</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14687</th>
      <td>keras\engine\training_test.py</td>
      <td>424</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>410</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14692</th>
      <td>keras\engine\training_test.py</td>
      <td>424</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>410</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14698</th>
      <td>keras\engine\training_test.py</td>
      <td>441</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>410</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14705</th>
      <td>keras\engine\training_test.py</td>
      <td>441</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>410</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14718</th>
      <td>keras\engine\training_test.py</td>
      <td>896</td>
      <td>test_masking_functional</td>
      <td>885</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>888</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14740</th>
      <td>keras\engine\training_test.py</td>
      <td>2263</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2242</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14741</th>
      <td>keras\engine\training_test.py</td>
      <td>2263</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2243</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14746</th>
      <td>keras\engine\training_test.py</td>
      <td>2264</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2242</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14747</th>
      <td>keras\engine\training_test.py</td>
      <td>2264</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2243</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14752</th>
      <td>keras\engine\training_test.py</td>
      <td>2277</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2242</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14753</th>
      <td>keras\engine\training_test.py</td>
      <td>2277</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2243</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14758</th>
      <td>keras\engine\training_test.py</td>
      <td>2278</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2242</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14759</th>
      <td>keras\engine\training_test.py</td>
      <td>2278</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2243</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>14856</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>68</td>
      <td>test_conv_lstm</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>52</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15006</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>138</td>
      <td>test_return_state</td>
      <td>120</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>129</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15116</th>
      <td>keras\layers\lstm_test.py</td>
      <td>342</td>
      <td>test_return_state</td>
      <td>325</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>333</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15120</th>
      <td>keras\layers\merge_test.py</td>
      <td>45</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>33</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15121</th>
      <td>keras\layers\merge_test.py</td>
      <td>45</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>34</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15122</th>
      <td>keras\layers\merge_test.py</td>
      <td>45</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>35</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15129</th>
      <td>keras\layers\merge_test.py</td>
      <td>46</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>33</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15130</th>
      <td>keras\layers\merge_test.py</td>
      <td>46</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>34</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15131</th>
      <td>keras\layers\merge_test.py</td>
      <td>46</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15141</th>
      <td>keras\layers\merge_test.py</td>
      <td>92</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>81</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15142</th>
      <td>keras\layers\merge_test.py</td>
      <td>92</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>82</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15143</th>
      <td>keras\layers\merge_test.py</td>
      <td>92</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>83</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15150</th>
      <td>keras\layers\merge_test.py</td>
      <td>93</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>81</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15151</th>
      <td>keras\layers\merge_test.py</td>
      <td>93</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>82</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15152</th>
      <td>keras\layers\merge_test.py</td>
      <td>93</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>83</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15162</th>
      <td>keras\layers\merge_test.py</td>
      <td>106</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>97</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15163</th>
      <td>keras\layers\merge_test.py</td>
      <td>106</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>98</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15169</th>
      <td>keras\layers\merge_test.py</td>
      <td>107</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>97</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15170</th>
      <td>keras\layers\merge_test.py</td>
      <td>107</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>98</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15178</th>
      <td>keras\layers\merge_test.py</td>
      <td>120</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>111</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15179</th>
      <td>keras\layers\merge_test.py</td>
      <td>120</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>112</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15185</th>
      <td>keras\layers\merge_test.py</td>
      <td>121</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>111</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15186</th>
      <td>keras\layers\merge_test.py</td>
      <td>121</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>112</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15194</th>
      <td>keras\layers\merge_test.py</td>
      <td>134</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>125</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15195</th>
      <td>keras\layers\merge_test.py</td>
      <td>134</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>126</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15201</th>
      <td>keras\layers\merge_test.py</td>
      <td>135</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>125</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15202</th>
      <td>keras\layers\merge_test.py</td>
      <td>135</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>126</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15210</th>
      <td>keras\layers\merge_test.py</td>
      <td>148</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>139</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15211</th>
      <td>keras\layers\merge_test.py</td>
      <td>148</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>140</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15217</th>
      <td>keras\layers\merge_test.py</td>
      <td>149</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>139</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15218</th>
      <td>keras\layers\merge_test.py</td>
      <td>149</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>140</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15226</th>
      <td>keras\layers\merge_test.py</td>
      <td>184</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>174</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15227</th>
      <td>keras\layers\merge_test.py</td>
      <td>184</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>175</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15233</th>
      <td>keras\layers\merge_test.py</td>
      <td>188</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>174</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15234</th>
      <td>keras\layers\merge_test.py</td>
      <td>188</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>175</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15242</th>
      <td>keras\layers\merge_test.py</td>
      <td>195</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>174</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15243</th>
      <td>keras\layers\merge_test.py</td>
      <td>195</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>175</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15250</th>
      <td>keras\layers\merge_test.py</td>
      <td>196</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>174</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15251</th>
      <td>keras\layers\merge_test.py</td>
      <td>196</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>175</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15258</th>
      <td>keras\layers\merge_test.py</td>
      <td>223</td>
      <td>test_merge_subtract</td>
      <td>219</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>220</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15259</th>
      <td>keras\layers\merge_test.py</td>
      <td>223</td>
      <td>test_merge_subtract</td>
      <td>219</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>221</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15297</th>
      <td>keras\layers\normalization_test.py</td>
      <td>174</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>164</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15300</th>
      <td>keras\layers\normalization_test.py</td>
      <td>175</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>164</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15302</th>
      <td>keras\layers\normalization_test.py</td>
      <td>175</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>161</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15304</th>
      <td>keras\layers\normalization_test.py</td>
      <td>176</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>164</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15307</th>
      <td>keras\layers\normalization_test.py</td>
      <td>183</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>179</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15310</th>
      <td>keras\layers\normalization_test.py</td>
      <td>184</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>164</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15313</th>
      <td>keras\layers\normalization_test.py</td>
      <td>185</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>179</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15317</th>
      <td>keras\layers\normalization_test.py</td>
      <td>208</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15322</th>
      <td>keras\layers\normalization_test.py</td>
      <td>208</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>194</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15328</th>
      <td>keras\layers\normalization_test.py</td>
      <td>225</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15335</th>
      <td>keras\layers\normalization_test.py</td>
      <td>225</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>194</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15342</th>
      <td>keras\layers\normalization_test.py</td>
      <td>256</td>
      <td>test_batchnorm_trainable</td>
      <td>227</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>239</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15352</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>426</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>419</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15354</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>426</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>419</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15361</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>443</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>419</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15362</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>443</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>434</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15374</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>510</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>493</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15380</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>510</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>493</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15386</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>531</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>493</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15393</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>531</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>493</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15400</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>613</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>607</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15402</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>622</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>607</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15406</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>637</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>607</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15409</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>661</td>
      <td>test_high_dimension_RNN_with_init_state</td>
      <td>639</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>650</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15410</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>661</td>
      <td>test_high_dimension_RNN_with_init_state</td>
      <td>639</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>651</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15416</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>688</td>
      <td>test_inconsistent_output_state_size</td>
      <td>675</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>682</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15418</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>697</td>
      <td>test_inconsistent_output_state_size</td>
      <td>675</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>682</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15422</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>707</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15425</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>708</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15426</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>708</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15430</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>713</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15434</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>714</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15435</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>714</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>705</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15472</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>166</td>
      <td>test_TimeDistributed_learning_phase</td>
      <td>157</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>161</td>
      <td>keras.layers.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15487</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>550</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15488</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>551</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15495</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>550</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15496</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>551</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>550</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15503</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>551</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15511</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>550</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15512</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>551</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15518</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>591</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15519</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>593</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15520</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>594</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15521</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>592</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15530</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>591</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15531</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>593</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15532</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>594</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15533</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>592</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15541</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>591</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15542</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>593</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15543</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>594</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15544</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>592</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15554</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>591</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15555</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>593</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15556</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>594</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>15557</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>592</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>26283</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>535</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>528</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>26292</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>536</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>528</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>26323</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>610</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
    <tr>
      <th>26329</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>610</td>
      <td>keras.Input</td>
      <td>tensorflow\python\keras\engine\input_layer.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 993403945efc9e7a933e9c8bd3ad029c36c6882b

 <br>Commit message: Remove a large amount of PY2 compatibility code.<br><br>PiperOrigin-RevId: 364677165<br>Change-Id: Ic52863fbda9b3f093948b9febbcb00a138d80ade<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/engine/input_layer.py b/tensorflow/python/keras/engine/input_layer.py
<br>index 75e0cc879f3..ff7fff06300 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/engine/input_layer.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/engine/input_layer.py</span>
<br>@@ -13,13 +13,10 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Input layer code (`Input` and `InputLayer`).</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Input layer code (`Input` and `InputLayer`)."""</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.distribute import distribution_strategy_context
<br><span style="color:green">+from tensorflow.python.framework import ops</span>
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br>&nbspfrom tensorflow.python.framework import tensor_spec
<br>&nbspfrom tensorflow.python.keras import backend
<br>@@ -32,6 +29,13 @@ from tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+def _assert_other_arg_none(arg_name, arg):</span>
<br><span style="color:green">+&nbsp &nbspif arg is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspraise ValueError('When `type_spec` is not None, all other args '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'except `name` must be None, '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'but %s is not None.' % arg_name)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp@keras_export('keras.layers.InputLayer')
<br>&nbspclass InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp"""Layer to be used as an entry point into a Network (a graph of layers).
<br>@@ -85,6 +89,9 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged dimensions. For more information about RaggedTensors, see
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[this guide](https://www.tensorflow.org/guide/ragged_tensors).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault to False.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptype_spec: A `tf.TypeSpec` object to create Input from. This `tf.TypeSpec`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprepresents the entire batch. When provided, all other args except</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname must be None.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name of the layer (string).
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>@@ -93,10 +100,18 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse=None,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged=None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptype_spec=None,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_input_shape = input_shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_batch_size = batch_size</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_dtype = dtype</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_sparse = sparse</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_ragged = ragged</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._init_type_spec = type_spec</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspstrategy = distribution_strategy_context.get_strategy()
<br>&nbsp &nbsp &nbsp &nbsp &nbspif strategy and batch_size is not None and \
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistributed_training_utils.global_batch_size_supported(strategy):
<br>@@ -112,8 +127,12 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Only provide the input_shape OR '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_input_shape argument to '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'InputLayer, not both at the same time.')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = batch_input_shape[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = batch_input_shape[1:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Set the input shape and batch size from the batch_input_shape.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Note that batch_input_shape can be None (unknown rank) or [] (scalar),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# in which case the batch size must be None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif batch_input_shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = batch_input_shape[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = batch_input_shape[1:]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif kwargs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Unrecognized keyword arguments:', kwargs.keys())
<br>&nbsp
<br>@@ -135,8 +154,8 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(input_tensor.dtype, dtype))
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(InputLayer, self).__init__(dtype=dtype, name=name)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.sparse = sparse</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.ragged = ragged</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.sparse = True if sparse else False</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.ragged = True if ragged else False</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.batch_size = batch_size
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.supports_masking = True
<br>&nbsp
<br>@@ -145,7 +164,32 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif isinstance(input_shape, int):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = (input_shape,)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif input_tensor is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif type_spec is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspargs_that_must_be_none = [</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('(input_)shape', self._init_input_shape),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('batch_size', self._init_batch_size),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('dtype', self._init_dtype),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('input_tensor', input_tensor),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('sparse', self._init_sparse),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('ragged', self._init_ragged),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor arg_name, arg in args_that_must_be_none:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_assert_other_arg_none(arg_name, arg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not ops.executing_eagerly_outside_functions():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Creating Keras inputs from a type_spec is only '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'supported when eager execution is enabled.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor = keras_tensor.keras_tensor_from_type_spec(type_spec)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(input_tensor, keras_tensor.SparseKerasTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.sparse = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(input_tensor, keras_tensor.RaggedKerasTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.ragged = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.is_placeholder = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._batch_input_shape = tuple(input_tensor.shape.as_list())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept ValueError:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If the shape cannot be represented as a tuple (e.g. unknown rank)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._batch_input_shape = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif input_tensor is None:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif input_shape is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_input_shape = (batch_size,) + tuple(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -162,7 +206,7 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.is_placeholder = True
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._batch_input_shape = batch_input_shape
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif keras_tensor.keras_tensors_enabled():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(input_tensor, keras_tensor.KerasTensor):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor = keras_tensor.keras_tensor_from_tensor(input_tensor)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -190,13 +234,19 @@ class InputLayer(base_layer.Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=input_tensor.shape, dtype=input_tensor.dtype, name=self.name)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconfig = {</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_input_shape': self._batch_input_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dtype': self.dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sparse': self.sparse,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': self.ragged,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'name': self.name</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._init_type_spec is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'name': self.name,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'type_spec': self._init_type_spec</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig = {</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_input_shape': self._batch_input_shape,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dtype': self.dtype,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sparse': self.sparse,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': self.ragged,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'name': self.name,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp}</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn config
<br>&nbsp
<br>&nbsp &nbsp &nbsp@property
<br>@@ -210,13 +260,14 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbspbatch_size=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbspname=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbspdtype=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsparse=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsparse=None,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptensor=None,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspragged=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspragged=None,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptype_spec=None,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br>&nbsp &nbsp &nbsp"""`Input()` is used to instantiate a Keras tensor.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspA Keras tensor is a TensorFlow symbolic tensor object,</span>
<br><span style="color:green">+&nbsp &nbspA Keras tensor is a symbolic tensor-like object,</span>
<br>&nbsp &nbsp &nbspwhich we augment with certain attributes that allow us to build a Keras model
<br>&nbsp &nbsp &nbspjust by knowing the inputs and outputs of the model.
<br>&nbsp
<br>@@ -248,6 +299,8 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues of 'None' in the 'shape' argument represent ragged dimensions.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor more information about RaggedTensors, see
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[this guide](https://www.tensorflow.org/guide/ragged_tensors).
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptype_spec: A `tf.TypeSpec` object to create the input placeholder from.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen provided, all other args except name must be None.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: deprecated arguments support. Supports `batch_shape` and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`batch_input_shape`.
<br>&nbsp
<br>@@ -264,20 +317,42 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp```
<br>&nbsp
<br>&nbsp &nbsp &nbspNote that even if eager execution is enabled,
<br><span style="color:red">- &nbsp &nbsp`Input` produces a symbolic tensor (i.e. a placeholder).</span>
<br><span style="color:red">- &nbsp &nbspThis symbolic tensor can be used with other</span>
<br><span style="color:red">- &nbsp &nbspTensorFlow ops, as such:</span>
<br><span style="color:green">+&nbsp &nbsp`Input` produces a symbolic tensor-like object (i.e. a placeholder).</span>
<br><span style="color:green">+&nbsp &nbspThis symbolic tensor-like object can be used with lower-level</span>
<br><span style="color:green">+&nbsp &nbspTensorFlow ops that take tensors as inputs, as such:</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp```python
<br>&nbsp &nbsp &nbspx = Input(shape=(32,))
<br><span style="color:red">- &nbsp &nbspy = tf.square(x)</span>
<br><span style="color:green">+&nbsp &nbspy = tf.square(x)  # This op will be treated like a layer</span>
<br><span style="color:green">+&nbsp &nbspmodel = Model(x, y)</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp(This behavior does not work for higher-order TensorFlow APIs such as</span>
<br><span style="color:green">+&nbsp &nbspcontrol flow and being directly watched by a `tf.GradientTape`).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspHowever, the resulting model will not track any variables that were</span>
<br><span style="color:green">+&nbsp &nbspused as inputs to TensorFlow ops. All variable usages must happen within</span>
<br><span style="color:green">+&nbsp &nbspKeras layers to make sure they will be tracked by the model's weights.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspThe Keras Input can also create a placeholder from an arbitrary `tf.TypeSpec`,</span>
<br><span style="color:green">+&nbsp &nbspe.g:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspx = Input(type_spec=tf.RaggedTensorSpec(shape=[None, None],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=tf.float32, ragged_rank=1))</span>
<br><span style="color:green">+&nbsp &nbspy = x.values</span>
<br><span style="color:green">+&nbsp &nbspmodel = Model(x, y)</span>
<br>&nbsp &nbsp &nbsp```
<br><span style="color:green">+&nbsp &nbspWhen passing an arbitrary `tf.TypeSpec`, it must represent the signature of an</span>
<br><span style="color:green">+&nbsp &nbspentire batch instead of just one example.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspRaises:
<br>&nbsp &nbsp &nbsp &nbsp &nbspValueError: If both `sparse` and `ragged` are provided.
<br>&nbsp &nbsp &nbsp &nbsp &nbspValueError: If both `shape` and (`batch_input_shape` or `batch_shape`) are
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprovided.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspValueError: If both `shape` and `tensor` are None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValueError: If `shape`, `tensor` and `type_spec` are None.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValueError: If arguments besides `type_spec` are non-None while `type_spec`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis passed.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspValueError: if any unrecognized parameters are provided.
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif sparse and ragged:
<br>@@ -285,16 +360,18 @@ def Input(  # pylint: disable=invalid-name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Cannot set both sparse and ragged to True in a Keras input.')
<br>&nbsp
<br>&nbsp &nbsp &nbspinput_layer_config = {'name': name, 'dtype': dtype, 'sparse': sparse,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': ragged, 'input_tensor': tensor}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ragged': ragged, 'input_tensor': tensor,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'type_spec': type_spec}</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspbatch_input_shape = kwargs.pop('batch_input_shape',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs.pop('batch_shape', None))
<br>&nbsp &nbsp &nbspif shape is not None and batch_input_shape is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Only provide the `shape` OR `batch_input_shape` argument '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to Input, not both at the same time.')
<br><span style="color:red">- &nbsp &nbspif batch_input_shape is None and shape is None and tensor is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspraise ValueError('Please provide to Input either a `shape`'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' or a `tensor` argument. Note that '</span>
<br><span style="color:green">+&nbsp &nbspif (batch_input_shape is None and shape is None and tensor is None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspand type_spec is None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspraise ValueError('Please provide to Input a `shape`'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' or a `tensor` or a `type_spec` argument. Note that '</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`shape` does not include the batch '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dimension.')
<br>&nbsp &nbsp &nbspif kwargs:
<br></p>
</div>
<br><br><br>_____________________________________ERROR_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13438</th>
      <td>keras\backend_test.py</td>
      <td>182</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>181</td>
      <td>keras.backend.array_ops.placeholder</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13440</th>
      <td>keras\backend_test.py</td>
      <td>184</td>
      <td>test_is_placeholder</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>181</td>
      <td>keras.backend.array_ops.placeholder</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13734</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>965</td>
      <td>keras.backend.local_conv</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13743</th>
      <td>keras\backend_test.py</td>
      <td>992</td>
      <td>test_local_conv_channels_dim</td>
      <td>932</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>982</td>
      <td>keras.backend.local_conv</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13753</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>1</td>
      <td>1018</td>
      <td>keras.backend.local_conv</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13759</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>1025</td>
      <td>keras.backend.local_conv1d</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>13760</th>
      <td>keras\backend_test.py</td>
      <td>1042</td>
      <td>test_local_conv_1d_and_2d</td>
      <td>1002</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>1031</td>
      <td>keras.backend.local_conv2d</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15088</th>
      <td>keras\layers\local_test.py</td>
      <td>316</td>
      <td>test_make_2d</td>
      <td>282</td>
      <td>assertAllCloseAccordingToType</td>
      <td>2</td>
      <td>313</td>
      <td>keras.layers.local.make_2d</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15436</th>
      <td>keras\layers\serialization_test.py</td>
      <td>32</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>31</td>
      <td>keras.layers.deserialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15437</th>
      <td>keras\layers\serialization_test.py</td>
      <td>32</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>30</td>
      <td>keras.layers.serialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15439</th>
      <td>keras\layers\serialization_test.py</td>
      <td>33</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>31</td>
      <td>keras.layers.deserialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15440</th>
      <td>keras\layers\serialization_test.py</td>
      <td>33</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>30</td>
      <td>keras.layers.serialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15442</th>
      <td>keras\layers\serialization_test.py</td>
      <td>35</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>31</td>
      <td>keras.layers.deserialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15443</th>
      <td>keras\layers\serialization_test.py</td>
      <td>35</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>30</td>
      <td>keras.layers.serialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15445</th>
      <td>keras\layers\serialization_test.py</td>
      <td>37</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>31</td>
      <td>keras.layers.deserialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15446</th>
      <td>keras\layers\serialization_test.py</td>
      <td>37</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>30</td>
      <td>keras.layers.serialize</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15641</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>36</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15642</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>38</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15643</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>38</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>37</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15644</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>43</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15645</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>43</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>37</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15646</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>43</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>41</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15647</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>46</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15648</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>46</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>37</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15649</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>46</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>41</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15650</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>46</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>44</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15651</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>50</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>35</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15652</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>50</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>37</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15653</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>50</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>41</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15654</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>50</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>44</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15655</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>50</td>
      <td>test_pad_sequences</td>
      <td>31</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>49</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15656</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>57</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>56</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15657</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>60</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>56</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15658</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>60</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>59</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15659</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>66</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>56</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15660</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>66</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>59</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15661</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>66</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>64</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15662</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>71</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>56</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15663</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>71</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>59</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15664</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>71</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>64</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15665</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>71</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>69</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15666</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>76</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>56</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15667</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>76</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>59</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15668</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>76</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>64</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15669</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>76</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>69</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15670</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>76</td>
      <td>test_pad_sequences_vector</td>
      <td>52</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>75</td>
      <td>keras.preprocessing.sequence.pad_sequences</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15671</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>81</td>
      <td>test_make_sampling_table</td>
      <td>79</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>80</td>
      <td>keras.preprocessing.sequence.make_sampling_table</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15716</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>33</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>32</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15717</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>34</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertLessEqual</td>
      <td>1</td>
      <td>32</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15718</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>40</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>32</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15719</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>40</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>39</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15720</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>41</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertLessEqual</td>
      <td>1</td>
      <td>32</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15721</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>41</td>
      <td>test_one_hot</td>
      <td>30</td>
      <td>assertLessEqual</td>
      <td>1</td>
      <td>39</td>
      <td>keras.preprocessing.text.one_hot</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15723</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>63</td>
      <td>test_tokenizer</td>
      <td>44</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>50</td>
      <td>keras.preprocessing.text.Tokenizer</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15724</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>68</td>
      <td>test_hashing_trick_hash</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>67</td>
      <td>keras.preprocessing.text.hashing_trick</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15725</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>69</td>
      <td>test_hashing_trick_hash</td>
      <td>65</td>
      <td>assertLessEqual</td>
      <td>1</td>
      <td>67</td>
      <td>keras.preprocessing.text.hashing_trick</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15726</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>76</td>
      <td>test_hashing_trick_md5</td>
      <td>72</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>74</td>
      <td>keras.preprocessing.text.hashing_trick</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15727</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>77</td>
      <td>test_hashing_trick_md5</td>
      <td>72</td>
      <td>assertLessEqual</td>
      <td>1</td>
      <td>74</td>
      <td>keras.preprocessing.text.hashing_trick</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15728</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>107</td>
      <td>test_sequential_fit</td>
      <td>96</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>103</td>
      <td>keras.preprocessing.text.Tokenizer</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15729</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>115</td>
      <td>test_text_to_word_sequence</td>
      <td>112</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>114</td>
      <td>keras.preprocessing.text.text_to_word_sequence</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15730</th>
      <td>keras\preprocessing\text_test.py</td>
      <td>120</td>
      <td>test_text_to_word_sequence_multichar_split</td>
      <td>117</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>119</td>
      <td>keras.preprocessing.text.text_to_word_sequence</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15750</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>70</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15754</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>71</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15758</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>71</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>62</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15759</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>73</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15763</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>73</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>63</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15764</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>87</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15765</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>87</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>64</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15766</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>87</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>67</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15767</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>87</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>81</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15768</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>87</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>84</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15772</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15773</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>64</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15774</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>67</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15775</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>81</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15776</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>84</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15780</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>62</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15781</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>88</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>78</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15783</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>59</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15784</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>64</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15785</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>67</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15786</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>81</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15787</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>84</td>
      <td>keras.utils.data_utils.get_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15791</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>63</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15792</th>
      <td>keras\utils\data_utils_test.py</td>
      <td>89</td>
      <td>test_get_file_and_validate_it</td>
      <td>38</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>79</td>
      <td>keras.utils.data_utils._hash_file</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15796</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>76</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>65</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15799</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>79</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>65</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15802</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>80</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>65</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15805</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>81</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>65</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15810</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>95</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>69</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
    <tr>
      <th>15813</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>100</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>63</td>
      <td>keras.utils.io_utils.HDF5Matrix</td>
      <td>ERROR</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: ERROR

 <br>Commit message: No commit within 100 days of the entered date.
<br>Commit id closest to desired version: ERROR

 <br>Commit message: No commit within 100 days of the entered date.
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\engine\sequential.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13995</th>
      <td>keras\backend_test.py</td>
      <td>1514</td>
      <td>test_string_input</td>
      <td>1508</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>1509</td>
      <td>keras.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14093</th>
      <td>keras\models_test.py</td>
      <td>73</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>60</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14096</th>
      <td>keras\models_test.py</td>
      <td>81</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>60</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14100</th>
      <td>keras\models_test.py</td>
      <td>89</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>60</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14262</th>
      <td>keras\optimizers_test.py</td>
      <td>185</td>
      <td>test_tfoptimizer_iterations</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>180</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14263</th>
      <td>keras\optimizers_test.py</td>
      <td>192</td>
      <td>test_tfoptimizer_iterations</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>180</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14264</th>
      <td>keras\optimizers_test.py</td>
      <td>201</td>
      <td>test_tfoptimizer_iterations</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>180</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14327</th>
      <td>keras\engine\saving_test.py</td>
      <td>251</td>
      <td>test_sequential_weight_loading</td>
      <td>222</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>236</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14328</th>
      <td>keras\engine\saving_test.py</td>
      <td>251</td>
      <td>test_sequential_weight_loading</td>
      <td>222</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>245</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14331</th>
      <td>keras\engine\saving_test.py</td>
      <td>251</td>
      <td>test_sequential_weight_loading</td>
      <td>222</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>236</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14334</th>
      <td>keras\engine\saving_test.py</td>
      <td>366</td>
      <td>test_sequential_model_saving</td>
      <td>332</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>337</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14342</th>
      <td>keras\engine\saving_test.py</td>
      <td>382</td>
      <td>test_sequential_model_saving</td>
      <td>332</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>337</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14350</th>
      <td>keras\engine\saving_test.py</td>
      <td>406</td>
      <td>test_sequential_model_saving_without_compile</td>
      <td>384</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>389</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14357</th>
      <td>keras\engine\saving_test.py</td>
      <td>442</td>
      <td>test_sequential_model_saving_2</td>
      <td>408</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>421</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14360</th>
      <td>keras\engine\saving_test.py</td>
      <td>442</td>
      <td>test_sequential_model_saving_2</td>
      <td>408</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>421</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14439</th>
      <td>keras\engine\sequential_test.py</td>
      <td>45</td>
      <td>test_basic_methods</td>
      <td>39</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>40</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14440</th>
      <td>keras\engine\sequential_test.py</td>
      <td>46</td>
      <td>test_basic_methods</td>
      <td>39</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>40</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14441</th>
      <td>keras\engine\sequential_test.py</td>
      <td>47</td>
      <td>test_basic_methods</td>
      <td>39</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>40</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14445</th>
      <td>keras\engine\sequential_test.py</td>
      <td>73</td>
      <td>test_sequential_pop</td>
      <td>50</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14447</th>
      <td>keras\engine\sequential_test.py</td>
      <td>74</td>
      <td>test_sequential_pop</td>
      <td>50</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14460</th>
      <td>keras\engine\sequential_test.py</td>
      <td>213</td>
      <td>test_nested_sequential_trainability</td>
      <td>201</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>209</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14461</th>
      <td>keras\engine\sequential_test.py</td>
      <td>215</td>
      <td>test_nested_sequential_trainability</td>
      <td>201</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>209</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14462</th>
      <td>keras\engine\sequential_test.py</td>
      <td>217</td>
      <td>test_nested_sequential_trainability</td>
      <td>201</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>209</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14463</th>
      <td>keras\engine\sequential_test.py</td>
      <td>219</td>
      <td>test_nested_sequential_trainability</td>
      <td>201</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>209</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14465</th>
      <td>keras\engine\sequential_test.py</td>
      <td>239</td>
      <td>test_sequential_update_disabling</td>
      <td>221</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>226</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14468</th>
      <td>keras\engine\sequential_test.py</td>
      <td>239</td>
      <td>test_sequential_update_disabling</td>
      <td>221</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>226</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14472</th>
      <td>keras\engine\sequential_test.py</td>
      <td>272</td>
      <td>test_sequential_deferred_build_serialization</td>
      <td>250</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>271</td>
      <td>keras.models.Sequential.from_config</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14684</th>
      <td>keras\engine\training_eager_test.py</td>
      <td>146</td>
      <td>test_generator_methods</td>
      <td>128</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>129</td>
      <td>keras.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14709</th>
      <td>keras\engine\training_test.py</td>
      <td>868</td>
      <td>test_masking_graph_sequential</td>
      <td>857</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>860</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14713</th>
      <td>keras\engine\training_test.py</td>
      <td>882</td>
      <td>test_masking_deferred_sequential</td>
      <td>871</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>874</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14723</th>
      <td>keras\engine\training_test.py</td>
      <td>951</td>
      <td>test_empty_model_no_learning_phase</td>
      <td>948</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>950</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14724</th>
      <td>keras\engine\training_test.py</td>
      <td>959</td>
      <td>test_dropout_has_learning_phase</td>
      <td>953</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>955</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14726</th>
      <td>keras\engine\training_test.py</td>
      <td>988</td>
      <td>test_trainable_argument</td>
      <td>977</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>982</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14729</th>
      <td>keras\engine\training_test.py</td>
      <td>988</td>
      <td>test_trainable_argument</td>
      <td>977</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>982</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14733</th>
      <td>keras\engine\training_test.py</td>
      <td>998</td>
      <td>test_trainable_argument</td>
      <td>977</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>982</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14737</th>
      <td>keras\engine\training_test.py</td>
      <td>998</td>
      <td>test_trainable_argument</td>
      <td>977</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>982</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14764</th>
      <td>keras\engine\training_test.py</td>
      <td>2424</td>
      <td>test_metrics_masking</td>
      <td>2406</td>
      <td>assertArrayNear</td>
      <td>1</td>
      <td>2409</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14769</th>
      <td>keras\engine\training_test.py</td>
      <td>2429</td>
      <td>test_metrics_masking</td>
      <td>2406</td>
      <td>assertArrayNear</td>
      <td>1</td>
      <td>2409</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14860</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>127</td>
      <td>test_conv_lstm_statefulness</td>
      <td>81</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>96</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14863</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>127</td>
      <td>test_conv_lstm_statefulness</td>
      <td>81</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>96</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14868</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>198</td>
      <td>test_conv_lstm_cloning</td>
      <td>183</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>185</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>14872</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>198</td>
      <td>test_conv_lstm_cloning</td>
      <td>183</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>185</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15008</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>197</td>
      <td>test_statefulness</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>185</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15010</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>216</td>
      <td>test_statefulness</td>
      <td>177</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>185</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15012</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>216</td>
      <td>test_statefulness</td>
      <td>177</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>185</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15036</th>
      <td>keras\layers\gru_test.py</td>
      <td>104</td>
      <td>test_statefulness_GRU</td>
      <td>84</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15038</th>
      <td>keras\layers\gru_test.py</td>
      <td>123</td>
      <td>test_statefulness_GRU</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15040</th>
      <td>keras\layers\gru_test.py</td>
      <td>123</td>
      <td>test_statefulness_GRU</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15042</th>
      <td>keras\layers\gru_test.py</td>
      <td>144</td>
      <td>test_statefulness_GRU</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15045</th>
      <td>keras\layers\gru_test.py</td>
      <td>144</td>
      <td>test_statefulness_GRU</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15094</th>
      <td>keras\layers\lstm_test.py</td>
      <td>119</td>
      <td>test_statefulness_LSTM</td>
      <td>99</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>106</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15096</th>
      <td>keras\layers\lstm_test.py</td>
      <td>138</td>
      <td>test_statefulness_LSTM</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>106</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15098</th>
      <td>keras\layers\lstm_test.py</td>
      <td>138</td>
      <td>test_statefulness_LSTM</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>106</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15100</th>
      <td>keras\layers\lstm_test.py</td>
      <td>159</td>
      <td>test_statefulness_LSTM</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>106</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15103</th>
      <td>keras\layers\lstm_test.py</td>
      <td>159</td>
      <td>test_statefulness_LSTM</td>
      <td>99</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>106</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15272</th>
      <td>keras\layers\normalization_test.py</td>
      <td>95</td>
      <td>test_batchnorm_correctness</td>
      <td>81</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>83</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15275</th>
      <td>keras\layers\normalization_test.py</td>
      <td>96</td>
      <td>test_batchnorm_correctness</td>
      <td>81</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>83</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15278</th>
      <td>keras\layers\normalization_test.py</td>
      <td>113</td>
      <td>test_batchnorm_mixed_precision</td>
      <td>98</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>100</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15281</th>
      <td>keras\layers\normalization_test.py</td>
      <td>114</td>
      <td>test_batchnorm_mixed_precision</td>
      <td>98</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>100</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15284</th>
      <td>keras\layers\normalization_test.py</td>
      <td>132</td>
      <td>test_batchnorm_convnet</td>
      <td>116</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>119</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15287</th>
      <td>keras\layers\normalization_test.py</td>
      <td>133</td>
      <td>test_batchnorm_convnet</td>
      <td>116</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>119</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15290</th>
      <td>keras\layers\normalization_test.py</td>
      <td>152</td>
      <td>test_batchnorm_convnet_channel_last</td>
      <td>135</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>139</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15293</th>
      <td>keras\layers\normalization_test.py</td>
      <td>153</td>
      <td>test_batchnorm_convnet_channel_last</td>
      <td>135</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>139</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15449</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>104</td>
      <td>test_statefulness_SimpleRNN</td>
      <td>84</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15451</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>123</td>
      <td>test_statefulness_SimpleRNN</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15453</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>123</td>
      <td>test_statefulness_SimpleRNN</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15455</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>144</td>
      <td>test_statefulness_SimpleRNN</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>1</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15458</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>144</td>
      <td>test_statefulness_SimpleRNN</td>
      <td>84</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>91</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15469</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>155</td>
      <td>test_regularizers</td>
      <td>146</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>148</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15474</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>188</td>
      <td>test_TimeDistributed_batchnorm</td>
      <td>168</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>171</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15480</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>323</td>
      <td>test_bidirectional_weight_loading</td>
      <td>307</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>315</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15483</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>323</td>
      <td>test_bidirectional_weight_loading</td>
      <td>307</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>315</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
    <tr>
      <th>15809</th>
      <td>keras\utils\io_utils_test.py</td>
      <td>95</td>
      <td>test_HDF5Matrix</td>
      <td>51</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>83</td>
      <td>keras.models.Sequential</td>
      <td>tensorflow\python\keras\engine\sequential.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: da6568a4d354c8863ecbb8991817e546c5f361e5

 <br>Commit message: Remove the API usage monitoring call in the legacy keras code.<br><br>PiperOrigin-RevId: 383499649<br>Change-Id: Idf581a8cc9e043714819a25a0d0104d177fee782<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/engine/sequential.py b/tensorflow/python/keras/engine/sequential.py
<br>index 293ad9ca9ed..2c5e92aaef1 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/engine/sequential.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/engine/sequential.py</span>
<br>@@ -13,11 +13,7 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Home of the `Sequential` model.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Home of the `Sequential` model."""</span>
<br>&nbsp
<br>&nbspimport copy
<br>&nbspimport warnings
<br>@@ -117,7 +113,6 @@ class Sequential(functional.Functional):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Skip the init in FunctionalModel since model doesn't have input/output yet
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(functional.Functional, self).__init__(  # pylint: disable=bad-super-call
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name, autocast=False)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('Sequential').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.supports_masking = True
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._compute_output_and_mask_jointly = True
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._auto_track_sub_layers = False
<br>@@ -363,7 +358,7 @@ class Sequential(functional.Functional):
<br>&nbsp &nbsp &nbspdef call(self, inputs, training=None, mask=None):  # pylint: disable=redefined-outer-name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# If applicable, update the static input shape of the model.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self._has_explicit_input_shape:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not tensor_util.is_tensor(inputs) and not isinstance(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not tensor_util.is_tf_type(inputs) and not isinstance(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, np_arrays.ndarray):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This is a Sequential with mutiple inputs. This is technically an
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# invalid use case of Sequential, but we tolerate it for backwards
<br>@@ -414,7 +409,7 @@ class Sequential(functional.Functional):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# TODO(omalleyt): b/123540974 This function is not really safe to call
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# by itself because it will duplicate any updates and losses in graph
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# mode by `call`ing the Layers again.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs = self.call(inputs, mask=mask)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutputs = self.call(inputs, mask=mask)  # pylint: disable=unexpected-keyword-arg</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn getattr(outputs, '_keras_mask', None)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef predict_proba(self, x, batch_size=32, verbose=0):
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\callbacks.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14001</th>
      <td>keras\callbacks_test.py</td>
      <td>469</td>
      <td>test_ReduceLROnPlateau_backwards_compatibility</td>
      <td>464</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>466</td>
      <td>keras.callbacks.ReduceLROnPlateau</td>
      <td>tensorflow\python\keras\callbacks.py</td>
    </tr>
    <tr>
      <th>14002</th>
      <td>keras\callbacks_test.py</td>
      <td>470</td>
      <td>test_ReduceLROnPlateau_backwards_compatibility</td>
      <td>464</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>466</td>
      <td>keras.callbacks.ReduceLROnPlateau</td>
      <td>tensorflow\python\keras\callbacks.py</td>
    </tr>
    <tr>
      <th>14003</th>
      <td>keras\callbacks_test.py</td>
      <td>471</td>
      <td>test_ReduceLROnPlateau_backwards_compatibility</td>
      <td>464</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>466</td>
      <td>keras.callbacks.ReduceLROnPlateau</td>
      <td>tensorflow\python\keras\callbacks.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 9489702e35b16a40a1accf3b8b5ed557efae10c7

 <br>Commit message: Merge pull request #45420 from offscale:args-for-google-style-docstrings<br><br>PiperOrigin-RevId: 348788129<br>Change-Id: I2e4c86b5526fdc83fec1e176702049f1462d1b12<br><br>
<br>Commit id closest to desired version: e104b6a9e87ea5956451ab56c1f5ca486c511bc4

 <br>Commit message: Fix Model graph logging to TensorBoard for ParameterServerStrategy.<br><br>PiperOrigin-RevId: 377328864<br>Change-Id: I796af0e8db39cceb444b807d20532f20d1cbd4fc<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/callbacks.py b/tensorflow/python/keras/callbacks.py
<br>index ae81157f00b..daa4b7c65d6 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/callbacks.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/callbacks.py</span>
<br>@@ -14,34 +14,32 @@
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=g-import-not-at-top
<br>&nbsp# pylint: disable=g-classes-have-attributes
<br><span style="color:red">- """Callbacks: utilities called at certain points during model training.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Callbacks: utilities called at certain points during model training."""</span>
<br>&nbsp
<br>&nbspimport collections
<br>&nbspimport copy
<br>&nbspimport csv
<br><span style="color:red">- import io</span>
<br>&nbspimport json
<br>&nbspimport os
<br>&nbspimport re
<br><span style="color:green">+import sys</span>
<br>&nbspimport time
<br>&nbsp
<br>&nbspimport numpy as np
<br><span style="color:red">- import six</span>
<br>&nbsp
<br>&nbspfrom tensorflow.core.framework import summary_pb2
<br>&nbspfrom tensorflow.python.data.ops import iterator_ops
<br>&nbspfrom tensorflow.python.distribute import collective_all_reduce_strategy
<br><span style="color:green">+from tensorflow.python.distribute import distribution_strategy_context as ds_context</span>
<br>&nbspfrom tensorflow.python.distribute import mirrored_strategy
<br><span style="color:green">+from tensorflow.python.distribute import parameter_server_strategy_v2</span>
<br>&nbspfrom tensorflow.python.distribute import tpu_strategy
<br>&nbspfrom tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.framework import constant_op
<br>&nbspfrom tensorflow.python.framework import dtypes
<br><span style="color:green">+from tensorflow.python.framework import errors</span>
<br>&nbspfrom tensorflow.python.framework import ops
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras.distribute import distributed_file_utils
<br>&nbspfrom tensorflow.python.keras.distribute import worker_training_state
<br>&nbspfrom tensorflow.python.keras.optimizer_v2 import learning_rate_schedule
<br>@@ -201,7 +199,7 @@ def make_logs(model, logs, outputs, mode, prefix=''):
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.callbacks.CallbackList')
<br><span style="color:red">- class CallbackList(object):</span>
<br><span style="color:green">+class CallbackList:</span>
<br>&nbsp &nbsp &nbsp"""Container abstracting a list of callbacks."""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>@@ -236,6 +234,14 @@ class CallbackList(object):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Performance optimization: determines if batch hooks need to be called.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# pylint: disable=protected-access
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._supports_tf_logs = all(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgetattr(cb, '_supports_tf_logs', False) for cb in self.callbacks)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._batch_hooks_support_tf_logs = all(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgetattr(cb, '_supports_tf_logs', False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor cb in self.callbacks</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif cb._implements_train_batch_hooks() or cb</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp._implements_test_batch_hooks() or cb._implements_predict_batch_hooks())</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._should_call_train_batch_hooks = any(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcb._implements_train_batch_hooks() for cb in self.callbacks)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._should_call_test_batch_hooks = any(
<br>@@ -244,10 +250,12 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcb._implements_predict_batch_hooks() for cb in self.callbacks)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# pylint: enable=protected-access
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._disallow_batch_hooks_in_ps_strategy()</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Performance check: Check batch hooks for slowness compared to batch time.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Only run check for custom callbacks (i.e. not present in this file).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._check_timing = any([cbk.__class__.__name__ not in globals()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor cbk in self.callbacks])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._check_timing = any(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcbk.__class__.__name__ not in globals() for cbk in self.callbacks)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._num_batches_for_timing_check = 5
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._hook_times = {}
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._batch_start_time = None
<br>@@ -272,6 +280,16 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._history = History()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.callbacks.append(self._history)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _process_logs(self, logs, is_batch_hook=False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Turns tensors into numpy arrays or Python scalars if necessary."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif logs is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn {}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._supports_tf_logs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn logs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif is_batch_hook and self._batch_hooks_support_tf_logs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn logs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspdef append(self, callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.callbacks.append(callback)
<br>&nbsp
<br>@@ -347,19 +365,13 @@ class CallbackList(object):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _call_batch_hook_helper(self, hook_name, batch, logs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Helper function for `on_*_batch_*` methods."""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._check_timing:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstart_time = time.time()
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs, is_batch_hook=True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphook = getattr(callback, hook_name)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphook(batch, logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphook(batch, numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsphook(batch, logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._check_timing:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hook_name not in self._hook_times:
<br>@@ -402,15 +414,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_begin(epoch, logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_begin(epoch, numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_begin(epoch, logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_end(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_epoch_end` methods of its callbacks.
<br>@@ -423,15 +429,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation epoch if validation is performed. Validation result keys
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare prefixed with `val_`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_end(epoch, logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_end(epoch, numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_epoch_end(epoch, logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_train_batch_begin(self, batch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_train_batch_begin` methods of its callbacks.
<br>@@ -506,15 +506,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_begin(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_begin(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_begin(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_train_end(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_train_end` methods of its callbacks.
<br>@@ -523,15 +517,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_end(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_end(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_train_end(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_test_begin(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_test_begin` methods of its callbacks.
<br>@@ -540,15 +528,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_begin(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_begin(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_begin(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_test_end(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_test_end` methods of its callbacks.
<br>@@ -557,15 +539,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_end(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_end(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_test_end(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_predict_begin(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the 'on_predict_begin` methods of its callbacks.
<br>@@ -574,15 +550,9 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_begin(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_begin(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_begin(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_predict_end(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Calls the `on_predict_end` methods of its callbacks.
<br>@@ -591,24 +561,83 @@ class CallbackList(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict. Currently no data is passed to this argument for this method
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbut that may change in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = logs or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnumpy_logs = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = self._process_logs(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor callback in self.callbacks:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(callback, '_supports_tf_logs', False):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_end(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif numpy_logs is None:  # Only convert once.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumpy_logs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_end(numpy_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallback.on_predict_end(logs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __iter__(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn iter(self.callbacks)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _disallow_batch_hooks_in_ps_strategy(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Error out if batch-level callbacks are passed with PSStrategy."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstrategy = ds_context.get_strategy()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif strategy._should_use_with_coordinator:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspunsupported_callbacks = []</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor cb in self.callbacks:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# These Callbacks can accept RemoteValues directly.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(cb, '_supports_tf_logs', False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontinue</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (cb._implements_train_batch_hooks() or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcb._implements_test_batch_hooks() or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcb._implements_predict_batch_hooks()):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspunsupported_callbacks.append(cb)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif unsupported_callbacks:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Batch-level `Callback`s are not supported with '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`ParameterServerStrategy`. Found unsupported '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'callbacks: {}'.format(unsupported_callbacks))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# pylint: enable=protected-access</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbsp@keras_export('keras.callbacks.Callback')
<br><span style="color:red">- class Callback(object):</span>
<br><span style="color:green">+class Callback:</span>
<br>&nbsp &nbsp &nbsp"""Abstract base class used to build new callbacks.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspCallbacks can be passed to keras methods such as `fit`, `evaluate`, and</span>
<br><span style="color:green">+&nbsp &nbsp`predict` in order to hook into the various stages of the model training and</span>
<br><span style="color:green">+&nbsp &nbspinference lifecycle.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspTo create a custom callback, subclass `keras.callbacks.Callback` and override</span>
<br><span style="color:green">+&nbsp &nbspthe method associated with the stage of interest. See</span>
<br><span style="color:green">+&nbsp &nbsphttps://www.tensorflow.org/guide/keras/custom_callback for more information.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExample:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> training_finished = False</span>
<br><span style="color:green">+&nbsp &nbsp>>> class MyCallback(tf.keras.callbacks.Callback):</span>
<br><span style="color:green">+&nbsp &nbsp...   def on_train_end(self, logs=None):</span>
<br><span style="color:green">+&nbsp &nbsp...     global training_finished</span>
<br><span style="color:green">+&nbsp &nbsp...     training_finished = True</span>
<br><span style="color:green">+&nbsp &nbsp>>> model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])</span>
<br><span style="color:green">+&nbsp &nbsp>>> model.compile(loss='mean_squared_error')</span>
<br><span style="color:green">+&nbsp &nbsp>>> model.fit(tf.constant([[1.0]]), tf.constant([[1.0]]),</span>
<br><span style="color:green">+&nbsp &nbsp...           callbacks=[MyCallback()])</span>
<br><span style="color:green">+&nbsp &nbsp>>> assert training_finished == True</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspIf you want to use `Callback` objects in a custom training loop:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp1. You should pack all your callbacks into a single `callbacks.CallbackList`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspso they can all be called together.</span>
<br><span style="color:green">+&nbsp &nbsp2. You will need to manually call all the `on_*` methods at the apropriate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsplocations in your loop. Like this:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp```</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspcallbacks =  tf.keras.callbacks.CallbackList([...])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspcallbacks.append(...)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_train_begin(...)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspfor epoch in range(EPOCHS):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_epoch_begin(epoch)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i, data in dataset.enumerate():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_train_batch_begin(i)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_logs = model.train_step(data)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_train_batch_end(i, batch_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepoch_logs = ...</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_epoch_end(epoch, epoch_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspfinal_logs=...</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_train_end(final_logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp```</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspAttributes:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparams: Dict. Training parameters
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(eg. verbosity, batch size, number of epochs...).
<br>@@ -670,7 +699,8 @@ class Callback(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs: Dict, metric results for this training epoch, and for the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation epoch if validation is performed. Validation result keys
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare prefixed with `val_`. For training epoch, the values of the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Model`'s metrics are returned. Example : `{'loss': 0.2, 'acc': 0.7}`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Model`'s metrics are returned. Example : `{'loss': 0.2, 'accuracy':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.7}`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbsp@doc_controls.for_subclass_implementers
<br>@@ -933,7 +963,7 @@ class TerminateOnNaN(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsplogs = logs or {}
<br>&nbsp &nbsp &nbsp &nbsp &nbsploss = logs.get('loss')
<br>&nbsp &nbsp &nbsp &nbsp &nbspif loss is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss = tf_utils.to_numpy_or_python_type(loss)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss = tf_utils.sync_to_numpy_or_python_type(loss)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif np.isnan(loss) or np.isinf(loss):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('Batch %d: Invalid loss, terminating training' % (batch))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.stop_training = True
<br>@@ -967,7 +997,7 @@ class ProgbarLogger(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Unknown `count_mode`: ' + str(count_mode))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Defaults to all Model's metrics except for loss.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.stateful_metrics = set(stateful_metrics) if stateful_metrics else None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.stateful_metrics = set(stateful_metrics) if stateful_metrics else set()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.seen = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.progbar = None
<br>@@ -1044,11 +1074,17 @@ class ProgbarLogger(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.progbar = None
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _maybe_init_progbar(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.stateful_metrics is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.model:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.stateful_metrics = set(m.name for m in self.model.metrics)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.stateful_metrics = set()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Instantiate a `Progbar` if not yet, and update the stateful metrics."""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TODO(rchao): Legacy TF1 code path may use list for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `self.stateful_metrics`. Remove "cast to set" when TF1 support is dropped.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.stateful_metrics = set(self.stateful_metrics)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.model:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Update the existing stateful metrics as `self.model.metrics` may contain</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# updated metrics after `MetricsContainer` is built in the first train</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# step.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.stateful_metrics = self.stateful_metrics.union(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspset(m.name for m in self.model.metrics))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.progbar is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.progbar = Progbar(
<br>@@ -1057,6 +1093,8 @@ class ProgbarLogger(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstateful_metrics=self.stateful_metrics,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspunit_name='step' if self.use_steps else 'sample')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.progbar._update_stateful_metrics(self.stateful_metrics)  # pylint: disable=protected-access</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspdef _implements_train_batch_hooks(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn self._call_batch_hooks
<br>&nbsp
<br>@@ -1083,11 +1121,11 @@ class ProgbarLogger(Callback):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.verbose == 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Only block async when verbose = 1.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.progbar.update(self.seen, list(logs.items()), finalize=False)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _finalize_progbar(self, logs, counter):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs or {})</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs or {})</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.target is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif counter is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcounter = counter.numpy()
<br>@@ -1105,6 +1143,19 @@ class History(Callback):
<br>&nbsp &nbsp &nbspThis callback is automatically applied to
<br>&nbsp &nbsp &nbspevery Keras model. The `History` object
<br>&nbsp &nbsp &nbspgets returned by the `fit` method of models.
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExample:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<br><span style="color:green">+&nbsp &nbsp>>> model.compile(tf.keras.optimizers.SGD(), loss='mse')</span>
<br><span style="color:green">+&nbsp &nbsp>>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<br><span style="color:green">+&nbsp &nbsp...                     epochs=10)</span>
<br><span style="color:green">+&nbsp &nbsp>>> print(history.params)</span>
<br><span style="color:green">+&nbsp &nbsp{'verbose': 1, 'epochs': 10, 'steps': 1}</span>
<br><span style="color:green">+&nbsp &nbsp>>> # check the keys of history object</span>
<br><span style="color:green">+&nbsp &nbsp>>> print(history.history.keys())</span>
<br><span style="color:green">+&nbsp &nbspdict_keys(['loss'])</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self):
<br>@@ -1205,8 +1256,9 @@ class ModelCheckpoint(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdecision to overwrite the current save file is made based on either
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe maximization or the minimization of the monitored quantity.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor `val_acc`, this should be `max`, for `val_loss` this should be
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`min`, etc. In `auto` mode, the direction is automatically inferred</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom the name of the monitored quantity.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`min`, etc. In `auto` mode, the mode is set to `max` if the quantities</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmonitored are 'acc' or start with 'fmeasure' and are set to `min` for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe rest of the quantities.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_weights_only: if True, then only the model's weights will be saved
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(`model.save_weights(filepath)`), else the full model is saved
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(`model.save(filepath)`).
<br>@@ -1252,7 +1304,7 @@ class ModelCheckpoint(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptions, checkpoint_options_lib.CheckpointOptions):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._options = options or checkpoint_options_lib.CheckpointOptions()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('If save_weights_only is True, then `options` must be'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('If save_weights_only is True, then `options` must be '</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'either None or a tf.train.CheckpointOptions')
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif options is None or isinstance(options, save_options_lib.SaveOptions):
<br>@@ -1307,14 +1359,6 @@ class ModelCheckpoint(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# restore checkpoint at on_train_begin().
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._chief_worker_only = False
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef set_model(self, model):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.model = model</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Use name matching rather than `isinstance` to avoid circular dependencies.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif (not self.save_weights_only and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot model._is_graph_network and  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel.__class__.__name__ != 'Sequential'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.save_weights_only = True</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef on_train_begin(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.load_weights_on_restart:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfilepath_to_load = (
<br>@@ -1376,7 +1420,7 @@ class ModelCheckpoint(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self.save_freq,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspint) or self.epochs_since_last_save >= self.period:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Block only when saving interval is reached.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.epochs_since_last_save = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfilepath = self._get_file_path(epoch, logs)
<br>&nbsp
<br>@@ -1412,9 +1456,13 @@ class ModelCheckpoint(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.save(filepath, overwrite=True, options=self._options)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._maybe_remove_file()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept IOError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept IsADirectoryError as e:  # h5py 3.x</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise IOError('Please specify a non-directory filepath for '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ModelCheckpoint. Filepath used is an existing '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'directory: {}'.format(filepath))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept IOError as e:  # h5py 2.x</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# `e.errno` appears to be `None` so checking the content of `e.args[0]`.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 'is a directory' in six.ensure_str(e.args[0]).lower():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 'is a directory' in str(e.args[0]).lower():</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise IOError('Please specify a non-directory filepath for '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'ModelCheckpoint. Filepath used is an existing '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'directory: {}'.format(filepath))
<br>@@ -1609,7 +1657,8 @@ class BackupAndRestore(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._supported_strategies = (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmirrored_strategy.MirroredStrategy,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcollective_all_reduce_strategy.CollectiveAllReduceStrategy,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptpu_strategy.TPUStrategy, tpu_strategy.TPUStrategyV2)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptpu_strategy.TPUStrategy, tpu_strategy.TPUStrategyV2,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparameter_server_strategy_v2.ParameterServerStrategyV2)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not context.executing_eagerly():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ops.inside_function():
<br>@@ -1626,9 +1675,6 @@ class BackupAndRestore(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# restore checkpoint at on_train_begin().
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._chief_worker_only = False
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspdef set_model(self, model):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.model = model</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbspdef on_train_begin(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# TrainingState is used to manage the training state needed for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# failure-recovery of a worker in training.
<br>@@ -1697,7 +1743,10 @@ class EarlyStopping(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsprestore_best_weights: Whether to restore model weights from
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe epoch with the best value of the monitored quantity.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf False, the model weights obtained at the last step of
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining are used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining are used. An epoch will be restored regardless</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the performance relative to the `baseline`. If no epoch</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimproves on `baseline`, training will run for `patience`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepochs and restore weights from the best epoch in that set.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspExample:
<br>&nbsp
<br>@@ -1757,30 +1806,33 @@ class EarlyStopping(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Allow instances to be re-used
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.wait = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.stopped_epoch = 0
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.baseline is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.best = self.baseline</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.best = np.Inf if self.monitor_op == np.less else -np.Inf</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.best = np.Inf if self.monitor_op == np.less else -np.Inf</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.best_weights = None
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_end(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspcurrent = self.get_monitor_value(logs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif current is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.monitor_op(current - self.min_delta, self.best):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.restore_best_weights and self.best_weights is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Restore the weights after first epoch if no progress is ever made.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.best_weights = self.model.get_weights()</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.wait += 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._is_improvement(current, self.best):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.best = current
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.wait = 0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.restore_best_weights:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.best_weights = self.model.get_weights()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.wait += 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.wait >= self.patience:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.stopped_epoch = epoch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.stop_training = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.restore_best_weights:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.verbose > 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('Restoring model weights from the end of the best epoch.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.set_weights(self.best_weights)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Only restart wait if we beat both the baseline and our previous best.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.baseline is None or self._is_improvement(current, self.baseline):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.wait = 0</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.wait >= self.patience:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.stopped_epoch = epoch</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.stop_training = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.restore_best_weights and self.best_weights is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.verbose > 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('Restoring model weights from the end of the best epoch.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.model.set_weights(self.best_weights)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_train_end(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.stopped_epoch > 0 and self.verbose > 0:
<br>@@ -1795,6 +1847,9 @@ class EarlyStopping(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.monitor, ','.join(list(logs.keys())))
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn monitor_value
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _is_improvement(self, monitor_value, reference_value):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self.monitor_op(monitor_value - self.min_delta, reference_value)</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbsp@keras_export('keras.callbacks.RemoteMonitor')
<br>&nbspclass RemoteMonitor(Callback):
<br>@@ -1906,7 +1961,7 @@ class LearningRateScheduler(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not hasattr(self.model.optimizer, 'lr'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Optimizer must have a "lr" attribute.')
<br>&nbsp &nbsp &nbsp &nbsp &nbsptry:  # new API
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplr = float(K.get_value(self.model.optimizer.lr))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplr = float(backend.get_value(self.model.optimizer.lr))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplr = self.schedule(epoch, lr)
<br>&nbsp &nbsp &nbsp &nbsp &nbspexcept TypeError:  # Support for old API for backward compatibility
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplr = self.schedule(epoch)
<br>@@ -1915,14 +1970,14 @@ class LearningRateScheduler(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'should be float.')
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The dtype of Tensor should be float')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspK.set_value(self.model.optimizer.lr, K.get_value(lr))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbackend.set_value(self.model.optimizer.lr, backend.get_value(lr))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.verbose > 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('\nEpoch %05d: LearningRateScheduler reducing learning '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('\nEpoch %05d: LearningRateScheduler setting learning '</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'rate to %s.' % (epoch + 1, lr))
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_end(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsplogs = logs or {}
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs['lr'] = K.get_value(self.model.optimizer.lr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs['lr'] = backend.get_value(self.model.optimizer.lr)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef keras_model_summary(name, data, step=None):
<br>@@ -1959,7 +2014,7 @@ def keras_model_summary(name, data, step=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspjson_string = data.to_json()
<br>&nbsp &nbsp &nbspexcept Exception as exc:  # pylint: disable=broad-except
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# An exception should not break a model code.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogging.warn('Model failed to serialize as JSON. Ignoring... %s', exc)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging.warning('Model failed to serialize as JSON. Ignoring... %s', exc)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn False
<br>&nbsp
<br>&nbsp &nbsp &nbspwith summary_ops_v2.summary_scope(name, 'graph_keras_model',
<br>@@ -1984,6 +2039,11 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp* Activation histograms
<br>&nbsp &nbsp &nbsp* Sampled profiling
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspWhen used in `Model.evaluate`, in addition to epoch summaries, there will be</span>
<br><span style="color:green">+&nbsp &nbspa summary that records evaluation metrics vs `Model.optimizer.iterations`</span>
<br><span style="color:green">+&nbsp &nbspwritten. The metric names will be prepended with `evaluation`, with</span>
<br><span style="color:green">+&nbsp &nbsp`Model.optimizer.iterations` being the step in the visualized TensorBoard.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspIf you have installed TensorFlow with pip, you should be able
<br>&nbsp &nbsp &nbspto launch TensorBoard from the command line:
<br>&nbsp
<br>@@ -2021,12 +2081,10 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto disable profiling.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspembeddings_freq: frequency (in epochs) at which embedding layers will be
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvisualized. If set to 0, embeddings won't be visualized.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspembeddings_metadata: a dictionary which maps layer name to a file name in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich metadata for this embedding layer is saved. See the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[details](</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabout metadata files format. In case if the same metadata file is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for all embedding layers, string can be passed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspembeddings_metadata: Dictionary which maps embedding layer names to the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfilename of a file in which to save metadata for the embedding layer.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn case the same metadata file is to be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused for all embedding layers, a single filename can be passed.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspExamples:
<br>&nbsp
<br>@@ -2122,7 +2180,6 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.embeddings_freq = embeddings_freq
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.embeddings_metadata = embeddings_metadata
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._init_profile_batch(profile_batch)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._epoch = 0</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._global_train_batch = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._previous_epoch_iterations = 0
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._train_accumulated_time = 0
<br>@@ -2209,7 +2266,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Writes Keras model train_function graph to TensorBoard."""
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith self._train_writer.as_default():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith summary_ops_v2.record_if(True):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_fn = self.model.train_function</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_fn = self.model.train_tf_function</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If the train_function is a `tf.function`, we can write out a graph
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(train_fn, 'function_spec'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.graph(train_fn._concrete_stateful_fn.graph)  # pylint: disable=protected-access
<br>@@ -2263,35 +2320,24 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.update_freq == 'epoch':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state = summary_ops_v2._summary_state  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._prev_summary_state.append({</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'is_recording': summary_state.is_recording,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'writer': summary_state.writer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'step': summary_state.step</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp})</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.update_freq == 'epoch':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshould_record = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwriter = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshould_record = lambda: math_ops.equal(step % self.update_freq, 0)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state.is_recording = should_record</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state.writer = writer</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshould_record = lambda: math_ops.equal(step % self.update_freq, 0)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# TODO(b/151339474): Fix deadlock when not using .value() here.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_ops_v2.set_step(step.value())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsummary_context = (writer.as_default(step.value()),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.record_if(should_record))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._prev_summary_state.append(summary_context)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsummary_context[0].__enter__()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsummary_context[1].__enter__()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _pop_writer(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Pops the current writer."""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.update_freq == 'epoch':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprev_state = self._prev_summary_state.pop()</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state = summary_ops_v2._summary_state  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state.is_recording = prev_state['is_recording']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_state.writer = prev_state['writer']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsummary_ops_v2.set_step(prev_state['step'])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# See _push_writer for the content of the previous_context, which is pair</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# of context.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprevious_context = self._prev_summary_state.pop()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprevious_context[1].__exit__(*sys.exc_info())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspprevious_context[0].__exit__(*sys.exc_info())</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _close_writers(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor writer in self._writers.values():
<br>@@ -2299,16 +2345,15 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _init_profile_batch(self, profile_batch):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Validate profile_batch value and set the range of batches to profile.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSets values of _start_batch and _stop_batch attributes,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspecifying the start and stop batch to profile.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspSetting `profile_batch=0` disables profiling.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofile_batch: The range of batches to profile. Should be a non-negative
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinteger or a comma separated string of pair of positive integers. A pair
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof positive integers signify a range of batches to profile.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA pair of non-negative integers specifying the start and stop batch to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofile.</span>
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspRaises:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If profile_batch is not an integer or a comma seperated pair
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof positive integers.
<br>@@ -2320,7 +2365,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to profile. Found: {}'.format(profile_batch))
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Support legacy way of specifying "start,stop" or "start" as str.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(profile_batch, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(profile_batch, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofile_batch = str(profile_batch).split(',')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofile_batch = nest.map_structure(int, profile_batch)
<br>&nbsp
<br>@@ -2335,10 +2380,14 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._start_batch < 0 or self._stop_batch < self._start_batch:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(profile_batch_error_message)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# True when the profiler was successfully started by this callback.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# We track the status here to make sure callbacks do not interfere with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# each other. The callback will only stop the profiler it started.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._profiler_started = False</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._start_batch > 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Warm up and improve the profiling accuracy.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofiler.start('')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofiler.stop(save=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._start_profiler(logdir='')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._stop_profiler(save=False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# True when a trace is running.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._is_tracing = False
<br>&nbsp
<br>@@ -2364,10 +2413,18 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._push_writer(self._val_writer, self._val_step)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_test_end(self, logs=None):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.model.optimizer and hasattr(self.model.optimizer, 'iterations'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith summary_ops_v2.record_if(True), self._val_writer.as_default():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor name, value in logs.items():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.scalar(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'evaluation_' + name + '_vs_iterations',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstep=self.model.optimizer.iterations.read_value())</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._pop_writer()
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _implements_train_batch_hooks(self):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn self._should_trace  # Only call batch hooks when tracing is enabled</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Only call batch hooks when tracing or write_steps_per_second are enabled</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn self._should_trace or self.write_steps_per_second</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_train_batch_begin(self, batch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._global_train_batch += 1
<br>@@ -2386,7 +2443,8 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.write_steps_per_second:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_run_time = time.time() - self._batch_start_time
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._train_accumulated_time += batch_run_time
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.scalar('batch_steps_per_second', 1. / batch_run_time)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.scalar(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch_steps_per_second', 1. / batch_run_time, step=self._train_step)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self._should_trace:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br>@@ -2395,7 +2453,6 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_begin(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Keeps track of epoch for profiling.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._epoch = epoch</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.write_steps_per_second:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._previous_epoch_iterations = self.model.optimizer.iterations.numpy()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._train_accumulated_time = 0
<br>@@ -2412,7 +2469,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _start_trace(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.trace_on(graph=True, profiler=False)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprofiler.start(logdir=self._train_dir)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._start_profiler(logdir=self._train_dir)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._is_tracing = True
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _stop_trace(self, batch=None):
<br>@@ -2423,7 +2480,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith summary_ops_v2.record_if(True):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(b/126388999): Remove step info in the summary name.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.trace_export(name='batch_%d' % batch, step=batch)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspprofiler.stop()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._stop_profiler()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._is_tracing = False
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _collect_learning_rate(self, logs):
<br>@@ -2480,23 +2537,23 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbspdef _log_weight_as_image(self, weight, weight_name, epoch):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Logs a weight as a TensorBoard image."""
<br>&nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.squeeze(weight)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshape = K.int_shape(w_img)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape = backend.int_shape(w_img)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(shape) == 1:  # Bias case
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.reshape(w_img, [1, shape[0], 1, 1])
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif len(shape) == 2:  # Dense layer kernel case
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif shape[0] > shape[1]:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.transpose(w_img)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = K.int_shape(w_img)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = backend.int_shape(w_img)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.reshape(w_img, [1, shape[0], shape[1], 1])
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif len(shape) == 3:  # ConvNet case
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif K.image_data_format() == 'channels_last':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif backend.image_data_format() == 'channels_last':</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Switch to channels_first to display every kernel as a separate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# image.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.transpose(w_img, perm=[2, 0, 1])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = K.int_shape(w_img)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = backend.int_shape(w_img)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspw_img = array_ops.reshape(w_img, [shape[0], shape[1], shape[2], 1])
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshape = K.int_shape(w_img)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape = backend.int_shape(w_img)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Not possible to handle 3D convnets etc.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif len(shape) == 4 and shape[-1] in [1, 3, 4]:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsummary_ops_v2.image(weight_name, w_img, step=epoch)
<br>@@ -2506,6 +2563,37 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras_embedding.ckpt-{}'.format(epoch))
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.model.save_weights(embeddings_ckpt)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspdef _start_profiler(self, logdir):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Starts the profiler if currently inactive.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogdir: Directory where profiler results will be saved.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._profiler_started:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofiler.start(logdir=logdir)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._profiler_started = True</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept errors.AlreadyExistsError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Profiler errors should not be fatal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.error('Failed to start profiler: %s', e.message)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _stop_profiler(self, save=True):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Stops the profiler if currently active.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave: Whether to save the profiler results to TensorBoard.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not self._profiler_started:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspprofiler.stop(save=save)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspexcept errors.UnavailableError as e:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Profiler errors should not be fatal.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.error('Failed to stop profiler: %s', e.message)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfinally:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._profiler_started = False</span>
<br><span style="color:green">+</span>
<br>&nbsp
<br>&nbsp@keras_export('keras.callbacks.ReduceLROnPlateau')
<br>&nbspclass ReduceLROnPlateau(Callback):
<br>@@ -2598,7 +2686,7 @@ class ReduceLROnPlateau(Callback):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_end(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsplogs = logs or {}
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs['lr'] = K.get_value(self.model.optimizer.lr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs['lr'] = backend.get_value(self.model.optimizer.lr)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspcurrent = logs.get(self.monitor)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif current is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('Learning rate reduction is conditioned on metric `%s` '
<br>@@ -2616,11 +2704,11 @@ class ReduceLROnPlateau(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif not self.in_cooldown():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.wait += 1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.wait >= self.patience:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspold_lr = K.get_value(self.model.optimizer.lr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspold_lr = backend.get_value(self.model.optimizer.lr)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif old_lr > np.float32(self.min_lr):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_lr = old_lr * self.factor
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_lr = max(new_lr, self.min_lr)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.set_value(self.model.optimizer.lr, new_lr)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.set_value(self.model.optimizer.lr, new_lr)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.verbose > 0:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('\nEpoch %05d: ReduceLROnPlateau reducing learning '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'rate to %s.' % (epoch + 1, new_lr))
<br>@@ -2659,32 +2747,24 @@ class CSVLogger(Callback):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.writer = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.keys = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.append_header = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif six.PY2:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.file_flags = 'b'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._open_args = {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.file_flags = ''</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._open_args = {'newline': '\n'}</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(CSVLogger, self).__init__()
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_train_begin(self, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.append:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif file_io.file_exists_v2(self.filename):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith open(self.filename, 'r' + self.file_flags) as f:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith gfile.GFile(self.filename, 'r') as f:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.append_header = not bool(len(f.readline()))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'a'
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode = 'w'
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.csv_file = io.open(self.filename,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmode + self.file_flags,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**self._open_args)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.csv_file = gfile.GFile(self.filename, mode)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef on_epoch_end(self, epoch, logs=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsplogs = logs or {}
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef handle_value(k):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(k, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(k, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn k
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif isinstance(k, collections.abc.Iterable) and not is_zero_dim_ndarray:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn '"[%s]"' % (', '.join(map(str, k)))
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\initializers.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14012</th>
      <td>keras\initializers_test.py</td>
      <td>151</td>
      <td>test_default_random_uniform</td>
      <td>149</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>150</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
    <tr>
      <th>14013</th>
      <td>keras\initializers_test.py</td>
      <td>152</td>
      <td>test_default_random_uniform</td>
      <td>149</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>150</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
    <tr>
      <th>14014</th>
      <td>keras\initializers_test.py</td>
      <td>156</td>
      <td>test_default_random_normal</td>
      <td>154</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>155</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
    <tr>
      <th>14015</th>
      <td>keras\initializers_test.py</td>
      <td>157</td>
      <td>test_default_random_normal</td>
      <td>154</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>155</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
    <tr>
      <th>14016</th>
      <td>keras\initializers_test.py</td>
      <td>161</td>
      <td>test_default_truncated_normal</td>
      <td>159</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>160</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
    <tr>
      <th>14017</th>
      <td>keras\initializers_test.py</td>
      <td>162</td>
      <td>test_default_truncated_normal</td>
      <td>159</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>160</td>
      <td>keras.initializers.get</td>
      <td>tensorflow\python\keras\initializers.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: fccc0ae3f84bdc8d4c60c37e913ed341c5f8cc84

 <br>Commit message: Make Keras maintain its own initializer classes.<br><br>Initializer classes are fundamentally Keras objects (e.g. featuring Keras serialization logic), that were implemented in the TF codebase because of technical details. This meant that the docstrings were disconnected from Keras usage and signatures could not conform to Keras defaults. For instance, the docstring for `tf.keras.initializers.Zeros()` would show examples using `tf.zeros_initializer()`, which made no sense.<br><br>We are keeping the logic in TF (to avoid code redundancy), but moving class definitions to Keras.<br><br>Benefits:<br>- Docstrings now corresponding to the objects in `tf.keras.initializers` and show Keras use cases.<br>- Call signature now defaults `dtype` to `floatx()`.<br>- Class names stay the same independently of TF version (e.g. keras.initializers.RandomNormal.__name__ == 'RandomNormal', not 'RandomNormalV2').<br>- Various edge cases surrounding classes aliased to functions are now fixed (lecun_uniform & friends).<br>PiperOrigin-RevId: 303156255<br>Change-Id: Idf4171e12e6a9afe231eb38892737d603bcbb851<br><br>
<br>Commit id closest to desired version: ERROR

 <br>Commit message: No commit within 100 days of the entered date.
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\engine\training.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14018</th>
      <td>keras\integration_test.py</td>
      <td>221</td>
      <td>test_vector_classification_shared_sequential</td>
      <td>194</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>217</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14022</th>
      <td>keras\integration_test.py</td>
      <td>222</td>
      <td>test_vector_classification_shared_sequential</td>
      <td>194</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>217</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14102</th>
      <td>keras\models_test.py</td>
      <td>118</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>110</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14113</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>110</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14125</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>110</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14135</th>
      <td>keras\models_test.py</td>
      <td>154</td>
      <td>test_clone_functional_model_with_masking</td>
      <td>141</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>148</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14267</th>
      <td>keras\engine\saving_test.py</td>
      <td>62</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14272</th>
      <td>keras\engine\saving_test.py</td>
      <td>62</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14277</th>
      <td>keras\engine\saving_test.py</td>
      <td>76</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14283</th>
      <td>keras\engine\saving_test.py</td>
      <td>76</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14288</th>
      <td>keras\engine\saving_test.py</td>
      <td>85</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14295</th>
      <td>keras\engine\saving_test.py</td>
      <td>85</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14300</th>
      <td>keras\engine\saving_test.py</td>
      <td>89</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14308</th>
      <td>keras\engine\saving_test.py</td>
      <td>89</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14313</th>
      <td>keras\engine\saving_test.py</td>
      <td>94</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14322</th>
      <td>keras\engine\saving_test.py</td>
      <td>94</td>
      <td>test_weight_loading</td>
      <td>50</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>55</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14365</th>
      <td>keras\engine\saving_test.py</td>
      <td>478</td>
      <td>test_functional_model_saving</td>
      <td>444</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>453</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14370</th>
      <td>keras\engine\saving_test.py</td>
      <td>478</td>
      <td>test_functional_model_saving</td>
      <td>444</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>453</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14378</th>
      <td>keras\engine\saving_test.py</td>
      <td>589</td>
      <td>test_saving_model_with_long_layer_names</td>
      <td>554</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>569</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14382</th>
      <td>keras\engine\saving_test.py</td>
      <td>589</td>
      <td>test_saving_model_with_long_layer_names</td>
      <td>554</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>569</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14388</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>613</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14393</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>613</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14400</th>
      <td>keras\engine\saving_test.py</td>
      <td>667</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>649</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14410</th>
      <td>keras\engine\saving_test.py</td>
      <td>675</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>649</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14554</th>
      <td>keras\engine\topology_test.py</td>
      <td>362</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>361</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14567</th>
      <td>keras\engine\topology_test.py</td>
      <td>389</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>388</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14573</th>
      <td>keras\engine\topology_test.py</td>
      <td>399</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>388</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14608</th>
      <td>keras\engine\topology_test.py</td>
      <td>487</td>
      <td>test_multi_input_layer</td>
      <td>460</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>486</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14609</th>
      <td>keras\engine\topology_test.py</td>
      <td>548</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>544</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14610</th>
      <td>keras\engine\topology_test.py</td>
      <td>550</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>544</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14614</th>
      <td>keras\engine\topology_test.py</td>
      <td>561</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>559</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14615</th>
      <td>keras\engine\topology_test.py</td>
      <td>562</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>559</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14616</th>
      <td>keras\engine\topology_test.py</td>
      <td>563</td>
      <td>test_recursion</td>
      <td>532</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>559</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14617</th>
      <td>keras\engine\topology_test.py</td>
      <td>732</td>
      <td>test_raw_tf_compatibility</td>
      <td>716</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>728</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14618</th>
      <td>keras\engine\topology_test.py</td>
      <td>734</td>
      <td>test_raw_tf_compatibility</td>
      <td>716</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>728</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14619</th>
      <td>keras\engine\topology_test.py</td>
      <td>758</td>
      <td>test_basic_masking</td>
      <td>754</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>757</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14623</th>
      <td>keras\engine\topology_test.py</td>
      <td>837</td>
      <td>test_layer_sharing_at_heterogenous_depth</td>
      <td>818</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>826</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14630</th>
      <td>keras\engine\topology_test.py</td>
      <td>837</td>
      <td>test_layer_sharing_at_heterogenous_depth</td>
      <td>818</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>826</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14635</th>
      <td>keras\engine\topology_test.py</td>
      <td>864</td>
      <td>test_layer_sharing_at_heterogenous_depth_with_concat</td>
      <td>839</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>852</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14640</th>
      <td>keras\engine\topology_test.py</td>
      <td>864</td>
      <td>test_layer_sharing_at_heterogenous_depth_with_concat</td>
      <td>839</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>852</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14643</th>
      <td>keras\engine\topology_test.py</td>
      <td>880</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>874</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14651</th>
      <td>keras\engine\topology_test.py</td>
      <td>886</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>874</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14652</th>
      <td>keras\engine\topology_test.py</td>
      <td>886</td>
      <td>test_explicit_training_argument</td>
      <td>866</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>884</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14659</th>
      <td>keras\engine\topology_test.py</td>
      <td>914</td>
      <td>test_multi_output_model_with_none_masking</td>
      <td>888</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>909</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14686</th>
      <td>keras\engine\training_test.py</td>
      <td>424</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>413</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14691</th>
      <td>keras\engine\training_test.py</td>
      <td>424</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>413</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14697</th>
      <td>keras\engine\training_test.py</td>
      <td>441</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>413</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14704</th>
      <td>keras\engine\training_test.py</td>
      <td>441</td>
      <td>test_that_trainable_disables_updates</td>
      <td>405</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>413</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14717</th>
      <td>keras\engine\training_test.py</td>
      <td>896</td>
      <td>test_masking_functional</td>
      <td>885</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>892</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14739</th>
      <td>keras\engine\training_test.py</td>
      <td>2263</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2250</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14745</th>
      <td>keras\engine\training_test.py</td>
      <td>2264</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2250</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14751</th>
      <td>keras\engine\training_test.py</td>
      <td>2277</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2250</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14757</th>
      <td>keras\engine\training_test.py</td>
      <td>2278</td>
      <td>test_metrics_names</td>
      <td>2241</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>2250</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>14855</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>68</td>
      <td>test_conv_lstm</td>
      <td>30</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>65</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15005</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>138</td>
      <td>test_return_state</td>
      <td>120</td>
      <td>assert_allclose</td>
      <td>2</td>
      <td>134</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15117</th>
      <td>keras\layers\lstm_test.py</td>
      <td>342</td>
      <td>test_return_state</td>
      <td>325</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>338</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15119</th>
      <td>keras\layers\merge_test.py</td>
      <td>45</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>39</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15128</th>
      <td>keras\layers\merge_test.py</td>
      <td>46</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>39</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15140</th>
      <td>keras\layers\merge_test.py</td>
      <td>92</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>86</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15149</th>
      <td>keras\layers\merge_test.py</td>
      <td>93</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>86</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15161</th>
      <td>keras\layers\merge_test.py</td>
      <td>106</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>101</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15168</th>
      <td>keras\layers\merge_test.py</td>
      <td>107</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>101</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15177</th>
      <td>keras\layers\merge_test.py</td>
      <td>120</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>115</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15184</th>
      <td>keras\layers\merge_test.py</td>
      <td>121</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>115</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15193</th>
      <td>keras\layers\merge_test.py</td>
      <td>134</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>129</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15200</th>
      <td>keras\layers\merge_test.py</td>
      <td>135</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>129</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15209</th>
      <td>keras\layers\merge_test.py</td>
      <td>148</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>143</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15216</th>
      <td>keras\layers\merge_test.py</td>
      <td>149</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>143</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15225</th>
      <td>keras\layers\merge_test.py</td>
      <td>184</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>178</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15232</th>
      <td>keras\layers\merge_test.py</td>
      <td>188</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>178</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15241</th>
      <td>keras\layers\merge_test.py</td>
      <td>195</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>178</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15249</th>
      <td>keras\layers\merge_test.py</td>
      <td>196</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>178</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15296</th>
      <td>keras\layers\normalization_test.py</td>
      <td>174</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>168</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15299</th>
      <td>keras\layers\normalization_test.py</td>
      <td>175</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>168</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15303</th>
      <td>keras\layers\normalization_test.py</td>
      <td>176</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>168</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15306</th>
      <td>keras\layers\normalization_test.py</td>
      <td>183</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>181</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15309</th>
      <td>keras\layers\normalization_test.py</td>
      <td>184</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>168</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15312</th>
      <td>keras\layers\normalization_test.py</td>
      <td>185</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>181</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15316</th>
      <td>keras\layers\normalization_test.py</td>
      <td>208</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>197</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15321</th>
      <td>keras\layers\normalization_test.py</td>
      <td>208</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>197</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15327</th>
      <td>keras\layers\normalization_test.py</td>
      <td>225</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>197</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15334</th>
      <td>keras\layers\normalization_test.py</td>
      <td>225</td>
      <td>test_that_trainable_disables_updates</td>
      <td>189</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>197</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15341</th>
      <td>keras\layers\normalization_test.py</td>
      <td>256</td>
      <td>test_batchnorm_trainable</td>
      <td>227</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>241</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15373</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>510</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>497</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15378</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>510</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>497</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15379</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>510</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>507</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15385</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>531</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>497</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15391</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>531</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>497</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15392</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>531</td>
      <td>test_builtin_rnn_cell_serialization</td>
      <td>487</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>507</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15401</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>622</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>617</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15404</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>637</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>617</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15405</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>637</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>632</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15408</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>661</td>
      <td>test_high_dimension_RNN_with_init_state</td>
      <td>639</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>655</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15417</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>697</td>
      <td>test_inconsistent_output_state_size</td>
      <td>675</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>692</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15473</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>166</td>
      <td>test_TimeDistributed_learning_phase</td>
      <td>157</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>164</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15486</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>557</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15493</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>557</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15494</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>577</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>574</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15501</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>557</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15508</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>557</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15509</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>574</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15510</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>586</td>
      <td>test_Bidirectional_with_constants</td>
      <td>547</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>583</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15517</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>600</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15528</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>600</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15529</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>625</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>622</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15540</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>600</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15551</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>600</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15552</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>622</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>15553</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>639</td>
      <td>test_Bidirectional_with_constants_layer_passing_initial_state</td>
      <td>588</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>636</td>
      <td>keras.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>26322</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>613</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>26327</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>613</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
    <tr>
      <th>26328</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>636</td>
      <td>testRNNCellSerialization</td>
      <td>601</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>633</td>
      <td>keras.models.Model</td>
      <td>tensorflow\python\keras\engine\training.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 9489702e35b16a40a1accf3b8b5ed557efae10c7

 <br>Commit message: Merge pull request #45420 from offscale:args-for-google-style-docstrings<br><br>PiperOrigin-RevId: 348788129<br>Change-Id: I2e4c86b5526fdc83fec1e176702049f1462d1b12<br><br>
<br>Commit id closest to desired version: da6568a4d354c8863ecbb8991817e546c5f361e5

 <br>Commit message: Remove the API usage monitoring call in the legacy keras code.<br><br>PiperOrigin-RevId: 383499649<br>Change-Id: Idf581a8cc9e043714819a25a0d0104d177fee782<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/engine/training.py b/tensorflow/python/keras/engine/training.py
<br>index d2c931d78aa..238800cc971 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/engine/training.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/engine/training.py</span>
<br>@@ -12,19 +12,14 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Training-related part of the Keras engine.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Training-related part of the Keras engine."""</span>
<br>&nbsp
<br>&nbspimport copy
<br>&nbspimport itertools
<br>&nbspimport json
<br>&nbspimport os
<br>&nbspimport warnings
<br><span style="color:red">- </span>
<br><span style="color:red">- import six</span>
<br><span style="color:green">+import weakref</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.autograph.lang import directives
<br>&nbspfrom tensorflow.python.data.experimental.ops import distribute_options
<br>@@ -32,9 +27,11 @@ from tensorflow.python.data.ops import dataset_ops
<br>&nbspfrom tensorflow.python.distribute import collective_all_reduce_strategy
<br>&nbspfrom tensorflow.python.distribute import distribution_strategy_context as ds_context
<br>&nbspfrom tensorflow.python.distribute import values as ds_values
<br><span style="color:green">+from tensorflow.python.distribute.coordinator import cluster_coordinator</span>
<br>&nbspfrom tensorflow.python.eager import backprop
<br>&nbspfrom tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.eager import def_function
<br><span style="color:green">+from tensorflow.python.framework import composite_tensor</span>
<br>&nbspfrom tensorflow.python.framework import errors
<br>&nbspfrom tensorflow.python.framework import errors_impl
<br>&nbspfrom tensorflow.python.framework import func_graph
<br>@@ -45,7 +42,6 @@ from tensorflow.python.keras import backend
<br>&nbspfrom tensorflow.python.keras import callbacks as callbacks_module
<br>&nbspfrom tensorflow.python.keras import optimizer_v1
<br>&nbspfrom tensorflow.python.keras import optimizers
<br><span style="color:red">- from tensorflow.python.keras.distribute import distributed_training_utils as dist_utils</span>
<br>&nbspfrom tensorflow.python.keras.engine import base_layer
<br>&nbspfrom tensorflow.python.keras.engine import base_layer_utils
<br>&nbspfrom tensorflow.python.keras.engine import compile_utils
<br>@@ -60,7 +56,7 @@ from tensorflow.python.keras.saving.saved_model import json_utils
<br>&nbspfrom tensorflow.python.keras.saving.saved_model import model_serialization
<br>&nbspfrom tensorflow.python.keras.utils import generic_utils
<br>&nbspfrom tensorflow.python.keras.utils import layer_utils
<br><span style="color:red">- from tensorflow.python.keras.utils import tf_inspect</span>
<br><span style="color:green">+from tensorflow.python.keras.utils import object_identity</span>
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.keras.utils import version_utils
<br>&nbspfrom tensorflow.python.keras.utils.io_utils import ask_to_proceed_with_overwrite
<br>@@ -78,7 +74,7 @@ from tensorflow.python.saved_model import loader_impl as sm_loader
<br>&nbspfrom tensorflow.python.training import checkpoint_management
<br>&nbspfrom tensorflow.python.training import py_checkpoint_reader
<br>&nbspfrom tensorflow.python.training.tracking import base as trackable
<br><span style="color:red">- from tensorflow.python.training.tracking import data_structures</span>
<br><span style="color:green">+from tensorflow.python.training.tracking import graph_view as graph_view_lib</span>
<br>&nbspfrom tensorflow.python.training.tracking import util as trackable_utils
<br>&nbspfrom tensorflow.python.util import nest
<br>&nbspfrom tensorflow.python.util import tf_decorator
<br>@@ -163,6 +159,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbspmodel = tf.keras.Model(inputs=inputs, outputs=outputs)
<br>&nbsp &nbsp &nbsp```
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspNote: Only dicts, lists, and tuples of input tensors are supported. Nested</span>
<br><span style="color:green">+&nbsp &nbspinputs are not supported (e.g. lists of list or dicts of dict).</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp2 - By subclassing the `Model` class: in that case, you should define your
<br>&nbsp &nbsp &nbsplayers in `__init__` and you should implement the model's forward pass
<br>&nbsp &nbsp &nbspin `call`.
<br>@@ -229,7 +228,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp@trackable.no_automatic_dependency_tracking
<br>&nbsp &nbsp &nbspdef __init__(self, *args, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._is_model_for_instrumentation = True
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('model').set(True)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Special case for Subclassed Functional Model, which we couldn't detect
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# when __new__ is called. We only realize it is a functional model when it
<br>@@ -266,7 +264,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspother_kwargs))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('Model subclass').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# The following are implemented as property functions:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# self.trainable_weights
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# self.non_trainable_weights
<br>@@ -306,6 +303,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = ds_context.get_strategy()
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = None
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._cluster_coordinator = None</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Defaults to value of `tf.config.experimental_functions_run_eagerly`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._run_eagerly = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Initialize cache attrs.
<br>@@ -314,8 +314,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Fault-tolerance handler. Set in `ModelCheckpoint`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._training_state = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._saved_model_inputs_spec = None
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._trackable_saver = (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrackable_utils.saver_with_op_caching(self))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._trackable_saver = saver_with_op_caching(self)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._steps_per_execution = None
<br>&nbsp
<br>@@ -338,17 +337,15 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif all(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisinstance(v, (base_layer.Layer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_structures.TrackableDataStructure)) or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisinstance(v, (base_layer.Layer, variables.Variable)) or</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbase_layer_utils.has_weights(v) for v in nest.flatten(value)):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._base_model_initialized
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexcept AttributeError:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# six.raise_from supresses the original AttributeError from being raised</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsix.raise_from(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRuntimeError('It looks like you are subclassing `Model` and you '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'forgot to call `super(YourClass, self).__init__()`.'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' Always start with this line.'), None)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise RuntimeError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'It looks like you are subclassing `Model` and you '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'forgot to call `super().__init__()`.'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' Always start with this line.')</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(Model, self).__setattr__(name, value)
<br>&nbsp
<br>@@ -468,7 +465,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspi.e. `model(inputs)`, which relies on the underlying `call` method.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: A tensor or list of tensors.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: Input tensor, or dict/list/tuple of input tensors.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining: Boolean or boolean scalar tensor, indicating whether to run
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `Network` in training mode or inference mode.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask: A mask or list of masks. A mask can be
<br>@@ -503,12 +500,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcategorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturns a weighted loss float tensor. If a custom `Loss` instance is
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused and reduction is set to NONE, return value has the shape</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspotherwise, it is a scalar. If the model has multiple outputs, you can</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse a different loss on each output by passing a dictionary or a list</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof losses. The loss value that will be minimized by the model will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthen be the sum of all individual losses.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused and reduction is set to `None`, return value has the shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`[batch_size, d0, .. dN-1]` i.e. per-sample or per-timestep loss</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues; otherwise, it is a scalar. If the model has multiple outputs,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspyou can use a different loss on each output by passing a dictionary</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor a list of losses. The loss value that will be minimized by the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel will then be the sum of all individual losses, unless</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`loss_weights` is specified.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics: List of metrics to be evaluated by the model during training
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand testing. Each of this can be a string (name of a built-in
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction), function or a `tf.keras.metrics.Metric` instance. See
<br>@@ -516,16 +514,16 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction is any callable with the signature `result = fn(y_true,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred)`. To specify different metrics for different outputs of a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmulti-output model, you could also pass a dictionary, such as
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspYou can also pass a list (len = len(outputs)) of lists of metrics</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsuch as `metrics=[['accuracy'], ['accuracy', 'mse']]` or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrings 'accuracy' or 'acc', we convert this to one of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.BinaryAccuracy`,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.CategoricalAccuracy`,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.SparseCategoricalAccuracy` based on the loss</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction used and the model output shape. We do a similar</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconversion for the strings 'crossentropy' and 'ce' as well.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspYou can also pass a list to specify a metric or a list of metrics</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor each output, such as `metrics=[['accuracy'], ['accuracy', 'mse']]`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrings 'accuracy' or 'acc', we convert this to one of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.BinaryAccuracy`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.CategoricalAccuracy`,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.metrics.SparseCategoricalAccuracy` based on the loss</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction used and the model output shape. We do a similar</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconversion for the strings 'crossentropy' and 'ce' as well.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss_weights: Optional list or dictionary specifying scalar coefficients
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Python floats) to weight the loss contributions of different model
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs. The loss value that will be minimized by the model will then
<br>@@ -535,11 +533,12 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs. If a dict, it is expected to map output names (strings)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto scalar coefficients.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweighted_metrics: List of metrics to be evaluated and weighted by
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight or class_weight during training and testing.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`sample_weight` or `class_weight` during training and testing.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogic will not be wrapped in a `tf.function`. Recommended to leave
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis as `None` unless your `Model` cannot be run inside a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.function`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.function`. `run_eagerly=True` is not supported when using</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_execution: Int. Defaults to 1. The number of batches to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprun during each `tf.function` call. Running multiple batches
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinside a single `tf.function` call can greatly improve performance
<br>@@ -557,15 +556,19 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of invalid arguments for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`optimizer`, `loss` or `metrics`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('compile').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith self.distribute_strategy.scope():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 'experimental_steps_per_execution' in kwargs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warn('The argument `steps_per_execution` is no longer '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'experimental. Pass `steps_per_execution` instead of '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`experimental_steps_per_execution`.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('The argument `steps_per_execution` is no longer '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'experimental. Pass `steps_per_execution` instead of '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`experimental_steps_per_execution`.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not steps_per_execution:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_execution = kwargs.pop('experimental_steps_per_execution')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When compiling from an already-serialized model, we do not want to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# reapply some processing steps (e.g. metric renaming for multi-output</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# models, which have prefixes added for each corresponding output name).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_serialized = kwargs.pop('from_serialized', False)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._validate_compile(optimizer, metrics, **kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._run_eagerly = run_eagerly
<br>&nbsp
<br>@@ -573,7 +576,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.compiled_loss = compile_utils.LossesContainer(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss, loss_weights, output_names=self.output_names)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.compiled_metrics = compile_utils.MetricsContainer(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics, weighted_metrics, output_names=self.output_names)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmetrics, weighted_metrics, output_names=self.output_names,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_serialized=from_serialized)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._configure_steps_per_execution(steps_per_execution or 1)
<br>&nbsp
<br>@@ -613,6 +617,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.train_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.test_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.predict_function = None
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Used to cache the `tf.function`'ed `train_function` to be logged in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TensorBoard, since the original `train_function` is not necessarily</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# a `tf.function` (e.g., with ParameterServerStrategy, the `train_function`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# is a scheduling of the actual training function to a remote worker).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.train_tf_function = None</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Used to cache `trainable` attr of `Layer`s for `fit`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._compiled_trainable_state = self._get_trainable_state()
<br>@@ -744,6 +753,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'constructed with `dynamic=True`). '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'You cannot set `run_eagerly=False`.')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._cluster_coordinator and self._run_eagerly:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('When using `Model` with `ParameterServerStrategy`, '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`run_eagerly` is not supported.')</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Run eagerly logic, by priority:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# (1) Dynamic models must be run eagerly.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# (2) Explicitly setting run_eagerly causes a Model to be run eagerly.
<br>@@ -760,6 +773,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""The logic for one training step.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis method can be overridden to support custom training logic.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspFor concrete examples of how to override this method see</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp[Customizing what happends in fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis method is called by `Model.make_train_function`.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspThis method should contain the mathematical logic for one step of training.
<br>@@ -784,14 +799,23 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# data when a `tf.data.Dataset` is provided.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata = data_adapter.expand_1d(data)
<br>&nbsp &nbsp &nbsp &nbsp &nbspx, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)
<br><span style="color:red">- </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Run forward pass.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith backprop.GradientTape() as tape:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred = self(x, training=True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss = self.compiled_loss(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy, y_pred, sample_weight, regularization_losses=self.losses)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Run backwards pass.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.optimizer.minimize(loss, self.trainable_variables, tape=tape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.compiled_metrics.update_state(y, y_pred, sample_weight)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn {m.name: m.result() for m in self.metrics}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Collect metrics to return</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn_metrics = {}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor metric in self.metrics:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = metric.result()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(result, dict):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_metrics.update(result)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_metrics[metric.name] = result</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn return_metrics</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef make_train_function(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Creates a function that executes one step of training.
<br>@@ -850,8 +874,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.run_eagerly:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_function = def_function.function(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_function, experimental_relax_shapes=True)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.train_tf_function = train_function</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.train_function = train_function
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._cluster_coordinator:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.train_function = lambda iterator: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_function, args=(iterator,))</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn self.train_function
<br>&nbsp
<br>&nbsp &nbsp &nbspdef fit(self,
<br>@@ -859,7 +889,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepochs=1,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose=1,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose='auto',</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_split=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_data=None,
<br>@@ -889,8 +919,17 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(inputs, targets, sample_weights)`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A generator or `keras.utils.Sequence` returning `(inputs, targets)`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `(inputs, targets, sample_weights)`.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.keras.utils.experimental.DatasetCreator`, which wraps a</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallable that takes a single argument of type</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.InputContext`, and returns a `tf.data.Dataset`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`DatasetCreator` should be used when users prefer to specify the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspper-replica batching and sharding logic for the `Dataset`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `tf.keras.utils.experimental.DatasetCreator` doc for more</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinformation.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA more detailed description of unpacking behavior for iterator types
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Dataset, generator, Sequence) is given below.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Dataset, generator, Sequence) is given below. If using</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`, only</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`DatasetCreator` type is supported for `x`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit could be either Numpy array(s) or TensorFlow tensor(s).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt should be consistent with `x` (you cannot have Numpy inputs and
<br>@@ -911,11 +950,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe model is not trained for a number of iterations
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgiven by `epochs`, but merely until the epoch
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof index `epochs` is reached.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: 0, 1, or 2. Verbosity mode.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose: 'auto', 0, 1, or 2. Verbosity mode.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0 = silent, 1 = progress bar, 2 = one line per epoch.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that the progress bar is not particularly useful when</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogged to a file, so verbose=2 is recommended when not running</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinteractively (eg, in a production environment).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'auto' defaults to 1 for most cases, but 2 when used with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`ParameterServerStrategy`. Note that the progress bar is not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparticularly useful when logged to a file, so verbose=2 is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecommended when not running interactively (eg, in a production</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspenvironment).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks: List of `keras.callbacks.Callback` instances.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspList of callbacks to apply during training.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSee `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`
<br>@@ -923,6 +964,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand need not be passed into `model.fit`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.callbacks.ProgbarLogger` is created or not based on
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`verbose` argument to `model.fit`.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCallbacks with batch-level calls are currently unsupported with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`, and users are</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadvised to implement epoch-level calls instead with an appropriate</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`steps_per_epoch` value.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_split: Float between 0 and 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFraction of the training data to be used as validation data.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe model will set apart this fraction of the training data,
<br>@@ -933,6 +978,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin the `x` and `y` data provided, before shuffling. This argument is
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnot supported when `x` is a dataset, generator or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` instance.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_split` is not yet supported with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_data: Data on which to evaluate
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe loss and any model metrics at the end of each epoch.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe model will not be trained on this data. Thus, note the fact
<br>@@ -941,16 +988,17 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnoise and dropout.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_data` will override `validation_split`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_data` could be:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- tuple `(x_val, y_val)` of Numpy arrays or tensors</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- dataset</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor the first two cases, `batch_size` must be provided.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor the last case, `validation_steps` could be provided.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that `validation_data` does not support all the data types that</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare supported in `x`, eg, dict, generator or `keras.utils.Sequence`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A tuple `(x_val, y_val)` of Numpy arrays or tensors.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A `tf.data.Dataset`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A Python generator or `keras.utils.Sequence` returning</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(inputs, targets)` or `(inputs, targets, sample_weights)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_data` is not yet supported with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Boolean (whether to shuffle the training data
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbefore each epoch) or str (for 'batch'). This argument is ignored
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen `x` is a generator. 'batch' is a special option for dealing</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen `x` is a generator or an object of tf.data.Dataset.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'batch' is a special option for dealing</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith the limitations of HDF5 data; it shuffles in batch-sized
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspchunks. Has no effect when `steps_per_epoch` is not `None`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_weight: Optional dictionary mapping class indices (integers)
<br>@@ -984,8 +1032,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.data` dataset, and 'steps_per_epoch'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis None, the epoch will run until the input dataset is exhausted.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen passing an infinitely repeating dataset, you must specify the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`steps_per_epoch` argument. This argument is not supported with</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`steps_per_epoch` argument. If `steps_per_epoch=-1` the training</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill run indefinitely with an infinitely repeating dataset.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThis argument is not supported with array inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen using `tf.distribute.experimental.ParameterServerStrategy`:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp* `steps_per_epoch=None` is not supported.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_steps: Only relevant if `validation_data` is provided and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis a `tf.data` dataset. Total number of steps (batches of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsamples) to draw before stopping when performing validation
<br>@@ -1015,8 +1066,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Used for generator or `keras.utils.Sequence` input
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsponly. Maximum number of processes to spin up
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhen using process-based threading. If unspecified, `workers`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill default to 1. If 0, will execute the generator on the main</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthread.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill default to 1.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean. Used for generator or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` input only. If `True`, use process-based
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthreading. If unspecified, `use_multiprocessing` will default to
<br>@@ -1061,13 +1111,18 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case of mismatch between the provided input data
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand what the model expects or when the input data is empty.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('fit').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Legacy graph support is contained in `training_v1.Model`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'fit')
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._check_call_args('fit')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_disallow_inside_tf_function('fit')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif verbose == 'auto':</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose = 2  # Default to epoch-level logging for PSStrategy.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspverbose = 1  # Default to batch-level logging otherwise.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif validation_split:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Create the validation data using the training data. Only supported for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# `Tensor` and `NumPy` input.
<br>@@ -1079,10 +1134,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval_x, val_y, val_sample_weight = (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_adapter.unpack_x_y_sample_weight(validation_data))
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cluster_coordinator = cluster_coordinator.ClusterCoordinator(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.distribute_strategy)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith self.distribute_strategy.scope(), \
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining_utils.RespectCompiledTrainableState(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Creates a `tf.data.Dataset` and handles batch and epoch iteration.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.DataHandler(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.get_data_handler(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx=x,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=y,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight=sample_weight,
<br>@@ -1141,6 +1200,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.stop_training:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbreak
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif logs is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Expect x to be a non-empty array or dataset.')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepoch_logs = copy.copy(logs)
<br>@@ -1149,8 +1209,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif validation_data and self._should_eval(epoch, validation_freq):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Create data_handler for evaluation and cache it.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(self, '_eval_data_handler', None) is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._fit_frame = tf_inspect.currentframe()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._eval_data_handler = data_adapter.DataHandler(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._eval_data_handler = data_adapter.get_data_handler(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx=val_x,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=val_y,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight=val_sample_weight,
<br>@@ -1173,7 +1232,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size=max_queue_size,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers=workers,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing=use_multiprocessing,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_dict=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_dict=True,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_use_cached_eval_dataset=True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspval_logs = {'val_' + name: val for name, val in val_logs.items()}
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepoch_logs.update(val_logs)
<br>&nbsp
<br>@@ -1185,7 +1245,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If eval data_hanlder exists, delete it after all epochs are done.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(self, '_eval_data_handler', None) is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel self._eval_data_handler
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel self._fit_frame</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_train_end(logs=training_logs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.history
<br>&nbsp
<br>@@ -1219,9 +1278,16 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Updates stateful loss metrics.
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.compiled_loss(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy, y_pred, sample_weight, regularization_losses=self.losses)
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.compiled_metrics.update_state(y, y_pred, sample_weight)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn {m.name: m.result() for m in self.metrics}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Collect metrics to return</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn_metrics = {}</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor metric in self.metrics:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspresult = metric.result()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(result, dict):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_metrics.update(result)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_metrics[metric.name] = result</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn return_metrics</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef make_test_function(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Creates a function that executes one step of evaluation.
<br>@@ -1280,6 +1346,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptest_function, experimental_relax_shapes=True)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.test_function = test_function
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._cluster_coordinator:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.test_function = lambda iterator: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptest_function, args=(iterator,))</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn self.test_function
<br>&nbsp
<br>&nbsp &nbsp &nbspdef evaluate(self,
<br>@@ -1293,7 +1364,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_queue_size=10,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers=1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing=False,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_dict=False):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_dict=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Returns the loss value & metrics values for the model in test mode.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspComputation is done in batches (see the `batch_size` arg.)
<br>@@ -1347,8 +1419,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`max_queue_size` will default to 10.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Used for generator or `keras.utils.Sequence` input
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsponly. Maximum number of processes to spin up when using process-based
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthreading. If unspecified, `workers` will default to 1. If 0, will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexecute the generator on the main thread.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthreading. If unspecified, `workers` will default to 1.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean. Used for generator or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` input only. If `True`, use process-based
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthreading. If unspecified, `use_multiprocessing` will default to
<br>@@ -1358,10 +1429,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn_dict: If `True`, loss and metric results are returned as a dict,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith each key being the name of the metric. If `False`, they are
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturned as a list.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: Unused at this time.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspSee the discussion of `Unpacking behavior for iterator-like inputs` for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp`Model.fit`.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`Model.evaluate` is not yet supported with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`tf.distribute.experimental.ParameterServerStrategy`.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspScalar test loss (if the model has a single output and no metrics)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor list of scalars (if the model has multiple outputs
<br>@@ -1372,21 +1447,26 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspRuntimeError: If `model.evaluate` is wrapped in `tf.function`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: in case of invalid arguments.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('evaluate').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'evaluate')
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._assert_compile_was_called()
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._check_call_args('evaluate')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_disallow_inside_tf_function('evaluate')
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspuse_cached_eval_dataset = kwargs.pop('_use_cached_eval_dataset', False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif kwargs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('Invalid keyword arguments: %s' % (kwargs,))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cluster_coordinator = cluster_coordinator.ClusterCoordinator(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.distribute_strategy)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith self.distribute_strategy.scope():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Use cached evaluation data only when it's called in `Model.fit`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (getattr(self, '_fit_frame', None) is not None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand tf_inspect.currentframe().f_back is self._fit_frame</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (use_cached_eval_dataset</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand getattr(self, '_eval_data_handler', None) is not None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = self._eval_data_handler
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Creates a `tf.data.Dataset` and handles batch and epoch iteration.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.DataHandler(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.get_data_handler(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx=x,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy=y,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_weight=sample_weight,
<br>@@ -1427,22 +1507,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tmp_logs  # No error, now safe to assign to logs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspend_step = step + data_handler.step_increment
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_test_batch_end(end_step, logs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_test_end(logs=logs)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif return_dict:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn logs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults = []</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor name in self.metrics_names:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif name in logs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults.append(logs[name])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor key in sorted(logs.keys()):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif key not in self.metrics_names:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults.append(logs[key])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(results) == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn flatten_metrics_in_order(logs, self.metrics_names)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef predict_step(self, data):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""The logic for one inference step.
<br>@@ -1585,7 +1656,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspworkers: Integer. Used for generator or `keras.utils.Sequence` input
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsponly. Maximum number of processes to spin up when using
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprocess-based threading. If unspecified, `workers` will default
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto 1. If 0, will execute the generator on the main thread.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto 1.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspuse_multiprocessing: Boolean. Used for generator or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.utils.Sequence` input only. If `True`, use process-based
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthreading. If unspecified, `use_multiprocessing` will default to
<br>@@ -1608,11 +1679,24 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor in case a stateful model receives a number of samples
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthat is not a multiple of the batch size.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_layer.keras_api_gauge.get_cell('predict').set(True)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspversion_utils.disallow_legacy_graph('Model', 'predict')
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._check_call_args('predict')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_disallow_inside_tf_function('predict')
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TODO(yashkatariya): Cache model on the coordinator for faster prediction.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If running under PSS, then swap it with OneDeviceStrategy so that</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# execution will run on the coordinator.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsporiginal_pss_strategy = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsporiginal_pss_strategy = self.distribute_strategy</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = None</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Cluster coordinator is set by `.fit()` and `.evaluate()` which is not</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# needed in `.predict()` because all the predictions happen on the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# coordinator/locally.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self._cluster_coordinator:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._cluster_coordinator = None</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutputs = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspwith self.distribute_strategy.scope():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Creates a `tf.data.Dataset` and handles batch and epoch iteration.
<br>@@ -1630,7 +1714,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'AutoShardPolicy.FILE might lead to out-of-order result'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'. Consider setting it to AutoShardPolicy.DATA.')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.DataHandler(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_handler = data_adapter.get_data_handler(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx=x,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=batch_size,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=steps,
<br>@@ -1679,7 +1763,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Expect x to be a non-empty array or dataset.')
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcallbacks.on_predict_end()
<br>&nbsp &nbsp &nbsp &nbsp &nbspall_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn tf_utils.to_numpy_or_python_type(all_outputs)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# If originally PSS strategy was used, then replace it back since predict</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# is running under `OneDeviceStrategy` after the swap and once its done</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# we need to replace it back to PSS again.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif original_pss_strategy is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._distribution_strategy = original_pss_strategy</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tf_utils.sync_to_numpy_or_python_type(all_outputs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef reset_metrics(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Resets the state of all the metrics in the model.
<br>@@ -1701,7 +1792,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor m in self.metrics:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspm.reset_states()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspm.reset_state()</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef train_on_batch(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,
<br>@@ -1763,14 +1854,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif reset_metrics:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.reset_metrics()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif return_dict:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn logs
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults = [logs.get(name, None) for name in self.metrics_names]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(results) == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn flatten_metrics_in_order(logs, self.metrics_names)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef test_on_batch(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,
<br>@@ -1781,11 +1869,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Test the model on a single batch of samples.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input data. It could be: - A Numpy array (or array-like), or a list</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof arrays (in case the model has multiple inputs). - A TensorFlow</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor, or a list of tensors (in case the model has multiple inputs).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input data. It could be:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A Numpy array (or array-like), or a list of arrays (in case the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel has multiple inputs).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A TensorFlow tensor, or a list of tensors (in case the model has</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple inputs).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A dict mapping input names to the corresponding array/tensors, if
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe model has named inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe model has named inputs.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy: Target data. Like the input data `x`, it could be either Numpy
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray(s) or TensorFlow tensor(s). It should be consistent with `x`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(you cannot have Numpy inputs and tensor targets, or inversely).
<br>@@ -1822,22 +1912,21 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif reset_metrics:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.reset_metrics()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogs = tf_utils.to_numpy_or_python_type(logs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogs = tf_utils.sync_to_numpy_or_python_type(logs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif return_dict:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn logs
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults = [logs.get(name, None) for name in self.metrics_names]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif len(results) == 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn results</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn flatten_metrics_in_order(logs, self.metrics_names)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef predict_on_batch(self, x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Returns predictions for a single batch of samples.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input data. It could be: - A Numpy array (or array-like), or a list</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof arrays (in case the model has multiple inputs). - A TensorFlow</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor, or a list of tensors (in case the model has multiple inputs).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input data. It could be:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A Numpy array (or array-like), or a list of arrays (in case the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel has multiple inputs).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- A TensorFlow tensor, or a list of tensors (in case the model has</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple inputs).</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNumpy array(s) of predictions.
<br>@@ -1853,7 +1942,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspiterator = data_adapter.single_batch_iterator(self.distribute_strategy, x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.predict_function = self.make_predict_function()
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = self.predict_function(iterator)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn tf_utils.to_numpy_or_python_type(outputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tf_utils.sync_to_numpy_or_python_type(outputs)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef fit_generator(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerator,
<br>@@ -2160,16 +2249,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsession = None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsession = backend.get_session()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = getattr(self, 'optimizer', None)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (optimizer</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand not isinstance(optimizer, trackable.Trackable)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('This model was compiled with a Keras optimizer (%s) but is being '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'saved in TensorFlow format with `save_weights`. The model\'s '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'weights will be saved, but unlike with TensorFlow optimizers in '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the TensorFlow format the optimizer\'s state will not be '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp% (optimizer,))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._trackable_saver.save(filepath, session=session, options=options)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Record this checkpoint so it's visible from tf.train.latest_checkpoint.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcheckpoint_management.update_checkpoint_state_internal(
<br>@@ -2231,7 +2310,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If `skip_mismatch` is set to `True` when `by_name` is
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`False`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif dist_utils.is_tpu_strategy(self._distribution_strategy):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif backend.is_tpu_strategy(self._distribution_strategy):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (self._distribution_strategy.extended.steps_per_run > 1 and
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(not saving_utils.is_hdf5_filepath(filepath))):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Load weights is not yet supported with TPUStrategy '
<br>@@ -2255,24 +2334,30 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# streaming restore for any variables created in the future.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrackable_utils.streaming_restore(status=status, session=session)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatus.assert_nontrivial_match()
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn status</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif h5py is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ImportError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`load_weights` requires h5py when loading weights from HDF5.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif not self._is_graph_network and not self.built:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Unable to load weights saved in HDF5 format into a subclassed '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Model which has not created its variables yet. Call the Model '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'first, then load the weights.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._assert_weights_created()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith h5py.File(filepath, 'r') as f:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 'layer_names' not in f.attrs and 'model_weights' in f:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = f['model_weights']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif by_name:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphdf5_format.load_weights_from_hdf5_group_by_name(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf, self.layers, skip_mismatch=skip_mismatch)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphdf5_format.load_weights_from_hdf5_group(f, self.layers)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspstatus = None</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif h5py is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ImportError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`load_weights` requires h5py when loading weights from HDF5.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self._is_graph_network and not self.built:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Unable to load weights saved in HDF5 format into a subclassed '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Model which has not created its variables yet. Call the Model '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'first, then load the weights.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._assert_weights_created()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith h5py.File(filepath, 'r') as f:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 'layer_names' not in f.attrs and 'model_weights' in f:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf = f['model_weights']</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif by_name:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphdf5_format.load_weights_from_hdf5_group_by_name(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf, self.layers, skip_mismatch=skip_mismatch)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphdf5_format.load_weights_from_hdf5_group(f, self.layers)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Perform any layer defined finalization of the layer state.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor layer in self.layers:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplayer.finalize_state()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn status</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _updated_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Util shared between different serialization methods.
<br>@@ -2296,11 +2381,20 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp
<br>&nbsp &nbsp &nbsp@classmethod
<br>&nbsp &nbsp &nbspdef from_config(cls, config, custom_objects=None):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Since only FunctionalModel produces config, the model can only</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# be constructed for FunctionalModel</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `from_config` assumes `cls` is either `Functional` or a child class of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `Functional`. In the case that `cls` is meant to behave like a child class</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# of `Functional` but only inherits from the `Model` class, we have to call</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# `cls(...)` instead of `Functional.from_config`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom tensorflow.python.keras.engine import functional  # pylint: disable=g-import-not-at-top
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn functional.Functional.from_config(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig, custom_objects=custom_objects)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith generic_utils.SharedObjectLoadingScope():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensors, output_tensors, created_layers = (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunctional.reconstruct_from_config(config, custom_objects))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Initialize a model belonging to `cls`, which can be user-defined or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# `Functional`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel = cls(inputs=input_tensors, outputs=output_tensors,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=config.get('name'))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunctional.connect_ancillary_layers(model, created_layers)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn model</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef to_json(self, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Returns a JSON string containing the network configuration.
<br>@@ -2647,14 +2741,17 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):
<br>&nbsp &nbsp &nbsp &nbsp &nbsptrain_function = self.train_function
<br>&nbsp &nbsp &nbsp &nbsp &nbsptest_function = self.test_function
<br>&nbsp &nbsp &nbsp &nbsp &nbsppredict_function = self.predict_function
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptrain_tf_function = self.train_tf_function</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.train_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.test_function = None
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.predict_function = None
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.train_tf_function = None</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfunctions = super(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspModel, self)._list_functions_for_serialization(serialization_cache)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.train_function = train_function
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.test_function = test_function
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.predict_function = predict_function
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.train_tf_function = train_tf_function</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn functions
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _should_eval(self, epoch, validation_freq):
<br>@@ -2730,7 +2827,7 @@ def reduce_per_replica(values, strategy, reduction='first'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Reduce a single `PerReplica` object."""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif reduction == 'concat' and _collective_all_reduce_multi_worker(strategy):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _multi_worker_concat(v, strategy)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif not isinstance(v, ds_values.PerReplica):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not _is_per_replica_instance(v):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn v
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif reduction == 'first':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn strategy.unwrap(v)[0]
<br>@@ -2753,7 +2850,7 @@ def concat(tensors, axis=0):
<br>&nbsp
<br>&nbsp
<br>&nbspdef _is_tpu_multi_host(strategy):
<br><span style="color:red">- &nbsp &nbspreturn (dist_utils.is_tpu_strategy(strategy) and</span>
<br><span style="color:green">+&nbsp &nbspreturn (backend.is_tpu_strategy(strategy) and</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstrategy.extended.num_hosts > 1)
<br>&nbsp
<br>&nbsp
<br>@@ -2782,24 +2879,19 @@ def _collective_all_reduce_multi_worker(strategy):
<br>&nbsp# for all strategies
<br>&nbspdef _multi_worker_concat(v, strategy):
<br>&nbsp &nbsp &nbsp"""Order PerReplica objects for CollectiveAllReduceStrategy and concat."""
<br><span style="color:red">- &nbsp &nbspreplicas = strategy.gather(v, axis=0)  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp# TODO(b/170435030): We now need to make sure these run after the iterator</span>
<br><span style="color:red">- &nbsp &nbsp# GetNext, so that we don't trigger aborting collective ops in the case of</span>
<br><span style="color:red">- &nbsp &nbsp# EOF. Remove after the issue is fixed.</span>
<br><span style="color:red">- &nbsp &nbspwith ops.control_dependencies([replicas]):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# v might not have the same shape on different replicas</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(v, ds_values.PerReplica):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshapes = array_ops.concat([</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims_v2(array_ops.shape(single_value)[0], axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor single_value in v.values</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_shapes = strategy.gather(shapes, axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# v is a tensor. This may happen when, say, we have 2x1 multi-worker.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall_shapes = strategy.gather(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims_v2(array_ops.shape(v)[0], axis=0),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=0)</span>
<br><span style="color:green">+&nbsp &nbspreplicas = strategy.gather(v, axis=0)</span>
<br><span style="color:green">+&nbsp &nbsp# v might not have the same shape on different replicas</span>
<br><span style="color:green">+&nbsp &nbspif _is_per_replica_instance(v):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshapes = array_ops.concat([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims_v2(array_ops.shape(single_value)[0], axis=0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor single_value in v.values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall_shapes = strategy.gather(shapes, axis=0)</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# v is a tensor. This may happen when, say, we have 2x1 multi-worker.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspall_shapes = strategy.gather(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims_v2(array_ops.shape(v)[0], axis=0), axis=0)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspreplicas = array_ops.split(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreplicas,
<br>@@ -2882,3 +2974,32 @@ def _is_readable_tf_checkpoint(filepath):
<br>&nbsp &nbsp &nbspexcept errors_impl.DataLossError:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# The checkpoint is not readable in TensorFlow format.
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn False
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def flatten_metrics_in_order(logs, metrics_names):</span>
<br><span style="color:green">+&nbsp &nbsp"""Turns the `logs` dict into a list as per key order of `metrics_names`."""</span>
<br><span style="color:green">+&nbsp &nbspresults = []</span>
<br><span style="color:green">+&nbsp &nbspfor name in metrics_names:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif name in logs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults.append(logs[name])</span>
<br><span style="color:green">+&nbsp &nbspfor key in sorted(logs.keys()):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif key not in metrics_names:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspresults.append(logs[key])</span>
<br><span style="color:green">+&nbsp &nbspif len(results) == 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn results[0]</span>
<br><span style="color:green">+&nbsp &nbspreturn results</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _is_per_replica_instance(obj):</span>
<br><span style="color:green">+&nbsp &nbspreturn (isinstance(obj, ds_values.DistributedValues) and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisinstance(obj, composite_tensor.CompositeTensor))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def saver_with_op_caching(obj):</span>
<br><span style="color:green">+&nbsp &nbspif context.executing_eagerly():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsaveables_cache = None</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsaveables_cache = object_identity.ObjectIdentityWeakKeyDictionary()</span>
<br><span style="color:green">+&nbsp &nbspreturn trackable_utils.TrackableSaver(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspgraph_view_lib.ObjectGraphView(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweakref.ref(obj), saveables_cache=saveables_cache))</span>
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\losses.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14026</th>
      <td>keras\losses_test.py</td>
      <td>97</td>
      <td>test_serialization</td>
      <td>93</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>94</td>
      <td>keras.losses.get</td>
      <td>tensorflow\python\keras\losses.py</td>
    </tr>
    <tr>
      <th>14027</th>
      <td>keras\losses_test.py</td>
      <td>97</td>
      <td>test_serialization</td>
      <td>93</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>96</td>
      <td>keras.losses.deserialize</td>
      <td>tensorflow\python\keras\losses.py</td>
    </tr>
    <tr>
      <th>14028</th>
      <td>keras\losses_test.py</td>
      <td>97</td>
      <td>test_serialization</td>
      <td>93</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>95</td>
      <td>keras.losses.serialize</td>
      <td>tensorflow\python\keras\losses.py</td>
    </tr>
    <tr>
      <th>14029</th>
      <td>keras\losses_test.py</td>
      <td>97</td>
      <td>test_serialization</td>
      <td>93</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>94</td>
      <td>keras.losses.get</td>
      <td>tensorflow\python\keras\losses.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: e43633feb66a7a239875aa86f3e5f479488ee570

 <br>Commit message: PR #47412: Add axis argument<br><br>Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/47412<br><br>PiperOrigin-RevId: 378700830<br>Change-Id: I42add0787e6215e1b86207b9bd25dc46b9761b7a<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/losses.py b/tensorflow/python/keras/losses.py
<br>index 58761790fdd..07b5666f24a 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/losses.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/losses.py</span>
<br>@@ -12,38 +12,41 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br>&nbsp"""Built-in loss functions."""
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br>&nbsp
<br>&nbspimport abc
<br><span style="color:red">- </span>
<br><span style="color:red">- import six</span>
<br><span style="color:green">+import functools</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.autograph.core import ag_ctx
<br>&nbspfrom tensorflow.python.autograph.impl import api as autograph
<br>&nbspfrom tensorflow.python.distribute import distribution_strategy_context
<br>&nbspfrom tensorflow.python.eager import context
<br><span style="color:green">+from tensorflow.python.framework import constant_op</span>
<br>&nbspfrom tensorflow.python.framework import ops
<br>&nbspfrom tensorflow.python.framework import smart_cond
<br><span style="color:green">+from tensorflow.python.framework import tensor_spec</span>
<br>&nbspfrom tensorflow.python.framework import tensor_util
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras.utils import losses_utils
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import deserialize_keras_object
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import serialize_keras_object
<br>&nbspfrom tensorflow.python.ops import array_ops
<br><span style="color:green">+from tensorflow.python.ops import control_flow_ops</span>
<br>&nbspfrom tensorflow.python.ops import math_ops
<br>&nbspfrom tensorflow.python.ops import nn
<br>&nbspfrom tensorflow.python.ops.losses import losses_impl
<br><span style="color:green">+from tensorflow.python.ops.ragged import ragged_map_ops</span>
<br><span style="color:green">+from tensorflow.python.ops.ragged import ragged_tensor</span>
<br><span style="color:green">+from tensorflow.python.ops.ragged import ragged_util</span>
<br>&nbspfrom tensorflow.python.util import dispatch
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbspfrom tensorflow.tools.docs import doc_controls
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.Loss')
<br><span style="color:red">- class Loss(object):</span>
<br><span style="color:green">+class Loss:</span>
<br>&nbsp &nbsp &nbsp"""Loss base class.
<br>&nbsp
<br>&nbsp &nbsp &nbspTo be implemented by subclasses:
<br>@@ -70,6 +73,7 @@ class Loss(object):
<br>&nbsp &nbsp &nbspdetails on this.
<br>&nbsp
<br>&nbsp &nbsp &nbspYou can implement 'SUM_OVER_BATCH_SIZE' using global batch size like:
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp```python
<br>&nbsp &nbsp &nbspwith strategy.scope():
<br>&nbsp &nbsp &nbsp &nbsp &nbsploss_obj = tf.keras.losses.CategoricalCrossentropy(
<br>@@ -84,7 +88,7 @@ class Loss(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `Loss` class.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -93,7 +97,7 @@ class Loss(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbsplosses_utils.ReductionV2.validate(reduction)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.reduction = reduction
<br>@@ -143,7 +147,7 @@ class Loss(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# accepted in scope name.
<br>&nbsp &nbsp &nbsp &nbsp &nbspgraph_ctx = tf_utils.graph_context_for_symbolic_tensors(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_true, y_pred, sample_weight)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith K.name_scope(self._name_scope), graph_ctx:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith backend.name_scope(self._name_scope), graph_ctx:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif context.executing_eagerly():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcall_fn = self.call
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -222,7 +226,7 @@ class LossFunctionWrapper(Loss):
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfn: The loss function to wrap, with signature `fn(y_true, y_pred,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs)`.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -231,10 +235,10 @@ class LossFunctionWrapper(Loss):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: (Optional) name for the loss.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: The keyword arguments that are passed on to `fn`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(reduction=reduction, name=name)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.fn = fn
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._fn_kwargs = kwargs
<br>&nbsp
<br>@@ -248,16 +252,17 @@ class LossFunctionWrapper(Loss):
<br>&nbsp &nbsp &nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLoss values per sample.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif tensor_util.is_tensor(y_pred) and tensor_util.is_tensor(y_true):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif tensor_util.is_tf_type(y_pred) and tensor_util.is_tf_type(y_true):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspag_fn = autograph.tf_convert(self.fn, ag_ctx.control_status_ctx())
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn ag_fn(y_true, y_pred, **self._fn_kwargs)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig = {}
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor k, v in six.iteritems(self._fn_kwargs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig[k] = K.eval(v) if tf_utils.is_tensor_or_variable(v) else v</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_config = super(LossFunctionWrapper, self).get_config()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfor k, v in self._fn_kwargs.items():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig[k] = backend.eval(v) if tf_utils.is_tensor_or_variable(v) else v</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbase_config = super().get_config()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn dict(list(base_config.items()) + list(config.items()))
<br>&nbsp
<br>&nbsp
<br>@@ -305,7 +310,7 @@ class MeanSquaredError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `MeanSquaredError` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -314,10 +319,9 @@ class MeanSquaredError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'mean_squared_error'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'mean_squared_error'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(MeanSquaredError, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean_squared_error, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(mean_squared_error, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.MeanAbsoluteError')
<br>@@ -364,7 +368,7 @@ class MeanAbsoluteError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `MeanAbsoluteError` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -373,10 +377,9 @@ class MeanAbsoluteError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'mean_absolute_error'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'mean_absolute_error'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(MeanAbsoluteError, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean_absolute_error, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(mean_absolute_error, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.MeanAbsolutePercentageError')
<br>@@ -424,7 +427,7 @@ class MeanAbsolutePercentageError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `MeanAbsolutePercentageError` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -433,10 +436,10 @@ class MeanAbsolutePercentageError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'mean_absolute_percentage_error'.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(MeanAbsolutePercentageError, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean_absolute_percentage_error, name=name, reduction=reduction)
<br>&nbsp
<br>&nbsp
<br>@@ -485,7 +488,7 @@ class MeanSquaredLogarithmicError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `MeanSquaredLogarithmicError` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -494,10 +497,10 @@ class MeanSquaredLogarithmicError(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'mean_squared_logarithmic_error'.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(MeanSquaredLogarithmicError, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean_squared_logarithmic_error, name=name, reduction=reduction)
<br>&nbsp
<br>&nbsp
<br>@@ -568,6 +571,7 @@ class BinaryCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=losses_utils.ReductionV2.AUTO,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='binary_crossentropy'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `BinaryCrossentropy` instance.
<br>@@ -576,12 +580,13 @@ class BinaryCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits: Whether to interpret `y_pred` as a tensor of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[logit](https://en.wikipedia.org/wiki/Logit) values. By default, we
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassume that `y_pred` contains probabilities (i.e., values in [0, 1]).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**Note - Using from_logits=True may be more numerically stable.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwe compute the loss between the predicted labels and a smoothed version
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the true labels, where the smoothing squeezes the labels towards 0.5.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspLarger values of `label_smoothing` correspond to heavier smoothing.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis: The axis along which to compute crossentropy (the features axis).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to -1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -590,14 +595,15 @@ class BinaryCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: (Optional) Name for the op. Defaults to 'binary_crossentropy'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Name for the op. Defaults to 'binary_crossentropy'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(BinaryCrossentropy, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbinary_crossentropy,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=reduction,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=from_logits,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.from_logits = from_logits
<br>&nbsp
<br>&nbsp
<br>@@ -649,6 +655,7 @@ class CategoricalCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1,</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=losses_utils.ReductionV2.AUTO,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='categorical_crossentropy'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `CategoricalCrossentropy` instance.
<br>@@ -656,12 +663,13 @@ class CategoricalCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault, we assume that `y_pred` encodes a probability distribution.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**Note - Using from_logits=True is more numerically stable.**</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. When > 0, label values are smoothed,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmeaning the confidence on label values are relaxed. For example, if
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`0.1`, use `0.1 / num_classes` for non-target labels and </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`0.1`, use `0.1 / num_classes` for non-target labels and</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`0.9 + 0.1 / num_classes` for target labels.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis: The axis along which to compute crossentropy (the features axis).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to -1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -670,14 +678,16 @@ class CategoricalCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'categorical_crossentropy'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to 'categorical_crossentropy'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(CategoricalCrossentropy, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcategorical_crossentropy,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=reduction,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=from_logits,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.SparseCategoricalCrossentropy')
<br>@@ -737,8 +747,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault, we assume that `y_pred` encodes a probability distribution.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**Note - Using from_logits=True may be more numerically stable.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -747,10 +756,10 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sparse_categorical_crossentropy'.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(SparseCategoricalCrossentropy, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse_categorical_crossentropy,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=reduction,
<br>@@ -802,7 +811,7 @@ class Hinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `Hinge` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -811,9 +820,9 @@ class Hinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'hinge'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'hinge'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(Hinge, self).__init__(hinge, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(hinge, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.SquaredHinge')
<br>@@ -863,7 +872,7 @@ class SquaredHinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `SquaredHinge` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -872,10 +881,9 @@ class SquaredHinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'squared_hinge'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'squared_hinge'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(SquaredHinge, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsquared_hinge, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(squared_hinge, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.CategoricalHinge')
<br>@@ -923,7 +931,7 @@ class CategoricalHinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `CategoricalHinge` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -932,10 +940,9 @@ class CategoricalHinge(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'categorical_hinge'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'categorical_hinge'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(CategoricalHinge, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcategorical_hinge, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(categorical_hinge, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.Poisson')
<br>@@ -980,7 +987,7 @@ class Poisson(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `Poisson` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -989,9 +996,9 @@ class Poisson(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'poisson'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'poisson'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(Poisson, self).__init__(poisson, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(poisson, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.LogCosh')
<br>@@ -1037,7 +1044,7 @@ class LogCosh(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `LogCosh` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -1046,9 +1053,9 @@ class LogCosh(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'log_cosh'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'log_cosh'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(LogCosh, self).__init__(log_cosh, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(log_cosh, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.KLDivergence')
<br>@@ -1097,7 +1104,7 @@ class KLDivergence(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Initializes `KLDivergence` instance.
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -1106,10 +1113,9 @@ class KLDivergence(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'kl_divergence'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'kl_divergence'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(KLDivergence, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkl_divergence, name=name, reduction=reduction)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(kl_divergence, name=name, reduction=reduction)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.Huber')
<br>@@ -1165,7 +1171,7 @@ class Huber(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdelta: A float, the point where the Huber loss function changes from a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspquadratic to linear.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss. Default value is `AUTO`. `AUTO` indicates that the reduction
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoption will be determined by the usage context. For almost all cases
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis defaults to `SUM_OVER_BATCH_SIZE`. When used with
<br>@@ -1174,10 +1180,9 @@ class Huber(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill raise an error. Please see this custom training [tutorial](
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://www.tensorflow.org/tutorials/distribute/custom_training) for
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmore details.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the op. Defaults to 'huber_loss'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspname: Optional name for the instance. Defaults to 'huber_loss'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(Huber, self).__init__(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphuber, name=name, reduction=reduction, delta=delta)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(huber, name=name, reduction=reduction, delta=delta)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.mean_squared_error', 'keras.metrics.mse',
<br>@@ -1210,7 +1215,105 @@ def mean_squared_error(y_true, y_pred):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred, y_pred_extra_dim=False):</span>
<br><span style="color:green">+&nbsp &nbsp"""Apply a loss function on a per batch basis.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsploss_fn: The loss function</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_true: truth values (RaggedTensor)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_pred: predicted values (RaggedTensor)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_pred_extra_dim: whether y_pred has an additional dimension compared to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_true</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspLoss-function result. A dense tensor if the output has a single dimension</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp(per-batch loss value); a ragged tensor otherwise.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef rt_is_equiv_dense(rt):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Returns true if this RaggedTensor has the same row_lenghts across</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall ragged dimensions and thus can be converted to a dense tensor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwithout loss of information.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprt: RaggedTensor.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn math_ops.reduce_all([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.equal(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.reduce_variance(math_ops.cast(row_lens, backend.floatx())),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstant_op.constant([0.])) for row_lens in rt.nested_row_lengths()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp])</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _convert_to_dense(inputs):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tuple(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprt.to_tensor() if isinstance(rt, ragged_tensor.RaggedTensor) else rt</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor rt in inputs)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _call_loss(inputs, ragged_output):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp""" Adapt the result to ragged or dense tensor according to the expected</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput type. This is done so that all the return values of the map</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoperation have the same type.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspr = loss_fn(*inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif ragged_output and not isinstance(r, ragged_tensor.RaggedTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = ragged_tensor.RaggedTensor.from_tensor(r)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif not ragged_output and isinstance(r, ragged_tensor.RaggedTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = r.to_tensor()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn r</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspdef _wrapper(inputs, ragged_output):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp_, y_pred = inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(y_pred, ragged_tensor.RaggedTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn control_flow_ops.cond(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprt_is_equiv_dense(y_pred),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: _call_loss(_convert_to_dense(inputs), ragged_output),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: _call_loss(inputs, ragged_output))</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn loss_fn(*inputs)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspif not isinstance(y_true, ragged_tensor.RaggedTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn loss_fn(y_true, y_pred.to_tensor())</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsplshape = y_pred.shape.as_list()[1:-1]</span>
<br><span style="color:green">+&nbsp &nbspif len(lshape) > 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspec = ragged_tensor.RaggedTensorSpec(shape=lshape, dtype=y_pred.dtype)</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspspec = tensor_spec.TensorSpec(shape=[], dtype=y_pred.dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspnested_splits_list = [rt.nested_row_splits for rt in (y_true, y_pred)]</span>
<br><span style="color:green">+&nbsp &nbspif y_pred_extra_dim:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# The last dimension of a categorical prediction may be ragged or not.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprdims = [len(slist) for slist in nested_splits_list]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif rdims[0] == rdims[1] - 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspnested_splits_list[1] = nested_splits_list[1][:-1]</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspmap_fn = functools.partial(_wrapper, ragged_output=len(lshape) > 1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspassertion_list = ragged_util.assert_splits_match(nested_splits_list)</span>
<br><span style="color:green">+&nbsp &nbspwith ops.control_dependencies(assertion_list):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn ragged_map_ops.map_fn(map_fn, elems=(y_true, y_pred), dtype=spec)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(mean_squared_error, ragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_mse(y_true, y_pred):</span>
<br><span style="color:green">+&nbsp &nbsp"""Implements support for handling RaggedTensors.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_true: RaggedTensor truth values. shape = `[batch_size, d0, .. dN]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_pred: RaggedTensor predicted values. shape = `[batch_size, d0, .. dN]`.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspMean squared error values. shape = `[batch_size, d0, .. dN-1]`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspWhen the number of dimensions of the batch feature vector [d0, .. dN] is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspgreater than one the return value is a RaggedTensor. Otherwise a Dense</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptensor with dimensions [batch_size] is returned.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(mean_squared_error, y_true, y_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.mean_absolute_error', 'keras.metrics.mae',
<br>@@ -1240,7 +1343,13 @@ def mean_absolute_error(y_true, y_pred):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(math_ops.abs(y_pred - y_true), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(math_ops.abs(y_pred - y_true), axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(mean_absolute_error, ragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_mae(y_true, y_pred):</span>
<br><span style="color:green">+&nbsp &nbsp"""RaggedTensor adapter for mean_absolute_error."""</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(mean_absolute_error, y_true, y_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.mean_absolute_percentage_error',
<br>@@ -1274,8 +1383,17 @@ def mean_absolute_percentage_error(y_true, y_pred):
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp &nbsp &nbspdiff = math_ops.abs(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(y_true - y_pred) / K.maximum(math_ops.abs(y_true), K.epsilon()))</span>
<br><span style="color:red">- &nbsp &nbspreturn 100. * K.mean(diff, axis=-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(y_true - y_pred) / backend.maximum(math_ops.abs(y_true),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.epsilon()))</span>
<br><span style="color:green">+&nbsp &nbspreturn 100. * backend.mean(diff, axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(mean_absolute_percentage_error,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_mape(y_true, y_pred):</span>
<br><span style="color:green">+&nbsp &nbsp"""Support RaggedTensors."""</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(mean_absolute_percentage_error, y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.mean_squared_logarithmic_error',
<br>@@ -1310,9 +1428,18 @@ def mean_squared_logarithmic_error(y_true, y_pred):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspfirst_log = math_ops.log(K.maximum(y_pred, K.epsilon()) + 1.)</span>
<br><span style="color:red">- &nbsp &nbspsecond_log = math_ops.log(K.maximum(y_true, K.epsilon()) + 1.)</span>
<br><span style="color:red">- &nbsp &nbspreturn K.mean(math_ops.squared_difference(first_log, second_log), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspfirst_log = math_ops.log(backend.maximum(y_pred, backend.epsilon()) + 1.)</span>
<br><span style="color:green">+&nbsp &nbspsecond_log = math_ops.log(backend.maximum(y_true, backend.epsilon()) + 1.)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.squared_difference(first_log, second_log), axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(mean_squared_logarithmic_error,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_msle(y_true, y_pred):</span>
<br><span style="color:green">+&nbsp &nbsp"""Implements support for handling RaggedTensors."""</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(mean_squared_logarithmic_error, y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _maybe_convert_labels(y_true):
<br>@@ -1359,7 +1486,7 @@ def squared_hinge(y_true, y_pred):
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp &nbsp &nbspy_true = _maybe_convert_labels(y_true)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.square(math_ops.maximum(1. - y_true * y_pred, 0.)), axis=-1)
<br>&nbsp
<br>&nbsp
<br>@@ -1392,7 +1519,7 @@ def hinge(y_true, y_pred):
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp &nbsp &nbspy_true = _maybe_convert_labels(y_true)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(math_ops.maximum(1. - y_true * y_pred, 0.), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(math_ops.maximum(1. - y_true * y_pred, 0.), axis=-1)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.losses.categorical_hinge')
<br>@@ -1415,7 +1542,8 @@ def categorical_hinge(y_true, y_pred):
<br>&nbsp &nbsp &nbsp>>> assert np.array_equal(loss.numpy(), np.maximum(0., neg - pos + 1.))
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspy_true: The ground truth values. `y_true` values are expected to be 0 or 1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_true: The ground truth values. `y_true` values are expected to be</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspeither `{-1, +1}` or `{0, 1}` (i.e. a one-hot-encoded tensor).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspy_pred: The predicted values.
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>@@ -1438,7 +1566,7 @@ def huber(y_true, y_pred, delta=1.0):
<br>&nbsp
<br>&nbsp &nbsp &nbsp```
<br>&nbsp &nbsp &nbsploss = 0.5 * x^2                  if |x| <= d
<br><span style="color:red">- &nbsp &nbsploss = 0.5 * d^2 + d * (|x| - d)  if |x| > d</span>
<br><span style="color:green">+&nbsp &nbsploss = d * |x| - 0.5 * d^2        if |x| > d</span>
<br>&nbsp &nbsp &nbsp```
<br>&nbsp &nbsp &nbspwhere d is `delta`. See: https://en.wikipedia.org/wiki/Huber_loss
<br>&nbsp
<br>@@ -1451,16 +1579,15 @@ def huber(y_true, y_pred, delta=1.0):
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspTensor with one scalar loss entry per sample.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspy_pred = math_ops.cast(y_pred, dtype=K.floatx())</span>
<br><span style="color:red">- &nbsp &nbspy_true = math_ops.cast(y_true, dtype=K.floatx())</span>
<br><span style="color:red">- &nbsp &nbspdelta = math_ops.cast(delta, dtype=K.floatx())</span>
<br><span style="color:green">+&nbsp &nbspy_pred = math_ops.cast(y_pred, dtype=backend.floatx())</span>
<br><span style="color:green">+&nbsp &nbspy_true = math_ops.cast(y_true, dtype=backend.floatx())</span>
<br><span style="color:green">+&nbsp &nbspdelta = math_ops.cast(delta, dtype=backend.floatx())</span>
<br>&nbsp &nbsp &nbsperror = math_ops.subtract(y_pred, y_true)
<br>&nbsp &nbsp &nbspabs_error = math_ops.abs(error)
<br>&nbsp &nbsp &nbsphalf = ops.convert_to_tensor_v2_with_dispatch(0.5, dtype=abs_error.dtype)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.where_v2(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspabs_error <= delta, half * math_ops.pow(error, 2),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphalf * math_ops.pow(delta, 2) + delta * (abs_error - delta)),</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.where_v2(abs_error <= delta, half * math_ops.square(error),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdelta * abs_error - half * math_ops.square(delta)),</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1)
<br>&nbsp
<br>&nbsp
<br>@@ -1498,9 +1625,10 @@ def log_cosh(y_true, y_pred):
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _logcosh(x):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn x + nn.softplus(-2. * x) - math_ops.cast(math_ops.log(2.), x.dtype)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn x + math_ops.softplus(-2. * x) - math_ops.cast(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.log(2.), x.dtype)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspreturn K.mean(_logcosh(y_pred - y_true), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(_logcosh(y_pred - y_true), axis=-1)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.categorical_crossentropy',
<br>@@ -1509,7 +1637,8 @@ def log_cosh(y_true, y_pred):
<br>&nbspdef categorical_crossentropy(y_true,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1):</span>
<br>&nbsp &nbsp &nbsp"""Computes the categorical crossentropy loss.
<br>&nbsp
<br>&nbsp &nbsp &nbspStandalone usage:
<br>@@ -1529,6 +1658,8 @@ def categorical_crossentropy(y_true,
<br>&nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. If > `0` then smooth the labels. For
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexample, if `0.1`, use `0.1 / num_classes` for non-target labels
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand `0.9 + 0.1 / num_classes` for target labels.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: Defaults to -1. The dimension along which the entropy is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomputed.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspCategorical crossentropy loss value.
<br>@@ -1536,7 +1667,7 @@ def categorical_crossentropy(y_true,
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp &nbsp &nbsplabel_smoothing = ops.convert_to_tensor_v2_with_dispatch(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing, dtype=K.floatx())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing, dtype=backend.floatx())</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _smooth_labels():
<br>&nbsp &nbsp &nbsp &nbsp &nbspnum_classes = math_ops.cast(array_ops.shape(y_true)[-1], y_pred.dtype)
<br>@@ -1544,7 +1675,50 @@ def categorical_crossentropy(y_true,
<br>&nbsp
<br>&nbsp &nbsp &nbspy_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: y_true)
<br><span style="color:red">- &nbsp &nbspreturn K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.categorical_crossentropy(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_true, y_pred, from_logits=from_logits, axis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(categorical_crossentropy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_categorical_crossentropy(y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1):</span>
<br><span style="color:green">+&nbsp &nbsp"""Implements support for handling RaggedTensors.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_true: Tensor of one-hot true targets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_pred: Tensor of predicted targets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By default,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwe assume that `y_pred` encodes a probability distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. If > `0` then smooth the labels. For</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspexample, if `0.1`, use `0.1 / num_classes` for non-target labels</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspand `0.9 + 0.1 / num_classes` for target labels.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: The axis along which to compute crossentropy (the features axis).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to -1.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspCategorical crossentropy loss value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExpected shape: (batch, sequence_len, n_classes) with sequence_len</span>
<br><span style="color:green">+&nbsp &nbspbeing variable per batch.</span>
<br><span style="color:green">+&nbsp &nbspReturn shape: (batch, sequence_len).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspWhen used by CategoricalCrossentropy() with the default reduction</span>
<br><span style="color:green">+&nbsp &nbsp(SUM_OVER_BATCH_SIZE), the reduction averages the loss over the</span>
<br><span style="color:green">+&nbsp &nbspnumber of elements independent of the batch. E.g. if the RaggedTensor</span>
<br><span style="color:green">+&nbsp &nbsphas 2 batches with [2, 1] values respectivly the resulting loss is</span>
<br><span style="color:green">+&nbsp &nbspthe sum of the individual loss values divided by 3.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspfn = functools.partial(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspcategorical_crossentropy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=from_logits,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis)</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(fn, y_true, y_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.sparse_categorical_crossentropy',
<br>@@ -1567,7 +1741,7 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):
<br>&nbsp &nbsp &nbsp &nbsp &nbspy_pred: The predicted values.
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By default,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwe assume that `y_pred` encodes a probability distribution.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis: (Optional) Defaults to -1. The dimension along which the entropy is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: Defaults to -1. The dimension along which the entropy is</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcomputed.
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>@@ -1575,14 +1749,41 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspreturn K.sparse_categorical_crossentropy(</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.sparse_categorical_crossentropy(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_true, y_pred, from_logits=from_logits, axis=axis)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@dispatch.dispatch_for_types(sparse_categorical_crossentropy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_sparse_categorical_crossentropy(y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1):</span>
<br><span style="color:green">+&nbsp &nbsp""" Implements support for handling RaggedTensors.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspExpected y_pred shape: (batch, sequence_len, n_classes) with sequence_len</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeing variable per batch.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspReturn shape: (batch, sequence_len).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspWhen used by SparseCategoricalCrossentropy() with the default reduction</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(SUM_OVER_BATCH_SIZE), the reduction averages the loss over the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspnumber of elements independent of the batch. E.g. if the RaggedTensor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsphas 2 batches with [2, 1] values respectively, the resulting loss is</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe sum of the individual loss values divided by 3.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspfn = functools.partial(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsparse_categorical_crossentropy, from_logits=from_logits, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp@keras_export('keras.metrics.binary_crossentropy',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras.losses.binary_crossentropy')
<br>&nbsp@dispatch.add_dispatch_support
<br><span style="color:red">- def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):</span>
<br><span style="color:green">+def binary_crossentropy(y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1):</span>
<br>&nbsp &nbsp &nbsp"""Computes the binary crossentropy loss.
<br>&nbsp
<br>&nbsp &nbsp &nbspStandalone usage:
<br>@@ -1599,9 +1800,10 @@ def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbspy_pred: The predicted values. shape = `[batch_size, d0, .. dN]`.
<br>&nbsp &nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By default,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwe assume that `y_pred` encodes a probability distribution.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. If > `0` then smooth the labels by </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. If > `0` then smooth the labels by</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsqueezing them towards 0.5 That is, using `1. - 0.5 * label_smoothing`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor the target class and `0.5 * label_smoothing` for the non-target class.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: The axis along which the mean is computed. Defaults to -1.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspBinary crossentropy loss value. shape = `[batch_size, d0, .. dN-1]`.
<br>@@ -1609,15 +1811,54 @@ def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br>&nbsp &nbsp &nbsplabel_smoothing = ops.convert_to_tensor_v2_with_dispatch(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing, dtype=K.floatx())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing, dtype=backend.floatx())</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _smooth_labels():
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing
<br>&nbsp
<br>&nbsp &nbsp &nbspy_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: y_true)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+@dispatch.dispatch_for_types(binary_crossentropy, ragged_tensor.RaggedTensor)</span>
<br><span style="color:green">+def _ragged_tensor_binary_crossentropy(y_true,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=False,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=0,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1):</span>
<br><span style="color:green">+&nbsp &nbsp"""Implements support for handling RaggedTensors.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_true: Tensor of one-hot true targets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspy_pred: Tensor of predicted targets.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfrom_logits: Whether `y_pred` is expected to be a logits tensor. By default,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwe assume that `y_pred` encodes a probability distribution.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplabel_smoothing: Float in [0, 1]. If > `0` then smooth the labels. For</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspexample, if `0.1`, use `0.1 / num_classes` for non-target labels</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspand `0.9 + 0.1 / num_classes` for target labels.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: Axis along which to compute crossentropy.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspBinary crossentropy loss value.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExpected shape: (batch, sequence_len) with sequence_len being variable</span>
<br><span style="color:green">+&nbsp &nbspper batch.</span>
<br><span style="color:green">+&nbsp &nbspReturn shape: (batch,); returns the per batch mean of the loss values.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspWhen used by BinaryCrossentropy() with the default reduction</span>
<br><span style="color:green">+&nbsp &nbsp(SUM_OVER_BATCH_SIZE), the reduction averages the per batch losses over</span>
<br><span style="color:green">+&nbsp &nbspthe number of batches.</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br><span style="color:green">+&nbsp &nbspfn = functools.partial(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbinary_crossentropy,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfrom_logits=from_logits,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplabel_smoothing=label_smoothing,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=axis)</span>
<br><span style="color:green">+&nbsp &nbspreturn _ragged_tensor_apply_loss(fn, y_true, y_pred)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.metrics.kl_divergence',
<br>@@ -1656,8 +1897,8 @@ def kl_divergence(y_true, y_pred):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspy_true = K.clip(y_true, K.epsilon(), 1)</span>
<br><span style="color:red">- &nbsp &nbspy_pred = K.clip(y_pred, K.epsilon(), 1)</span>
<br><span style="color:green">+&nbsp &nbspy_true = backend.clip(y_true, backend.epsilon(), 1)</span>
<br><span style="color:green">+&nbsp &nbspy_pred = backend.clip(y_pred, backend.epsilon(), 1)</span>
<br>&nbsp &nbsp &nbspreturn math_ops.reduce_sum(y_true * math_ops.log(y_true / y_pred), axis=-1)
<br>&nbsp
<br>&nbsp
<br>@@ -1692,7 +1933,8 @@ def poisson(y_true, y_pred):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspy_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
<br>&nbsp &nbsp &nbspy_true = math_ops.cast(y_true, y_pred.dtype)
<br><span style="color:red">- &nbsp &nbspreturn K.mean(y_pred - y_true * math_ops.log(y_pred + K.epsilon()), axis=-1)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.mean(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_pred - y_true * math_ops.log(y_pred + backend.epsilon()), axis=-1)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export(
<br>@@ -1760,8 +2002,8 @@ class CosineSimilarity(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp>>> y_pred = [[1., 0.], [1., 1.]]
<br>&nbsp &nbsp &nbsp>>> # Using 'auto'/'sum_over_batch_size' reduction type.
<br>&nbsp &nbsp &nbsp>>> cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)
<br><span style="color:red">- &nbsp &nbsp>>> # l2_norm(y_true) = [[0., 1.], [1./1.414], 1./1.414]]]</span>
<br><span style="color:red">- &nbsp &nbsp>>> # l2_norm(y_pred) = [[1., 0.], [1./1.414], 1./1.414]]]</span>
<br><span style="color:green">+&nbsp &nbsp>>> # l2_norm(y_true) = [[0., 1.], [1./1.414, 1./1.414]]</span>
<br><span style="color:green">+&nbsp &nbsp>>> # l2_norm(y_pred) = [[1., 0.], [1./1.414, 1./1.414]]</span>
<br>&nbsp &nbsp &nbsp>>> # l2_norm(y_true) . l2_norm(y_pred) = [[0., 0.], [0.5, 0.5]]
<br>&nbsp &nbsp &nbsp>>> # loss = mean(sum(l2_norm(y_true) . l2_norm(y_pred), axis=1))
<br>&nbsp &nbsp &nbsp>>> #       = -((0. + 0.) +  (0.5 + 0.5)) / 2
<br>@@ -1791,9 +2033,9 @@ class CosineSimilarity(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp```
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis: (Optional) Defaults to -1. The dimension along which the cosine</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsimilarity is computed.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to loss.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: The axis along which the cosine similarity is computed</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(the features axis). Defaults to -1.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreduction: Type of `tf.keras.losses.Reduction` to apply to loss.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefault value is `AUTO`. `AUTO` indicates that the reduction option will
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe determined by the usage context. For almost all cases this defaults to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`SUM_OVER_BATCH_SIZE`. When used with `tf.distribute.Strategy`, outside of
<br>@@ -1802,14 +2044,14 @@ class CosineSimilarity(LossFunctionWrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcustom training [tutorial]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(https://www.tensorflow.org/tutorials/distribute/custom_training) for more
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdetails.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspname: Optional name for the op.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspname: Optional name for the instance.</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction=losses_utils.ReductionV2.AUTO,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='cosine_similarity'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(CosineSimilarity, self).__init__(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspsuper().__init__(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcosine_similarity, reduction=reduction, name=name, axis=axis)
<br>&nbsp
<br>&nbsp
<br>@@ -1878,7 +2120,7 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp<class 'function'>
<br>&nbsp &nbsp &nbsp>>> loss = tf.keras.losses.get("CategoricalCrossentropy")
<br>&nbsp &nbsp &nbsp>>> type(loss)
<br><span style="color:red">- &nbsp &nbsp<class '...tensorflow.python.keras.losses.CategoricalCrossentropy'></span>
<br><span style="color:green">+&nbsp &nbsp<class '...keras.losses.CategoricalCrossentropy'></span>
<br>&nbsp
<br>&nbsp &nbsp &nbspYou can also specify `config` of the loss to this function by passing dict
<br>&nbsp &nbsp &nbspcontaining `class_name` and `config` as an identifier. Also note that the
<br>@@ -1888,12 +2130,12 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp...               "config": {"from_logits": True}}
<br>&nbsp &nbsp &nbsp>>> loss = tf.keras.losses.get(identifier)
<br>&nbsp &nbsp &nbsp>>> type(loss)
<br><span style="color:red">- &nbsp &nbsp<class '...tensorflow.python.keras.losses.CategoricalCrossentropy'></span>
<br><span style="color:green">+&nbsp &nbsp<class '...keras.losses.CategoricalCrossentropy'></span>
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbspidentifier: A loss identifier. One of None or string name of a loss
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfunction/class or loss configuration dictionary or a loss function or a
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss class instance</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsploss class instance.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspA Keras loss as a `function`/ `Loss` class instance.
<br>@@ -1903,16 +2145,15 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif identifier is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br><span style="color:red">- &nbsp &nbspif isinstance(identifier, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbspif isinstance(identifier, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspidentifier = str(identifier)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(identifier)
<br>&nbsp &nbsp &nbspif isinstance(identifier, dict):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(identifier)
<br><span style="color:red">- &nbsp &nbspelif callable(identifier):</span>
<br><span style="color:green">+&nbsp &nbspif callable(identifier):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn identifier
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Could not interpret loss function identifier: {}'.format(identifier))</span>
<br><span style="color:green">+&nbsp &nbspraise ValueError(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'Could not interpret loss function identifier: {identifier}')</span>
<br>&nbsp
<br>&nbsp
<br>&nbspLABEL_DTYPES_FOR_LOSSES = {
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\models.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14092</th>
      <td>keras\models_test.py</td>
      <td>73</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>71</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14094</th>
      <td>keras\models_test.py</td>
      <td>81</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>71</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14095</th>
      <td>keras\models_test.py</td>
      <td>81</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>79</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14097</th>
      <td>keras\models_test.py</td>
      <td>89</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>71</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14098</th>
      <td>keras\models_test.py</td>
      <td>89</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>79</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14099</th>
      <td>keras\models_test.py</td>
      <td>89</td>
      <td>test_clone_sequential_model</td>
      <td>55</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>87</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14101</th>
      <td>keras\models_test.py</td>
      <td>118</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>117</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14111</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>117</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14112</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>125</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14122</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>117</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14123</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>125</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14124</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>134</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14136</th>
      <td>keras\models_test.py</td>
      <td>154</td>
      <td>test_clone_functional_model_with_masking</td>
      <td>141</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>150</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
    <tr>
      <th>14871</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>198</td>
      <td>test_conv_lstm_cloning</td>
      <td>183</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>194</td>
      <td>keras.models.clone_model</td>
      <td>tensorflow\python\keras\models.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: fdbab06fd69563add14a75d6a1f4ea2a3086f307

 <br>Commit message: Expose several keras methods that are used by estimator as tf.__internal__.<br><br>All the methods are non-trival, eg rely on internal global variable, which we don't want to expose.<br><br>PiperOrigin-RevId: 368489730<br>Change-Id: Ibc7a4dcd9d812d749a528a32de9b4e53639e03c7<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/models.py b/tensorflow/python/keras/models.py
<br>index b16e0d6fb60..31ba64daed8 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/models.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/models.py</span>
<br>@@ -13,14 +13,10 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Code for model cloning, plus model-related API entries.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Code for model cloning, plus model-related API entries."""</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.framework import ops
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras import metrics as metrics_module
<br>&nbspfrom tensorflow.python.keras import optimizer_v1
<br>&nbspfrom tensorflow.python.keras.engine import functional
<br>@@ -181,7 +177,7 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Cache input layer. Create a new layer if the tensor is originally not
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# from a Keras layer.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not K.is_keras_tensor(input_tensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not backend.is_keras_tensor(input_tensor):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname = original_input_layer.name
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensor = Input(tensor=input_tensor,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='input_wrapper_for_' + name)
<br>@@ -344,7 +340,7 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(input_tensors, tuple):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensors = list(input_tensors)
<br>&nbsp &nbsp &nbsp &nbsp &nbspx = generic_utils.to_list(input_tensors)[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif K.is_keras_tensor(x):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif backend.is_keras_tensor(x):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporigin_layer = x._keras_history.layer
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(origin_layer, InputLayer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcloned_model = Sequential(
<br>@@ -387,18 +383,23 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):
<br>&nbsp
<br>&nbsp@keras_export('keras.models.clone_model')
<br>&nbspdef clone_model(model, input_tensors=None, clone_function=None):
<br><span style="color:red">- &nbsp &nbsp"""Clone any `Model` instance.</span>
<br><span style="color:green">+&nbsp &nbsp"""Clone a Functional or Sequential `Model` instance.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspModel cloning is similar to calling a model on new inputs,
<br>&nbsp &nbsp &nbspexcept that it creates new layers (and thus new weights) instead
<br>&nbsp &nbsp &nbspof sharing the weights of the existing layers.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspNote that</span>
<br><span style="color:green">+&nbsp &nbsp`clone_model` will not preserve the uniqueness of shared objects within the</span>
<br><span style="color:green">+&nbsp &nbspmodel (e.g. a single variable attached to two distinct layers will be</span>
<br><span style="color:green">+&nbsp &nbsprestored as two separate variables).</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel: Instance of `Model`
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(could be a functional model or a Sequential model).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(could be a Functional model or a Sequential model).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_tensors: optional list of input tensors or InputLayer objects
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto build the model upon. If not provided,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspplaceholders will be created.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew `Input` objects will be created.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclone_function: Callable to be used to clone each layer in the target
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel (except `InputLayer` instances). It takes as argument the layer
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinstance to be cloned, and returns the corresponding layer instance to
<br>@@ -411,24 +412,45 @@ def clone_model(model, input_tensors=None, clone_function=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`Bidirectional(LSTM(...))` instances, for example).
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspAn instance of `Model` reproducing the behavior</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the original model, on top of new inputs tensors,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspusing newly instantiated weights. The cloned model might behave</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdifferently from the original model if a custom clone_function</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodifies the layer.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: in case of invalid `model` argument value.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspAn instance of `Model` reproducing the behavior</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspof the original model, on top of new inputs tensors,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspusing newly instantiated weights. The cloned model may behave</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdifferently from the original model if a custom `clone_function`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspmodifies the layer.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExample:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbsp# Create a test Sequential model.</span>
<br><span style="color:green">+&nbsp &nbspmodel = keras.Sequential([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.Input(shape=(728,)),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.layers.Dense(32, activation='relu'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras.layers.Dense(1, activation='sigmoid'),</span>
<br><span style="color:green">+&nbsp &nbsp])</span>
<br><span style="color:green">+&nbsp &nbsp# Create a copy of the test model (with freshly initialized weights).</span>
<br><span style="color:green">+&nbsp &nbspnew_model = clone_model(model)</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspNote that subclassed models cannot be cloned, since their internal</span>
<br><span style="color:green">+&nbsp &nbsplayer structure is not known. To achieve equivalent functionality</span>
<br><span style="color:green">+&nbsp &nbspas `clone_model` in the case of a subclassed model, simply make sure</span>
<br><span style="color:green">+&nbsp &nbspthat the model class implements `get_config()`</span>
<br><span style="color:green">+&nbsp &nbsp(and optionally `from_config()`), and call:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspnew_model = model.__class__.from_config(model.get_config())</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspif clone_function is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspclone_function = _clone_layer</span>
<br><span style="color:green">+&nbsp &nbspwith generic_utils.DisableSharedObjectScope():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif clone_function is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspclone_function = _clone_layer</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspif isinstance(model, Sequential):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn _clone_sequential_model(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel, input_tensors=input_tensors, layer_fn=clone_function)</span>
<br><span style="color:red">- &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn _clone_functional_model(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel, input_tensors=input_tensors, layer_fn=clone_function)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(model, Sequential):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _clone_sequential_model(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel, input_tensors=input_tensors, layer_fn=clone_function)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn _clone_functional_model(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel, input_tensors=input_tensors, layer_fn=clone_function)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp# "Clone" a subclassed model by reseting all of the attributes.
<br>@@ -556,6 +578,9 @@ def _reset_build_compile_trackers(model):
<br>&nbsp &nbsp &nbspmodel.optimizer = None
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@keras_export(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp'keras.__internal__.models.in_place_subclassed_model_state_restoration',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspv1=[])</span>
<br>&nbspdef in_place_subclassed_model_state_restoration(model):
<br>&nbsp &nbsp &nbsp"""Restores the original state of a model after it was "reset".
<br>&nbsp
<br>@@ -588,6 +613,7 @@ def in_place_subclassed_model_state_restoration(model):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp_reset_build_compile_trackers(model)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@keras_export('keras.__internal__.models.clone_and_build_model', v1=[])</span>
<br>&nbspdef clone_and_build_model(
<br>&nbsp &nbsp &nbsp &nbsp &nbspmodel, input_tensors=None, target_tensors=None, custom_objects=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbspcompile_clone=True, in_place_reset=False, optimizer_iterations=None,
<br>@@ -655,7 +681,7 @@ def clone_and_build_model(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclone.build(model._build_input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclone._set_inputs(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.placeholder(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.placeholder(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmodel._build_input_shape, dtype=model.inputs[0].dtype))
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptry:
<br>@@ -685,7 +711,7 @@ def clone_and_build_model(
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(orig_optimizer, optimizer_v1.TFOptimizer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoptimizer = optimizer_v1.TFOptimizer(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporig_optimizer.optimizer, optimizer_iterations)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.track_tf_optimizer(optimizer)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.track_tf_optimizer(optimizer)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(orig_optimizer, (tuple, list)):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporig_optimizer = [orig_optimizer]
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\merge.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14105</th>
      <td>keras\models_test.py</td>
      <td>118</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>109</td>
      <td>keras.layers.add</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>14116</th>
      <td>keras\models_test.py</td>
      <td>127</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>109</td>
      <td>keras.layers.add</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>14128</th>
      <td>keras\models_test.py</td>
      <td>136</td>
      <td>test_clone_functional_model</td>
      <td>93</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>109</td>
      <td>keras.layers.add</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>14549</th>
      <td>keras\engine\topology_test.py</td>
      <td>358</td>
      <td>test_learning_phase</td>
      <td>344</td>
      <td>assertTrue</td>
      <td>1</td>
      <td>357</td>
      <td>keras.layers.concatenate</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15123</th>
      <td>keras\layers\merge_test.py</td>
      <td>45</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>37</td>
      <td>keras.layers.add</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15132</th>
      <td>keras\layers\merge_test.py</td>
      <td>46</td>
      <td>test_merge_add</td>
      <td>32</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>37</td>
      <td>keras.layers.add</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15144</th>
      <td>keras\layers\merge_test.py</td>
      <td>92</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>84</td>
      <td>keras.layers.multiply</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15153</th>
      <td>keras\layers\merge_test.py</td>
      <td>93</td>
      <td>test_merge_multiply</td>
      <td>80</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>84</td>
      <td>keras.layers.multiply</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15164</th>
      <td>keras\layers\merge_test.py</td>
      <td>106</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>99</td>
      <td>keras.layers.average</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15171</th>
      <td>keras\layers\merge_test.py</td>
      <td>107</td>
      <td>test_merge_average</td>
      <td>96</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>99</td>
      <td>keras.layers.average</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15180</th>
      <td>keras\layers\merge_test.py</td>
      <td>120</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>113</td>
      <td>keras.layers.maximum</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15187</th>
      <td>keras\layers\merge_test.py</td>
      <td>121</td>
      <td>test_merge_maximum</td>
      <td>110</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>113</td>
      <td>keras.layers.maximum</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15196</th>
      <td>keras\layers\merge_test.py</td>
      <td>134</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>127</td>
      <td>keras.layers.minimum</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15203</th>
      <td>keras\layers\merge_test.py</td>
      <td>135</td>
      <td>test_merge_minimum</td>
      <td>124</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>127</td>
      <td>keras.layers.minimum</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15212</th>
      <td>keras\layers\merge_test.py</td>
      <td>148</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>141</td>
      <td>keras.layers.concatenate</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15219</th>
      <td>keras\layers\merge_test.py</td>
      <td>149</td>
      <td>test_merge_concatenate</td>
      <td>138</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>141</td>
      <td>keras.layers.concatenate</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15228</th>
      <td>keras\layers\merge_test.py</td>
      <td>184</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>176</td>
      <td>keras.layers.dot</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15235</th>
      <td>keras\layers\merge_test.py</td>
      <td>188</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>176</td>
      <td>keras.layers.dot</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15244</th>
      <td>keras\layers\merge_test.py</td>
      <td>195</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>176</td>
      <td>keras.layers.dot</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15252</th>
      <td>keras\layers\merge_test.py</td>
      <td>196</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>176</td>
      <td>keras.layers.dot</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15256</th>
      <td>keras\layers\merge_test.py</td>
      <td>200</td>
      <td>test_merge_dot</td>
      <td>173</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>199</td>
      <td>keras.layers.Dot</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
    <tr>
      <th>15257</th>
      <td>keras\layers\merge_test.py</td>
      <td>223</td>
      <td>test_merge_subtract</td>
      <td>219</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>222</td>
      <td>keras.layers.subtract</td>
      <td>tensorflow\python\keras\layers\merge.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 980ed0664ce73bcb1ba4f7edcef3706679a3e482

 <br>Commit message: PR #48716: Fix invalid string formatting in merge.py<br><br>Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/48716<br><br>Copybara import of the project:<br><br>--<br>f444f868df477470747305debd8bccc757c9e50f by Felix Vollmer <felixvollmer@gmail.com>:<br><br>Fix invalid string formatting in merge.py<br><br>PiperOrigin-RevId: 374854904<br>Change-Id: I3a0f56b339196c23ca0d5ae4f6f224578aaaaab0<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/merge.py b/tensorflow/python/keras/layers/merge.py
<br>index 490629a6005..0959b3e582a 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/merge.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/merge.py</span>
<br>@@ -14,13 +14,9 @@
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=not-callable
<br>&nbsp# pylint: disable=redefined-builtin
<br><span style="color:red">- """Layers that can merge several inputs into one.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Layers that can merge several inputs into one."""</span>
<br>&nbsp
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras.engine import base_layer_utils
<br>&nbspfrom tensorflow.python.keras.engine.base_layer import Layer
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>@@ -122,14 +118,14 @@ class _Merge(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('A merge layer should be called on a list of inputs.')
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._reshape_required:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreshaped_inputs = []
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_ndims = list(map(K.ndim, inputs))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_ndims = list(map(backend.ndim, inputs))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif None not in input_ndims:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If ranks of all inputs are available,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# we simply expand each of them at axis=1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# until all of them have the same rank.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmax_ndim = max(input_ndims)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor x in inputs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_ndim = K.ndim(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_ndim = backend.ndim(x)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor _ in range(max_ndim - x_ndim):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx = array_ops.expand_dims(x, axis=1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreshaped_inputs.append(x)
<br>@@ -139,11 +135,11 @@ class _Merge(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# (batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptransposed = False
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor x in inputs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_ndim = K.ndim(x)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_ndim = backend.ndim(x)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x_ndim is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_shape = array_ops.shape(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = x_shape[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_shape = K.concatenate(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_shape = backend.concatenate(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[x_shape[1:],
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims(batch_size, axis=-1)])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_transposed = array_ops.reshape(
<br>@@ -162,14 +158,14 @@ class _Merge(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We don't transpose inputs if they are 1D vectors or scalars.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreshaped_inputs.append(x)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = self._merge_function(reshaped_inputs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_ndim = K.ndim(y)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_ndim = backend.ndim(y)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif transposed:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If inputs have been transposed, we have to transpose the output too.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif y_ndim is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_shape = array_ops.shape(y)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_ndim = array_ops.shape(y_shape)[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size = y_shape[y_ndim - 1]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_shape = K.concatenate([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_shape = backend.concatenate([</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.expand_dims(batch_size, axis=-1), y_shape[:y_ndim - 1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = array_ops.reshape(y, (-1, batch_size))
<br>@@ -214,7 +210,8 @@ class _Merge(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif all(m is None for m in mask):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br>&nbsp &nbsp &nbsp &nbsp &nbspmasks = [array_ops.expand_dims(m, axis=0) for m in mask if m is not None]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn backend.all(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.concatenate(masks, axis=0), axis=0, keepdims=False)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.layers.Add')
<br>@@ -319,7 +316,7 @@ class Multiply(_Merge):
<br>&nbsp &nbsp &nbspdef _merge_function(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutput = inputs[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor i in range(1, len(inputs)):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput *= inputs[i]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = output * inputs[i]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp
<br>@@ -519,7 +516,7 @@ class Concatenate(_Merge):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(err_msg)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _merge_function(self, inputs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn K.concatenate(inputs, axis=self.axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn backend.concatenate(inputs, axis=self.axis)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef compute_output_shape(self, input_shape):
<br>@@ -559,13 +556,13 @@ class Concatenate(_Merge):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mask_i is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Input is unmasked. Append all 1s to masks,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmasks.append(array_ops.ones_like(input_i, dtype='bool'))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif K.ndim(mask_i) < K.ndim(input_i):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif backend.ndim(mask_i) < backend.ndim(input_i):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Mask is smaller than the input, expand it
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmasks.append(array_ops.expand_dims(mask_i, axis=-1))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmasks.append(mask_i)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconcatenated = K.concatenate(masks, axis=self.axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn K.all(concatenated, axis=-1, keepdims=False)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspconcatenated = backend.concatenate(masks, axis=self.axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn backend.all(concatenated, axis=-1, keepdims=False)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig = {
<br>@@ -687,20 +684,20 @@ class Dot(_Merge):
<br>&nbsp &nbsp &nbsp &nbsp &nbspx2 = inputs[1]
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self.axes, int):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.axes < 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes = [self.axes % K.ndim(x1), self.axes % K.ndim(x2)]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes = [self.axes % backend.ndim(x1), self.axes % backend.ndim(x2)]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes = [self.axes] * 2
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes = []
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor i in range(len(self.axes)):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.axes[i] < 0:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes.append(self.axes[i] % K.ndim(inputs[i]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes.append(self.axes[i] % backend.ndim(inputs[i]))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxes.append(self.axes[i])
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.normalize:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx1 = nn.l2_normalize(x1, axis=axes[0])
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx2 = nn.l2_normalize(x2, axis=axes[1])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput = K.batch_dot(x1, x2, axes)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutput = backend.batch_dot(x1, x2, axes)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>@@ -757,7 +754,7 @@ def add(inputs, **kwargs):
<br>&nbsp &nbsp &nbsp>>> print(y.shape)
<br>&nbsp &nbsp &nbsp(2, 3, 4)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspUsed in a functiona model:</span>
<br><span style="color:green">+&nbsp &nbspUsed in a functional model:</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp>>> input1 = tf.keras.layers.Input(shape=(16,))
<br>&nbsp &nbsp &nbsp>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)
<br>@@ -804,6 +801,23 @@ def subtract(inputs, **kwargs):
<br>&nbspdef multiply(inputs, **kwargs):
<br>&nbsp &nbsp &nbsp"""Functional interface to the `Multiply` layer.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspExample:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> x1 = np.arange(3.0)</span>
<br><span style="color:green">+&nbsp &nbsp>>> x2 = np.arange(3.0)</span>
<br><span style="color:green">+&nbsp &nbsp>>> tf.keras.layers.multiply([x1, x2])</span>
<br><span style="color:green">+&nbsp &nbsp<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 4.], ...)></span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspUsage in a functional model:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> input1 = tf.keras.layers.Input(shape=(16,))</span>
<br><span style="color:green">+&nbsp &nbsp>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1) #shape=(None, 8)</span>
<br><span style="color:green">+&nbsp &nbsp>>> input2 = tf.keras.layers.Input(shape=(32,))</span>
<br><span style="color:green">+&nbsp &nbsp>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2) #shape=(None, 8)</span>
<br><span style="color:green">+&nbsp &nbsp>>> out = tf.keras.layers.multiply([x1,x2]) #shape=(None, 8)</span>
<br><span style="color:green">+&nbsp &nbsp>>> out = tf.keras.layers.Dense(4)(out)</span>
<br><span style="color:green">+&nbsp &nbsp>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs: A list of input tensors (at least 2).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs: Standard layer keyword arguments.
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\engine\saving.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14337</th>
      <td>keras\engine\saving_test.py</td>
      <td>366</td>
      <td>test_sequential_model_saving</td>
      <td>332</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>361</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14346</th>
      <td>keras\engine\saving_test.py</td>
      <td>382</td>
      <td>test_sequential_model_saving</td>
      <td>332</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>361</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14353</th>
      <td>keras\engine\saving_test.py</td>
      <td>406</td>
      <td>test_sequential_model_saving_without_compile</td>
      <td>384</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>401</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14361</th>
      <td>keras\engine\saving_test.py</td>
      <td>442</td>
      <td>test_sequential_model_saving_2</td>
      <td>408</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>434</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14371</th>
      <td>keras\engine\saving_test.py</td>
      <td>478</td>
      <td>test_functional_model_saving</td>
      <td>444</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>473</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14383</th>
      <td>keras\engine\saving_test.py</td>
      <td>589</td>
      <td>test_saving_model_with_long_layer_names</td>
      <td>554</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>579</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14394</th>
      <td>keras\engine\saving_test.py</td>
      <td>634</td>
      <td>test_saving_model_with_long_weights_names</td>
      <td>595</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>623</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14405</th>
      <td>keras\engine\saving_test.py</td>
      <td>667</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>665</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
    <tr>
      <th>14416</th>
      <td>keras\engine\saving_test.py</td>
      <td>675</td>
      <td>test_model_saving_to_pre_created_h5py_file</td>
      <td>640</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>665</td>
      <td>keras.models.load_model</td>
      <td>tensorflow\python\keras\engine\saving.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: ERROR

 <br>Commit message: No commit within 100 days of the entered date.
<br>Commit id closest to desired version: 993403945efc9e7a933e9c8bd3ad029c36c6882b

 <br>Commit message: Remove a large amount of PY2 compatibility code.<br><br>PiperOrigin-RevId: 364677165<br>Change-Id: Ic52863fbda9b3f093948b9febbcb00a138d80ade<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\normalization.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14485</th>
      <td>keras\engine\topology_test.py</td>
      <td>114</td>
      <td>test_get_updates_bn</td>
      <td>109</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>111</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>14486</th>
      <td>keras\engine\topology_test.py</td>
      <td>115</td>
      <td>test_get_updates_bn</td>
      <td>109</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>111</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>14488</th>
      <td>keras\engine\topology_test.py</td>
      <td>116</td>
      <td>test_get_updates_bn</td>
      <td>109</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>111</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15260</th>
      <td>keras\layers\normalization_test.py</td>
      <td>60</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>58</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15261</th>
      <td>keras\layers\normalization_test.py</td>
      <td>61</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>58</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15262</th>
      <td>keras\layers\normalization_test.py</td>
      <td>65</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>58</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15263</th>
      <td>keras\layers\normalization_test.py</td>
      <td>65</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>63</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15264</th>
      <td>keras\layers\normalization_test.py</td>
      <td>66</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>58</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15265</th>
      <td>keras\layers\normalization_test.py</td>
      <td>66</td>
      <td>test_batchnorm_weights</td>
      <td>56</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>63</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15266</th>
      <td>keras\layers\normalization_test.py</td>
      <td>73</td>
      <td>test_batchnorm_regularization</td>
      <td>68</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15267</th>
      <td>keras\layers\normalization_test.py</td>
      <td>78</td>
      <td>test_batchnorm_regularization</td>
      <td>68</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15268</th>
      <td>keras\layers\normalization_test.py</td>
      <td>78</td>
      <td>test_batchnorm_regularization</td>
      <td>68</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>75</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15269</th>
      <td>keras\layers\normalization_test.py</td>
      <td>79</td>
      <td>test_batchnorm_regularization</td>
      <td>68</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15270</th>
      <td>keras\layers\normalization_test.py</td>
      <td>79</td>
      <td>test_batchnorm_regularization</td>
      <td>68</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>75</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
    <tr>
      <th>15295</th>
      <td>keras\layers\normalization_test.py</td>
      <td>173</td>
      <td>test_shared_batchnorm</td>
      <td>155</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>160</td>
      <td>keras.layers.BatchNormalization</td>
      <td>tensorflow\python\keras\layers\normalization.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 9eac822bb2b3416f25398e44282125d0405d69ba

 <br>Commit message: Create semantic layered directories for normalization layers<br><br>PiperOrigin-RevId: 371140922<br>Change-Id: I4fdb6335b68b527996a5f168245f9c231edd7aee<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/normalization.py b/tensorflow/python/keras/layers/normalization.py
<br>deleted file mode 100644
<br>index b03ce54f78b..00000000000
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/normalization.py</span>
<br><span style="color:green">+++ /dev/null</span>
<br>@@ -1,1311 +0,0 @@
<br><span style="color:red">- # Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<br><span style="color:red">- #</span>
<br><span style="color:red">- # Licensed under the Apache License, Version 2.0 (the "License");</span>
<br><span style="color:red">- # you may not use this file except in compliance with the License.</span>
<br><span style="color:red">- # You may obtain a copy of the License at</span>
<br><span style="color:red">- #</span>
<br><span style="color:red">- #     http://www.apache.org/licenses/LICENSE-2.0</span>
<br><span style="color:red">- #</span>
<br><span style="color:red">- # Unless required by applicable law or agreed to in writing, software</span>
<br><span style="color:red">- # distributed under the License is distributed on an "AS IS" BASIS,</span>
<br><span style="color:red">- # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<br><span style="color:red">- # See the License for the specific language governing permissions and</span>
<br><span style="color:red">- # limitations under the License.</span>
<br><span style="color:red">- # ==============================================================================</span>
<br><span style="color:red">- """Normalization layers."""</span>
<br><span style="color:red">- # pylint: disable=g-classes-have-attributes</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- from tensorflow.python.distribute import distribution_strategy_context</span>
<br><span style="color:red">- from tensorflow.python.framework import constant_op</span>
<br><span style="color:red">- from tensorflow.python.framework import dtypes</span>
<br><span style="color:red">- from tensorflow.python.framework import ops</span>
<br><span style="color:red">- from tensorflow.python.framework import tensor_shape</span>
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:red">- from tensorflow.python.keras import constraints</span>
<br><span style="color:red">- from tensorflow.python.keras import initializers</span>
<br><span style="color:red">- from tensorflow.python.keras import regularizers</span>
<br><span style="color:red">- from tensorflow.python.keras.engine.base_layer import Layer</span>
<br><span style="color:red">- from tensorflow.python.keras.engine.input_spec import InputSpec</span>
<br><span style="color:red">- from tensorflow.python.keras.utils import control_flow_util</span>
<br><span style="color:red">- from tensorflow.python.ops import array_ops</span>
<br><span style="color:red">- from tensorflow.python.ops import init_ops</span>
<br><span style="color:red">- from tensorflow.python.ops import math_ops</span>
<br><span style="color:red">- from tensorflow.python.ops import nn</span>
<br><span style="color:red">- from tensorflow.python.ops import state_ops</span>
<br><span style="color:red">- from tensorflow.python.ops import variables as tf_variables</span>
<br><span style="color:red">- from tensorflow.python.ops.control_flow_ops import get_enclosing_xla_context</span>
<br><span style="color:red">- from tensorflow.python.platform import tf_logging as logging</span>
<br><span style="color:red">- from tensorflow.python.util.tf_export import keras_export</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br><span style="color:red">- class BatchNormalizationBase(Layer):</span>
<br><span style="color:red">- &nbsp &nbspr"""Layer that normalizes its inputs.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspBatch normalization applies a transformation that maintains the mean output</span>
<br><span style="color:red">- &nbsp &nbspclose to 0 and the output standard deviation close to 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspImportantly, batch normalization works differently during training and</span>
<br><span style="color:red">- &nbsp &nbspduring inference.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp**During training** (i.e. when using `fit()` or when calling the layer/model</span>
<br><span style="color:red">- &nbsp &nbspwith the argument `training=True`), the layer normalizes its output using</span>
<br><span style="color:red">- &nbsp &nbspthe mean and standard deviation of the current batch of inputs. That is to</span>
<br><span style="color:red">- &nbsp &nbspsay, for each channel being normalized, the layer returns</span>
<br><span style="color:red">- &nbsp &nbsp`(batch - mean(batch)) / (var(batch) + epsilon) * gamma + beta`, where:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp- `epsilon` is small constant (configurable as part of the constructor</span>
<br><span style="color:red">- &nbsp &nbsparguments)</span>
<br><span style="color:red">- &nbsp &nbsp- `gamma` is a learned scaling factor (initialized as 1), which</span>
<br><span style="color:red">- &nbsp &nbspcan be disabled by passing `scale=False` to the constructor.</span>
<br><span style="color:red">- &nbsp &nbsp- `beta` is a learned offset factor (initialized as 0), which</span>
<br><span style="color:red">- &nbsp &nbspcan be disabled by passing `center=False` to the constructor.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp**During inference** (i.e. when using `evaluate()` or `predict()` or when</span>
<br><span style="color:red">- &nbsp &nbspcalling the layer/model with the argument `training=False` (which is the</span>
<br><span style="color:red">- &nbsp &nbspdefault), the layer normalizes its output using a moving average of the</span>
<br><span style="color:red">- &nbsp &nbspmean and standard deviation of the batches it has seen during training. That</span>
<br><span style="color:red">- &nbsp &nbspis to say, it returns</span>
<br><span style="color:red">- &nbsp &nbsp`(batch - self.moving_mean) / (self.moving_var + epsilon) * gamma + beta`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp`self.moving_mean` and `self.moving_var` are non-trainable variables that</span>
<br><span style="color:red">- &nbsp &nbspare updated each time the layer in called in training mode, as such:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp- `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`</span>
<br><span style="color:red">- &nbsp &nbsp- `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspAs such, the layer will only normalize its inputs during inference</span>
<br><span style="color:red">- &nbsp &nbsp*after having been trained on data that has similar statistics as the</span>
<br><span style="color:red">- &nbsp &nbspinference data*.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspArgs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis: Integer or a list of integers, the axis that should be normalized</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp(typically the features axis). For instance, after a `Conv2D` layer with</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`data_format="channels_first"`, set `axis=1` in `BatchNormalization`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmomentum: Momentum for the moving average.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspepsilon: Small float added to variance to avoid dividing by zero.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcenter: If True, add offset of `beta` to normalized tensor. If False, `beta`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis ignored.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscale: If True, multiply by `gamma`. If False, `gamma` is not used. When the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnext layer is linear (also e.g. `nn.relu`), this can be disabled since the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscaling will be done by the next layer.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_initializer: Initializer for the beta weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_initializer: Initializer for the gamma weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmoving_mean_initializer: Initializer for the moving mean.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmoving_variance_initializer: Initializer for the moving variance.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_regularizer: Optional regularizer for the beta weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_regularizer: Optional regularizer for the gamma weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_constraint: Optional constraint for the beta weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_constraint: Optional constraint for the gamma weight.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprenorm: Whether to use [Batch Renormalization](</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphttps://arxiv.org/abs/1702.03275). This adds extra variables during</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining. The inference is the same for either value of this parameter.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprenorm_clipping: A dictionary that may map keys 'rmax', 'rmin', 'dmax' to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscalar `Tensors` used to clip the renorm correction. The correction `(r,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd)` is used as `corrected_value = normalized_value * r + d`, with `r`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclipped to [rmin, rmax], and `d` to [-dmax, dmax]. Missing rmax, rmin,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdmax are set to inf, 0, inf, respectively.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprenorm_momentum: Momentum used to update the moving means and standard</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdeviations with renorm. Unlike `momentum`, this affects training and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshould be neither too small (which would add noise) nor too large (which</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwould give stale estimates). Note that `momentum` is still applied to get</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe means and variances for inference.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfused: if `True`, use a faster, fused implementation, or raise a ValueError</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif the fused implementation cannot be used. If `None`, use the faster</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation if possible. If False, do not used the fused</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimplementation.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that in TensorFlow 1.x, the meaning of `fused=True` is different:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif `False`, the layer uses the system-recommended implementation.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptrainable: Boolean, if `True` the variables will be marked as trainable.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvirtual_batch_size: An `int`. By default, `virtual_batch_size` is `None`,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich means batch normalization is performed across the whole batch. When</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`virtual_batch_size` is not `None`, instead perform "Ghost Batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNormalization", which creates virtual sub-batches which are each</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnormalized separately (with shared gamma, beta, and moving statistics).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMust divide the actual batch size during execution.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspadjustment: A function taking the `Tensor` containing the (dynamic) shape of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe input tensor and returning a pair (scale, bias) to apply to the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnormalized values (before gamma and beta), only during training. For</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexample, if `axis=-1`,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`adjustment = lambda shape: (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf.random.uniform(shape[-1:], 0.93, 1.07),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf.random.uniform(shape[-1:], -0.1, 0.1))` will scale the normalized</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue by up to 7% up or down, then shift the result by up to 0.1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(with independent scaling and bias for each feature but shared</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspacross all examples), and finally apply gamma and/or beta. If</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`, no adjustment is applied. Cannot be specified if</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvirtual_batch_size is specified.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspCall arguments:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs: Input tensor (of any rank).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptraining: Python boolean indicating whether the layer should behave in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining mode or in inference mode.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `training=True`: The layer will normalize its inputs using the mean and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance of the current batch of inputs.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `training=False`: The layer will normalize its inputs using the mean and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance of its moving statistics, learned during training.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspInput shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspArbitrary. Use the keyword argument `input_shape` (tuple of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspintegers, does not include the samples axis) when using this layer as the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfirst layer in a model.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspOutput shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSame shape as input.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspReference:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp- [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).</span>
<br><span style="color:red">- &nbsp &nbsp"""</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp# By default, the base class uses V2 behavior. The BatchNormalization V1</span>
<br><span style="color:red">- &nbsp &nbsp# subclass sets this to False to use the V1 behavior.</span>
<br><span style="color:red">- &nbsp &nbsp_USE_V2_BEHAVIOR = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef __init__(self,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmomentum=0.99,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepsilon=1e-3,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcenter=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_initializer='zeros',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_initializer='ones',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_mean_initializer='zeros',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_variance_initializer='ones',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_regularizer=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_regularizer=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_constraint=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_constraint=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprenorm=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprenorm_clipping=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprenorm_momentum=0.99,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfused=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvirtual_batch_size=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadjustment=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(BatchNormalizationBase, self).__init__(name=name, **kwargs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(axis, (list, tuple)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = axis[:]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif isinstance(axis, int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('Expected an int or a list/tuple of ints for the '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'argument \'axis\', but received: %r' % axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.momentum = momentum</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.epsilon = epsilon</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.center = center</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.scale = scale</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_initializer = initializers.get(beta_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_initializer = initializers.get(gamma_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.moving_mean_initializer = initializers.get(moving_mean_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.moving_variance_initializer = initializers.get(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_variance_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_regularizer = regularizers.get(beta_regularizer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_regularizer = regularizers.get(gamma_regularizer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_constraint = constraints.get(beta_constraint)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_constraint = constraints.get(gamma_constraint)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.renorm = renorm</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.virtual_batch_size = virtual_batch_size</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.adjustment = adjustment</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._USE_V2_BEHAVIOR:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._raise_if_fused_cannot_be_used()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We leave fused as None if self._fused_can_be_used()==True, since we</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# still may set it to False in self.build() if the input rank is not 4.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif fused is None and not self._fused_can_be_used():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfused = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif fused is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfused = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.supports_masking = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.fused = fused</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._bessels_correction_test_only = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.trainable = trainable</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprenorm_clipping = renorm_clipping or {}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeys = ['rmax', 'rmin', 'dmax']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif set(renorm_clipping) - set(keys):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('renorm_clipping %s contains keys not in %s' %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(renorm_clipping, keys))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.renorm_clipping = renorm_clipping</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.renorm_momentum = renorm_momentum</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _raise_if_fused_cannot_be_used(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Raises a ValueError if fused implementation cannot be used.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspIn addition to the checks done in this function, the input tensors rank must</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbe 4. The input rank check can only be done once the input shape is known.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Note the ValueErrors in this function are caught and not reraised in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# _fused_can_be_used(). No other exception besides ValueError should be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# raised here.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Currently fused batch norm doesn't support renorm. It also only supports a</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# channel dimension on axis 1 or 3, when no virtual batch size or adjustment</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# is used.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Passing both `fused=True` and `renorm=True` is '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'not supported')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis = [self.axis] if isinstance(self.axis, int) else self.axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Axis -3 is equivalent to 1, and axis -1 is equivalent to 3, because the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# input rank is required to be 4 (which is checked later).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(b/173253101): Once the input rank can be 5, update this check.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif len(axis) > 1 or axis[0] not in (-3, -1, 1, 3):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Passing `fused=True` is only supported when axis is 1 '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'or 3. Got axis %s' % (axis,))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Passing `fused=True` is not supported when '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`virtual_batch_size` is specified.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.adjustment is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Passing `fused=True` is not supported when '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`adjustment` is specified.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(reedwm): Support fp64 in FusedBatchNorm then remove this check.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._compute_dtype not in ('float16', 'bfloat16', 'float32', None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Passing `fused=True` is only supported when the compute '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dtype is float16, bfloat16, or float32. Got dtype: %s' %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self._compute_dtype,))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _fused_can_be_used(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._raise_if_fused_cannot_be_used()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspexcept ValueError:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn False</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp@property</span>
<br><span style="color:red">- &nbsp &nbspdef trainable(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn self._trainable</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp@trainable.setter</span>
<br><span style="color:red">- &nbsp &nbspdef trainable(self, value):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._trainable = value</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp@property</span>
<br><span style="color:red">- &nbsp &nbspdef _param_dtype(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Raise parameters of fp16 batch norm to fp32</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.dtype == dtypes.float16 or self.dtype == dtypes.bfloat16:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn dtypes.float32</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.dtype or dtypes.float32</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _support_zero_size_input(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn distribution_strategy_context.has_strategy() and getattr(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdistribution_strategy_context.get_strategy().extended,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'experimental_enable_get_next_as_optional', False)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef build(self, input_shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinput_shape = tensor_shape.TensorShape(input_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif not input_shape.ndims:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Input has undefined rank.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspndims = len(input_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Convert axis to list and resolve negatives</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(self.axis, int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = [self.axis]</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor idx, x in enumerate(self.axis):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x < 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis[idx] = ndims + x</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate axes</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor x in self.axis:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x < 0 or x >= ndims:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Invalid axis: %s' % (self.axis,))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif len(self.axis) != len(set(self.axis)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Duplicate axis: %s' % (self.axis,))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size <= 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('virtual_batch_size must be a positive integer that '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'divides the true batch size of the input tensor')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If using virtual batches, the first dimension must be the batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# dimension and cannot be the batch norm axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0 in self.axis:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('When using virtual_batch_size, the batch dimension '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'must be 0 and thus axis cannot include 0. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Received axis=%s' % (self.axis,))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.adjustment is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('When using virtual_batch_size, adjustment cannot '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'be specified')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.fused in (None, True):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(yaozhang): if input is not 4D, reshape it to 4D and reshape the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# output back to its original shape accordingly.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._USE_V2_BEHAVIOR:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(b/173253101): Using fused in the 5D case is currently disabled</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# due to a regression on UNet, so it is only currently only supported in</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the 4D case.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.fused is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.fused = ndims == 4</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif self.fused and ndims != 4:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Batch normalization layers with `fused=True` only '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'support 4D or 5D input tensors. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Received tensor with shape: %s' %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(tuple(input_shape),))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassert self.fused is not None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.fused = (ndims == 4 and self._fused_can_be_used())</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(chrisying): fused batch norm is currently not supported for</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# multi-axis batch norm and by extension virtual batches. In some cases,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# it might be possible to use fused batch norm but would require reshaping</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# the Tensor to 4D with the axis in 1 or 3 (preferred 1) which is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# particularly tricky. A compromise might be to just support the most</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# common use case (turning 5D w/ virtual batch to NCHW)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.axis == [1] and ndims == 4:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._data_format = 'NCHW'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif self.axis == [1] and ndims == 5:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._data_format = 'NCDHW'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif self.axis == [3] and ndims == 4:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._data_format = 'NHWC'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif self.axis == [4] and ndims == 5:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._data_format = 'NDHWC'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelif ndims == 5:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# 5D tensors that can be passed in but should not use fused batch norm</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# due to unsupported axis.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.fused = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif ndims == 4:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Unsupported axis. The use of `fused=True` is only possible with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`axis=1` or `axis=3` for 4D input tensors. Received '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'axis=%s' % (self.axis,))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Unsupported axis. The use of `fused=True` is only possible with '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`axis=1` or `axis=4` for 5D input tensors. Received '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'axis=%s' % (self.axis,))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis_to_dim = {x: input_shape.dims[x].value for x in self.axis}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor x in axis_to_dim:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif axis_to_dim[x] is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Input has undefined `axis` dimension. Received input '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'with shape %s. Axis value: %s' %</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(tuple(input_shape), self.axis))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.input_spec = InputSpec(ndim=ndims, axes=axis_to_dim)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif len(axis_to_dim) == 1 and self.virtual_batch_size is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Single axis batch norm (most common/default use-case)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparam_shape = (list(axis_to_dim.values())[0],)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Parameter shape is the original shape but with 1 in all non-axis dims</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparam_shape = [</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis_to_dim[i] if i in axis_to_dim else 1 for i in range(ndims)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When using virtual batches, add an extra dim at index 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspparam_shape.insert(1, 1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor idx, x in enumerate(self.axis):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis[idx] = x + 1  # Account for added dimension</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.scale:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.gamma = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='gamma',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.gamma_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.gamma_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.gamma_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.gamma = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._gamma_const = K.constant(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1.0, dtype=self._param_dtype, shape=param_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.center:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.beta = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='beta',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.beta_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.beta_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.beta_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.beta = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._beta_const = K.constant(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp0.0, dtype=self._param_dtype, shape=param_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptry:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Disable variable partitioning when creating the moving mean and variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(self, '_scope') and self._scope:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppartitioner = self._scope.partitioner</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._scope.set_partitioner(None)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppartitioner = None</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_mean = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='moving_mean',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.moving_mean_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsynchronization=tf_variables.VariableSynchronization.ON_READ,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaggregation=tf_variables.VariableAggregation.MEAN,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_variance = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='moving_variance',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.moving_variance_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsynchronization=tf_variables.VariableSynchronization.ON_READ,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaggregation=tf_variables.VariableAggregation.MEAN,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In batch renormalization we track the inference moving stddev instead</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# of the moving variance to more closely align with the paper.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef moving_stddev_initializer(*args, **kwargs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn math_ops.sqrt(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_variance_initializer(*args, **kwargs))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith distribution_strategy_context.get_strategy(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp).extended.colocate_vars_with(self.moving_variance):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_stddev = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='moving_stddev',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=moving_stddev_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsynchronization=tf_variables.VariableSynchronization.ON_READ,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaggregation=tf_variables.VariableAggregation.MEAN,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Create variables to maintain the moving mean and standard deviation.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# These are used in training and thus are different from the moving</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# averages above. The renorm variables are colocated with moving_mean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# and moving_stddev.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# NOTE: below, the outer `with device` block causes the current device</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# stack to be cleared. The nested ones use a `lambda` to set the desired</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# device and ignore any devices that may be set by the custom getter.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _renorm_variable(name,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=init_ops.zeros_initializer()):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Create a renorm variable."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvar = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname=name,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._param_dtype,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsynchronization=tf_variables.VariableSynchronization.ON_READ,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaggregation=tf_variables.VariableAggregation.MEAN,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn var</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith distribution_strategy_context.get_strategy(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp).extended.colocate_vars_with(self.moving_mean):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.renorm_mean = _renorm_variable('renorm_mean', param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_mean_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith distribution_strategy_context.get_strategy(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp).extended.colocate_vars_with(self.moving_stddev):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.renorm_stddev = _renorm_variable('renorm_stddev', param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_stddev_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfinally:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif partitioner:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._scope.set_partitioner(partitioner)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.built = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _assign_moving_average(self, variable, value, momentum, inputs_size):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith K.name_scope('AssignMovingAvg') as scope:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith ops.colocate_with(variable):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdecay = ops.convert_to_tensor_v2_with_dispatch(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp1.0 - momentum, name='decay')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif decay.dtype != variable.dtype.base_dtype:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdecay = math_ops.cast(decay, variable.dtype.base_dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdate_delta = (variable - math_ops.cast(value, variable.dtype)) * decay</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif inputs_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdate_delta = array_ops.where(inputs_size > 0, update_delta,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.zeros_like(update_delta))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn state_ops.assign_sub(variable, update_delta, name=scope)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _assign_new_value(self, variable, value):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith K.name_scope('AssignNewValue') as scope:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith ops.colocate_with(variable):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn state_ops.assign(variable, value, name=scope)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _fused_batch_norm(self, inputs, training):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Returns the output of fused batch norm."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta = self.beta if self.center else self._beta_const</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma = self.gamma if self.scale else self._gamma_const</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(b/129279393): Support zero batch input in non DistributionStrategy</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# code as well.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._support_zero_size_input():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Keras assumes that batch dimension is the first dimension for Batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Normalization.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size = array_ops.shape(inputs)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(rmlarsen): Support using fused avg updates for non-eager execution</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# after fixing graph pattern matching and enabling fused_batch_norm to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# take exponential_avg_factor as a tensor input.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspuse_fused_avg_updates = (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspops.executing_eagerly_outside_functions() and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspisinstance(self.momentum, (float, int)) and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspget_enclosing_xla_context() is None)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif use_fused_avg_updates:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexponential_avg_factor = 1.0 - self.momentum</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexponential_avg_factor = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _maybe_add_or_remove_bessels_correction(variance, remove=True):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr"""Add or remove Bessel's correction."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Removes Bessel's correction if remove == True, adds it otherwise.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This is to be consistent with non-fused batch norm. Note that the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# variance computed by fused batch norm is with Bessel's correction.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This is only used in legacy V1 batch norm tests.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._bessels_correction_test_only:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_size = math_ops.cast(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.size(inputs) / array_ops.size(variance), variance.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif remove:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfactor = (sample_size -</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.cast(1.0, variance.dtype)) / sample_size</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfactor = sample_size / (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsample_size - math_ops.cast(1.0, variance.dtype))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn variance * factor</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _fused_batch_norm_training():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn nn.fused_batch_norm(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean=self.moving_mean,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance=_maybe_add_or_remove_bessels_correction(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_variance, remove=False),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepsilon=self.epsilon,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_training=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self._data_format,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexponential_avg_factor=exponential_avg_factor)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _fused_batch_norm_training_empty():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn inputs, self.moving_mean, self.moving_variance</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _fused_batch_norm_inference():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn nn.fused_batch_norm(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean=self.moving_mean,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance=self.moving_variance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepsilon=self.epsilon,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_training=False,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self._data_format)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptrain_op = _fused_batch_norm_training</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif use_fused_avg_updates and input_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# pylint: disable=g-long-lambda</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrain_op = lambda: control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size > 0, _fused_batch_norm_training,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_fused_batch_norm_training_empty)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# pylint: enable=g-long-lambda</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput, mean, variance = control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining, train_op, _fused_batch_norm_inference)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvariance = _maybe_add_or_remove_bessels_correction(variance, remove=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptraining_value = control_flow_util.constant_value(training)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif training_value or training_value is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not use_fused_avg_updates:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif training_value is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmomentum = control_flow_util.smart_cond(training,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: self.momentum,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: 1.0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmomentum = ops.convert_to_tensor_v2_with_dispatch(self.momentum)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef mean_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Update self.moving_mean with the most recent data point."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif use_fused_avg_updates:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_new_value(self.moving_mean, mean)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_moving_average(self.moving_mean, mean, momentum,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef variance_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Update self.moving_variance with the most recent data point."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif use_fused_avg_updates:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_new_value(self.moving_variance, variance)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_moving_average(self.moving_variance, variance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmomentum, input_batch_size)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(mean_update)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(variance_update)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn output</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _renorm_correction_and_moments(self, mean, variance, training,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_size):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Returns the correction and update values for renorm."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstddev = math_ops.sqrt(variance + self.epsilon)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Compute the average mean and standard deviation, as if they were</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# initialized with this batch's moments.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprenorm_mean = self.renorm_mean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Avoid divide by zero early on in training.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprenorm_stddev = math_ops.maximum(self.renorm_stddev,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.sqrt(self.epsilon))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Compute the corrections for batch renorm.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr = stddev / renorm_stddev</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspd = (mean - renorm_mean) / renorm_stddev</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Ensure the corrections use pre-update moving averages.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith ops.control_dependencies([r, d]):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = array_ops.identity(mean)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstddev = array_ops.identity(stddev)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsprmin, rmax, dmax = [</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.renorm_clipping.get(key) for key in ['rmin', 'rmax', 'dmax']</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif rmin is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = math_ops.maximum(r, rmin)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif rmax is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = math_ops.minimum(r, rmax)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif dmax is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd = math_ops.maximum(d, -dmax)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd = math_ops.minimum(d, dmax)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# When not training, use r=1, d=0.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspr = control_flow_util.smart_cond(training, lambda: r,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: array_ops.ones_like(r))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspd = control_flow_util.smart_cond(training, lambda: d,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: array_ops.zeros_like(d))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _update_renorm_variable(var, value, inputs_size):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Updates a moving average and weight, returns the unbiased value."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue = array_ops.identity(value)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _do_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Updates the var, returns the updated value."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_var = self._assign_moving_average(var, value, self.renorm_momentum,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_size)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn new_var</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _fake_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn array_ops.identity(var)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn control_flow_util.smart_cond(training, _do_update, _fake_update)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(yuefengz): colocate the operations</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspupdate_new_mean = _update_renorm_variable(self.renorm_mean, mean,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_size)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspupdate_new_stddev = _update_renorm_variable(self.renorm_stddev, stddev,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_size)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Update the inference mode moving averages with the batch value.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith ops.control_dependencies([update_new_mean, update_new_stddev]):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout_mean = array_ops.identity(mean)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout_variance = array_ops.identity(variance)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn (r, d, out_mean, out_variance)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _calculate_mean_and_var(self, inputs, reduction_axes, keep_dims):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn nn.moments(inputs, reduction_axes, keep_dims=keep_dims)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _moments(self, inputs, reduction_axes, keep_dims):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmean, variance = self._calculate_mean_and_var(inputs, reduction_axes,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeep_dims)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(b/129279393): Support zero batch input in non DistributionStrategy</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# code as well.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._support_zero_size_input():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size = array_ops.shape(inputs)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = array_ops.where(input_batch_size > 0, mean, K.zeros_like(mean))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance = array_ops.where(input_batch_size > 0, variance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.zeros_like(variance))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn mean, variance</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _get_training_value(self, training=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif training is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining = K.learning_phase()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self._USE_V2_BEHAVIOR:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(training, int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining = bool(training)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not self.trainable:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When the layer is not trainable, it overrides the value passed from</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# model.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining = False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn training</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef call(self, inputs, training=None):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptraining = self._get_training_value(training)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Virtual batches (aka ghost batches) can be simulated by reshaping the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Tensor and reusing the existing batch norm implementation</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporiginal_shape = array_ops.shape(inputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporiginal_shape = array_ops.concat(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[constant_op.constant([-1]), original_shape[1:]], axis=0)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexpanded_shape = array_ops.concat([</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstant_op.constant([self.virtual_batch_size, -1]),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsporiginal_shape[1:]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=0)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Will cause errors if virtual_batch_size does not divide the batch size</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = array_ops.reshape(inputs, expanded_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef undo_virtual_batching(outputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = array_ops.reshape(outputs, original_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = self._fused_batch_norm(inputs, training=training)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Currently never reaches here since fused_batch_norm does not support</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# virtual batching</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = undo_virtual_batching(outputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs_dtype = inputs.dtype.base_dtype</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif inputs_dtype in (dtypes.float16, dtypes.bfloat16):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Do all math in float32 if given 16-bit inputs for numeric stability.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In particular, it's very easy for variance to overflow in float16 and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# for safety we also choose to cast bfloat16 to float32.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = math_ops.cast(inputs, dtypes.float32)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Compute the axes along which to reduce the mean / variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinput_shape = inputs.shape</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspndims = len(input_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreduction_axes = [i for i in range(ndims) if i not in self.axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdel reduction_axes[1]  # Do not reduce along virtual batch dim</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Broadcasting only necessary for single-axis batch norm where the axis is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# not the last dimension</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbroadcast_shape = [1] * ndims</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbroadcast_shape[self.axis[0]] = input_shape.dims[self.axis[0]].value</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _broadcast(v):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (v is not None and len(v.shape) != ndims and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction_axes != list(range(ndims - 1))):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn array_ops.reshape(v, broadcast_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn v</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscale, offset = _broadcast(self.gamma), _broadcast(self.beta)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _compose_transforms(scale, offset, then_scale, then_offset):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif then_scale is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale *= then_scale</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset *= then_scale</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif then_offset is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset += then_offset</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (scale, offset)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Determine a boolean value for `training`: could be True, False, or None.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptraining_value = control_flow_util.constant_value(training)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif training_value == False:  # pylint: disable=singleton-comparison,g-explicit-bool-comparison</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean, variance = self.moving_mean, self.moving_variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.adjustment:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadj_scale, adj_bias = self.adjustment(array_ops.shape(inputs))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Adjust only during training.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadj_scale = control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining, lambda: adj_scale, lambda: array_ops.ones_like(adj_scale))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadj_bias = control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining, lambda: adj_bias, lambda: array_ops.zeros_like(adj_bias))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale, offset = _compose_transforms(adj_scale, adj_bias, scale, offset)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Some of the computations here are not necessary when training==False</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# but not a constant. However, this makes the code simpler.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeep_dims = self.virtual_batch_size is not None or len(self.axis) > 1</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean, variance = self._moments(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.cast(inputs, self._param_dtype),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreduction_axes,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeep_dims=keep_dims)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_mean = self.moving_mean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_variance = self.moving_variance</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean = control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining, lambda: mean,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: ops.convert_to_tensor_v2_with_dispatch(moving_mean))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance = control_flow_util.smart_cond(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptraining, lambda: variance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: ops.convert_to_tensor_v2_with_dispatch(moving_variance))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This isn't strictly correct since in ghost batch norm, you are</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# supposed to sequentially update the moving_mean and moving_variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# with each sub-batch. However, since the moving statistics are only</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# used during evaluation, it is more efficient to just update in one</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# step and should not make a significant difference in the result.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_mean = math_ops.reduce_mean(mean, axis=1, keepdims=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_variance = math_ops.reduce_mean(variance, axis=1, keepdims=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_mean, new_variance = mean, variance</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self._support_zero_size_input():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Keras assumes that batch dimension is the first dimension for Batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Normalization.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size = array_ops.shape(inputs)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr, d, new_mean, new_variance = self._renorm_correction_and_moments(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_mean, new_variance, training, input_batch_size)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# When training, the normalized values (say, x) will be transformed as</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# x * gamma + beta without renorm, and (x * r + d) * gamma + beta</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# = x * (r * gamma) + (d * gamma + beta) with renorm.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = _broadcast(array_ops.stop_gradient(r, name='renorm_r'))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspd = _broadcast(array_ops.stop_gradient(d, name='renorm_d'))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale, offset = _compose_transforms(r, d, scale, offset)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _do_update(var, value):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Compute the updates for mean and variance."""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_moving_average(var, value, self.momentum,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_batch_size)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef mean_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrue_branch = lambda: _do_update(self.moving_mean, new_mean)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfalse_branch = lambda: self.moving_mean</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn control_flow_util.smart_cond(training, true_branch, false_branch)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef variance_update():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"""Update the moving variance."""</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef true_branch_renorm():</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We apply epsilon as part of the moving_stddev to mirror the training</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# code path.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmoving_stddev = _do_update(self.moving_stddev,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.sqrt(new_variance + self.epsilon))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self._assign_new_value(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.moving_variance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Apply relu in case floating point rounding causes it to go</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# negative.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.relu(moving_stddev * moving_stddev - self.epsilon))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrue_branch = true_branch_renorm</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrue_branch = lambda: _do_update(self.moving_variance, new_variance)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfalse_branch = lambda: self.moving_variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn control_flow_util.smart_cond(training, true_branch, false_branch)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(mean_update)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(variance_update)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspmean = math_ops.cast(mean, inputs.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspvariance = math_ops.cast(variance, inputs.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif offset is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset = math_ops.cast(offset, inputs.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif scale is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = math_ops.cast(scale, inputs.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs = nn.batch_normalization(inputs, _broadcast(mean),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_broadcast(variance), offset, scale,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.epsilon)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif inputs_dtype in (dtypes.float16, dtypes.bfloat16):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = math_ops.cast(outputs, inputs_dtype)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If some components of the shape got lost due to adjustments, fix that.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs.set_shape(input_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = undo_virtual_batching(outputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef compute_output_shape(self, input_shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn input_shape</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef get_config(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconfig = {</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'axis':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'momentum':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.momentum,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'epsilon':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.epsilon,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'center':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.center,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scale':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.scale,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.beta_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.gamma_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'moving_mean_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.moving_mean_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'moving_variance_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.moving_variance_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_regularizer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizers.serialize(self.beta_regularizer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_regularizer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizers.serialize(self.gamma_regularizer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_constraint':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraints.serialize(self.beta_constraint),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_constraint':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraints.serialize(self.gamma_constraint)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Only add TensorFlow-specific parameters if they are set, so as to preserve</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# model compatibility with external Keras.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.renorm:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig['renorm'] = True</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig['renorm_clipping'] = self.renorm_clipping</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig['renorm_momentum'] = self.renorm_momentum</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.virtual_batch_size is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconfig['virtual_batch_size'] = self.virtual_batch_size</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Note: adjustment is not serializable.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.adjustment is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplogging.warning('The `adjustment` function of this `BatchNormalization` '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'layer cannot be serialized and has been omitted from '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the layer config. It will not be included when '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp're-creating the layer from the saved config.')</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_config = super(BatchNormalizationBase, self).get_config()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn dict(list(base_config.items()) + list(config.items()))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br><span style="color:red">- # pylint: disable=missing-docstring</span>
<br><span style="color:red">- @keras_export(v1=['keras.layers.BatchNormalization'])</span>
<br><span style="color:red">- class BatchNormalization(BatchNormalizationBase):</span>
<br><span style="color:red">- &nbsp &nbsp_USE_V2_BEHAVIOR = False</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- </span>
<br><span style="color:red">- @keras_export('keras.layers.LayerNormalization')</span>
<br><span style="color:red">- class LayerNormalization(Layer):</span>
<br><span style="color:red">- &nbsp &nbsp"""Layer normalization layer (Ba et al., 2016).</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspNormalize the activations of the previous layer for each given example in a</span>
<br><span style="color:red">- &nbsp &nbspbatch independently, rather than across a batch like Batch Normalization.</span>
<br><span style="color:red">- &nbsp &nbspi.e. applies a transformation that maintains the mean activation within each</span>
<br><span style="color:red">- &nbsp &nbspexample close to 0 and the activation standard deviation close to 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspGiven a tensor `inputs`, moments are calculated and normalization</span>
<br><span style="color:red">- &nbsp &nbspis performed across the axes specified in `axis`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspExample:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp>>> data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)</span>
<br><span style="color:red">- &nbsp &nbsp>>> print(data)</span>
<br><span style="color:red">- &nbsp &nbsptf.Tensor(</span>
<br><span style="color:red">- &nbsp &nbsp[[ 0. 10.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[20. 30.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[40. 50.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[60. 70.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[80. 90.]], shape=(5, 2), dtype=float32)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp>>> layer = tf.keras.layers.LayerNormalization(axis=1)</span>
<br><span style="color:red">- &nbsp &nbsp>>> output = layer(data)</span>
<br><span style="color:red">- &nbsp &nbsp>>> print(output)</span>
<br><span style="color:red">- &nbsp &nbsptf.Tensor(</span>
<br><span style="color:red">- &nbsp &nbsp[[-1. 1.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[-1. 1.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[-1. 1.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[-1. 1.]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp[-1. 1.]], shape=(5, 2), dtype=float32)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspNotice that with Layer Normalization the normalization happens across the</span>
<br><span style="color:red">- &nbsp &nbspaxes *within* each example, rather than across different examples in the</span>
<br><span style="color:red">- &nbsp &nbspbatch.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspIf `scale` or `center` are enabled, the layer will scale the normalized</span>
<br><span style="color:red">- &nbsp &nbspoutputs by broadcasting them with a trainable variable `gamma`, and center</span>
<br><span style="color:red">- &nbsp &nbspthe outputs by broadcasting with a trainable variable `beta`. `gamma` will</span>
<br><span style="color:red">- &nbsp &nbspdefault to a ones tensor and `beta` will default to a zeros tensor, so that</span>
<br><span style="color:red">- &nbsp &nbspcentering and scaling are no-ops before training has begun.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspSo, with scaling and centering enabled the normalization equations</span>
<br><span style="color:red">- &nbsp &nbspare as follows:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspLet the intermediate activations for a mini-batch to be the `inputs`.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspFor each sample `x_i` in `inputs` with `k` features, we compute the mean and</span>
<br><span style="color:red">- &nbsp &nbspvariance of the sample:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp```python</span>
<br><span style="color:red">- &nbsp &nbspmean_i = sum(x_i[j] for j in range(k)) / k</span>
<br><span style="color:red">- &nbsp &nbspvar_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k</span>
<br><span style="color:red">- &nbsp &nbsp```</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspand then compute a normalized `x_i_normalized`, including a small factor</span>
<br><span style="color:red">- &nbsp &nbsp`epsilon` for numerical stability.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp```python</span>
<br><span style="color:red">- &nbsp &nbspx_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)</span>
<br><span style="color:red">- &nbsp &nbsp```</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspAnd finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,</span>
<br><span style="color:red">- &nbsp &nbspwhich are learned parameters:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp```python</span>
<br><span style="color:red">- &nbsp &nbspoutput_i = x_i_normalized * gamma + beta</span>
<br><span style="color:red">- &nbsp &nbsp```</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp`gamma` and `beta` will span the axes of `inputs` specified in `axis`, and</span>
<br><span style="color:red">- &nbsp &nbspthis part of the inputs' shape must be fully defined.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspFor example:</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp>>> layer = tf.keras.layers.LayerNormalization(axis=[1, 2, 3])</span>
<br><span style="color:red">- &nbsp &nbsp>>> layer.build([5, 20, 30, 40])</span>
<br><span style="color:red">- &nbsp &nbsp>>> print(layer.beta.shape)</span>
<br><span style="color:red">- &nbsp &nbsp(20, 30, 40)</span>
<br><span style="color:red">- &nbsp &nbsp>>> print(layer.gamma.shape)</span>
<br><span style="color:red">- &nbsp &nbsp(20, 30, 40)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspNote that other implementations of layer normalization may choose to define</span>
<br><span style="color:red">- &nbsp &nbsp`gamma` and `beta` over a separate set of axes from the axes being</span>
<br><span style="color:red">- &nbsp &nbspnormalized across. For example, Group Normalization</span>
<br><span style="color:red">- &nbsp &nbsp([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1</span>
<br><span style="color:red">- &nbsp &nbspcorresponds to a Layer Normalization that normalizes across height, width,</span>
<br><span style="color:red">- &nbsp &nbspand channel and has `gamma` and `beta` span only the channel dimension.</span>
<br><span style="color:red">- &nbsp &nbspSo, this Layer Normalization implementation will not match a Group</span>
<br><span style="color:red">- &nbsp &nbspNormalization layer with group size set to 1.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspArgs:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis: Integer or List/Tuple. The axis or axes to normalize across. Typically</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthis is the features axis/axes. The left-out axes are typically the batch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis/axes. This argument defaults to `-1`, the last dimension in the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspepsilon: Small float added to variance to avoid dividing by zero. Defaults</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto 1e-3</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcenter: If True, add offset of `beta` to normalized tensor. If False, `beta`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis ignored. Defaults to True.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspscale: If True, multiply by `gamma`. If False, `gamma` is not used. Defaults</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto True. When the next layer is linear (also e.g. `nn.relu`), this can be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdisabled since the scaling will be done by the next layer.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_initializer: Initializer for the beta weight. Defaults to zeros.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_initializer: Initializer for the gamma weight. Defaults to ones.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_regularizer: Optional regularizer for the beta weight. None by default.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_regularizer: Optional regularizer for the gamma weight. None by</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbeta_constraint: Optional constraint for the beta weight. None by default.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspgamma_constraint: Optional constraint for the gamma weight. None by default.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspInput shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspArbitrary. Use the keyword argument `input_shape` (tuple of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspintegers, does not include the samples axis) when using this layer as the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfirst layer in a model.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspOutput shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspSame shape as input.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspReference:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp- [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).</span>
<br><span style="color:red">- &nbsp &nbsp"""</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef __init__(self,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis=-1,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepsilon=1e-3,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcenter=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_initializer='zeros',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_initializer='ones',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_regularizer=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_regularizer=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbeta_constraint=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgamma_constraint=None,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspsuper(LayerNormalization, self).__init__(**kwargs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(axis, (list, tuple)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = axis[:]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif isinstance(axis, int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError('Expected an int or a list/tuple of ints for the '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'argument \'axis\', but received: %r' % axis)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.epsilon = epsilon</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.center = center</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.scale = scale</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_initializer = initializers.get(beta_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_initializer = initializers.get(gamma_initializer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_regularizer = regularizers.get(beta_regularizer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_regularizer = regularizers.get(gamma_regularizer)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.beta_constraint = constraints.get(beta_constraint)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.gamma_constraint = constraints.get(gamma_constraint)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.supports_masking = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Indicates whether a faster fused implementation can be used. This will be</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# set to True or False in build()"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._fused = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef _fused_can_be_used(self, ndims):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""Return false if fused implementation cannot be used.</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspCheck if the axis is contiguous and can be collapsed into the last axis.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspThe self.axis is assumed to have no duplicates.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp"""</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspaxis = sorted(self.axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspcan_use_fused = False</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif axis[-1] == ndims - 1 and axis[-1] - axis[0] == len(axis) - 1:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_use_fused = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# fused_batch_norm will silently raise epsilon to be at least 1.001e-5, so</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# we cannot used the fused version if epsilon is below that value. Also, the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# variable dtype must be float32, as fused_batch_norm only supports float32</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# variables.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.epsilon < 1.001e-5 or self.dtype != 'float32':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcan_use_fused = False</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn can_use_fused</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef build(self, input_shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspndims = len(input_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif ndims is None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Input shape %s has undefined rank.' % input_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Convert axis to list and resolve negatives</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(self.axis, int):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = [self.axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif isinstance(self.axis, tuple):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis = list(self.axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor idx, x in enumerate(self.axis):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x < 0:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.axis[idx] = ndims + x</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Validate axes</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor x in self.axis:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif x < 0 or x >= ndims:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Invalid axis: %d' % x)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif len(self.axis) != len(set(self.axis)):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Duplicate axis: {}'.format(tuple(self.axis)))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspparam_shape = [input_shape[dim] for dim in self.axis]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.scale:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.gamma = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='gamma',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.gamma_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.gamma_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.gamma_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.gamma = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif self.center:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.beta = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='beta',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=param_shape,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.beta_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.beta_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.beta_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptrainable=True,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.beta = None</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._fused = self._fused_can_be_used(ndims)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.built = True</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef call(self, inputs):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Compute the axes along which to reduce the mean / variance</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinput_shape = inputs.shape</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspndims = len(input_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Broadcasting only necessary for norm when the axis is not just</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# the last dimension</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbroadcast_shape = [1] * ndims</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspfor dim in self.axis:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbroadcast_shape[dim] = input_shape.dims[dim].value</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdef _broadcast(v):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif (v is not None and len(v.shape) != ndims and self.axis != [ndims - 1]):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn array_ops.reshape(v, broadcast_shape)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn v</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif not self._fused:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_dtype = inputs.dtype</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif input_dtype in ('float16', 'bfloat16') and self.dtype == 'float32':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# If mixed precision is used, cast inputs to float32 so that this is at</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# least as numerically stable as the fused version.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = math_ops.cast(inputs, 'float32')</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Calculate the moments on the last axis (layer activations).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean, variance = nn.moments(inputs, self.axis, keep_dims=True)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale, offset = _broadcast(self.gamma), _broadcast(self.beta)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute layer normalization using the batch_normalization function.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = nn.batch_normalization(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmean,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset=offset,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale=scale,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvariance_epsilon=self.epsilon)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = math_ops.cast(outputs, input_dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Collapse dims before self.axis, and dims in self.axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppre_dim, in_dim = (1, 1)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis = sorted(self.axis)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor_shape = array_ops.shape(inputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor dim in range(0, ndims):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdim_tensor = tensor_shape[dim]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif dim < axis[0]:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppre_dim = pre_dim * dim_tensor</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspassert dim in axis</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin_dim = in_dim * dim_tensor</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsqueezed_shape = [1, pre_dim, in_dim, 1]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# This fused operation requires reshaped inputs to be NCHW.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format = 'NCHW'</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = array_ops.reshape(inputs, squeezed_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _set_const_tensor(val, dtype, shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn array_ops.fill(shape, constant_op.constant(val, dtype=dtype))</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# self.gamma and self.beta have the wrong shape for fused_batch_norm, so</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# we cannot pass them as the scale and offset parameters. Therefore, we</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# create two constant tensors in correct shapes for fused_batch_norm and</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# later construct a separate calculation on the scale and offset.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale = _set_const_tensor(1.0, self.dtype, [pre_dim])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset = _set_const_tensor(0.0, self.dtype, [pre_dim])</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Compute layer normalization using the fused_batch_norm function.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs, _, _ = nn.fused_batch_norm(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale=scale,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoffset=offset,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspepsilon=self.epsilon,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=data_format)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = array_ops.reshape(outputs, tensor_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale, offset = _broadcast(self.gamma), _broadcast(self.beta)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif scale is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = outputs * math_ops.cast(scale, outputs.dtype)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif offset is not None:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = outputs + math_ops.cast(offset, outputs.dtype)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# If some components of the shape got lost due to adjustments, fix that.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutputs.set_shape(input_shape)</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef compute_output_shape(self, input_shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn input_shape</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- &nbsp &nbspdef get_config(self):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconfig = {</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'axis': self.axis,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'epsilon': self.epsilon,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'center': self.center,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'scale': self.scale,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_initializer': initializers.serialize(self.beta_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_initializer': initializers.serialize(self.gamma_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_regularizer': regularizers.serialize(self.beta_regularizer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'beta_constraint': constraints.serialize(self.beta_constraint),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'gamma_constraint': constraints.serialize(self.gamma_constraint)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp}</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbase_config = super(LayerNormalization, self).get_config()</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn dict(list(base_config.items()) + list(config.items()))</span>
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\core.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14489</th>
      <td>keras\engine\topology_test.py</td>
      <td>188</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>186</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14491</th>
      <td>keras\engine\topology_test.py</td>
      <td>189</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>186</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14494</th>
      <td>keras\engine\topology_test.py</td>
      <td>190</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>186</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14495</th>
      <td>keras\engine\topology_test.py</td>
      <td>191</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>186</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14496</th>
      <td>keras\engine\topology_test.py</td>
      <td>198</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14498</th>
      <td>keras\engine\topology_test.py</td>
      <td>199</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14500</th>
      <td>keras\engine\topology_test.py</td>
      <td>200</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14503</th>
      <td>keras\engine\topology_test.py</td>
      <td>201</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14506</th>
      <td>keras\engine\topology_test.py</td>
      <td>202</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14507</th>
      <td>keras\engine\topology_test.py</td>
      <td>203</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14508</th>
      <td>keras\engine\topology_test.py</td>
      <td>204</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14509</th>
      <td>keras\engine\topology_test.py</td>
      <td>205</td>
      <td>testTopologicalAttributes</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>194</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14516</th>
      <td>keras\engine\topology_test.py</td>
      <td>281</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14520</th>
      <td>keras\engine\topology_test.py</td>
      <td>282</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14524</th>
      <td>keras\engine\topology_test.py</td>
      <td>283</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14528</th>
      <td>keras\engine\topology_test.py</td>
      <td>284</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14537</th>
      <td>keras\engine\topology_test.py</td>
      <td>298</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14544</th>
      <td>keras\engine\topology_test.py</td>
      <td>300</td>
      <td>testBasicNetwork</td>
      <td>271</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>274</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14579</th>
      <td>keras\engine\topology_test.py</td>
      <td>429</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14580</th>
      <td>keras\engine\topology_test.py</td>
      <td>430</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14581</th>
      <td>keras\engine\topology_test.py</td>
      <td>432</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14582</th>
      <td>keras\engine\topology_test.py</td>
      <td>434</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14583</th>
      <td>keras\engine\topology_test.py</td>
      <td>442</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>439</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14585</th>
      <td>keras\engine\topology_test.py</td>
      <td>443</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>439</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14588</th>
      <td>keras\engine\topology_test.py</td>
      <td>444</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>439</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14589</th>
      <td>keras\engine\topology_test.py</td>
      <td>445</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>439</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14590</th>
      <td>keras\engine\topology_test.py</td>
      <td>447</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14592</th>
      <td>keras\engine\topology_test.py</td>
      <td>448</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14594</th>
      <td>keras\engine\topology_test.py</td>
      <td>449</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14597</th>
      <td>keras\engine\topology_test.py</td>
      <td>450</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14600</th>
      <td>keras\engine\topology_test.py</td>
      <td>451</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14601</th>
      <td>keras\engine\topology_test.py</td>
      <td>452</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14602</th>
      <td>keras\engine\topology_test.py</td>
      <td>453</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14603</th>
      <td>keras\engine\topology_test.py</td>
      <td>454</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14604</th>
      <td>keras\engine\topology_test.py</td>
      <td>455</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14605</th>
      <td>keras\engine\topology_test.py</td>
      <td>456</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14606</th>
      <td>keras\engine\topology_test.py</td>
      <td>457</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14607</th>
      <td>keras\engine\topology_test.py</td>
      <td>458</td>
      <td>test_node_construction</td>
      <td>401</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>425</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14970</th>
      <td>keras\layers\core_test.py</td>
      <td>52</td>
      <td>test_dropout</td>
      <td>37</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>51</td>
      <td>keras.layers.Dropout</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14977</th>
      <td>keras\layers\core_test.py</td>
      <td>221</td>
      <td>test_dense_regularization</td>
      <td>212</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>214</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14978</th>
      <td>keras\layers\core_test.py</td>
      <td>230</td>
      <td>test_dense_constraints</td>
      <td>223</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>227</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14980</th>
      <td>keras\layers\core_test.py</td>
      <td>231</td>
      <td>test_dense_constraints</td>
      <td>223</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>227</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14982</th>
      <td>keras\layers\core_test.py</td>
      <td>237</td>
      <td>test_activity_regularization</td>
      <td>233</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>235</td>
      <td>keras.layers.ActivityRegularization</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14984</th>
      <td>keras\layers\core_test.py</td>
      <td>263</td>
      <td>test_lambda_output_shape_autocalculate_multiple_inputs</td>
      <td>256</td>
      <td>assertAllEqual</td>
      <td>2</td>
      <td>261</td>
      <td>keras.layers.Lambda</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14986</th>
      <td>keras\layers\core_test.py</td>
      <td>273</td>
      <td>test_lambda_output_shape_list_multiple_outputs</td>
      <td>266</td>
      <td>assertAllEqual</td>
      <td>2</td>
      <td>271</td>
      <td>keras.layers.Lambda</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>14988</th>
      <td>keras\layers\core_test.py</td>
      <td>298</td>
      <td>test_lambda_output_shape_function_multiple_outputs</td>
      <td>288</td>
      <td>assertAllEqual</td>
      <td>2</td>
      <td>296</td>
      <td>keras.layers.Lambda</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>15438</th>
      <td>keras\layers\serialization_test.py</td>
      <td>32</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>28</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>15441</th>
      <td>keras\layers\serialization_test.py</td>
      <td>33</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>28</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>15444</th>
      <td>keras\layers\serialization_test.py</td>
      <td>35</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>28</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
    <tr>
      <th>15447</th>
      <td>keras\layers\serialization_test.py</td>
      <td>37</td>
      <td>test_serialize_deserialize</td>
      <td>27</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>28</td>
      <td>keras.layers.Dense</td>
      <td>tensorflow\python\keras\layers\core.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: da6568a4d354c8863ecbb8991817e546c5f361e5

 <br>Commit message: Remove the API usage monitoring call in the legacy keras code.<br><br>PiperOrigin-RevId: 383499649<br>Change-Id: Idf581a8cc9e043714819a25a0d0104d177fee782<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/core.py b/tensorflow/python/keras/layers/core.py
<br>index d42a021ec4f..abc8b69b540 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/core.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/core.py</span>
<br>@@ -12,11 +12,7 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Core Keras layers.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Core Keras layers."""</span>
<br>&nbsp
<br>&nbspimport copy
<br>&nbspimport functools
<br>@@ -30,10 +26,10 @@ import numpy as np
<br>&nbsp
<br>&nbspfrom tensorflow.python.eager import backprop
<br>&nbspfrom tensorflow.python.eager import context
<br><span style="color:red">- from tensorflow.python.eager import monitoring</span>
<br>&nbspfrom tensorflow.python.framework import constant_op
<br>&nbspfrom tensorflow.python.framework import dtypes
<br>&nbspfrom tensorflow.python.framework import ops
<br><span style="color:green">+from tensorflow.python.framework import sparse_tensor</span>
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br>&nbspfrom tensorflow.python.keras import activations
<br>&nbspfrom tensorflow.python.keras import backend as K
<br>@@ -43,16 +39,21 @@ from tensorflow.python.keras import regularizers
<br>&nbspfrom tensorflow.python.keras.engine import keras_tensor
<br>&nbspfrom tensorflow.python.keras.engine.base_layer import Layer
<br>&nbspfrom tensorflow.python.keras.engine.input_spec import InputSpec
<br><span style="color:red">- from tensorflow.python.keras.layers.ops import core as core_ops</span>
<br>&nbspfrom tensorflow.python.keras.utils import control_flow_util
<br>&nbspfrom tensorflow.python.keras.utils import conv_utils
<br>&nbspfrom tensorflow.python.keras.utils import generic_utils
<br>&nbspfrom tensorflow.python.keras.utils import tf_inspect
<br>&nbspfrom tensorflow.python.keras.utils import tf_utils
<br>&nbspfrom tensorflow.python.ops import array_ops
<br><span style="color:green">+from tensorflow.python.ops import embedding_ops</span>
<br><span style="color:green">+from tensorflow.python.ops import gen_math_ops</span>
<br>&nbspfrom tensorflow.python.ops import math_ops
<br>&nbspfrom tensorflow.python.ops import nn
<br><span style="color:green">+from tensorflow.python.ops import nn_ops</span>
<br><span style="color:green">+from tensorflow.python.ops import sparse_ops</span>
<br><span style="color:green">+from tensorflow.python.ops import standard_ops</span>
<br>&nbspfrom tensorflow.python.ops import variable_scope
<br><span style="color:green">+from tensorflow.python.ops.ragged import ragged_getitem</span>
<br>&nbspfrom tensorflow.python.ops.ragged import ragged_tensor
<br>&nbspfrom tensorflow.python.platform import tf_logging
<br>&nbspfrom tensorflow.python.training.tracking import base as trackable
<br>@@ -63,13 +64,6 @@ from tensorflow.python.util.tf_export import get_canonical_name_for_symbol
<br>&nbspfrom tensorflow.python.util.tf_export import get_symbol_from_name
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbsp
<br><span style="color:red">- # TODO(b/168039935): track dropout rate to decide whether/how to make a</span>
<br><span style="color:red">- # dropout rate fastpath.</span>
<br><span style="color:red">- keras_temporary_dropout_rate = monitoring.BoolGauge(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp'/tensorflow/api/keras/dropout/temp_rate_is_zero',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp'Temporarily record if Keras dropout layer was created w/'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp'constant rate = 0')</span>
<br><span style="color:red">- </span>
<br>&nbsp
<br>&nbsp# pylint: disable=g-classes-have-attributes
<br>&nbsp@keras_export('keras.layers.Masking')
<br>@@ -193,11 +187,10 @@ class Dropout(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self, rate, noise_shape=None, seed=None, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(Dropout, self).__init__(**kwargs)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(rate, (int, float)) and not 0 <= rate <= 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Invalid value {rate} received for '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'`rate`, expected a value between 0 and 1.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.rate = rate
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(rate, (int, float)) and not rate:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras_temporary_dropout_rate.get_cell().set(True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkeras_temporary_dropout_rate.get_cell().set(False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.noise_shape = noise_shape
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.seed = seed
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.supports_masking = True
<br>@@ -737,6 +730,8 @@ class RepeatVector(Layer):
<br>&nbsp &nbsp &nbspdef __init__(self, n, **kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(RepeatVector, self).__init__(**kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.n = n
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not isinstance(n, int):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise TypeError(f'Expected an integer value for `n`, got {type(n)}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = InputSpec(ndim=2)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef compute_output_shape(self, input_shape):
<br>@@ -756,13 +751,15 @@ class RepeatVector(Layer):
<br>&nbspclass Lambda(Layer):
<br>&nbsp &nbsp &nbsp"""Wraps arbitrary expressions as a `Layer` object.
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspThe `Lambda` layer exists so that arbitrary TensorFlow functions</span>
<br><span style="color:red">- &nbsp &nbspcan be used when constructing `Sequential` and Functional API</span>
<br><span style="color:red">- &nbsp &nbspmodels. `Lambda` layers are best suited for simple operations or</span>
<br><span style="color:red">- &nbsp &nbspquick experimentation. For more advanced use cases, follow</span>
<br><span style="color:green">+&nbsp &nbspThe `Lambda` layer exists so that arbitrary expressions can be used</span>
<br><span style="color:green">+&nbsp &nbspas a `Layer` when constructing `Sequential`</span>
<br><span style="color:green">+&nbsp &nbspand Functional API models. `Lambda` layers are best suited for simple</span>
<br><span style="color:green">+&nbsp &nbspoperations or quick experimentation. For more advanced use cases, follow</span>
<br>&nbsp &nbsp &nbsp[this guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models)
<br>&nbsp &nbsp &nbspfor subclassing `tf.keras.layers.Layer`.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspWARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspThe main reason to subclass `tf.keras.layers.Layer` instead of using a
<br>&nbsp &nbsp &nbsp`Lambda` layer is saving and inspecting a Model. `Lambda` layers
<br>&nbsp &nbsp &nbspare saved by serializing the Python bytecode, which is fundamentally
<br>@@ -962,7 +959,7 @@ class Lambda(Layer):
<br>&nbsp &nbsp &nbspdef _warn(self, msg):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# This method will be overridden in a unit test to raise an error, because
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# self.assertWarns is not universally implemented.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn tf_logging.warn(msg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tf_logging.warning(msg)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef compute_mask(self, inputs, mask=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif callable(self.mask):
<br>@@ -1085,11 +1082,12 @@ class Dense(Layer):
<br>&nbsp &nbsp &nbspwhere `activation` is the element-wise activation function
<br>&nbsp &nbsp &nbsppassed as the `activation` argument, `kernel` is a weights matrix
<br>&nbsp &nbsp &nbspcreated by the layer, and `bias` is a bias vector created by the layer
<br><span style="color:red">- &nbsp &nbsp(only applicable if `use_bias` is `True`).</span>
<br><span style="color:green">+&nbsp &nbsp(only applicable if `use_bias` is `True`). These are all attributes of</span>
<br><span style="color:green">+&nbsp &nbsp`Dense`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspNote: If the input to the layer has a rank greater than 2, then `Dense`
<br>&nbsp &nbsp &nbspcomputes the dot product between the `inputs` and the `kernel` along the
<br><span style="color:red">- &nbsp &nbsplast axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).</span>
<br><span style="color:green">+&nbsp &nbsplast axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).</span>
<br>&nbsp &nbsp &nbspFor example, if input has dimensions `(batch_size, d0, d1)`,
<br>&nbsp &nbsp &nbspthen we create a `kernel` with shape `(d1, units)`, and the `kernel` operates
<br>&nbsp &nbsp &nbspalong axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`
<br>@@ -1098,6 +1096,9 @@ class Dense(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspBesides, layer attributes cannot be modified after the layer has been called
<br>&nbsp &nbsp &nbsponce (except the `trainable` attribute).
<br><span style="color:green">+&nbsp &nbspWhen a popular kwarg `input_shape` is passed, then keras will create</span>
<br><span style="color:green">+&nbsp &nbspan input layer to insert before the current layer. This can be treated</span>
<br><span style="color:green">+&nbsp &nbspequivalent to explicitly defining an `InputLayer`.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspExample:
<br>&nbsp
<br>@@ -1157,6 +1158,9 @@ class Dense(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspactivity_regularizer=activity_regularizer, **kwargs)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.units = int(units) if not isinstance(units, int) else units
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.units < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Received an invalid value for `units`, expected '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'a positive integer, got {units}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.activation = activations.get(activation)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.use_bias = use_bias
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.kernel_initializer = initializers.get(kernel_initializer)
<br>@@ -1203,12 +1207,51 @@ class Dense(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn core_ops.dense(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.kernel,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.activation,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self._compute_dtype_object)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif inputs.dtype.base_dtype != self._compute_dtype_object.base_dtype:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = math_ops.cast(inputs, dtype=self._compute_dtype_object)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsprank = inputs.shape.rank</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif rank == 2 or rank is None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We use embedding_lookup_sparse as a more efficient matmul operation for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# large sparse input tensors. The op will result in a sparse gradient, as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# opposed to sparse_ops.sparse_tensor_dense_matmul which results in dense</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# gradients. This can lead to sigfinicant speedups, see b/171762937.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(inputs, sparse_tensor.SparseTensor):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We need to fill empty rows, as the op assumes at least one id per row.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, _ = sparse_ops.sparse_fill_empty_rows(inputs, 0)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# We need to do some munging of our input to use the embedding lookup as</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# a matrix multiply. We split our input matrix into separate ids and</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# weights tensors. The values of the ids tensor should be the column</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# indices of our input matrix and the values of the weights tensor</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# can continue to the actual matrix weights.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# The column arrangement of ids and weights</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# will be summed over and does not matter. See the documentation for</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# sparse_ops.sparse_tensor_dense_matmul a more detailed explanation</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# of the inputs to both ops.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspids = sparse_tensor.SparseTensor(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindices=inputs.indices,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalues=inputs.indices[:, 1],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdense_shape=inputs.dense_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspweights = inputs</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = embedding_ops.embedding_lookup_sparse_v2(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.kernel, ids, weights, combiner='sum')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = gen_math_ops.MatMul(a=inputs, b=self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Broadcast kernel to inputs.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = standard_ops.tensordot(inputs, self.kernel, [[rank - 1], [0]])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Reshape the output back to the original ndim of the input.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not context.executing_eagerly():</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape = inputs.shape.as_list()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_shape = shape[:-1] + [self.kernel.shape[-1]]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs.set_shape(output_shape)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.use_bias:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = nn_ops.bias_add(outputs, self.bias)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif self.activation is not None:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = self.activation(outputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn outputs</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef compute_output_shape(self, input_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_shape = tensor_shape.TensorShape(input_shape)
<br>@@ -1216,32 +1259,23 @@ class Dense(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif tensor_shape.dimension_value(input_shape[-1]) is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'The innermost dimension of input_shape must be defined, but saw: %s'
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp% input_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp% (input_shape,))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn input_shape[:-1].concatenate(self.units)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig = super(Dense, self).get_config()
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig.update({
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'units':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.units,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'activation':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspactivations.serialize(self.activation),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'use_bias':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.use_bias,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.kernel_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_initializer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.serialize(self.bias_initializer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_regularizer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizers.serialize(self.kernel_regularizer),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_regularizer':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizers.serialize(self.bias_regularizer),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'units': self.units,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'activation': activations.serialize(self.activation),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'use_bias': self.use_bias,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_initializer': initializers.serialize(self.kernel_initializer),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_initializer': initializers.serialize(self.bias_initializer),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_regularizer': regularizers.serialize(self.bias_regularizer),</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'activity_regularizer':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizers.serialize(self.activity_regularizer),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_constraint':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraints.serialize(self.kernel_constraint),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_constraint':</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraints.serialize(self.bias_constraint)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'kernel_constraint': constraints.serialize(self.kernel_constraint),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'bias_constraint': constraints.serialize(self.bias_constraint)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp})
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn config
<br>&nbsp
<br>@@ -1404,7 +1438,7 @@ class TFOpLambda(Layer):
<br>&nbsp &nbsp &nbspdef _warn(self, msg):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# This method will be overridden in a unit test to raise an error, because
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# self.assertWarns is not universally implemented.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn tf_logging.warn(msg)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn tf_logging.warning(msg)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.symbol:
<br>@@ -1538,9 +1572,12 @@ class TFSlicingOpDispatcher(dispatch.OpDispatcher):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.NOT_SUPPORTED
<br>&nbsp
<br><span style="color:red">- for slicing_op in [array_ops._slice_helper,  # pylint: disable=protected-access</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.boolean_mask,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsparray_ops.boolean_mask_v2]:</span>
<br><span style="color:green">+for slicing_op in [</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray_ops._slice_helper,  # pylint: disable=protected-access</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray_ops.boolean_mask,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsparray_ops.boolean_mask_v2,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspragged_getitem.ragged_tensor_getitem</span>
<br><span style="color:green">+]:</span>
<br>&nbsp &nbsp &nbspTFSlicingOpDispatcher(slicing_op).register(slicing_op)
<br>&nbsp
<br>&nbsp
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\engine\network.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14574</th>
      <td>keras\engine\topology_test.py</td>
      <td>399</td>
      <td>test_layer_call_arguments</td>
      <td>383</td>
      <td>assertFalse</td>
      <td>1</td>
      <td>398</td>
      <td>keras.models.Model.from_config</td>
      <td>tensorflow\python\keras\engine\network.py</td>
    </tr>
    <tr>
      <th>14628</th>
      <td>keras\engine\topology_test.py</td>
      <td>837</td>
      <td>test_layer_sharing_at_heterogenous_depth</td>
      <td>818</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>833</td>
      <td>keras.models.Model.from_config</td>
      <td>tensorflow\python\keras\engine\network.py</td>
    </tr>
    <tr>
      <th>14638</th>
      <td>keras\engine\topology_test.py</td>
      <td>864</td>
      <td>test_layer_sharing_at_heterogenous_depth_with_concat</td>
      <td>839</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>860</td>
      <td>keras.models.Model.from_config</td>
      <td>tensorflow\python\keras\engine\network.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: bb15c97379f197a6a46ec1446d8fb0b292b860ba

 <br>Commit message: Restructure the Keras class hierarchy for Network, Model and Sequential.<br><br>The intention of this change is to reduce the code complexity within Keras class, especially for Network, which currently contains logic for both subclass Model and functional Model.<br><br>After this change, the subclass model and functional model become individual class and become self contained.<br><br>1. Model is now the base class for subclass model. It doesn't contains network structure management, and the topology will be created within __init__ and __call__, which is for user to implement. It also contains compile/fit/eval/predict, which is the basic functionality for model training.<br><br>2. Functional is created based on existing Network class. It extends the Model, which allows it leverage compile/fit/eval/predict. In addition, it also take input/output as init parameter and manage the network topology.<br><br>3. Sequential model is now a subclass of Functional, since it will use Functional's method to manage it topology (layer stacking).<br><br>Model(input, output) will create a Functional under the hood, and behave the same way as before.<br><br>PiperOrigin-RevId: 311232972<br>Change-Id: I6dd32e089cd294d35d5a1f3684e1a1ae1a0ab320<br><br>
<br>Commit id closest to desired version: ERROR

 <br>Commit message: No commit within 100 days of the entered date.
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\convolutional_recurrent.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14865</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>165</td>
      <td>test_conv_lstm_regularizers</td>
      <td>133</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>163</td>
      <td>keras.layers.ConvLSTM2D</td>
      <td>tensorflow\python\keras\layers\convolutional_recurrent.py</td>
    </tr>
    <tr>
      <th>14866</th>
      <td>keras\layers\convolutional_recurrent_test.py</td>
      <td>167</td>
      <td>test_conv_lstm_regularizers</td>
      <td>133</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>163</td>
      <td>keras.layers.ConvLSTM2D</td>
      <td>tensorflow\python\keras\layers\convolutional_recurrent.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 993403945efc9e7a933e9c8bd3ad029c36c6882b

 <br>Commit message: Remove a large amount of PY2 compatibility code.<br><br>PiperOrigin-RevId: 364677165<br>Change-Id: Ic52863fbda9b3f093948b9febbcb00a138d80ade<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/convolutional_recurrent.py b/tensorflow/python/keras/layers/convolutional_recurrent.py
<br>index 1da37a4cf13..0e56fc4fc1a 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/convolutional_recurrent.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/convolutional_recurrent.py</span>
<br>@@ -13,16 +13,13 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Convolutional-recurrent layers.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+"""Convolutional-recurrent layers."""</span>
<br>&nbsp
<br>&nbspimport numpy as np
<br>&nbsp
<br>&nbspfrom tensorflow.python.keras import activations
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras import constraints
<br>&nbspfrom tensorflow.python.keras import initializers
<br>&nbspfrom tensorflow.python.keras import regularizers
<br>@@ -276,9 +273,9 @@ class ConvRNN2D(RNN):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_initial_state(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# (samples, timesteps, rows, cols, filters)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinitial_state = K.zeros_like(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinitial_state = backend.zeros_like(inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# (samples, rows, cols, filters)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinitial_state = K.sum(initial_state, axis=1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinitial_state = backend.sum(initial_state, axis=1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspshape = list(self.cell.kernel_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspshape[-1] = self.cell.filters
<br>&nbsp &nbsp &nbsp &nbsp &nbspinitial_state = self.cell.input_conv(initial_state,
<br>@@ -304,7 +301,7 @@ class ConvRNN2D(RNN):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(mask, list):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask = mask[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsptimesteps = K.int_shape(inputs)[1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsptimesteps = backend.int_shape(inputs)[1]</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspkwargs = {}
<br>&nbsp &nbsp &nbsp &nbsp &nbspif generic_utils.has_arg(self.cell.call, 'training'):
<br>@@ -322,16 +319,16 @@ class ConvRNN2D(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef step(inputs, states):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn self.cell.call(inputs, states, **kwargs)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplast_output, outputs, states = K.rnn(step,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants=constants,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgo_backwards=self.go_backwards,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=mask,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length=timesteps)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplast_output, outputs, states = backend.rnn(step,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants=constants,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgo_backwards=self.go_backwards,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmask=mask,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length=timesteps)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.stateful:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspupdates = [
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.update(self_state, state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.update(self_state, state)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor self_state, state in zip(self.states, states)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(updates)
<br>@@ -387,17 +384,17 @@ class ConvRNN2D(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# initialize state if None
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.states[0] is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(self.cell.state_size, '__len__'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.states = [K.zeros(get_tuple_shape(dim))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.states = [backend.zeros(get_tuple_shape(dim))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor dim in self.cell.state_size]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.states = [K.zeros(get_tuple_shape(self.cell.state_size))]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.states = [backend.zeros(get_tuple_shape(self.cell.state_size))]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif states is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif hasattr(self.cell.state_size, '__len__'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor state, dim in zip(self.states, self.cell.state_size):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.set_value(state, np.zeros(get_tuple_shape(dim)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.set_value(state, np.zeros(get_tuple_shape(dim)))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.set_value(self.states[0],</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros(get_tuple_shape(self.cell.state_size)))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.set_value(self.states[0],</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros(get_tuple_shape(self.cell.state_size)))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not isinstance(states, (list, tuple)):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstates = [states]
<br>@@ -418,7 +415,7 @@ class ConvRNN2D(RNN):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstr(get_tuple_shape(dim)) +
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp', found shape=' + str(value.shape))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# TODO(anjalisridhar): consider batch calls to `set_value`.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.set_value(state, value)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.set_value(state, value)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspclass ConvLSTM2DCell(DropoutRNNCellMixin, Layer):
<br>@@ -570,7 +567,7 @@ class ConvLSTM2DCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.unit_forget_bias:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef bias_initializer(_, *args, **kwargs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn K.concatenate([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn backend.concatenate([</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias_initializer((self.filters,), *args, **kwargs),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.get('ones')((self.filters,), *args, **kwargs),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias_initializer((self.filters * 2,), *args, **kwargs),
<br>@@ -648,19 +645,19 @@ class ConvLSTM2DCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn h, [h, c]
<br>&nbsp
<br>&nbsp &nbsp &nbspdef input_conv(self, x, w, b=None, padding='valid'):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconv_out = K.conv2d(x, w, strides=self.strides,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppadding=padding,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdilation_rate=self.dilation_rate)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspconv_out = backend.conv2d(x, w, strides=self.strides,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppadding=padding,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdilation_rate=self.dilation_rate)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif b is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconv_out = K.bias_add(conv_out, b,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspconv_out = backend.bias_add(conv_out, b,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn conv_out
<br>&nbsp
<br>&nbsp &nbsp &nbspdef recurrent_conv(self, x, w):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspconv_out = K.conv2d(x, w, strides=(1, 1),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppadding='same',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspconv_out = backend.conv2d(x, w, strides=(1, 1),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppadding='same',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=self.data_format)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn conv_out
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>@@ -698,10 +695,16 @@ class ConvLSTM2DCell(DropoutRNNCellMixin, Layer):
<br>&nbsp
<br>&nbsp@keras_export('keras.layers.ConvLSTM2D')
<br>&nbspclass ConvLSTM2D(ConvRNN2D):
<br><span style="color:red">- &nbsp &nbsp"""Convolutional LSTM.</span>
<br><span style="color:green">+&nbsp &nbsp"""2D Convolutional LSTM layer.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspIt is similar to an LSTM layer, but the input transformations</span>
<br><span style="color:red">- &nbsp &nbspand recurrent transformations are both convolutional.</span>
<br><span style="color:green">+&nbsp &nbspA convolutional LSTM is similar to an LSTM, but the input transformations</span>
<br><span style="color:green">+&nbsp &nbspand recurrent transformations are both convolutional. This layer is typically</span>
<br><span style="color:green">+&nbsp &nbspused to process timeseries of images (i.e. video-like data).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspIt is known to perform well for weather data forecasting,</span>
<br><span style="color:green">+&nbsp &nbspusing inputs that are timeseries of 2D grids of sensor values.</span>
<br><span style="color:green">+&nbsp &nbspIt isn't usually applied to regular video data, due to its high computational</span>
<br><span style="color:green">+&nbsp &nbspcost.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbspfilters: Integer, the dimensionality of the output space
<br>@@ -713,8 +716,8 @@ class ConvLSTM2D(ConvRNN2D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecifying any stride value != 1 is incompatible with specifying
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspany `dilation_rate` value != 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppadding: One of `"valid"` or `"same"` (case-insensitive).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"valid"` means no padding. `"same"` results in padding evenly to </span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe left/right or up/down of the input such that output has the same </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"valid"` means no padding. `"same"` results in padding evenly to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe left/right or up/down of the input such that output has the same</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspheight/width dimension as the input.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdata_format: A string,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspone of `channels_last` (default) or `channels_first`.
<br>@@ -775,7 +778,7 @@ class ConvLSTM2D(ConvRNN2D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe linear transformation of the recurrent state.
<br>&nbsp
<br>&nbsp &nbsp &nbspCall arguments:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs: A 5D tensor.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs: A 5D float tensor (see input shape description below).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmask: Binary tensor of shape `(samples, timesteps)` indicating whether
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa given timestep should be masked.
<br>&nbsp &nbsp &nbsp &nbsp &nbsptraining: Python boolean indicating whether the layer should behave in
<br>@@ -823,6 +826,20 @@ class ConvLSTM2D(ConvRNN2D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp- [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp(the current implementation does not include the feedback loop on the
<br>&nbsp &nbsp &nbsp &nbsp &nbspcells output).
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspExample:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspsteps = 10</span>
<br><span style="color:green">+&nbsp &nbspheight = 32</span>
<br><span style="color:green">+&nbsp &nbspwidth = 32</span>
<br><span style="color:green">+&nbsp &nbspinput_channels = 3</span>
<br><span style="color:green">+&nbsp &nbspoutput_channels = 6</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspinputs = tf.keras.Input(shape=(steps, height, width, input_channels))</span>
<br><span style="color:green">+&nbsp &nbsplayer = tf.keras.layers.ConvLSTM2D(filters=output_channels, kernel_size=3)</span>
<br><span style="color:green">+&nbsp &nbspoutputs = layer(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\convolutional.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14874</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>80</td>
      <td>test_conv1d_regularizers</td>
      <td>67</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>78</td>
      <td>keras.layers.Conv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14875</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>82</td>
      <td>test_conv1d_regularizers</td>
      <td>67</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>78</td>
      <td>keras.layers.Conv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14876</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>99</td>
      <td>test_conv1d_constraints</td>
      <td>84</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>97</td>
      <td>keras.layers.Conv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14878</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>100</td>
      <td>test_conv1d_constraints</td>
      <td>84</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>97</td>
      <td>keras.layers.Conv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14880</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>155</td>
      <td>test_conv2d_regularizers</td>
      <td>142</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>153</td>
      <td>keras.layers.Conv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14881</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>157</td>
      <td>test_conv2d_regularizers</td>
      <td>142</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>153</td>
      <td>keras.layers.Conv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14882</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>174</td>
      <td>test_conv2d_constraints</td>
      <td>159</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>172</td>
      <td>keras.layers.Conv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14884</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>175</td>
      <td>test_conv2d_constraints</td>
      <td>159</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>172</td>
      <td>keras.layers.Conv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14886</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>220</td>
      <td>test_conv2dtranspose_regularizers</td>
      <td>207</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>218</td>
      <td>keras.layers.Conv2DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14887</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>222</td>
      <td>test_conv2dtranspose_regularizers</td>
      <td>207</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>218</td>
      <td>keras.layers.Conv2DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14888</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>239</td>
      <td>test_conv2dtranspose_constraints</td>
      <td>224</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>237</td>
      <td>keras.layers.Conv2DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14890</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>240</td>
      <td>test_conv2dtranspose_constraints</td>
      <td>224</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>237</td>
      <td>keras.layers.Conv2DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14892</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>286</td>
      <td>test_conv3dtranspose_regularizers</td>
      <td>273</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>284</td>
      <td>keras.layers.Conv3DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14893</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>288</td>
      <td>test_conv3dtranspose_regularizers</td>
      <td>273</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>284</td>
      <td>keras.layers.Conv3DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14894</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>305</td>
      <td>test_conv3dtranspose_constraints</td>
      <td>290</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>303</td>
      <td>keras.layers.Conv3DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14896</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>306</td>
      <td>test_conv3dtranspose_constraints</td>
      <td>290</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>303</td>
      <td>keras.layers.Conv3DTranspose</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14898</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>358</td>
      <td>test_separable_conv1d_regularizers</td>
      <td>344</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>356</td>
      <td>keras.layers.SeparableConv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14899</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>360</td>
      <td>test_separable_conv1d_regularizers</td>
      <td>344</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>356</td>
      <td>keras.layers.SeparableConv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14900</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>379</td>
      <td>test_separable_conv1d_constraints</td>
      <td>362</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>377</td>
      <td>keras.layers.SeparableConv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14902</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>380</td>
      <td>test_separable_conv1d_constraints</td>
      <td>362</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>377</td>
      <td>keras.layers.SeparableConv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14904</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>381</td>
      <td>test_separable_conv1d_constraints</td>
      <td>362</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>377</td>
      <td>keras.layers.SeparableConv1D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14906</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>436</td>
      <td>test_separable_conv2d_regularizers</td>
      <td>422</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>434</td>
      <td>keras.layers.SeparableConv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14907</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>438</td>
      <td>test_separable_conv2d_regularizers</td>
      <td>422</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>434</td>
      <td>keras.layers.SeparableConv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14908</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>457</td>
      <td>test_separable_conv2d_constraints</td>
      <td>440</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>455</td>
      <td>keras.layers.SeparableConv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14910</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>458</td>
      <td>test_separable_conv2d_constraints</td>
      <td>440</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>455</td>
      <td>keras.layers.SeparableConv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14912</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>459</td>
      <td>test_separable_conv2d_constraints</td>
      <td>440</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>455</td>
      <td>keras.layers.SeparableConv2D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14914</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>506</td>
      <td>test_conv3d_regularizers</td>
      <td>493</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>504</td>
      <td>keras.layers.Conv3D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14915</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>507</td>
      <td>test_conv3d_regularizers</td>
      <td>493</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>504</td>
      <td>keras.layers.Conv3D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14916</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>509</td>
      <td>test_conv3d_regularizers</td>
      <td>493</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>504</td>
      <td>keras.layers.Conv3D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14917</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>526</td>
      <td>test_conv3d_constraints</td>
      <td>511</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>524</td>
      <td>keras.layers.Conv3D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
    <tr>
      <th>14919</th>
      <td>keras\layers\convolutional_test.py</td>
      <td>527</td>
      <td>test_conv3d_constraints</td>
      <td>511</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>524</td>
      <td>keras.layers.Conv3D</td>
      <td>tensorflow\python\keras\layers\convolutional.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 8f57aaa1e7ad3922ec1f6835379038320e573c0f

 <br>Commit message: Fix conv layer for partially unknown spatial shape<br><br>
<br>Commit id closest to desired version: 0174bcb337e2c8e7d6782b60b094ea70460ad071

 <br>Commit message: Internal change<br><br>PiperOrigin-RevId: 373618178<br>Change-Id: I53189d7334f34499df6d4b362b5049712385d07e<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/convolutional.py b/tensorflow/python/keras/layers/convolutional.py
<br>index d3ff378e7ae..cf1098fbfc5 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/convolutional.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/convolutional.py</span>
<br>@@ -12,15 +12,9 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Keras convolution layers and image transformation layers.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Keras convolution layers and image transformation layers."""</span>
<br>&nbsp
<br>&nbspimport functools
<br><span style="color:red">- import six</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br>@@ -64,7 +58,8 @@ class Conv(Layer):
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsprank: An integer, the rank of the convolution, e.g. "2" for 2D convolution.
<br>&nbsp &nbsp &nbsp &nbsp &nbspfilters: Integer, the dimensionality of the output space (i.e. the number
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof filters in the convolution).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspof filters in the convolution). Could be "None", eg in the case of</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepth wise convolution.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_size: An integer or tuple/list of n integers, specifying the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplength of the convolution window.
<br>&nbsp &nbsp &nbsp &nbsp &nbspstrides: An integer or tuple/list of n integers,
<br>@@ -93,9 +88,10 @@ class Conv(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspactivation: Activation function to use.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you don't specify anything, no activation is applied.
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_initializer: An initializer for the convolution kernel.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_initializer: An initializer for the convolution kernel. If None, the </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspdefault initializer (glorot_uniform) will be used. </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: An initializer for the bias vector. If None, the default
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer will be used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer (zeros) will be used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Optional regularizer for the convolution kernel.
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Optional regularizer for the bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspactivity_regularizer: Optional regularizer function for the output.
<br>@@ -140,6 +136,9 @@ class Conv(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(filters, float):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfilters = int(filters)
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif filters is not None and filters < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Received a negative value for `filters`.'</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'Was expecting a positive value, got {filters}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.filters = filters
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.groups = groups or 1
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.kernel_size = conv_utils.normalize_tuple(
<br>@@ -178,6 +177,10 @@ class Conv(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The argument `kernel_size` cannot contain 0(s). '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Received: %s' % (self.kernel_size,))
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif not all(self.strides):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The argument `strides` cannot contains 0(s). '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Received: %s' % (self.strides,))</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif (self.padding == 'causal' and not isinstance(self,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(Conv1D, SeparableConv1D))):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Causal padding is only supported for `Conv1D`'
<br>@@ -221,7 +224,7 @@ class Conv(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Convert Keras formats to TF native formats.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.padding == 'causal':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_padding = 'VALID'  # Causal padding handled in `call`.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelif isinstance(self.padding, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelif isinstance(self.padding, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_padding = self.padding.upper()
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_padding = self.padding
<br>@@ -262,7 +265,7 @@ class Conv(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef _apply_fn(o):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn nn.bias_add(o, self.bias, data_format=self._tf_data_format)
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = nn_ops.squeeze_batch_dims(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = conv_utils.squeeze_batch_dims(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs, _apply_fn, inner_rank=self.rank + 1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs = nn.bias_add(
<br>@@ -450,9 +453,9 @@ class Conv1D(Conv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (
<br>@@ -533,7 +536,8 @@ class Conv2D(Conv):
<br>&nbsp &nbsp &nbspprovide the keyword argument `input_shape`
<br>&nbsp &nbsp &nbsp(tuple of integers or `None`, does not include the sample axis),
<br>&nbsp &nbsp &nbspe.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
<br><span style="color:red">- &nbsp &nbspin `data_format="channels_last"`.</span>
<br><span style="color:green">+&nbsp &nbspin `data_format="channels_last"`. You can use `None` when</span>
<br><span style="color:green">+&nbsp &nbspa dimension has variable size.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspExamples:
<br>&nbsp
<br>@@ -606,13 +610,13 @@ class Conv2D(Conv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspactivation is applied (see `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to the `kernel` weights
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix (see `keras.regularizers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix (see `keras.regularizers`). </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.regularizers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.regularizers`). </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspactivity_regularizer: Regularizer function applied to the output of the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplayer (its "activation") (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_constraint: Constraint function applied to the kernel matrix (see
<br>@@ -751,9 +755,9 @@ class Conv3D(Conv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspactivation is applied (see `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (see
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to the `kernel` weights
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (see
<br>@@ -872,9 +876,9 @@ class Conv1DTranspose(Conv1D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (
<br>@@ -1136,9 +1140,9 @@ class Conv2DTranspose(Conv2D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (
<br>@@ -1439,8 +1443,10 @@ class Conv3DTranspose(Conv3D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you don't specify anything, no activation is applied (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_initializer: Initializer for the `kernel` weights matrix (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'glorot_uniform'.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). Defaults to 'zeros'.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspkernel_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `kernel` weights matrix (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.regularizers`).
<br>@@ -1729,10 +1735,14 @@ class SeparableConv(Conv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you don't specify anything, no activation is applied (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdepthwise_initializer: An initializer for the depthwise convolution kernel.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppointwise_initializer: An initializer for the pointwise convolution kernel.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdepthwise_initializer: An initializer for the depthwise convolution kernel (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'glorot_uniform') will be used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppointwise_initializer: An initializer for the pointwise convolution kernel (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('glorot_uniform') will be used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: An initializer for the bias vector. If None, the default
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer will be used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer ('zeros') will be used (see `keras.initializers`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_regularizer: Optional regularizer for the depthwise
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconvolution kernel.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppointwise_regularizer: Optional regularizer for the pointwise
<br>@@ -1935,11 +1945,13 @@ class SeparableConv1D(SeparableConv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_initializer: An initializer for the depthwise convolution kernel (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'glorot_uniform') will be used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsppointwise_initializer: An initializer for the pointwise convolution kernel (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('glorot_uniform') will be used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: An initializer for the bias vector. If None, the default
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer will be used (see `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer ('zeros') will be used (see `keras.initializers`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_regularizer: Optional regularizer for the depthwise
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconvolution kernel (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsppointwise_regularizer: Optional regularizer for the pointwise
<br>@@ -2098,7 +2110,8 @@ class SeparableConv2D(SeparableConv):
<br>&nbsp &nbsp &nbsp &nbsp &nbspstrides: An integer or tuple/list of 2 integers,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspecifying the strides of the convolution along the height and width.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspCan be a single integer to specify the same value for
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspall spatial dimensions.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspall spatial dimensions. Current implementation only supports equal </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsplength strides in the row and column dimensions.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspSpecifying any stride value != 1 is incompatible with specifying
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspany `dilation_rate` value != 1.
<br>&nbsp &nbsp &nbsp &nbsp &nbsppadding: one of `"valid"` or `"same"` (case-insensitive).
<br>@@ -2127,12 +2140,14 @@ class SeparableConv2D(SeparableConv):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf you don't specify anything, no activation is applied (
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdepthwise_initializer: Initializer for the depthwise kernel matrix (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppointwise_initializer: Initializer for the pointwise kernel matrix (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdepthwise_initializer: An initializer for the depthwise convolution kernel (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'glorot_uniform') will be used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppointwise_initializer: An initializer for the pointwise convolution kernel (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, then the default initializer </span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp('glorot_uniform') will be used.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbias_initializer: An initializer for the bias vector. If None, the default</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer ('zeros') will be used (see `keras.initializers`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe depthwise kernel matrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsppointwise_regularizer: Regularizer function applied to
<br>@@ -2245,11 +2260,22 @@ class SeparableConv2D(SeparableConv):
<br>&nbsp
<br>&nbsp@keras_export('keras.layers.DepthwiseConv2D')
<br>&nbspclass DepthwiseConv2D(Conv2D):
<br><span style="color:red">- &nbsp &nbsp"""Depthwise separable 2D convolution.</span>
<br><span style="color:green">+&nbsp &nbsp"""Depthwise 2D convolution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspDepthwise convolution is a type of convolution in which a single convolutional</span>
<br><span style="color:green">+&nbsp &nbspfilter is apply to each input channel (i.e. in a depthwise way).</span>
<br><span style="color:green">+&nbsp &nbspYou can understand depthwise convolution as being</span>
<br><span style="color:green">+&nbsp &nbspthe first step in a depthwise separable convolution.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspIt is implemented via the following steps:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp- Split the input into individual channels.</span>
<br><span style="color:green">+&nbsp &nbsp- Convolve each input with the layer's kernel (called a depthwise kernel).</span>
<br><span style="color:green">+&nbsp &nbsp- Stack the convolved outputs together (along the channels axis).</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspUnlike a regular 2D convolution, depthwise convolution does not mix</span>
<br><span style="color:green">+&nbsp &nbspinformation across different input channels.</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspDepthwise Separable convolutions consist of performing</span>
<br><span style="color:red">- &nbsp &nbspjust the first step in a depthwise spatial convolution</span>
<br><span style="color:red">- &nbsp &nbsp(which acts on each input channel separately).</span>
<br>&nbsp &nbsp &nbspThe `depth_multiplier` argument controls how many
<br>&nbsp &nbsp &nbspoutput channels are generated per input channel in the depthwise step.
<br>&nbsp
<br>@@ -2291,9 +2317,11 @@ class DepthwiseConv2D(Conv2D):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.activations`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspuse_bias: Boolean, whether the layer uses a bias vector.
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_initializer: Initializer for the depthwise kernel matrix (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, the default initializer (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'glorot_uniform') will be used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_initializer: Initializer for the bias vector (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsee `keras.initializers`). If None, the default initializer (</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'zeros') will bs used.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspdepthwise_regularizer: Regularizer function applied to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe depthwise kernel matrix (see `keras.regularizers`).
<br>&nbsp &nbsp &nbsp &nbsp &nbspbias_regularizer: Regularizer function applied to the bias vector (
<br>@@ -2315,10 +2343,11 @@ class DepthwiseConv2D(Conv2D):
<br>&nbsp
<br>&nbsp &nbsp &nbspOutput shape:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp4D tensor with shape:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`[batch_size, filters, new_rows, new_cols]` if data_format='channels_first'</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspor 4D tensor with shape:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`[batch_size, new_rows, new_cols, filters]` if data_format='channels_last'.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp`rows` and `cols` values might have changed due to padding.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`[batch_size, channels * depth_multiplier, new_rows, new_cols]` if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata_format='channels_first' or 4D tensor with shape:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp`[batch_size, new_rows, new_cols, channels * depth_multiplier]` if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdata_format='channels_last'. `rows` and `cols` values might have</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspchanged due to padding.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbspA tensor of rank 4 representing
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\constraints.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14979</th>
      <td>keras\layers\core_test.py</td>
      <td>230</td>
      <td>test_dense_constraints</td>
      <td>223</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>225</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>14981</th>
      <td>keras\layers\core_test.py</td>
      <td>231</td>
      <td>test_dense_constraints</td>
      <td>223</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>226</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15051</th>
      <td>keras\layers\gru_test.py</td>
      <td>182</td>
      <td>test_constraints_GRU</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>170</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15053</th>
      <td>keras\layers\gru_test.py</td>
      <td>183</td>
      <td>test_constraints_GRU</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>171</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15055</th>
      <td>keras\layers\gru_test.py</td>
      <td>184</td>
      <td>test_constraints_GRU</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>172</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15060</th>
      <td>keras\layers\local_test.py</td>
      <td>111</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>100</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15063</th>
      <td>keras\layers\local_test.py</td>
      <td>112</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>101</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15068</th>
      <td>keras\layers\local_test.py</td>
      <td>220</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>209</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15071</th>
      <td>keras\layers\local_test.py</td>
      <td>221</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>210</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15109</th>
      <td>keras\layers\lstm_test.py</td>
      <td>196</td>
      <td>test_constraints_LSTM</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>184</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15111</th>
      <td>keras\layers\lstm_test.py</td>
      <td>197</td>
      <td>test_constraints_LSTM</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>185</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15113</th>
      <td>keras\layers\lstm_test.py</td>
      <td>198</td>
      <td>test_constraints_LSTM</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>186</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15464</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>182</td>
      <td>test_constraints_SimpleRNN</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>170</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15466</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>183</td>
      <td>test_constraints_SimpleRNN</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>171</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
    <tr>
      <th>15468</th>
      <td>keras\layers\simplernn_test.py</td>
      <td>184</td>
      <td>test_constraints_SimpleRNN</td>
      <td>166</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>172</td>
      <td>keras.constraints.max_norm</td>
      <td>tensorflow\python\keras\constraints.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 993403945efc9e7a933e9c8bd3ad029c36c6882b

 <br>Commit message: Remove a large amount of PY2 compatibility code.<br><br>PiperOrigin-RevId: 364677165<br>Change-Id: Ic52863fbda9b3f093948b9febbcb00a138d80ade<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/constraints.py b/tensorflow/python/keras/constraints.py
<br>index 8f42d9f937f..6ff57d34a72 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/constraints.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/constraints.py</span>
<br>@@ -13,16 +13,11 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=invalid-name
<br><span style="color:red">- """Constraints: functions that impose constraints on weight values.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- import six</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+"""Constraints: functions that impose constraints on weight values."""</span>
<br>&nbsp
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import deserialize_keras_object
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import serialize_keras_object
<br>&nbspfrom tensorflow.python.ops import array_ops
<br>@@ -33,12 +28,54 @@ from tensorflow.tools.docs import doc_controls
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.constraints.Constraint')
<br><span style="color:red">- class Constraint(object):</span>
<br><span style="color:green">+class Constraint:</span>
<br><span style="color:green">+&nbsp &nbsp"""Base class for weight constraints.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspA `Constraint` instance works like a stateless function.</span>
<br><span style="color:green">+&nbsp &nbspUsers who subclass this</span>
<br><span style="color:green">+&nbsp &nbspclass should override the `__call__` method, which takes a single</span>
<br><span style="color:green">+&nbsp &nbspweight parameter and return a projected version of that parameter</span>
<br><span style="color:green">+&nbsp &nbsp(e.g. normalized or clipped). Constraints can be used with various Keras</span>
<br><span style="color:green">+&nbsp &nbsplayers via the `kernel_constraint` or `bias_constraint` arguments.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspHere's a simple example of a non-negative weight constraint:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> class NonNegative(tf.keras.constraints.Constraint):</span>
<br><span style="color:green">+&nbsp &nbsp...</span>
<br><span style="color:green">+&nbsp &nbsp...  def __call__(self, w):</span>
<br><span style="color:green">+&nbsp &nbsp...    return w * tf.cast(tf.math.greater_equal(w, 0.), w.dtype)</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> weight = tf.constant((-1.0, 1.0))</span>
<br><span style="color:green">+&nbsp &nbsp>>> NonNegative()(weight)</span>
<br><span style="color:green">+&nbsp &nbsp<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.,  1.], dtype=float32)></span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> tf.keras.layers.Dense(4, kernel_constraint=NonNegative())</span>
<br><span style="color:green">+&nbsp &nbsp"""</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __call__(self, w):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Applies the constraint to the input weight variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspBy default, the inputs weight variable is not modified.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspUsers should override this method to implement their own projection</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspfunction.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspArgs:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspw: Input weight variable.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspProjected variable (by default, returns unmodified inputs).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn w
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""Returns a Python dict of the object config.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspA constraint config is a Python dictionary (JSON-serializable) that can</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspbe used to reinstantiate the same object.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspReturns:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspPython dict containing the configuration of the constraint object.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp"""</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn {}
<br>&nbsp
<br>&nbsp
<br>@@ -73,10 +110,10 @@ class MaxNorm(Constraint):
<br>&nbsp
<br>&nbsp &nbsp &nbsp@doc_controls.do_not_generate_docs
<br>&nbsp &nbsp &nbspdef __call__(self, w):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnorms = K.sqrt(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnorms = backend.sqrt(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.reduce_sum(math_ops.square(w), axis=self.axis, keepdims=True))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdesired = K.clip(norms, 0, self.max_value)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn w * (desired / (K.epsilon() + norms))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdesired = backend.clip(norms, 0, self.max_value)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn w * (desired / (backend.epsilon() + norms))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@doc_controls.do_not_generate_docs
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>@@ -91,7 +128,7 @@ class NonNeg(Constraint):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __call__(self, w):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn w * math_ops.cast(math_ops.greater_equal(w, 0.), K.floatx())</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn w * math_ops.cast(math_ops.greater_equal(w, 0.), backend.floatx())</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.constraints.UnitNorm', 'keras.constraints.unit_norm')
<br>@@ -120,7 +157,7 @@ class UnitNorm(Constraint):
<br>&nbsp &nbsp &nbsp@doc_controls.do_not_generate_docs
<br>&nbsp &nbsp &nbspdef __call__(self, w):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn w / (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.epsilon() + K.sqrt(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.epsilon() + backend.sqrt(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.reduce_sum(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.square(w), axis=self.axis, keepdims=True)))
<br>&nbsp
<br>@@ -169,12 +206,12 @@ class MinMaxNorm(Constraint):
<br>&nbsp
<br>&nbsp &nbsp &nbsp@doc_controls.do_not_generate_docs
<br>&nbsp &nbsp &nbspdef __call__(self, w):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspnorms = K.sqrt(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspnorms = backend.sqrt(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.reduce_sum(math_ops.square(w), axis=self.axis, keepdims=True))
<br>&nbsp &nbsp &nbsp &nbsp &nbspdesired = (
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.rate * K.clip(norms, self.min_value, self.max_value) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.rate * backend.clip(norms, self.min_value, self.max_value) +</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(1 - self.rate) * norms)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn w * (desired / (K.epsilon() + norms))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn w * (desired / (backend.epsilon() + norms))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp@doc_controls.do_not_generate_docs
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>@@ -226,32 +263,32 @@ class RadialConstraint(Constraint):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'The weight tensor must be of rank 4, but is of shape: %s' % w_shape)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspheight, width, channels, kernels = w_shape
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspw = K.reshape(w, (height, width, channels * kernels))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TODO(cpeter): Switch map_fn for a faster tf.vectorized_map once K.switch</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# is supported.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspw = K.map_fn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspw = backend.reshape(w, (height, width, channels * kernels))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# TODO(cpeter): Switch map_fn for a faster tf.vectorized_map once</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# backend.switch is supported.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspw = backend.map_fn(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._kernel_constraint,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.stack(array_ops.unstack(w, axis=-1), axis=0))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn K.reshape(K.stack(array_ops.unstack(w, axis=0), axis=-1),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(height, width, channels, kernels))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.stack(array_ops.unstack(w, axis=-1), axis=0))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn backend.reshape(backend.stack(array_ops.unstack(w, axis=0), axis=-1),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(height, width, channels, kernels))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _kernel_constraint(self, kernel):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""Radially constraints a kernel with shape (height, width, channels)."""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsppadding = K.constant([[1, 1], [1, 1]], dtype='int32')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsppadding = backend.constant([[1, 1], [1, 1]], dtype='int32')</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_shape = K.shape(kernel)[0]</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstart = K.cast(kernel_shape / 2, 'int32')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_shape = backend.shape(kernel)[0]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstart = backend.cast(kernel_shape / 2, 'int32')</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspkernel_new = K.switch(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.cast(math_ops.floormod(kernel_shape, 2), 'bool'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspkernel_new = backend.switch(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.cast(math_ops.floormod(kernel_shape, 2), 'bool'),</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: kernel[start - 1:start, start - 1:start],
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: kernel[start - 1:start, start - 1:start] + K.zeros(  # pylint: disable=g-long-lambda</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: kernel[start - 1:start, start - 1:start] + backend.zeros(  # pylint: disable=g-long-lambda</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(2, 2), dtype=kernel.dtype))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspindex = K.switch(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.cast(math_ops.floormod(kernel_shape, 2), 'bool'),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: K.constant(0, dtype='int32'),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: K.constant(1, dtype='int32'))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwhile_condition = lambda index, *args: K.less(index, start)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspindex = backend.switch(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.cast(math_ops.floormod(kernel_shape, 2), 'bool'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: backend.constant(0, dtype='int32'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda: backend.constant(1, dtype='int32'))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwhile_condition = lambda index, *args: backend.less(index, start)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspdef body_fn(i, array):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn i + 1, array_ops.pad(
<br>@@ -302,7 +339,7 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br>&nbsp &nbsp &nbspif isinstance(identifier, dict):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(identifier)
<br><span style="color:red">- &nbsp &nbspelif isinstance(identifier, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbspelif isinstance(identifier, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig = {'class_name': str(identifier), 'config': {}}
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(config)
<br>&nbsp &nbsp &nbspelif callable(identifier):
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\wrappers.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15015</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>271</td>
      <td>test_load_weights_between_noncudnn_rnn</td>
      <td>227</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>255</td>
      <td>keras.layers.Bidirectional</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
    <tr>
      <th>15019</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>271</td>
      <td>test_load_weights_between_noncudnn_rnn</td>
      <td>227</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>259</td>
      <td>keras.layers.Bidirectional</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
    <tr>
      <th>15023</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>347</td>
      <td>test_load_weights_between_noncudnn_rnn_time_distributed</td>
      <td>306</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>334</td>
      <td>keras.layers.TimeDistributed</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
    <tr>
      <th>15027</th>
      <td>keras\layers\cudnn_recurrent_test.py</td>
      <td>347</td>
      <td>test_load_weights_between_noncudnn_rnn_time_distributed</td>
      <td>306</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>337</td>
      <td>keras.layers.TimeDistributed</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
    <tr>
      <th>15475</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>195</td>
      <td>test_TimeDistributed_trainable</td>
      <td>190</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>193</td>
      <td>keras.layers.TimeDistributed</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
    <tr>
      <th>15476</th>
      <td>keras\layers\wrappers_test.py</td>
      <td>196</td>
      <td>test_TimeDistributed_trainable</td>
      <td>190</td>
      <td>assertEquals</td>
      <td>1</td>
      <td>193</td>
      <td>keras.layers.TimeDistributed</td>
      <td>tensorflow\python\keras\layers\wrappers.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: b9f7840446cd71bab40aa0552a9a5c9851f9f003

 <br>Commit message: Add docs about forcing zero output for mask with Bidirectional<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/wrappers.py b/tensorflow/python/keras/layers/wrappers.py
<br>index aa0b5c7a544..dbbf395c343 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/wrappers.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/wrappers.py</span>
<br>@@ -13,17 +13,14 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Wrapper layers: layers that augment the functionality of another layer.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+"""Wrapper layers: layers that augment the functionality of another layer."""</span>
<br>&nbsp
<br>&nbspimport copy
<br>&nbsp
<br>&nbspfrom tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras.engine.base_layer import Layer
<br>&nbspfrom tensorflow.python.keras.engine.input_spec import InputSpec
<br>&nbspfrom tensorflow.python.keras.layers.recurrent import _standardize_args
<br>@@ -156,14 +153,14 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `tensor.shape`, where every `None` is replaced by
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe corresponding dimension from `tf.shape(tensor)`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# replace all None in int_shape by K.shape</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# replace all None in int_shape by backend.shape</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif int_shape is None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspint_shape = K.int_shape(tensor)[start_idx:]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspint_shape = backend.int_shape(tensor)[start_idx:]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(int_shape, tensor_shape.TensorShape):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspint_shape = int_shape.as_list()
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not any(not s for s in int_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn init_tuple + tuple(int_shape)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspshape = K.shape(tensor)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspshape = backend.shape(tensor)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspint_shape = list(int_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor i, s in enumerate(int_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not s:
<br>@@ -212,11 +209,11 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['training'] = training
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_shape = nest.map_structure(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda x: tensor_shape.TensorShape(K.int_shape(x)), inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda x: tensor_shape.TensorShape(backend.int_shape(x)), inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspbatch_size = tf_utils.convert_shapes(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspbatch_size = nest.flatten(batch_size)[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbspif batch_size and not self._always_use_reshape:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, row_lengths = K.convert_inputs_if_ragged(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, row_lengths = backend.convert_inputs_if_ragged(inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_ragged_input = row_lengths is not None
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = tf_utils.convert_shapes(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = nest.flatten(input_length)[1]
<br>@@ -226,7 +223,7 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = self.layer(x, **kwargs)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output, []
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, outputs, _ = K.rnn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp_, outputs, _ = backend.rnn(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstep,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_states=[],
<br>@@ -235,8 +232,8 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspunroll=False)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# pylint: disable=g-long-lambda
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = nest.map_structure(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda output: K.maybe_convert_to_ragged(is_ragged_input, output,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprow_lengths), outputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda output: backend.maybe_convert_to_ragged(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_ragged_input, output, row_lengths), outputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# No batch size specified, therefore the layer will be able
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# to process batches of any size.
<br>@@ -271,7 +268,7 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# (num_samples * timesteps, ...)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif generic_utils.has_arg(self.layer.call, 'mask') and mask is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinner_mask_shape = self._get_shape_tuple((-1,), mask, 2)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['mask'] = K.reshape(mask, inner_mask_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['mask'] = backend.reshape(mask, inner_mask_shape)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy = self.layer(inputs, **kwargs)
<br>&nbsp
<br>@@ -330,7 +327,7 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# cases need to call the layer.compute_mask when input_mask is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# Masking layer and Embedding layer with mask_zero
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_shape = nest.map_structure(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda x: tensor_shape.TensorShape(K.int_shape(x)), inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda x: tensor_shape.TensorShape(backend.int_shape(x)), inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinput_shape = tf_utils.convert_shapes(input_shape, to_tuples=False)
<br>&nbsp &nbsp &nbsp &nbsp &nbspbatch_size = tf_utils.convert_shapes(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspbatch_size = nest.flatten(batch_size)[0]
<br>@@ -344,7 +341,7 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspinner_mask = mask
<br>&nbsp &nbsp &nbsp &nbsp &nbspif inner_mask is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinner_mask_shape = self._get_shape_tuple((-1,), mask, 2)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinner_mask = K.reshape(inner_mask, inner_mask_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinner_mask = backend.reshape(inner_mask, inner_mask_shape)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspinner_input_shape = nest.map_structure(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda tensor: self._get_shape_tuple((-1,), tensor, 2), inputs)
<br>&nbsp &nbsp &nbsp &nbsp &nbspinner_inputs = nest.map_structure_up_to(inputs, array_ops.reshape, inputs,
<br>@@ -356,27 +353,27 @@ class TimeDistributed(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# input_mask is not None, and output_mask is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# we should return a not-None mask
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask = mask
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor _ in range(2, len(K.int_shape(mask))):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask = K.any(output_mask, axis=-1)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor _ in range(2, len(backend.int_shape(mask))):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask = backend.any(output_mask, axis=-1)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# output_mask is not None. We need to reshape it
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = tf_utils.convert_shapes(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = nest.flatten(input_length)[1]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not input_length:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = nest.map_structure(lambda x: K.shape(x)[1], inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = nest.map_structure(lambda x: backend.shape(x)[1], inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_length = nest.flatten(input_length)[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = K.int_shape(output_mask)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = backend.int_shape(output_mask)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif output_mask_int_shape is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# if the output_mask does not have a static shape,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# its shape must be the same as mask's
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif mask is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = K.int_shape(mask)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = backend.int_shape(mask)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = generic_utils.to_list(nest.flatten(input_shape))[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = K.compute_output_shape(input_shape)[:-1]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_int_shape = backend.compute_output_shape(input_shape)[:-1]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask_shape = self._get_shape_tuple(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(-1, input_length), output_mask, 1, output_mask_int_shape[1:])
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask = K.reshape(output_mask, output_mask_shape)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput_mask = backend.reshape(output_mask, output_mask_shape)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output_mask
<br>&nbsp
<br>&nbsp
<br>@@ -396,6 +393,9 @@ class Bidirectional(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that the recommended way to create new RNN layers is to write a
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcustom RNN cell and use it with `keras.layers.RNN`, instead of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubclassing `keras.layers.Layer` directly.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- When the `returns_sequences` is true, the output of the masked timestep</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be zero regardless of the layer's original `zero_output_for_mask`</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalue.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspmerge_mode: Mode by which outputs of the forward and backward RNNs will be
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcombined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutputs will not be combined, they will be returned as a list. Default
<br>@@ -407,7 +407,7 @@ class Bidirectional(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspautomatically.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspNote that the provided `backward_layer` layer should have properties
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatching those of the `layer` argument, in particular it should have the
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsame values for `stateful`, `return_states`, `return_sequence`, etc.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspsame values for `stateful`, `return_states`, `return_sequences`, etc.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn addition, `backward_layer` and `layer` should have different
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`go_backwards` argument values.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA `ValueError` will be raised if these requirements are not met.
<br>@@ -602,7 +602,7 @@ class Bidirectional(Wrapper):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['initial_state'] = initial_state
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_inputs += initial_state
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate_specs = [InputSpec(shape=K.int_shape(state))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate_specs = [InputSpec(shape=backend.int_shape(state))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor state in initial_state]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.forward_layer.state_spec = state_specs[:num_states // 2]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.backward_layer.state_spec = state_specs[num_states // 2:]
<br>@@ -610,7 +610,7 @@ class Bidirectional(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif constants is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['constants'] = constants
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_inputs += constants
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants_spec = [InputSpec(shape=K.int_shape(constant))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants_spec = [InputSpec(shape=backend.int_shape(constant))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor constant in constants]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.forward_layer.constants_spec = constants_spec
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.backward_layer.constants_spec = constants_spec
<br>@@ -620,9 +620,9 @@ class Bidirectional(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.forward_layer._num_constants = self._num_constants
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.backward_layer._num_constants = self._num_constants
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis_keras_tensor = K.is_keras_tensor(additional_inputs[0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_keras_tensor = backend.is_keras_tensor(additional_inputs[0])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor tensor in additional_inputs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif K.is_keras_tensor(tensor) != is_keras_tensor:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif backend.is_keras_tensor(tensor) != is_keras_tensor:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The initial state of a Bidirectional'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' layer cannot be specified with a mix of'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' Keras tensors and non-Keras tensors'
<br>@@ -713,9 +713,9 @@ class Bidirectional(Wrapper):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.return_sequences:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptime_dim = 0 if getattr(self.forward_layer, 'time_major', False) else 1
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_rev = K.reverse(y_rev, time_dim)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspy_rev = backend.reverse(y_rev, time_dim)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.merge_mode == 'concat':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.concatenate([y, y_rev])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.concatenate([y, y_rev])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif self.merge_mode == 'sum':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = y + y_rev
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif self.merge_mode == 'ave':
<br>@@ -739,9 +739,9 @@ class Bidirectional(Wrapper):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.backward_layer.reset_states()
<br>&nbsp
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith K.name_scope(self.forward_layer.name):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith backend.name_scope(self.forward_layer.name):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.forward_layer.build(input_shape)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspwith K.name_scope(self.backward_layer.name):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspwith backend.name_scope(self.backward_layer.name):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.backward_layer.build(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>&nbsp
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\embeddings.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15034</th>
      <td>keras\layers\embeddings_test.py</td>
      <td>93</td>
      <td>test_eager_gpu_cpu</td>
      <td>84</td>
      <td>assertAllEqual</td>
      <td>1</td>
      <td>85</td>
      <td>keras.layers.Embedding</td>
      <td>tensorflow\python\keras\layers\embeddings.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: a279b46a97a386e2f15182826779192fced3473e

 <br>Commit message: Stop pinning embedding weights to CPU. Let the user make the placement decision with device scopes.<br><br>PiperOrigin-RevId: 365673712<br>Change-Id: I3eacc3c91958bb129604b9e3d26c2188ebc968ae<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/embeddings.py b/tensorflow/python/keras/layers/embeddings.py
<br>index 3ccaf2a2bd2..381f3b9eac7 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/embeddings.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/embeddings.py</span>
<br>@@ -12,17 +12,10 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Embedding layer.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- from tensorflow.python.distribute import sharded_variable</span>
<br><span style="color:red">- from tensorflow.python.eager import context</span>
<br><span style="color:red">- from tensorflow.python.framework import config as tf_config</span>
<br><span style="color:red">- from tensorflow.python.framework import ops</span>
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+"""Embedding layer."""</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras import constraints
<br>&nbspfrom tensorflow.python.keras import initializers
<br>&nbspfrom tensorflow.python.keras import regularizers
<br>@@ -86,6 +79,28 @@ class Embedding(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspOutput shape:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp3D tensor with shape: `(batch_size, input_length, output_dim)`.
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp**Note on variable placement:**</span>
<br><span style="color:green">+&nbsp &nbspBy default, if a GPU is available, the embedding matrix will be placed on</span>
<br><span style="color:green">+&nbsp &nbspthe GPU. This achieves the best performance, but it might cause issues:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp- You may be using an optimizer that does not support sparse GPU kernels.</span>
<br><span style="color:green">+&nbsp &nbspIn this case you will see an error upon training your model.</span>
<br><span style="color:green">+&nbsp &nbsp- Your embedding matrix may be too large to fit on your GPU. In this case</span>
<br><span style="color:green">+&nbsp &nbspyou will see an Out Of Memory (OOM) error.</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspIn such cases, you should place the embedding matrix on the CPU memory.</span>
<br><span style="color:green">+&nbsp &nbspYou can do so with a device scope, as such:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp```python</span>
<br><span style="color:green">+&nbsp &nbspwith tf.device('cpu:0'):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspembedding_layer = Embedding(...)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspembedding_layer.build()</span>
<br><span style="color:green">+&nbsp &nbsp```</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbspThe pre-built `embedding_layer` instance can then be added to a `Sequential`</span>
<br><span style="color:green">+&nbsp &nbspmodel (e.g. `model.add(embedding_layer)`), called in a Functional model</span>
<br><span style="color:green">+&nbsp &nbsp(e.g. `x = embedding_layer(x)`), or used in a subclassed model.</span>
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __init__(self,
<br>@@ -111,7 +126,7 @@ class Embedding(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'dtype' not in kwargs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In TF1, the dtype defaults to the input dtype which is typically int32,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# so explicitly set it to floatx
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['dtype'] = K.floatx()</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspkwargs['dtype'] = backend.floatx()</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# We set autocast to False, as we do not want to cast floating- point inputs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# to self.dtype. In call(), we cast to int32, and casting to self.dtype
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# before casting to int32 might cause the int32 values to be different due
<br>@@ -130,36 +145,19 @@ class Embedding(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_length = input_length
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br><span style="color:red">- &nbsp &nbspdef build(self, input_shape):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# Note: most sparse optimizers do not have GPU kernels defined. When</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# building graphs, the placement algorithm is able to place variables on CPU</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# since it knows all kernels using the variable only exist on CPU.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# When eager execution is enabled, the placement decision has to be made</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# right now. Checking for the presence of GPUs to avoid complicating the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# TPU codepaths which can handle sparse optimizers.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif context.executing_eagerly() and tf_config.list_logical_devices('GPU'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith ops.device('cpu:0'):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.embeddings = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.input_dim, self.output_dim),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.embeddings_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='embeddings',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.embeddings_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.embeddings_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.embeddings = self.add_weight(</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.input_dim, self.output_dim),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.embeddings_initializer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='embeddings',</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.embeddings_regularizer,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.embeddings_constraint,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br><span style="color:green">+&nbsp &nbspdef build(self, input_shape=None):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.embeddings = self.add_weight(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshape=(self.input_dim, self.output_dim),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializer=self.embeddings_initializer,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspname='embeddings',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspregularizer=self.embeddings_regularizer,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstraint=self.embeddings_constraint,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspexperimental_autocast=False)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.built = True
<br>&nbsp
<br>&nbsp &nbsp &nbspdef compute_mask(self, inputs, mask=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif not self.mask_zero:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br><span style="color:red">- </span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn math_ops.not_equal(inputs, 0)
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>@@ -187,13 +185,10 @@ class Embedding(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn (input_shape[0],) + tuple(in_lens) + (self.output_dim,)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspdtype = K.dtype(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspdtype = backend.dtype(inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif dtype != 'int32' and dtype != 'int64':
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = math_ops.cast(inputs, 'int32')
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif isinstance(self.embeddings, sharded_variable.ShardedVariable):</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = embedding_ops.embedding_lookup_v2(self.embeddings.variables, inputs)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspout = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspout = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self._dtype_policy.compute_dtype != self._dtype_policy.variable_dtype:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# Instead of casting the variable as in most layers, cast the output, as
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# this is mathematically equivalent but is faster.
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\local.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15056</th>
      <td>keras\layers\local_test.py</td>
      <td>93</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15057</th>
      <td>keras\layers\local_test.py</td>
      <td>98</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15058</th>
      <td>keras\layers\local_test.py</td>
      <td>111</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15059</th>
      <td>keras\layers\local_test.py</td>
      <td>111</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>109</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15061</th>
      <td>keras\layers\local_test.py</td>
      <td>112</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>91</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15062</th>
      <td>keras\layers\local_test.py</td>
      <td>112</td>
      <td>test_locallyconnected_1d_regularization</td>
      <td>65</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>109</td>
      <td>keras.layers.LocallyConnected1D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15064</th>
      <td>keras\layers\local_test.py</td>
      <td>203</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>201</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15065</th>
      <td>keras\layers\local_test.py</td>
      <td>207</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>201</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15066</th>
      <td>keras\layers\local_test.py</td>
      <td>220</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>201</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15067</th>
      <td>keras\layers\local_test.py</td>
      <td>220</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>218</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15069</th>
      <td>keras\layers\local_test.py</td>
      <td>221</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>201</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
    <tr>
      <th>15070</th>
      <td>keras\layers\local_test.py</td>
      <td>221</td>
      <td>test_locallyconnected_2d_regularization</td>
      <td>177</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>218</td>
      <td>keras.layers.LocallyConnected2D</td>
      <td>tensorflow\python\keras\layers\local.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 27c7ce8072285fdcd5f98a6bf331e6c63abb6e21

 <br>Commit message: overridden default input_spec_signature<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/local.py b/tensorflow/python/keras/layers/local.py
<br>index 06ba00ad08b..a422bce276b 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/local.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/local.py</span>
<br>@@ -12,15 +12,13 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br>&nbsp"""Locally-connected layers."""
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br>&nbsp
<br>&nbspimport numpy as np
<br>&nbsp
<br>&nbspfrom tensorflow.python.keras import activations
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras import constraints
<br>&nbspfrom tensorflow.python.keras import initializers
<br>&nbspfrom tensorflow.python.keras import regularizers
<br>@@ -155,6 +153,10 @@ class LocallyConnected1D(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.implementation = implementation
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = InputSpec(ndim=3)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@property</span>
<br><span style="color:green">+&nbsp &nbspdef _use_input_spec_as_call_signature(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn False</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.data_format == 'channels_first':
<br>@@ -263,8 +265,9 @@ class LocallyConnected1D(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.implementation == 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.local_conv(inputs, self.kernel, self.kernel_size, self.strides,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.output_length,), self.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.local_conv(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, self.kernel, self.kernel_size, self.strides,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.output_length,), self.data_format)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif self.implementation == 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = local_conv_matmul(inputs, self.kernel, self.kernel_mask,
<br>@@ -280,7 +283,7 @@ class LocallyConnected1D(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.bias_add(output, self.bias, data_format=self.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.bias_add(output, self.bias, data_format=self.data_format)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutput = self.activation(output)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>@@ -457,6 +460,10 @@ class LocallyConnected2D(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.implementation = implementation
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.input_spec = InputSpec(ndim=4)
<br>&nbsp
<br><span style="color:green">+&nbsp &nbsp@property</span>
<br><span style="color:green">+&nbsp &nbspdef _use_input_spec_as_call_signature(self):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn False</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>&nbsp &nbsp &nbspdef build(self, input_shape):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.data_format == 'channels_last':
<br>@@ -572,9 +579,10 @@ class LocallyConnected2D(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbspdef call(self, inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.implementation == 1:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.local_conv(inputs, self.kernel, self.kernel_size, self.strides,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.output_row, self.output_col),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.local_conv(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs, self.kernel, self.kernel_size, self.strides,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(self.output_row, self.output_col),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.data_format)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif self.implementation == 2:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = local_conv_matmul(inputs, self.kernel, self.kernel_mask,
<br>@@ -590,7 +598,7 @@ class LocallyConnected2D(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.bias_add(output, self.bias, data_format=self.data_format)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.bias_add(output, self.bias, data_format=self.data_format)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspoutput = self.activation(output)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn output
<br>@@ -729,14 +737,14 @@ def local_conv_matmul(inputs, kernel, kernel_mask, output_shape):
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOutput (N+2)-D tensor with shape `output_shape`.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspinputs_flat = K.reshape(inputs, (K.shape(inputs)[0], -1))</span>
<br><span style="color:green">+&nbsp &nbspinputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspkernel = kernel_mask * kernel
<br><span style="color:red">- &nbsp &nbspkernel = make_2d(kernel, split_dim=K.ndim(kernel) // 2)</span>
<br><span style="color:green">+&nbsp &nbspkernel = make_2d(kernel, split_dim=backend.ndim(kernel) // 2)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspoutput_flat = math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)</span>
<br><span style="color:red">- &nbsp &nbspoutput = K.reshape(output_flat, [</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.shape(output_flat)[0],</span>
<br><span style="color:green">+&nbsp &nbspoutput_flat = math_ops.matmul(inputs_flat, kernel, b_is_sparse=True)</span>
<br><span style="color:green">+&nbsp &nbspoutput = backend.reshape(output_flat, [</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.shape(output_flat)[0],</span>
<br>&nbsp &nbsp &nbsp] + output_shape.as_list()[1:])
<br>&nbsp &nbsp &nbspreturn output
<br>&nbsp
<br>@@ -767,17 +775,17 @@ def local_conv_sparse_matmul(inputs, kernel, kernel_idxs, kernel_shape,
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspOutput (N+2)-D dense tensor with shape `output_shape`.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspinputs_flat = K.reshape(inputs, (K.shape(inputs)[0], -1))</span>
<br><span style="color:green">+&nbsp &nbspinputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))</span>
<br>&nbsp &nbsp &nbspoutput_flat = gen_sparse_ops.SparseTensorDenseMatMul(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_indices=kernel_idxs,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_values=kernel,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa_shape=kernel_shape,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb=inputs_flat,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadjoint_b=True)
<br><span style="color:red">- &nbsp &nbspoutput_flat_transpose = K.transpose(output_flat)</span>
<br><span style="color:green">+&nbsp &nbspoutput_flat_transpose = backend.transpose(output_flat)</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspoutput_reshaped = K.reshape(output_flat_transpose, [</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.shape(output_flat_transpose)[0],</span>
<br><span style="color:green">+&nbsp &nbspoutput_reshaped = backend.reshape(output_flat_transpose, [</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.shape(output_flat_transpose)[0],</span>
<br>&nbsp &nbsp &nbsp] + output_shape.as_list()[1:])
<br>&nbsp &nbsp &nbspreturn output_reshaped
<br>&nbsp
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\layers\recurrent.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15345</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>413</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15346</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>415</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15347</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>416</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15348</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>424</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15349</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>425</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15351</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>426</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15355</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>441</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15356</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>441</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>431</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15357</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>442</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15358</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>442</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>431</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15359</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>443</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>409</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15360</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>443</td>
      <td>test_stacked_rnn_attributes</td>
      <td>406</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>431</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15398</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>613</td>
      <td>test_high_dimension_RNN</td>
      <td>596</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>608</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15414</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>688</td>
      <td>test_inconsistent_output_state_size</td>
      <td>675</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>683</td>
      <td>keras.layers.RNN</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15421</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>707</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>700</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15424</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>708</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>700</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15429</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>713</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>700</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>15433</th>
      <td>keras\layers\recurrent_test.py</td>
      <td>714</td>
      <td>test_get_initial_state</td>
      <td>699</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>700</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26161</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>344</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26164</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>345</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26168</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>353</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26176</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>354</td>
      <td>testRNNWithKerasSimpleRNNCell</td>
      <td>323</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>335</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26184</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>377</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26187</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>378</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26191</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>386</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26199</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>387</td>
      <td>testRNNWithKerasGRUCell</td>
      <td>356</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>368</td>
      <td>keras.layers.GRUCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26207</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>410</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26210</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>411</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26214</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>421</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26223</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>422</td>
      <td>testRNNWithKerasLSTMCell</td>
      <td>389</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>401</td>
      <td>keras.layers.LSTMCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26231</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>449</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26234</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>450</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26238</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>462</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26247</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>463</td>
      <td>testRNNWithStackKerasCell</td>
      <td>426</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>438</td>
      <td>keras.layers.StackedRNNCells</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26255</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>489</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26257</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>491</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26260</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>501</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26268</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>503</td>
      <td>testStaticRNNWithKerasSimpleRNNCell</td>
      <td>467</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>480</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26277</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>535</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26286</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>536</td>
      <td>testKerasAndTFRNNLayerOutputComparison</td>
      <td>505</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>522</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26295</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>574</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26303</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>574</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26309</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>575</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>1</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
    <tr>
      <th>26317</th>
      <td>kernel_tests\rnn_test.py</td>
      <td>575</td>
      <td>testSimpleRNNCellAndBasicRNNCellComparison</td>
      <td>538</td>
      <td>assertAllClose</td>
      <td>2</td>
      <td>560</td>
      <td>keras.layers.SimpleRNNCell</td>
      <td>tensorflow\python\keras\layers\recurrent.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: a9cf3a0e4b419630f0183b0cc4e48e0641a62721

 <br>Commit message: Merge pull request #48725 from amogh7joshi:patch-3<br><br>PiperOrigin-RevId: 372395334<br>Change-Id: Ie8841999976df629318bc10af1a9e822114d552c<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/layers/recurrent.py b/tensorflow/python/keras/layers/recurrent.py
<br>index cc20fe825f8..d48e685a1cb 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/layers/recurrent.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/layers/recurrent.py</span>
<br>@@ -13,11 +13,8 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp# pylint: disable=protected-access
<br><span style="color:red">- """Recurrent layers and their base classes.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+# pylint: disable=g-classes-have-attributes</span>
<br><span style="color:green">+"""Recurrent layers and their base classes."""</span>
<br>&nbsp
<br>&nbspimport collections
<br>&nbspimport warnings
<br>@@ -29,7 +26,7 @@ from tensorflow.python.eager import context
<br>&nbspfrom tensorflow.python.framework import ops
<br>&nbspfrom tensorflow.python.framework import tensor_shape
<br>&nbspfrom tensorflow.python.keras import activations
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br>&nbspfrom tensorflow.python.keras import constraints
<br>&nbspfrom tensorflow.python.keras import initializers
<br>&nbspfrom tensorflow.python.keras import regularizers
<br>@@ -45,7 +42,6 @@ from tensorflow.python.ops import math_ops
<br>&nbspfrom tensorflow.python.ops import state_ops
<br>&nbspfrom tensorflow.python.platform import tf_logging as logging
<br>&nbspfrom tensorflow.python.training.tracking import base as trackable
<br><span style="color:red">- from tensorflow.python.training.tracking import data_structures</span>
<br>&nbspfrom tensorflow.python.util import nest
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br>&nbspfrom tensorflow.tools.docs import doc_controls
<br>@@ -167,7 +163,7 @@ class StackedRNNCells(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = input_shape[0]
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor cell in self.cells:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif isinstance(cell, Layer) and not cell.built:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith K.name_scope(cell.name):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith backend.name_scope(cell.name):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell.build(input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcell.built = True
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(cell, 'output_size', None) is not None:
<br>@@ -236,7 +232,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`batch_size` is a scalar tensor that represents the batch size
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof the inputs. `dtype` is `tf.DType` that represents the dtype of
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe inputs.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor backward compatible reason, if this method is not implemented</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspFor backward compatibility, if this method is not implemented</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspby the cell, the RNN layer will create a zero filled tensor with the
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize of [batch_size, cell.state_size].
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIn the case that `cell` is a list of RNN cell instances, the cells
<br>@@ -371,8 +367,8 @@ class RNN(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef call(self, inputs, states):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprev_output = states[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = K.dot(inputs, self.kernel)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = h + K.dot(prev_output, self.recurrent_kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = backend.dot(inputs, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = h + backend.dot(prev_output, self.recurrent_kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output, [output]
<br>&nbsp
<br>&nbsp &nbsp &nbsp# Let's use this cell in a RNN layer:
<br>@@ -586,7 +582,7 @@ class RNN(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# allow cell (if layer) to build before we set or validate state_spec.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif isinstance(self.cell, Layer) and not self.cell.built:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith K.name_scope(self.cell.name):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith backend.name_scope(self.cell.name):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.cell.build(step_input_shape)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.cell.built = True
<br>&nbsp
<br>@@ -680,22 +676,22 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspif initial_state is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_inputs += initial_state
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.state_spec = nest.map_structure(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda s: InputSpec(shape=K.int_shape(s)), initial_state)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsplambda s: InputSpec(shape=backend.int_shape(s)), initial_state)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_specs += self.state_spec
<br>&nbsp &nbsp &nbsp &nbsp &nbspif constants is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_inputs += constants
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.constants_spec = [
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInputSpec(shape=K.int_shape(constant)) for constant in constants</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspInputSpec(shape=backend.int_shape(constant)) for constant in constants</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._num_constants = len(constants)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspadditional_specs += self.constants_spec
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# additional_inputs can be empty if initial_state or constants are provided
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# but empty (e.g. the cell is stateless).
<br>&nbsp &nbsp &nbsp &nbsp &nbspflat_additional_inputs = nest.flatten(additional_inputs)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspis_keras_tensor = K.is_keras_tensor(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspis_keras_tensor = backend.is_keras_tensor(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_additional_inputs[0]) if flat_additional_inputs else True
<br>&nbsp &nbsp &nbsp &nbsp &nbspfor tensor in flat_additional_inputs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif K.is_keras_tensor(tensor) != is_keras_tensor:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspif backend.is_keras_tensor(tensor) != is_keras_tensor:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('The initial state or constants of an RNN'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' layer cannot be specified with a mix of'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp' Keras tensors and non-Keras tensors'
<br>@@ -736,7 +732,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspconstants=None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# The input should be dense, padded with zeros. If a ragged input is fed
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# into the layer, it is padded and the row lengths are used for masking.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspinputs, row_lengths = K.convert_inputs_if_ragged(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspinputs, row_lengths = backend.convert_inputs_if_ragged(inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspis_ragged_input = (row_lengths is not None)
<br>&nbsp &nbsp &nbsp &nbsp &nbspself._validate_args_if_ragged(is_ragged_input, mask)
<br>&nbsp
<br>@@ -755,9 +751,9 @@ class RNN(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif nest.is_nested(inputs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# In the case of nested input, use the first element for shape check.
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = K.int_shape(nest.flatten(inputs)[0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = backend.int_shape(nest.flatten(inputs)[0])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = K.int_shape(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspinput_shape = backend.int_shape(inputs)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsptimesteps = input_shape[0] if self.time_major else input_shape[1]
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.unroll and timesteps is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Cannot unroll a RNN if the '
<br>@@ -803,7 +799,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not nest.is_nested(new_states):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnew_states = [new_states]
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output, new_states
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplast_output, outputs, states = K.rnn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplast_output, outputs, states = backend.rnn(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstep,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitial_state,
<br>@@ -823,7 +819,8 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.add_update(updates)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.return_sequences:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = K.maybe_convert_to_ragged(is_ragged_input, outputs, row_lengths)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = backend.maybe_convert_to_ragged(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspis_ragged_input, outputs, row_lengths, go_backwards=self.go_backwards)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = last_output
<br>&nbsp
<br>@@ -938,12 +935,12 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif getattr(self.cell, 'get_initial_state', None):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_init_state_values = nest.flatten(self.cell.get_initial_state(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs=None, batch_size=batch_size,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self.dtype or K.floatx()))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype=self.dtype or backend.floatx()))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_init_state_values = nest.flatten(_generate_zero_filled_state(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size, self.cell.state_size, self.dtype or K.floatx()))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size, self.cell.state_size, self.dtype or backend.floatx()))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_states_variables = nest.map_structure(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.variable, flat_init_state_values)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.variable, flat_init_state_values)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.states = nest.pack_sequence_as(self.cell.state_size,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_states_variables)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif not nest.is_nested(self.states):
<br>@@ -951,8 +948,9 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelif states is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor state, size in zip(nest.flatten(self.states),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnest.flatten(self.cell.state_size)):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.set_value(state, np.zeros([batch_size] +</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptensor_shape.TensorShape(size).as_list()))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.set_value(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspstate,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspnp.zeros([batch_size] + tensor_shape.TensorShape(size).as_list()))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_states = nest.flatten(self.states)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspflat_input_states = nest.flatten(states)
<br>@@ -970,7 +968,7 @@ class RNN(Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.name + ': expected shape=' + str(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(batch_size, state)) + ', found shape=' + str(value.shape))
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspset_value_tuples.append((state, value))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.batch_set_value(set_value_tuples)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.batch_set_value(set_value_tuples)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspdef get_config(self):
<br>&nbsp &nbsp &nbsp &nbsp &nbspconfig = {
<br>@@ -1041,8 +1039,8 @@ class AbstractRNNCell(Layer):
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef call(self, inputs, states):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprev_output = states[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = K.dot(inputs, self.kernel)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = h + K.dot(prev_output, self.recurrent_kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = backend.dot(inputs, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = h + backend.dot(prev_output, self.recurrent_kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn output, output
<br>&nbsp &nbsp &nbsp```
<br>&nbsp
<br>@@ -1132,8 +1130,9 @@ class DropoutRNNCellMixin(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspby python when deepcopy, we don't want `layer._obj_reference_counts_dict`
<br>&nbsp &nbsp &nbsp &nbsp &nbspto track it by default.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._dropout_mask_cache = K.ContextValueCache(self._create_dropout_mask)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself._recurrent_dropout_mask_cache = K.ContextValueCache(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._dropout_mask_cache = backend.ContextValueCache(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._create_dropout_mask)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself._recurrent_dropout_mask_cache = backend.ContextValueCache(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._create_recurrent_dropout_mask)
<br>&nbsp
<br>&nbsp &nbsp &nbspdef reset_dropout_mask(self):
<br>@@ -1223,9 +1222,9 @@ class DropoutRNNCellMixin(object):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn state
<br>&nbsp
<br>&nbsp &nbsp &nbspdef __setstate__(self, state):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstate['_dropout_mask_cache'] = K.ContextValueCache(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstate['_dropout_mask_cache'] = backend.ContextValueCache(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._create_dropout_mask)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspstate['_recurrent_dropout_mask_cache'] = K.ContextValueCache(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstate['_recurrent_dropout_mask_cache'] = backend.ContextValueCache(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._create_recurrent_dropout_mask)
<br>&nbsp &nbsp &nbsp &nbsp &nbspsuper(DropoutRNNCellMixin, self).__setstate__(state)
<br>&nbsp
<br>@@ -1315,6 +1314,9 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif units < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Received an invalid value for units, expected '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'a positive integer, got {units}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# By default use cached variable under v2 mode, see b/143699808.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', True)
<br>@@ -1378,15 +1380,15 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprev_output, training)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif dp_mask is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = K.dot(inputs * dp_mask, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = backend.dot(inputs * dp_mask, self.kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = K.dot(inputs, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = backend.dot(inputs, self.kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.bias is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = K.bias_add(h, self.bias)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsph = backend.bias_add(h, self.bias)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbspif rec_dp_mask is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprev_output = prev_output * rec_dp_mask
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput = h + K.dot(prev_output, self.recurrent_kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspoutput = h + backend.dot(prev_output, self.recurrent_kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspif self.activation is not None:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = self.activation(output)
<br>&nbsp
<br>@@ -1753,6 +1755,9 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreset_after=False,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif units < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Received an invalid value for units, expected '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'a positive integer, got {units}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# By default use cached variable under v2 mode, see b/143699808.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', True)
<br>@@ -1850,14 +1855,14 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_r = inputs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_h = inputs
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z = K.dot(inputs_z, self.kernel[:, :self.units])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_r = K.dot(inputs_r, self.kernel[:, self.units:self.units * 2])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_h = K.dot(inputs_h, self.kernel[:, self.units * 2:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z = backend.dot(inputs_z, self.kernel[:, :self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_r = backend.dot(inputs_r, self.kernel[:, self.units:self.units * 2])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_h = backend.dot(inputs_h, self.kernel[:, self.units * 2:])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z = K.bias_add(x_z, input_bias[:self.units])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_r = K.bias_add(x_r, input_bias[self.units: self.units * 2])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_h = K.bias_add(x_h, input_bias[self.units * 2:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z = backend.bias_add(x_z, input_bias[:self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_r = backend.bias_add(x_r, input_bias[self.units: self.units * 2])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_h = backend.bias_add(x_h, input_bias[self.units * 2:])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0. < self.recurrent_dropout < 1.:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_z = h_tm1 * rec_dp_mask[0]
<br>@@ -1868,26 +1873,28 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_r = h_tm1
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_h = h_tm1
<br>&nbsp
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z = K.dot(h_tm1_z, self.recurrent_kernel[:, :self.units])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r = K.dot(h_tm1_r,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel[:, self.units:self.units * 2])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z = backend.dot(h_tm1_z, self.recurrent_kernel[:, :self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r = backend.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_r, self.recurrent_kernel[:, self.units:self.units * 2])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after and self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z = K.bias_add(recurrent_z, recurrent_bias[:self.units])</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r = K.bias_add(recurrent_r,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_bias[self.units:self.units * 2])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z = backend.bias_add(recurrent_z, recurrent_bias[:self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r = backend.bias_add(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_r, recurrent_bias[self.units:self.units * 2])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = self.recurrent_activation(x_z + recurrent_z)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr = self.recurrent_activation(x_r + recurrent_r)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# reset gate applied after/before matrix multiplication
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = K.dot(h_tm1_h, self.recurrent_kernel[:, self.units * 2:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = backend.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_h, self.recurrent_kernel[:, self.units * 2:])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = K.bias_add(recurrent_h, recurrent_bias[self.units * 2:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = backend.bias_add(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h, recurrent_bias[self.units * 2:])</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = r * recurrent_h
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = K.dot(r * h_tm1_h,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel[:, self.units * 2:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = backend.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr * h_tm1_h, self.recurrent_kernel[:, self.units * 2:])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphh = self.activation(x_h + recurrent_h)
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>@@ -1895,21 +1902,22 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = inputs * dp_mask[0]
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# inputs projected by all gate matrices at once
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_x = K.dot(inputs, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_x = backend.dot(inputs, self.kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# biases: bias_z_i, bias_r_i, bias_h_i
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_x = K.bias_add(matrix_x, input_bias)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_x = backend.bias_add(matrix_x, input_bias)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_z, x_r, x_h = array_ops.split(matrix_x, 3, axis=-1)
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# hidden state projected by all gate matrices at once
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = K.dot(h_tm1, self.recurrent_kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = backend.dot(h_tm1, self.recurrent_kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = K.bias_add(matrix_inner, recurrent_bias)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = backend.bias_add(matrix_inner, recurrent_bias)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# hidden state projected separately for update/reset and new
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = K.dot(h_tm1, self.recurrent_kernel[:, :2 * self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner = backend.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1, self.recurrent_kernel[:, :2 * self.units])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_z, recurrent_r, recurrent_h = array_ops.split(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmatrix_inner, [self.units, self.units, -1], axis=-1)
<br>@@ -1920,8 +1928,8 @@ class GRUCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.reset_after:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = r * recurrent_h
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspelse:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = K.dot(r * h_tm1,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.recurrent_kernel[:, 2 * self.units:])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_h = backend.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspr * h_tm1, self.recurrent_kernel[:, 2 * self.units:])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphh = self.activation(x_h + recurrent_h)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# previous and candidate state mixed by update gate
<br>@@ -2310,6 +2318,9 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprecurrent_dropout=0.,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs):
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif units < 0:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(f'Received an invalid value for units, expected '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspf'a positive integer, got {units}.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp# By default use cached variable under v2 mode, see b/143699808.
<br>&nbsp &nbsp &nbsp &nbsp &nbspif ops.executing_eagerly_outside_functions():
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself._enable_caching_device = kwargs.pop('enable_caching_device', True)
<br>@@ -2342,13 +2353,7 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = 1
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.implementation = implementation
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# tuple(_ListWrapper) was silently dropping list content in at least 2.7.10,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# and fixed after 2.7.16. Converting the state_size to wrapper around</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# NoDependency(), so that the base_layer.__setattr__ will not convert it to</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# ListWrapper. Down the stream, self.states will be a list since it is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# generated from nest.map_structure with list, and tuple(list) will work</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp# properly.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspself.state_size = data_structures.NoDependency([self.units, self.units])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspself.state_size = [self.units, self.units]</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspself.output_size = self.units
<br>&nbsp
<br>&nbsp &nbsp &nbsp@tf_utils.shape_type_conversion
<br>@@ -2374,7 +2379,7 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.unit_forget_bias:
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdef bias_initializer(_, *args, **kwargs):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn K.concatenate([</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreturn backend.concatenate([</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias_initializer((self.units,), *args, **kwargs),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinitializers.get('ones')((self.units,), *args, **kwargs),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias_initializer((self.units * 2,), *args, **kwargs),
<br>@@ -2397,13 +2402,13 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspx_i, x_f, x_c, x_o = x
<br>&nbsp &nbsp &nbsp &nbsp &nbsph_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1
<br>&nbsp &nbsp &nbsp &nbsp &nbspi = self.recurrent_activation(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspf = self.recurrent_activation(x_f + K.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i + backend.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspf = self.recurrent_activation(x_f + backend.dot(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]))
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspc = f * c_tm1 + i * self.activation(x_c + K.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspc = f * c_tm1 + i * self.activation(x_c + backend.dot(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))
<br>&nbsp &nbsp &nbsp &nbsp &nbspo = self.recurrent_activation(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o + K.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn c, o
<br>&nbsp
<br>&nbsp &nbsp &nbspdef _compute_carry_and_output_fused(self, z, c_tm1):
<br>@@ -2436,17 +2441,17 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs_o = inputs
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspk_i, k_f, k_c, k_o = array_ops.split(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.kernel, num_or_size_splits=4, axis=1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i = K.dot(inputs_i, k_i)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_f = K.dot(inputs_f, k_f)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_c = K.dot(inputs_c, k_c)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o = K.dot(inputs_o, k_o)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i = backend.dot(inputs_i, k_i)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_f = backend.dot(inputs_f, k_f)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_c = backend.dot(inputs_c, k_c)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o = backend.dot(inputs_o, k_o)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspb_i, b_f, b_c, b_o = array_ops.split(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.bias, num_or_size_splits=4, axis=0)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i = K.bias_add(x_i, b_i)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_f = K.bias_add(x_f, b_f)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_c = K.bias_add(x_c, b_c)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o = K.bias_add(x_o, b_o)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i = backend.bias_add(x_i, b_i)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_f = backend.bias_add(x_f, b_f)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_c = backend.bias_add(x_c, b_c)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o = backend.bias_add(x_o, b_o)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0 < self.recurrent_dropout < 1.:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_i = h_tm1 * rec_dp_mask[0]
<br>@@ -2464,10 +2469,10 @@ class LSTMCell(DropoutRNNCellMixin, Layer):
<br>&nbsp &nbsp &nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif 0. < self.dropout < 1.:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinputs = inputs * dp_mask[0]
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = K.dot(inputs, self.kernel)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz += K.dot(h_tm1, self.recurrent_kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = backend.dot(inputs, self.kernel)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspz += backend.dot(h_tm1, self.recurrent_kernel)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif self.use_bias:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = K.bias_add(z, self.bias)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = backend.bias_add(z, self.bias)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspz = array_ops.split(z, num_or_size_splits=4, axis=1)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspc, o = self._compute_carry_and_output_fused(z, c_tm1)
<br>@@ -2617,15 +2622,15 @@ class PeepholeLSTMCell(LSTMCell):
<br>&nbsp &nbsp &nbsp &nbsp &nbspx_i, x_f, x_c, x_o = x
<br>&nbsp &nbsp &nbsp &nbsp &nbsph_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1
<br>&nbsp &nbsp &nbsp &nbsp &nbspi = self.recurrent_activation(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_i + backend.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]) +</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.input_gate_peephole_weights * c_tm1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspf = self.recurrent_activation(x_f + K.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspf = self.recurrent_activation(x_f + backend.dot(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]) +
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.forget_gate_peephole_weights * c_tm1)
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspc = f * c_tm1 + i * self.activation(x_c + K.dot(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspc = f * c_tm1 + i * self.activation(x_c + backend.dot(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsph_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))
<br>&nbsp &nbsp &nbsp &nbsp &nbspo = self.recurrent_activation(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o + K.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]) +</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_o + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]) +</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspself.output_gate_peephole_weights * c)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn c, o
<br>&nbsp
<br>@@ -2918,14 +2923,14 @@ class LSTM(RNN):
<br>&nbsp
<br>&nbspdef _generate_dropout_mask(ones, rate, training=None, count=1):
<br>&nbsp &nbsp &nbspdef dropped_inputs():
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspreturn K.dropout(ones, rate)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspreturn backend.dropout(ones, rate)</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspif count > 1:
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn [
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspK.in_train_phase(dropped_inputs, ones, training=training)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbackend.in_train_phase(dropped_inputs, ones, training=training)</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfor _ in range(count)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp]
<br><span style="color:red">- &nbsp &nbspreturn K.in_train_phase(dropped_inputs, ones, training=training)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.in_train_phase(dropped_inputs, ones, training=training)</span>
<br>&nbsp
<br>&nbsp
<br>&nbspdef _standardize_args(inputs, initial_state, constants, num_constants):
<br>@@ -3047,22 +3052,23 @@ def _caching_device(rnn_cell):
<br>&nbsp &nbsp &nbsp# prevents forward computations in loop iterations from re-reading the
<br>&nbsp &nbsp &nbsp# updated weights.
<br>&nbsp &nbsp &nbspif control_flow_util.IsInWhileLoop(ops.get_default_graph()):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogging.warn('Variable read device caching has been disabled because the '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'RNN is in tf.while_loop loop context, which will cause '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'reading stalled value in forward path. This could slow down '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the training due to duplicated variable reads. Please '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'consider updating your code to remove tf.while_loop if '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'possible.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging.warning(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Variable read device caching has been disabled because the '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'RNN is in tf.while_loop loop context, which will cause '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'reading stalled value in forward path. This could slow down '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the training due to duplicated variable reads. Please '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'consider updating your code to remove tf.while_loop if possible.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br>&nbsp &nbsp &nbspif (rnn_cell._dtype_policy.compute_dtype !=
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprnn_cell._dtype_policy.variable_dtype):
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsplogging.warn('Variable read device caching has been disabled since it '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'doesn\'t work with the mixed precision API. This is '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'likely to cause a slowdown for RNN training due to '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'duplicated read of variable for each timestep, which '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'will be significant in a multi remote worker setting. '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Please consider disabling mixed precision API if '</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the performance has been affected.')</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsplogging.warning(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Variable read device caching has been disabled since it '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'doesn\'t work with the mixed precision API. This is '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'likely to cause a slowdown for RNN training due to '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'duplicated read of variable for each timestep, which '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'will be significant in a multi remote worker setting. '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Please consider disabling mixed precision API if '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'the performance has been affected.')</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br>&nbsp &nbsp &nbsp# Cache the value on the device that access the variable.
<br>&nbsp &nbsp &nbspreturn lambda op: op.device
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\preprocessing\image.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15564</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>206</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15567</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>207</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15570</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>208</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15573</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>234</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15574</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>234</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>226</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15577</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>236</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15578</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>236</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>226</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15581</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>237</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>202</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15582</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>237</td>
      <td>test_directory_iterator</td>
      <td>156</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>226</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15585</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>289</td>
      <td>directory_iterator_with_validation_split_test_helper</td>
      <td>241</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>279</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15589</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>293</td>
      <td>directory_iterator_with_validation_split_test_helper</td>
      <td>241</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>279</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15593</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>296</td>
      <td>directory_iterator_with_validation_split_test_helper</td>
      <td>241</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>279</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15596</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>297</td>
      <td>directory_iterator_with_validation_split_test_helper</td>
      <td>241</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>279</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15600</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>298</td>
      <td>directory_iterator_with_validation_split_test_helper</td>
      <td>241</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>279</td>
      <td>keras.preprocessing.image.ImageDataGenerator</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15603</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>322</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15606</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>325</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>323</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15607</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>325</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15608</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>330</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15609</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>330</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>328</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15612</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>333</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>323</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15614</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>333</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>331</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15615</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>333</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15616</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>338</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15617</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>338</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>328</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15618</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>338</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>337</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15621</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>340</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>323</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15623</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>340</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>331</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15625</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>340</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>339</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15626</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>340</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15627</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>344</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15628</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>344</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>328</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15629</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>344</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>337</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15630</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>344</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>343</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15633</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>346</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>323</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15635</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>346</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>331</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15637</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>346</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>339</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15639</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>346</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>345</td>
      <td>keras.preprocessing.image.img_to_array</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
    <tr>
      <th>15640</th>
      <td>keras\preprocessing\image_test.py</td>
      <td>346</td>
      <td>test_img_utils</td>
      <td>312</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>320</td>
      <td>keras.preprocessing.image.array_to_img</td>
      <td>tensorflow\python\keras\preprocessing\image.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: a0fd51fc9f1c7c69622e34ab1caa5dee1bc460eb

 <br>Commit message: Updating example code for completeness.<br><br>PiperOrigin-RevId: 378685522<br>Change-Id: I61a787494f1fa6f92647a40396a643dfebec27df<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/preprocessing/image.py b/tensorflow/python/keras/preprocessing/image.py
<br>index feff5d783bc..6c875e1c480 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/preprocessing/image.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/preprocessing/image.py</span>
<br>@@ -15,11 +15,7 @@
<br>&nbsp# pylint: disable=invalid-name
<br>&nbsp# pylint: disable=g-import-not-at-top
<br>&nbsp# pylint: disable=g-classes-have-attributes
<br><span style="color:red">- """Set of tools for real-time data augmentation on image data.</span>
<br><span style="color:red">- """</span>
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br><span style="color:green">+"""Set of tools for real-time data augmentation on image data."""</span>
<br>&nbsp
<br>&nbspfrom keras_preprocessing import image
<br>&nbspimport numpy as np
<br>@@ -96,8 +92,9 @@ def smart_resize(x, size, interpolation='bilinear'):
<br>&nbsp &nbsp &nbspwe resize the `(340, 340)` crop to `(200, 200)`.
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspx: Input image (as a tensor or NumPy array). Must be in format</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(height, width, channels)`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx: Input image or batch of images (as a tensor or NumPy array).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspMust be in format `(height, width, channels)` or</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`(batch_size, height, width, channels)`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspsize: Tuple of `(height, width)` integer. Target size.
<br>&nbsp &nbsp &nbsp &nbsp &nbspinterpolation: String, interpolation to use for resizing.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDefaults to `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`,
<br>@@ -113,12 +110,17 @@ def smart_resize(x, size, interpolation='bilinear'):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'but got: %s' % (size,))
<br>&nbsp &nbsp &nbspimg = ops.convert_to_tensor_v2_with_dispatch(x)
<br>&nbsp &nbsp &nbspif img.shape.rank is not None:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspif img.shape.rank != 3:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif img.shape.rank < 3 or img.shape.rank > 4:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspraise ValueError(
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Expected an image array with shape `(height, width, channels)`, but '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Expected an image array with shape `(height, width, channels)`, '</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'or `(batch_size, height, width, channels)` but '</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'got input with incorrect rank, of shape %s' % (img.shape,))
<br>&nbsp &nbsp &nbspshape = array_ops.shape(img)
<br><span style="color:red">- &nbsp &nbspheight, width = shape[0], shape[1]</span>
<br><span style="color:green">+&nbsp &nbspif img.shape.rank == 4:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspheight, width = shape[1], shape[2]</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspstatic_num_channels = img.shape[-1]</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspheight, width = shape[0], shape[1]</span>
<br>&nbsp &nbsp &nbsptarget_height, target_width = size
<br>&nbsp
<br>&nbsp &nbsp &nbspcrop_height = math_ops.cast(
<br>@@ -135,20 +137,28 @@ def smart_resize(x, size, interpolation='bilinear'):
<br>&nbsp &nbsp &nbspcrop_box_wstart = math_ops.cast(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmath_ops.cast(width - crop_width, 'float32') / 2, 'int32')
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspcrop_box_start = array_ops.stack([crop_box_hstart, crop_box_wstart, 0])</span>
<br><span style="color:red">- &nbsp &nbspcrop_box_size = array_ops.stack([crop_height, crop_width, -1])</span>
<br><span style="color:green">+&nbsp &nbspif img.shape.rank == 4:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcrop_box_start = array_ops.stack([0, crop_box_hstart, crop_box_wstart, 0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcrop_box_size = array_ops.stack([-1, crop_height, crop_width, -1])</span>
<br><span style="color:green">+&nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcrop_box_start = array_ops.stack([crop_box_hstart, crop_box_wstart, 0])</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspcrop_box_size = array_ops.stack([crop_height, crop_width, -1])</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspimg = array_ops.slice(img, crop_box_start, crop_box_size)
<br>&nbsp &nbsp &nbspimg = image_ops.resize_images_v2(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimages=img,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsize=size,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmethod=interpolation)
<br><span style="color:green">+&nbsp &nbspif img.shape.rank == 4:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp# Apparent bug in resize_images_v2 may cause shape to be lost</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspimg.set_shape((None, None, None, static_num_channels))</span>
<br>&nbsp &nbsp &nbspif isinstance(x, np.ndarray):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn img.numpy()
<br>&nbsp &nbsp &nbspreturn img
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- @keras_export('keras.preprocessing.image.array_to_img')</span>
<br><span style="color:green">+@keras_export('keras.utils.array_to_img',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras.preprocessing.image.array_to_img')</span>
<br>&nbspdef array_to_img(x, data_format=None, scale=True, dtype=None):
<br>&nbsp &nbsp &nbsp"""Converts a 3D Numpy array to a PIL Image instance.
<br>&nbsp
<br>@@ -162,13 +172,13 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):
<br>&nbsp
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input Numpy array.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input data, in any form that can be converted to a Numpy array.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format: Image data format, can be either "channels_first" or
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"channels_last". Defaults to `None`, in which case the global setting
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.backend.image_data_format()` is used (unless you changed it,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspit defaults to "channels_last").
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale: Whether to rescale image values to be within `[0, 255]`. Defaults</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto `True`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale: Whether to rescale the image such that minimum and maximum values</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare 0 and 255 respectively. Defaults to `True`.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype: Dtype to use. Default to `None`, in which case the global setting
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`tf.keras.backend.floatx()` is used (unless you changed it, it defaults
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspto "float32")
<br>@@ -191,7 +201,8 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):
<br>&nbsp &nbsp &nbspreturn image.array_to_img(x, data_format=data_format, scale=scale, **kwargs)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- @keras_export('keras.preprocessing.image.img_to_array')</span>
<br><span style="color:green">+@keras_export('keras.utils.img_to_array',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras.preprocessing.image.img_to_array')</span>
<br>&nbspdef img_to_array(img, data_format=None, dtype=None):
<br>&nbsp &nbsp &nbsp"""Converts a PIL Image instance to a Numpy array.
<br>&nbsp
<br>@@ -232,7 +243,8 @@ def img_to_array(img, data_format=None, dtype=None):
<br>&nbsp &nbsp &nbspreturn image.img_to_array(img, data_format=data_format, **kwargs)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- @keras_export('keras.preprocessing.image.save_img')</span>
<br><span style="color:green">+@keras_export('keras.utils.save_img',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras.preprocessing.image.save_img')</span>
<br>&nbspdef save_img(path,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata_format=None,
<br>@@ -262,6 +274,8 @@ def save_img(path,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspscale=scale, **kwargs)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+@keras_export('keras.utils.load_img',</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'keras.preprocessing.image.load_img')</span>
<br>&nbspdef load_img(path, grayscale=False, color_mode='rgb', target_size=None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspinterpolation='nearest'):
<br>&nbsp &nbsp &nbsp"""Loads an image into PIL format.
<br>@@ -270,7 +284,7 @@ def load_img(path, grayscale=False, color_mode='rgb', target_size=None,
<br>&nbsp
<br>&nbsp &nbsp &nbsp```
<br>&nbsp &nbsp &nbspimage = tf.keras.preprocessing.image.load_img(image_path)
<br><span style="color:red">- &nbsp &nbspinput_arr = keras.preprocessing.image.img_to_array(image)</span>
<br><span style="color:green">+&nbsp &nbspinput_arr = tf.keras.preprocessing.image.img_to_array(image)</span>
<br>&nbsp &nbsp &nbspinput_arr = np.array([input_arr])  # Convert single image to a batch.
<br>&nbsp &nbsp &nbsppredictions = model.predict(input_arr)
<br>&nbsp &nbsp &nbsp```
<br>@@ -306,7 +320,7 @@ class Iterator(image.Iterator, data_utils.Sequence):
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.preprocessing.image.DirectoryIterator')
<br><span style="color:red">- class DirectoryIterator(image.DirectoryIterator, Iterator):</span>
<br><span style="color:green">+class DirectoryIterator(image.DirectoryIterator, Iterator):  # pylint: disable=inconsistent-mro</span>
<br>&nbsp &nbsp &nbsp"""Iterator capable of reading images from a directory on disk.
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br>@@ -324,12 +338,12 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcontaining images from each class (e.g. `["dogs", "cats"]`).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIt will be computed automatically if not set.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_mode: Mode for yielding the targets:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"binary"`: binary targets (if there are only two classes),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"categorical"`: categorical targets,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"sparse"`: integer targets,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"input"`: targets are images identical to input images (mainly</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"binary"`: binary targets (if there are only two classes),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"categorical"`: categorical targets,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"sparse"`: integer targets,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"input"`: targets are images identical to input images (mainly</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspused to work with autoencoders),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`None`: no targets get yielded (only input images are yielded).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `None`: no targets get yielded (only input images are yielded).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Integer, size of a batch.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Boolean, whether to shuffle the data between epochs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed: Random seed for data shuffling.
<br>@@ -460,21 +474,23 @@ class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp**kwargs)
<br>&nbsp
<br>&nbsp
<br><span style="color:red">- class DataFrameIterator(image.DataFrameIterator, Iterator):</span>
<br><span style="color:green">+class DataFrameIterator(image.DataFrameIterator, Iterator):  # pylint: disable=inconsistent-mro</span>
<br>&nbsp &nbsp &nbsp"""Iterator capable of reading images from a directory on disk as a dataframe.
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataframe: Pandas dataframe containing the filepaths relative to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`directory` (or absolute paths if `directory` is None) of the images in
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa string column. It should include other column/s</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepending on the `class_mode`: - if `class_mode` is `"categorical"`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default value) it must include the `y_col` column with the class/es</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof each image. Values in column can be string/list/tuple if a single</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass or list/tuple if multiple classes. - if `class_mode` is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"binary"` or `"sparse"` it must include the given `y_col` column</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith class values as strings. - if `class_mode` is `"raw"` or</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"multi_output"` it should contain the columns specified in `y_col`.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"input"` or `None` no extra column is needed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspa string column. It should include other column/s depending on the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`class_mode`:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"categorical"` (default value) it must include</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `y_col` column with the class/es of each image. Values in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcolumn can be string/list/tuple if a single class or list/tuple if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple classes.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"binary"` or `"sparse"` it must include the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgiven `y_col` column with class values as strings.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"raw"` or `"multi_output"` it should contain the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcolumns specified in `y_col`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"input"` or `None` no extra column is needed.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdirectory: string, path to the directory to read images from. If `None`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata in `x_col` column should be absolute paths.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspimage_data_generator: Instance of `ImageDataGenerator` to use for random
<br>@@ -491,8 +507,8 @@ class DataFrameIterator(image.DataFrameIterator, Iterator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclasses: Optional list of strings, classes to use (e.g. `["dogs",
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"cats"]`). If None, all classes in `y_col` will be used.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_mode: one of "binary", "categorical", "input", "multi_output",
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"raw", "sparse" or None. Default: "categorical".</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMode for yielding the targets:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"raw", "sparse" or None. Default: "categorical".</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspMode for yielding the targets:</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"binary"`: 1D numpy array of binary labels,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"categorical"`: 2D numpy array of one-hot encoded labels. Supports
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmulti-label output.
<br>@@ -500,9 +516,9 @@ class DataFrameIterator(image.DataFrameIterator, Iterator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith autoencoders),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"multi_output"`: list with the values of the different columns,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"raw"`: numpy array of values in `y_col` column(s),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"sparse"`: 1D numpy array of integer labels, - `None`, no targets</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare returned (the generator will only yield batches of image data,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich is useful to use in `model.predict()`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"sparse"`: 1D numpy array of integer labels,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `None`, no targets are returned (the generator will only yield</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches of image data, which is useful to use in `model.predict()`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Integer, size of a batch.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Boolean, whether to shuffle the data between epochs.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed: Random seed for data shuffling.
<br>@@ -655,6 +671,12 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(strictly between 0 and 1).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdtype: Dtype to use for the generated arrays.
<br>&nbsp
<br><span style="color:green">+&nbsp &nbspRaises:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValueError: If the value of the argument, `data_format` is other than</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"channels_last"` or `"channels_first"`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspValueError: If the value of the argument, `validation_split` > 1</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspor `validation_split` < 0.</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspExamples:
<br>&nbsp
<br>&nbsp &nbsp &nbspExample of using `.flow(x, y)`:
<br>@@ -669,13 +691,17 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprotation_range=20,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwidth_shift_range=0.2,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspheight_shift_range=0.2,
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsphorizontal_flip=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsphorizontal_flip=True,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_split=0.2)</span>
<br>&nbsp &nbsp &nbsp# compute quantities required for featurewise normalization
<br>&nbsp &nbsp &nbsp# (std, mean, and principal components if ZCA whitening is applied)
<br>&nbsp &nbsp &nbspdatagen.fit(x_train)
<br>&nbsp &nbsp &nbsp# fits the model on batches with real-time data augmentation:
<br><span style="color:red">- &nbsp &nbspmodel.fit(datagen.flow(x_train, y_train, batch_size=32),</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=len(x_train) / 32, epochs=epochs)</span>
<br><span style="color:green">+&nbsp &nbspmodel.fit(datagen.flow(x_train, y_train, batch_size=32,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubset='training'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspvalidation_data=datagen.flow(x_train, y_train,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size=8, subset='validation'),</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsteps_per_epoch=len(x_train) / 32, epochs=epochs)</span>
<br>&nbsp &nbsp &nbsp# here's a more "manual" example
<br>&nbsp &nbsp &nbspfor e in range(epochs):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspprint('Epoch', e)
<br>@@ -835,7 +861,8 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerated (useful for visualizing what you are doing).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_prefix: Str (default: `''`). Prefix to use for filenames of saved
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsppictures (only relevant if `save_to_dir` is set).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: one of "png", "jpeg"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: one of "png", "jpeg", "bmp", "pdf", "ppm", "gif",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"tif", "jpg"</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(only relevant if `save_to_dir` is set). Default: "png".
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubset: Subset of data (`"training"` or `"validation"`) if
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_split` is set in `ImageDataGenerator`.
<br>@@ -849,6 +876,10 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof corresponding labels. If 'sample_weight' is not None,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe yielded tuples are of the form `(x, y, sample_weight)`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspIf `y` is None, only the numpy array `x` is returned.
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspRaises:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: If the Value of the argument, `subset` is other than</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"training" or "validation".</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn NumpyArrayIterator(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx,
<br>@@ -902,15 +933,17 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspindices can be obtained via the attribute `class_indices`.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_mode: One of "categorical", "binary", "sparse",
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"input", or None. Default: "categorical".
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDetermines the type of label arrays that are returned: -</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"categorical" will be 2D one-hot encoded labels, - "binary" will</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbe 1D binary labels, "sparse" will be 1D integer labels, - "input"</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill be images identical to input images (mainly used to work with</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspautoencoders). - If None, no labels are returned (the generator</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwill only yield batches of image data, which is useful to use with</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`model.predict()`). Please note that in case of</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_mode None, the data still needs to reside in a subdirectory</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspof `directory` for it to work correctly.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDetermines the type of label arrays that are returned:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "categorical" will be 2D one-hot encoded labels,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "binary" will be 1D binary labels,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "sparse" will be 1D integer labels,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- "input"  will be images identical to input images (mainly used to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwork with autoencoders).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- If None, no labels are returned (the generator will only yield</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches of image data, which is useful to use with</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`model.predict()`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspPlease note that in case of class_mode None, the data still needs to</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspreside in a subdirectory of `directory` for it to work correctly.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Size of the batches of data (default: 32).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: Whether to shuffle the data (default: True) If set to False,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsorts the data in alphanumeric order.
<br>@@ -920,7 +953,8 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerated (useful for visualizing what you are doing).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_prefix: Str. Prefix to use for filenames of saved pictures (only
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprelevant if `save_to_dir` is set).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: One of "png", "jpeg"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: one of "png", "jpeg", "bmp", "pdf", "ppm", "gif",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"tif", "jpg"</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(only relevant if `save_to_dir` is set). Default: "png".
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspfollow_links: Whether to follow symlinks inside
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass subdirectories (default: False).
<br>@@ -988,15 +1022,16 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdataframe: Pandas dataframe containing the filepaths relative to
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`directory` (or absolute paths if `directory` is None) of the images
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspin a string column. It should include other column/s
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepending on the `class_mode`: - if `class_mode` is `"categorical"`</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(default value) it must include the `y_col` column with the</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass/es of each image. Values in column can be string/list/tuple</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspif a single class or list/tuple if multiple classes. - if</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`class_mode` is `"binary"` or `"sparse"` it must include the given</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`y_col` column with class values as strings. - if `class_mode` is</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`"raw"` or `"multi_output"` it should contain the columns</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspspecified in `y_col`. - if `class_mode` is `"input"` or `None` no</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspextra column is needed.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdepending on the `class_mode`:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"categorical"` (default value) it must include</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe `y_col` column with the class/es of each image. Values in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspcolumn can be string/list/tuple if a single class or list/tuple if</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspmultiple classes.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"binary"` or `"sparse"` it must include the</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgiven `y_col` column with class values as strings.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"raw"` or `"multi_output"` it should contain</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspthe columns specified in `y_col`.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- if `class_mode` is `"input"` or `None` no extra column is needed.</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdirectory: string, path to the directory to read images from. If `None`,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspdata in `x_col` column should be absolute paths.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx_col: string, column in `dataframe` that contains the filenames (or
<br>@@ -1024,9 +1059,10 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwith autoencoders),
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"multi_output"`: list with the values of the different columns,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"raw"`: numpy array of values in `y_col` column(s),
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"sparse"`: 1D numpy array of integer labels, - `None`, no targets</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspare returned (the generator will only yield batches of image data,</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspwhich is useful to use in `model.predict()`).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `"sparse"`: 1D numpy array of integer labels,</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `None`, no targets are returned (the generator will only yield</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatches of image data, which is useful to use in</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`model.predict()`).</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: size of the batches of data (default: 32).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspshuffle: whether to shuffle the data (default: True)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspseed: optional random seed for shuffling and transformations.
<br>@@ -1035,7 +1071,8 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspgenerated (useful for visualizing what you are doing).
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_prefix: str. Prefix to use for filenames of saved pictures (only
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsprelevant if `save_to_dir` is set).
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: one of "png", "jpeg"</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsave_format: one of "png", "jpeg", "bmp", "pdf", "ppm", "gif",</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp"tif", "jpg"</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(only relevant if `save_to_dir` is set). Default: "png".
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspsubset: Subset of data (`"training"` or `"validation"`) if
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp`validation_split` is set in `ImageDataGenerator`.
<br>@@ -1058,21 +1095,21 @@ class ImageDataGenerator(image.ImageDataGenerator):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand `y` is a numpy array of corresponding labels.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbsp &nbsp &nbspif 'has_ext' in kwargs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warning(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'has_ext is deprecated, filenames in the dataframe have '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'to match the exact filenames in disk.', DeprecationWarning)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif 'sort' in kwargs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warning(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'sort is deprecated, batches will be created in the'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'same order than the filenames provided if shuffle'
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'is set to False.', DeprecationWarning)
<br>&nbsp &nbsp &nbsp &nbsp &nbspif class_mode == 'other':
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warning(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`class_mode` "other" is deprecated, please use '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'`class_mode` "raw".', DeprecationWarning)
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspclass_mode = 'raw'
<br>&nbsp &nbsp &nbsp &nbsp &nbspif 'drop_duplicates' in kwargs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warn(</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsptf_logging.warning(</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'drop_duplicates is deprecated, you can drop duplicates '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'by using the pandas.DataFrame.drop_duplicates method.',
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspDeprecationWarning)
<br>@@ -1113,4 +1150,3 @@ keras_export(
<br>&nbspkeras_export('keras.preprocessing.image.random_brightness')(random_brightness)
<br>&nbspkeras_export(
<br>&nbsp &nbsp &nbsp &nbsp &nbsp'keras.preprocessing.image.apply_affine_transform')(apply_affine_transform)
<br><span style="color:red">- keras_export('keras.preprocessing.image.load_img')(load_img)</span>
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\preprocessing\sequence.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15672</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>106</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>104</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15675</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>118</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>104</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15676</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>118</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>116</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15679</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>137</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>104</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15680</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>137</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>116</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15681</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>137</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>124</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15682</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>137</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>135</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15685</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>151</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>104</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15686</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>151</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>116</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15687</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>151</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>124</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15688</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>151</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>135</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15689</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>151</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>143</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15692</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>104</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15693</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>116</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15694</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>124</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15695</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>135</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15696</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>143</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15697</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>168</td>
      <td>test_TimeseriesGenerator</td>
      <td>100</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>159</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
    <tr>
      <th>15703</th>
      <td>keras\preprocessing\sequence_test.py</td>
      <td>188</td>
      <td>test_TimeSeriesGenerator_doesnt_miss_any_sample</td>
      <td>180</td>
      <td>assertEqual</td>
      <td>2</td>
      <td>184</td>
      <td>keras.preprocessing.sequence.TimeseriesGenerator</td>
      <td>tensorflow\python\keras\preprocessing\sequence.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 63abb4d5e5d3b511dbfff6c30d2f267419d5ab41

 <br>Commit message: Update sequence.py<br><br>Updated broken link for tf.keras.utils.Sequence<br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/preprocessing/sequence.py b/tensorflow/python/keras/preprocessing/sequence.py
<br>index 2e531e6b56b..51a4110f774 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/preprocessing/sequence.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/preprocessing/sequence.py</span>
<br>@@ -12,12 +12,8 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Utilities for preprocessing sequence data.</span>
<br><span style="color:red">- """</span>
<br><span style="color:green">+"""Utilities for preprocessing sequence data."""</span>
<br>&nbsp# pylint: disable=invalid-name
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br>&nbsp
<br>&nbspfrom keras_preprocessing import sequence
<br>&nbsp
<br>@@ -66,7 +62,7 @@ class TimeseriesGenerator(sequence.TimeseriesGenerator, data_utils.Sequence):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspbatch_size: Number of timeseries samples in each batch
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(except maybe the last one).
<br>&nbsp &nbsp &nbsp# Returns
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspA [Sequence](/utils/#sequence) instance.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspA [Sequence](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) instance.</span>
<br>&nbsp &nbsp &nbsp# Examples
<br>&nbsp &nbsp &nbsp```python
<br>&nbsp &nbsp &nbspfrom keras.preprocessing.sequence import TimeseriesGenerator
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\activations.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15794</th>
      <td>keras\utils\generic_utils_test.py</td>
      <td>69</td>
      <td>test_custom_object_scope</td>
      <td>58</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>68</td>
      <td>keras.activations.get</td>
      <td>tensorflow\python\keras\activations.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 2c3575146b32f90a3038e0873d1a58e3867d4494

 <br>Commit message: Fix keras docstring format and typo for activations.py<br><br>PiperOrigin-RevId: 372976744<br>Change-Id: I8e854d954ad808afe7e9fb8e7831ea8f8cbea039<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/activations.py b/tensorflow/python/keras/activations.py
<br>index 5b33d96df0a..9afb77323d9 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/activations.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/activations.py</span>
<br>@@ -13,20 +13,15 @@
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br>&nbsp"""Built-in activation functions."""
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br>&nbsp
<br><span style="color:red">- import six</span>
<br><span style="color:red">- </span>
<br><span style="color:red">- from tensorflow.python.keras import backend as K</span>
<br><span style="color:green">+from tensorflow.python.keras import backend</span>
<br><span style="color:green">+from tensorflow.python.keras.layers import advanced_activations</span>
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import deserialize_keras_object
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import serialize_keras_object
<br>&nbspfrom tensorflow.python.ops import math_ops
<br>&nbspfrom tensorflow.python.ops import nn
<br>&nbspfrom tensorflow.python.util import dispatch
<br>&nbspfrom tensorflow.python.util.tf_export import keras_export
<br><span style="color:red">- from tensorflow.python.keras.layers import advanced_activations</span>
<br>&nbsp
<br>&nbsp# b/123041942
<br>&nbsp# In TF 2.x, if the `tf.nn.softmax` is used as an activation function in Keras
<br>@@ -34,7 +29,6 @@ from tensorflow.python.keras.layers import advanced_activations
<br>&nbsp# internal method name is returned in serialization. This results in errors in
<br>&nbsp# model exporting and loading as Keras can't find any activation function with
<br>&nbsp# the name of `softmax_v2`.
<br><span style="color:red">- </span>
<br>&nbsp# This dict maps the activation function name from its v2 version to its
<br>&nbsp# canonical name.
<br>&nbsp_TF_ACTIVATIONS_V2 = {
<br>@@ -45,7 +39,7 @@ _TF_ACTIVATIONS_V2 = {
<br>&nbsp@keras_export('keras.activations.softmax')
<br>&nbsp@dispatch.add_dispatch_support
<br>&nbspdef softmax(x, axis=-1):
<br><span style="color:red">- &nbsp &nbsp"""Softmax converts a real vector to a vector of categorical probabilities.</span>
<br><span style="color:green">+&nbsp &nbsp"""Softmax converts a vector of values to a probability distribution.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspThe elements of the output vector are in range (0, 1) and sum to 1.
<br>&nbsp
<br>@@ -62,23 +56,34 @@ def softmax(x, axis=-1):
<br>&nbsp &nbsp &nbspThe input values in are the log-odds of the resulting probability.
<br>&nbsp
<br>&nbsp &nbsp &nbspArgs:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx : Input tensor.</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspaxis: Integer, axis along which the softmax normalization is applied.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspx : Input tensor.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspaxis: Integer, axis along which the softmax normalization is applied.</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensor, output of softmax transformation (all values are non-negative</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspand sum to 1).</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspTensor, output of softmax transformation (all values are non-negative</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspand sum to 1).</span>
<br>&nbsp
<br><span style="color:red">- &nbsp &nbspRaises:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsp &nbsp &nbspValueError: In case `dim(x) == 1`.</span>
<br><span style="color:green">+&nbsp &nbspExamples:</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp**Example 1: standalone usage**</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> inputs = tf.random.normal(shape=(32, 10))</span>
<br><span style="color:green">+&nbsp &nbsp>>> outputs = tf.keras.activations.softmax(inputs)</span>
<br><span style="color:green">+&nbsp &nbsp>>> tf.reduce_sum(outputs[0, :])  # Each sample in the batch now sums to 1</span>
<br><span style="color:green">+&nbsp &nbsp<tf.Tensor: shape=(), dtype=float32, numpy=1.0000001></span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp**Example 2: usage in a `Dense` layer**</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+&nbsp &nbsp>>> layer = tf.keras.layers.Dense(32, activation=tf.keras.activations.softmax)</span>
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbsprank = x.shape.rank</span>
<br><span style="color:red">- &nbsp &nbspif rank == 2:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput = nn.softmax(x)</span>
<br><span style="color:red">- &nbsp &nbspelif rank > 2:</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspe = math_ops.exp(x - math_ops.reduce_max(x, axis=axis, keepdims=True))</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbsps = math_ops.reduce_sum(e, axis=axis, keepdims=True)</span>
<br><span style="color:red">- &nbsp &nbsp &nbsp &nbspoutput = e / s</span>
<br><span style="color:green">+&nbsp &nbspif x.shape.rank > 1:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspif isinstance(axis, int):</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = nn.softmax(x, axis=axis)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbspelse:</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp# nn.softmax does not support tuple axis.</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspe = math_ops.exp(x - math_ops.reduce_max(x, axis=axis, keepdims=True))</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbsps = math_ops.reduce_sum(e, axis=axis, keepdims=True)</span>
<br><span style="color:green">+&nbsp &nbsp &nbsp &nbsp &nbsp &nbspoutput = e / s</span>
<br>&nbsp &nbsp &nbspelse:
<br>&nbsp &nbsp &nbsp &nbsp &nbspraise ValueError('Cannot apply softmax to a tensor that is 1D. '
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp'Received input: %s' % (x,))
<br>@@ -135,7 +140,7 @@ def elu(x, alpha=1.0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp[Fast and Accurate Deep Network Learning by Exponential Linear Units
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp(ELUs) (Clevert et al, 2016)](https://arxiv.org/abs/1511.07289)
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspreturn K.elu(x, alpha)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.elu(x, alpha)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.activations.selu')
<br>@@ -196,31 +201,31 @@ def selu(x):
<br>&nbsp@dispatch.add_dispatch_support
<br>&nbspdef softplus(x):
<br>&nbsp &nbsp &nbsp"""Softplus activation function, `softplus(x) = log(exp(x) + 1)`.
<br><span style="color:red">- &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspExample Usage:
<br><span style="color:red">- &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp>>> a = tf.constant([-20, -1.0, 0.0, 1.0, 20], dtype = tf.float32)
<br><span style="color:red">- &nbsp &nbsp>>> b = tf.keras.activations.softplus(a) </span>
<br><span style="color:green">+&nbsp &nbsp>>> b = tf.keras.activations.softplus(a)</span>
<br>&nbsp &nbsp &nbsp>>> b.numpy()
<br>&nbsp &nbsp &nbsparray([2.0611537e-09, 3.1326166e-01, 6.9314718e-01, 1.3132616e+00,
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp2.0000000e+01], dtype=float32)
<br><span style="color:red">- &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspArgs:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspx: Input tensor.
<br>&nbsp
<br>&nbsp &nbsp &nbspReturns:
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspThe softplus activation: `log(exp(x) + 1)`.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspreturn nn.softplus(x)</span>
<br><span style="color:green">+&nbsp &nbspreturn math_ops.softplus(x)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.activations.softsign')
<br>&nbsp@dispatch.add_dispatch_support
<br>&nbspdef softsign(x):
<br>&nbsp &nbsp &nbsp"""Softsign activation function, `softsign(x) = x / (abs(x) + 1)`.
<br><span style="color:red">- &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbspExample Usage:
<br><span style="color:red">- &nbsp &nbsp</span>
<br><span style="color:green">+</span>
<br>&nbsp &nbsp &nbsp>>> a = tf.constant([-1.0, 0.0, 1.0], dtype = tf.float32)
<br>&nbsp &nbsp &nbsp>>> b = tf.keras.activations.softsign(a)
<br>&nbsp &nbsp &nbsp>>> b.numpy()
<br>@@ -304,7 +309,7 @@ def relu(x, alpha=0., max_value=None, threshold=0):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsptransformed by the relu activation function.
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbspTensor will be of the same shape and dtype of input `x`.
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspreturn K.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.activations.gelu', v1=[])
<br>@@ -429,6 +434,8 @@ def hard_sigmoid(x):
<br>&nbsp &nbsp &nbsp"""Hard sigmoid activation function.
<br>&nbsp
<br>&nbsp &nbsp &nbspA faster approximation of the sigmoid activation.
<br><span style="color:green">+&nbsp &nbspPiecewise linear approximation of the sigmoid function.</span>
<br><span style="color:green">+&nbsp &nbspRef: 'https://en.wikipedia.org/wiki/Hard_sigmoid'</span>
<br>&nbsp
<br>&nbsp &nbsp &nbspFor example:
<br>&nbsp
<br>@@ -447,7 +454,7 @@ def hard_sigmoid(x):
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `if x > 2.5: return 1`
<br>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp- `if -2.5 <= x <= 2.5: return 0.2 * x + 0.5`
<br>&nbsp &nbsp &nbsp"""
<br><span style="color:red">- &nbsp &nbspreturn K.hard_sigmoid(x)</span>
<br><span style="color:green">+&nbsp &nbspreturn backend.hard_sigmoid(x)</span>
<br>&nbsp
<br>&nbsp
<br>&nbsp@keras_export('keras.activations.linear')
<br>@@ -502,6 +509,14 @@ def serialize(activation):
<br>&nbsp &nbsp &nbspreturn serialize_keras_object(activation)
<br>&nbsp
<br>&nbsp
<br><span style="color:green">+# Add additional globals so that deserialize can find these common activation</span>
<br><span style="color:green">+# functions</span>
<br><span style="color:green">+leaky_relu = nn.leaky_relu</span>
<br><span style="color:green">+log_softmax = nn.log_softmax</span>
<br><span style="color:green">+relu6 = nn.relu6</span>
<br><span style="color:green">+silu = nn.swish</span>
<br><span style="color:green">+</span>
<br><span style="color:green">+</span>
<br>&nbsp@keras_export('keras.activations.deserialize')
<br>&nbsp@dispatch.add_dispatch_support
<br>&nbspdef deserialize(name, custom_objects=None):
<br>@@ -577,7 +592,7 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp"""
<br>&nbsp &nbsp &nbspif identifier is None:
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn linear
<br><span style="color:red">- &nbsp &nbspif isinstance(identifier, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbspif isinstance(identifier, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspidentifier = str(identifier)
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(identifier)
<br>&nbsp &nbsp &nbspelif isinstance(identifier, dict):
<br></p>
</div>
<br><br><br>_____________________________________tensorflow\python\keras\regularizers.py_________________________________________
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>File_Path</th>
      <th>Line_Number</th>
      <th>Found_in_Function</th>
      <th>Function_Definition_Line_Number</th>
      <th>Assert_Statement_Type</th>
      <th>Oracle_Argument_ Position</th>
      <th>Differential_Function_Line_Number</th>
      <th>Differential_Test_Function</th>
      <th>Extracted_Function_File_Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15795</th>
      <td>keras\utils\generic_utils_test.py</td>
      <td>71</td>
      <td>test_custom_object_scope</td>
      <td>58</td>
      <td>assertEqual</td>
      <td>1</td>
      <td>70</td>
      <td>keras.regularizers.get</td>
      <td>tensorflow\python\keras\regularizers.py</td>
    </tr>
  </tbody>
</table>
 <br>Commit id closest to current version: 17c5b631b967e097f70094d4ebb97b587c1868d7

 <br>Commit message: [*.py,tensorflow/cc/framework/cc_op_gen.cc] Rename "Arguments:" to "Args:"<br><br>
<br>Commit id closest to desired version: 993403945efc9e7a933e9c8bd3ad029c36c6882b

 <br>Commit message: Remove a large amount of PY2 compatibility code.<br><br>PiperOrigin-RevId: 364677165<br>Change-Id: Ic52863fbda9b3f093948b9febbcb00a138d80ade<br><br>
<br><button type="button" class="collapsible">Git Diff</button>
<div class="content">
<p>diff --git a/tensorflow/python/keras/regularizers.py b/tensorflow/python/keras/regularizers.py
<br>index 9243e0a23c8..ac00bd4589a 100644
<br><span style="color:red">- -- a/tensorflow/python/keras/regularizers.py</span>
<br><span style="color:green">+++ b/tensorflow/python/keras/regularizers.py</span>
<br>@@ -12,17 +12,11 @@
<br>&nbsp# See the License for the specific language governing permissions and
<br>&nbsp# limitations under the License.
<br>&nbsp# ==============================================================================
<br><span style="color:red">- """Built-in regularizers.</span>
<br><span style="color:red">- """</span>
<br><span style="color:green">+"""Built-in regularizers."""</span>
<br>&nbsp# pylint: disable=invalid-name
<br><span style="color:red">- from __future__ import absolute_import</span>
<br><span style="color:red">- from __future__ import division</span>
<br><span style="color:red">- from __future__ import print_function</span>
<br>&nbsp
<br>&nbspimport math
<br>&nbsp
<br><span style="color:red">- import six</span>
<br><span style="color:red">- </span>
<br>&nbspfrom tensorflow.python.keras import backend
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import deserialize_keras_object
<br>&nbspfrom tensorflow.python.keras.utils.generic_utils import serialize_keras_object
<br>@@ -375,7 +369,7 @@ def get(identifier):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn None
<br>&nbsp &nbsp &nbspif isinstance(identifier, dict):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(identifier)
<br><span style="color:red">- &nbsp &nbspelif isinstance(identifier, six.string_types):</span>
<br><span style="color:green">+&nbsp &nbspelif isinstance(identifier, str):</span>
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn deserialize(str(identifier))
<br>&nbsp &nbsp &nbspelif callable(identifier):
<br>&nbsp &nbsp &nbsp &nbsp &nbspreturn identifier
<br></p>
</div>
<br><br><br>
<br>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
</body>
</html>